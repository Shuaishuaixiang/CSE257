2021-05-28 23:56:26.655311 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 0 finished
---------------------------------------------------  ---------------
replay_buffer/size                                   2000
trainer/QF1 Loss                                        0.859269
trainer/QF2 Loss                                        0.857957
trainer/Policy Loss                                    -1.37896
trainer/Q1 Predictions Mean                            -0.00107763
trainer/Q1 Predictions Std                              0.000652063
trainer/Q1 Predictions Max                              0.000429391
trainer/Q1 Predictions Min                             -0.00218645
trainer/Q2 Predictions Mean                            -0.000210815
trainer/Q2 Predictions Std                              0.000665921
trainer/Q2 Predictions Max                              0.00126331
trainer/Q2 Predictions Min                             -0.0016474
trainer/Q Targets Mean                                  0.755954
trainer/Q Targets Std                                   0.534951
trainer/Q Targets Max                                   1.67429
trainer/Q Targets Min                                  -1.28457
trainer/Log Pis Mean                                   -1.38022
trainer/Log Pis Std                                     0.289181
trainer/Log Pis Max                                    -0.579982
trainer/Log Pis Min                                    -2.60851
trainer/Policy mu Mean                                  0.000976768
trainer/Policy mu Std                                   0.000575161
trainer/Policy mu Max                                   0.00214173
trainer/Policy mu Min                                   8.66313e-05
trainer/Policy log std Mean                             6.60632e-05
trainer/Policy log std Std                              0.000661669
trainer/Policy log std Max                              0.000923157
trainer/Policy log std Min                             -0.00128984
trainer/Alpha                                           0.997005
trainer/Alpha Loss                                     -0
exploration/num steps total                          1100
exploration/num paths total                            55
exploration/path length Mean                           20
exploration/path length Std                             0
exploration/path length Max                            20
exploration/path length Min                            20
exploration/Rewards Mean                               -0.894558
exploration/Rewards Std                                 0.288095
exploration/Rewards Max                                -0.276107
exploration/Rewards Min                                -1.39334
exploration/Returns Mean                              -17.8912
exploration/Returns Std                                 1.66774
exploration/Returns Max                               -15.1245
exploration/Returns Min                               -20.2107
exploration/Actions Mean                                0.0654491
exploration/Actions Std                                 0.588905
exploration/Actions Max                                 0.981492
exploration/Actions Min                                -0.954686
exploration/Num Paths                                   5
exploration/Average Returns                           -17.8912
exploration/env_infos/final/reward_energy Mean         -0.801525
exploration/env_infos/final/reward_energy Std           0.306136
exploration/env_infos/final/reward_energy Max          -0.194674
exploration/env_infos/final/reward_energy Min          -1.03165
exploration/env_infos/initial/reward_energy Mean       -0.893995
exploration/env_infos/initial/reward_energy Std         0.139184
exploration/env_infos/initial/reward_energy Max        -0.716431
exploration/env_infos/initial/reward_energy Min        -1.11081
exploration/env_infos/reward_energy Mean               -0.790128
exploration/env_infos/reward_energy Std                 0.279076
exploration/env_infos/reward_energy Max                -0.187349
exploration/env_infos/reward_energy Min                -1.25594
exploration/env_infos/final/end_effector_loc Mean       0.431034
exploration/env_infos/final/end_effector_loc Std        0.67482
exploration/env_infos/final/end_effector_loc Max        1
exploration/env_infos/final/end_effector_loc Min       -1
exploration/env_infos/initial/end_effector_loc Mean     0.0223467
exploration/env_infos/initial/end_effector_loc Std      0.0228883
exploration/env_infos/initial/end_effector_loc Max      0.0473303
exploration/env_infos/initial/end_effector_loc Min     -0.0352754
exploration/env_infos/end_effector_loc Mean             0.283594
exploration/env_infos/end_effector_loc Std              0.490879
exploration/env_infos/end_effector_loc Max              1
exploration/env_infos/end_effector_loc Min             -1
exploration/env_infos/final/reward_safety Mean          0
exploration/env_infos/final/reward_safety Std           0
exploration/env_infos/final/reward_safety Max           0
exploration/env_infos/final/reward_safety Min           0
exploration/env_infos/initial/reward_safety Mean        0
exploration/env_infos/initial/reward_safety Std         0
exploration/env_infos/initial/reward_safety Max         0
exploration/env_infos/initial/reward_safety Min         0
exploration/env_infos/reward_safety Mean                0
exploration/env_infos/reward_safety Std                 0
exploration/env_infos/reward_safety Max                 0
exploration/env_infos/reward_safety Min                 0
exploration/env_infos/final/reward_dist Mean            2.85135e-92
exploration/env_infos/final/reward_dist Std             5.57901e-92
exploration/env_infos/final/reward_dist Max             1.40077e-91
exploration/env_infos/final/reward_dist Min             2.11901e-122
exploration/env_infos/initial/reward_dist Mean          0.000645633
exploration/env_infos/initial/reward_dist Std           0.000773254
exploration/env_infos/initial/reward_dist Max           0.00166986
exploration/env_infos/initial/reward_dist Min           9.91688e-07
exploration/env_infos/reward_dist Mean                  4.65643e-05
exploration/env_infos/reward_dist Std                   0.00025734
exploration/env_infos/reward_dist Max                   0.00166986
exploration/env_infos/reward_dist Min                   2.11901e-122
evaluation/num steps total                           1000
evaluation/num paths total                             50
evaluation/path length Mean                            20
evaluation/path length Std                              0
evaluation/path length Max                             20
evaluation/path length Min                             20
evaluation/Rewards Mean                                -0.0724238
evaluation/Rewards Std                                  0.0456905
evaluation/Rewards Max                                  0.0273882
evaluation/Rewards Min                                 -0.145049
evaluation/Returns Mean                                -1.44848
evaluation/Returns Std                                  0.912568
evaluation/Returns Max                                  0.437927
evaluation/Returns Min                                 -2.87246
evaluation/Actions Mean                                 0.000980846
evaluation/Actions Std                                  0.000595694
evaluation/Actions Max                                  0.00203524
evaluation/Actions Min                                  0.000153851
evaluation/Num Paths                                   50
evaluation/Average Returns                             -1.44848
evaluation/env_infos/final/reward_energy Mean          -0.00164662
evaluation/env_infos/final/reward_energy Std            0.000274058
evaluation/env_infos/final/reward_energy Max           -0.0011215
evaluation/env_infos/final/reward_energy Min           -0.00206738
evaluation/env_infos/initial/reward_energy Mean        -0.00155927
evaluation/env_infos/initial/reward_energy Std          0.000240541
evaluation/env_infos/initial/reward_energy Max         -0.00113108
evaluation/env_infos/initial/reward_energy Min         -0.00193048
evaluation/env_infos/reward_energy Mean                -0.00160215
evaluation/env_infos/reward_energy Std                  0.000258701
evaluation/env_infos/reward_energy Max                 -0.0011215
evaluation/env_infos/reward_energy Min                 -0.00206738
evaluation/env_infos/final/end_effector_loc Mean        0.010226
evaluation/env_infos/final/end_effector_loc Std         0.0061497
evaluation/env_infos/final/end_effector_loc Max         0.0203188
evaluation/env_infos/final/end_effector_loc Min         0.00180004
evaluation/env_infos/initial/end_effector_loc Mean      4.80138e-05
evaluation/env_infos/initial/end_effector_loc Std       2.83926e-05
evaluation/env_infos/initial/end_effector_loc Max       9.60617e-05
evaluation/env_infos/initial/end_effector_loc Min       7.69257e-06
evaluation/env_infos/end_effector_loc Mean              0.00373622
evaluation/env_infos/end_effector_loc Std               0.00432289
evaluation/env_infos/end_effector_loc Max               0.0203188
evaluation/env_infos/end_effector_loc Min               7.69257e-06
evaluation/env_infos/final/reward_safety Mean           0
evaluation/env_infos/final/reward_safety Std            0
evaluation/env_infos/final/reward_safety Max            0
evaluation/env_infos/final/reward_safety Min            0
evaluation/env_infos/initial/reward_safety Mean         0
evaluation/env_infos/initial/reward_safety Std          0
evaluation/env_infos/initial/reward_safety Max          0
evaluation/env_infos/initial/reward_safety Min          0
evaluation/env_infos/reward_safety Mean                 0
evaluation/env_infos/reward_safety Std                  0
evaluation/env_infos/reward_safety Max                  0
evaluation/env_infos/reward_safety Min                  0
evaluation/env_infos/final/reward_dist Mean             0.00345347
evaluation/env_infos/final/reward_dist Std              0.00716752
evaluation/env_infos/final/reward_dist Max              0.0294951
evaluation/env_infos/final/reward_dist Min              3.19905e-07
evaluation/env_infos/initial/reward_dist Mean           0.00264807
evaluation/env_infos/initial/reward_dist Std            0.00510559
evaluation/env_infos/initial/reward_dist Max            0.020763
evaluation/env_infos/initial/reward_dist Min            1.16923e-06
evaluation/env_infos/reward_dist Mean                   0.00287612
evaluation/env_infos/reward_dist Std                    0.00567184
evaluation/env_infos/reward_dist Max                    0.0294951
evaluation/env_infos/reward_dist Min                    3.19905e-07
time/data storing (s)                                   4.09208
time/evaluation sampling (s)                            0.768884
time/exploration sampling (s)                           0.0918078
time/logging (s)                                        0.0162739
time/saving (s)                                         0.230391
time/training (s)                                      24.4985
time/epoch (s)                                         29.6979
time/total (s)                                         34.0533
Epoch                                                   0
---------------------------------------------------  ---------------
2021-05-28 23:57:03.449545 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 1 finished
---------------------------------------------------  --------------
replay_buffer/size                                   2000
trainer/QF1 Loss                                        0.026035
trainer/QF2 Loss                                        0.0268043
trainer/Policy Loss                                    -1.37006
trainer/Q1 Predictions Mean                             0.0482457
trainer/Q1 Predictions Std                              0.704357
trainer/Q1 Predictions Max                              1.01414
trainer/Q1 Predictions Min                             -1.85175
trainer/Q2 Predictions Mean                             0.0802346
trainer/Q2 Predictions Std                              0.704233
trainer/Q2 Predictions Max                              0.991488
trainer/Q2 Predictions Min                             -1.8382
trainer/Q Targets Mean                                  0.0887015
trainer/Q Targets Std                                   0.722874
trainer/Q Targets Max                                   1.52801
trainer/Q Targets Min                                  -1.90893
trainer/Log Pis Mean                                   -1.28251
trainer/Log Pis Std                                     0.36437
trainer/Log Pis Max                                    -0.421073
trainer/Log Pis Min                                    -3.42628
trainer/Policy mu Mean                                  0.0277259
trainer/Policy mu Std                                   0.0354877
trainer/Policy mu Max                                   0.117633
trainer/Policy mu Min                                  -0.0542589
trainer/Policy log std Mean                            -0.36727
trainer/Policy log std Std                              0.147315
trainer/Policy log std Max                             -0.156296
trainer/Policy log std Min                             -0.77487
trainer/Alpha                                           0.224278
trainer/Alpha Loss                                     -4.89729
exploration/num steps total                          1200
exploration/num paths total                            60
exploration/path length Mean                           20
exploration/path length Std                             0
exploration/path length Max                            20
exploration/path length Min                            20
exploration/Rewards Mean                               -0.438197
exploration/Rewards Std                                 0.210263
exploration/Rewards Max                                 0.0187872
exploration/Rewards Min                                -1.01809
exploration/Returns Mean                               -8.76394
exploration/Returns Std                                 2.05948
exploration/Returns Max                                -6.47309
exploration/Returns Min                               -12.5987
exploration/Actions Mean                                0.031205
exploration/Actions Std                                 0.428915
exploration/Actions Max                                 0.969157
exploration/Actions Min                                -0.94144
exploration/Num Paths                                   5
exploration/Average Returns                            -8.76394
exploration/env_infos/final/reward_energy Mean         -0.574928
exploration/env_infos/final/reward_energy Std           0.223812
exploration/env_infos/final/reward_energy Max          -0.210315
exploration/env_infos/final/reward_energy Min          -0.86498
exploration/env_infos/initial/reward_energy Mean       -0.498972
exploration/env_infos/initial/reward_energy Std         0.139962
exploration/env_infos/initial/reward_energy Max        -0.248884
exploration/env_infos/initial/reward_energy Min        -0.668055
exploration/env_infos/reward_energy Mean               -0.543829
exploration/env_infos/reward_energy Std                 0.272277
exploration/env_infos/reward_energy Max                -0.0517831
exploration/env_infos/reward_energy Min                -1.27874
exploration/env_infos/final/end_effector_loc Mean       0.187997
exploration/env_infos/final/end_effector_loc Std        0.67506
exploration/env_infos/final/end_effector_loc Max        1
exploration/env_infos/final/end_effector_loc Min       -1
exploration/env_infos/initial/end_effector_loc Mean    -0.00132162
exploration/env_infos/initial/end_effector_loc Std      0.0182745
exploration/env_infos/initial/end_effector_loc Max      0.0232494
exploration/env_infos/initial/end_effector_loc Min     -0.0316174
exploration/env_infos/end_effector_loc Mean             0.0671886
exploration/env_infos/end_effector_loc Std              0.456752
exploration/env_infos/end_effector_loc Max              1
exploration/env_infos/end_effector_loc Min             -1
exploration/env_infos/final/reward_safety Mean          0
exploration/env_infos/final/reward_safety Std           0
exploration/env_infos/final/reward_safety Max           0
exploration/env_infos/final/reward_safety Min           0
exploration/env_infos/initial/reward_safety Mean        0
exploration/env_infos/initial/reward_safety Std         0
exploration/env_infos/initial/reward_safety Max         0
exploration/env_infos/initial/reward_safety Min         0
exploration/env_infos/reward_safety Mean                0
exploration/env_infos/reward_safety Std                 0
exploration/env_infos/reward_safety Max                 0
exploration/env_infos/reward_safety Min                 0
exploration/env_infos/final/reward_dist Mean            2.89852e-39
exploration/env_infos/final/reward_dist Std             5.79703e-39
exploration/env_infos/final/reward_dist Max             1.44926e-38
exploration/env_infos/final/reward_dist Min             3.5249e-116
exploration/env_infos/initial/reward_dist Mean          0.0181947
exploration/env_infos/initial/reward_dist Std           0.0358167
exploration/env_infos/initial/reward_dist Max           0.089824
exploration/env_infos/initial/reward_dist Min           1.12937e-07
exploration/env_infos/reward_dist Mean                  0.00640305
exploration/env_infos/reward_dist Std                   0.0444399
exploration/env_infos/reward_dist Max                   0.422242
exploration/env_infos/reward_dist Min                   3.5249e-116
evaluation/num steps total                           2000
evaluation/num paths total                            100
evaluation/path length Mean                            20
evaluation/path length Std                              0
evaluation/path length Max                             20
evaluation/path length Min                             20
evaluation/Rewards Mean                                -0.124865
evaluation/Rewards Std                                  0.0970685
evaluation/Rewards Max                                  0.126595
evaluation/Rewards Min                                 -0.558996
evaluation/Returns Mean                                -2.49729
evaluation/Returns Std                                  1.22544
evaluation/Returns Max                                  0.503759
evaluation/Returns Min                                 -5.37092
evaluation/Actions Mean                                 0.032128
evaluation/Actions Std                                  0.0332869
evaluation/Actions Max                                  0.0853171
evaluation/Actions Min                                 -0.0608201
evaluation/Num Paths                                   50
evaluation/Average Returns                             -2.49729
evaluation/env_infos/final/reward_energy Mean          -0.0739149
evaluation/env_infos/final/reward_energy Std            0.0221218
evaluation/env_infos/final/reward_energy Max           -0.0266842
evaluation/env_infos/final/reward_energy Min           -0.10017
evaluation/env_infos/initial/reward_energy Mean        -0.0581171
evaluation/env_infos/initial/reward_energy Std          0.0109615
evaluation/env_infos/initial/reward_energy Max         -0.0306527
evaluation/env_infos/initial/reward_energy Min         -0.0810994
evaluation/env_infos/reward_energy Mean                -0.0633745
evaluation/env_infos/reward_energy Std                  0.016252
evaluation/env_infos/reward_energy Max                 -0.0266842
evaluation/env_infos/reward_energy Min                 -0.10017
evaluation/env_infos/final/end_effector_loc Mean        0.292165
evaluation/env_infos/final/end_effector_loc Std         0.343325
evaluation/env_infos/final/end_effector_loc Max         0.667555
evaluation/env_infos/final/end_effector_loc Min        -0.543026
evaluation/env_infos/initial/end_effector_loc Mean      0.00105115
evaluation/env_infos/initial/end_effector_loc Std       0.00180756
evaluation/env_infos/initial/end_effector_loc Max       0.00333023
evaluation/env_infos/initial/end_effector_loc Min      -0.003041
evaluation/env_infos/end_effector_loc Mean              0.0994961
evaluation/env_infos/end_effector_loc Std               0.190325
evaluation/env_infos/end_effector_loc Max               0.667555
evaluation/env_infos/end_effector_loc Min              -0.543026
evaluation/env_infos/final/reward_safety Mean           0
evaluation/env_infos/final/reward_safety Std            0
evaluation/env_infos/final/reward_safety Max            0
evaluation/env_infos/final/reward_safety Min            0
evaluation/env_infos/initial/reward_safety Mean         0
evaluation/env_infos/initial/reward_safety Std          0
evaluation/env_infos/initial/reward_safety Max          0
evaluation/env_infos/initial/reward_safety Min          0
evaluation/env_infos/reward_safety Mean                 0
evaluation/env_infos/reward_safety Std                  0
evaluation/env_infos/reward_safety Max                  0
evaluation/env_infos/reward_safety Min                  0
evaluation/env_infos/final/reward_dist Mean             0.00387522
evaluation/env_infos/final/reward_dist Std              0.0185742
evaluation/env_infos/final/reward_dist Max              0.101568
evaluation/env_infos/final/reward_dist Min              3.88254e-61
evaluation/env_infos/initial/reward_dist Mean           0.00387031
evaluation/env_infos/initial/reward_dist Std            0.00657853
evaluation/env_infos/initial/reward_dist Max            0.0266906
evaluation/env_infos/initial/reward_dist Min            9.35748e-07
evaluation/env_infos/reward_dist Mean                   0.0319299
evaluation/env_infos/reward_dist Std                    0.109082
evaluation/env_infos/reward_dist Max                    0.990716
evaluation/env_infos/reward_dist Min                    3.88254e-61
time/data storing (s)                                   4.64919
time/evaluation sampling (s)                            0.68896
time/exploration sampling (s)                           0.0919638
time/logging (s)                                        0.0317747
time/saving (s)                                         0.16715
time/training (s)                                      31.0801
time/epoch (s)                                         36.7091
time/total (s)                                         70.8612
Epoch                                                   1
---------------------------------------------------  --------------
2021-05-28 23:57:42.989714 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 2 finished
---------------------------------------------------  ---------------
replay_buffer/size                                   2000
trainer/QF1 Loss                                        0.0193356
trainer/QF2 Loss                                        0.0249536
trainer/Policy Loss                                     0.315165
trainer/Q1 Predictions Mean                            -0.725099
trainer/Q1 Predictions Std                              1.08202
trainer/Q1 Predictions Max                              0.782717
trainer/Q1 Predictions Min                             -3.69135
trainer/Q2 Predictions Mean                            -0.680556
trainer/Q2 Predictions Std                              1.04191
trainer/Q2 Predictions Max                              0.744388
trainer/Q2 Predictions Min                             -3.62067
trainer/Q Targets Mean                                 -0.717725
trainer/Q Targets Std                                   1.11128
trainer/Q Targets Max                                   0.782078
trainer/Q Targets Min                                  -3.70515
trainer/Log Pis Mean                                   -0.222026
trainer/Log Pis Std                                     1.03164
trainer/Log Pis Max                                     2.16079
trainer/Log Pis Min                                    -4.85233
trainer/Policy mu Mean                                  0.052517
trainer/Policy mu Std                                   0.18011
trainer/Policy mu Max                                   1.20275
trainer/Policy mu Min                                  -0.945738
trainer/Policy log std Mean                            -1.10772
trainer/Policy log std Std                              0.455095
trainer/Policy log std Max                             -0.18713
trainer/Policy log std Min                             -2.03898
trainer/Alpha                                           0.058396
trainer/Alpha Loss                                     -6.30635
exploration/num steps total                          1300
exploration/num paths total                            65
exploration/path length Mean                           20
exploration/path length Std                             0
exploration/path length Max                            20
exploration/path length Min                            20
exploration/Rewards Mean                               -0.374322
exploration/Rewards Std                                 0.202557
exploration/Rewards Max                                 0.0309397
exploration/Rewards Min                                -0.998069
exploration/Returns Mean                               -7.48644
exploration/Returns Std                                 1.74023
exploration/Returns Max                                -5.00352
exploration/Returns Min                                -9.08586
exploration/Actions Mean                                0.0642283
exploration/Actions Std                                 0.2784
exploration/Actions Max                                 0.974688
exploration/Actions Min                                -0.648232
exploration/Num Paths                                   5
exploration/Average Returns                            -7.48644
exploration/env_infos/final/reward_energy Mean         -0.350079
exploration/env_infos/final/reward_energy Std           0.155456
exploration/env_infos/final/reward_energy Max          -0.151294
exploration/env_infos/final/reward_energy Min          -0.534855
exploration/env_infos/initial/reward_energy Mean       -0.484234
exploration/env_infos/initial/reward_energy Std         0.254706
exploration/env_infos/initial/reward_energy Max        -0.12522
exploration/env_infos/initial/reward_energy Min        -0.89273
exploration/env_infos/reward_energy Mean               -0.342882
exploration/env_infos/reward_energy Std                 0.213764
exploration/env_infos/reward_energy Max                -0.0162647
exploration/env_infos/reward_energy Min                -1.11468
exploration/env_infos/final/end_effector_loc Mean       0.689631
exploration/env_infos/final/end_effector_loc Std        0.417164
exploration/env_infos/final/end_effector_loc Max        1
exploration/env_infos/final/end_effector_loc Min       -0.244552
exploration/env_infos/initial/end_effector_loc Mean    -0.00151083
exploration/env_infos/initial/end_effector_loc Std      0.0192851
exploration/env_infos/initial/end_effector_loc Max      0.0406157
exploration/env_infos/initial/end_effector_loc Min     -0.023912
exploration/env_infos/end_effector_loc Mean             0.319297
exploration/env_infos/end_effector_loc Std              0.351437
exploration/env_infos/end_effector_loc Max              1
exploration/env_infos/end_effector_loc Min             -0.256271
exploration/env_infos/final/reward_safety Mean          0
exploration/env_infos/final/reward_safety Std           0
exploration/env_infos/final/reward_safety Max           0
exploration/env_infos/final/reward_safety Min           0
exploration/env_infos/initial/reward_safety Mean        0
exploration/env_infos/initial/reward_safety Std         0
exploration/env_infos/initial/reward_safety Max         0
exploration/env_infos/initial/reward_safety Min         0
exploration/env_infos/reward_safety Mean                0
exploration/env_infos/reward_safety Std                 0
exploration/env_infos/reward_safety Max                 0
exploration/env_infos/reward_safety Min                 0
exploration/env_infos/final/reward_dist Mean            1.26062e-47
exploration/env_infos/final/reward_dist Std             2.52025e-47
exploration/env_infos/final/reward_dist Max             6.30112e-47
exploration/env_infos/final/reward_dist Min             1.42093e-100
exploration/env_infos/initial/reward_dist Mean          0.00259425
exploration/env_infos/initial/reward_dist Std           0.00294723
exploration/env_infos/initial/reward_dist Max           0.00700648
exploration/env_infos/initial/reward_dist Min           1.79091e-06
exploration/env_infos/reward_dist Mean                  0.0362356
exploration/env_infos/reward_dist Std                   0.144111
exploration/env_infos/reward_dist Max                   0.997699
exploration/env_infos/reward_dist Min                   1.42093e-100
evaluation/num steps total                           3000
evaluation/num paths total                            150
evaluation/path length Mean                            20
evaluation/path length Std                              0
evaluation/path length Max                             20
evaluation/path length Min                             20
evaluation/Rewards Mean                                -0.185845
evaluation/Rewards Std                                  0.196437
evaluation/Rewards Max                                  0.140501
evaluation/Rewards Min                                 -1.16594
evaluation/Returns Mean                                -3.71689
evaluation/Returns Std                                  2.60437
evaluation/Returns Max                                 -0.517778
evaluation/Returns Min                                -11.0514
evaluation/Actions Mean                                 0.0507565
evaluation/Actions Std                                  0.081155
evaluation/Actions Max                                  0.432005
evaluation/Actions Min                                 -0.27244
evaluation/Num Paths                                   50
evaluation/Average Returns                             -3.71689
evaluation/env_infos/final/reward_energy Mean          -0.15031
evaluation/env_infos/final/reward_energy Std            0.0955549
evaluation/env_infos/final/reward_energy Max           -0.0469236
evaluation/env_infos/final/reward_energy Min           -0.510737
evaluation/env_infos/initial/reward_energy Mean        -0.0955699
evaluation/env_infos/initial/reward_energy Std          0.0778575
evaluation/env_infos/initial/reward_energy Max         -0.0113951
evaluation/env_infos/initial/reward_energy Min         -0.432263
evaluation/env_infos/reward_energy Mean                -0.111419
evaluation/env_infos/reward_energy Std                  0.0768805
evaluation/env_infos/reward_energy Max                 -0.001761
evaluation/env_infos/reward_energy Min                 -0.510737
evaluation/env_infos/final/end_effector_loc Mean        0.365471
evaluation/env_infos/final/end_effector_loc Std         0.550579
evaluation/env_infos/final/end_effector_loc Max         1
evaluation/env_infos/final/end_effector_loc Min        -0.966681
evaluation/env_infos/initial/end_effector_loc Mean      0.00175127
evaluation/env_infos/initial/end_effector_loc Std       0.0039909
evaluation/env_infos/initial/end_effector_loc Max       0.0162891
evaluation/env_infos/initial/end_effector_loc Min      -0.00472017
evaluation/env_infos/end_effector_loc Mean              0.155996
evaluation/env_infos/end_effector_loc Std               0.337667
evaluation/env_infos/end_effector_loc Max               1
evaluation/env_infos/end_effector_loc Min              -0.966681
evaluation/env_infos/final/reward_safety Mean           0
evaluation/env_infos/final/reward_safety Std            0
evaluation/env_infos/final/reward_safety Max            0
evaluation/env_infos/final/reward_safety Min            0
evaluation/env_infos/initial/reward_safety Mean         0
evaluation/env_infos/initial/reward_safety Std          0
evaluation/env_infos/initial/reward_safety Max          0
evaluation/env_infos/initial/reward_safety Min          0
evaluation/env_infos/reward_safety Mean                 0
evaluation/env_infos/reward_safety Std                  0
evaluation/env_infos/reward_safety Max                  0
evaluation/env_infos/reward_safety Min                  0
evaluation/env_infos/final/reward_dist Mean             0.00539974
evaluation/env_infos/final/reward_dist Std              0.0352235
evaluation/env_infos/final/reward_dist Max              0.251305
evaluation/env_infos/final/reward_dist Min              5.38732e-166
evaluation/env_infos/initial/reward_dist Mean           0.00259408
evaluation/env_infos/initial/reward_dist Std            0.00546299
evaluation/env_infos/initial/reward_dist Max            0.0239386
evaluation/env_infos/initial/reward_dist Min            1.29314e-06
evaluation/env_infos/reward_dist Mean                   0.04729
evaluation/env_infos/reward_dist Std                    0.148162
evaluation/env_infos/reward_dist Max                    0.976577
evaluation/env_infos/reward_dist Min                    5.38732e-166
time/data storing (s)                                   5.30575
time/evaluation sampling (s)                            1.11889
time/exploration sampling (s)                           0.112722
time/logging (s)                                        0.0161205
time/saving (s)                                         0.129814
time/training (s)                                      32.7881
time/epoch (s)                                         39.4714
time/total (s)                                        110.384
Epoch                                                   2
---------------------------------------------------  ---------------
2021-05-28 23:58:22.386650 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 3 finished
---------------------------------------------------  ---------------
replay_buffer/size                                   2000
trainer/QF1 Loss                                        0.0134018
trainer/QF2 Loss                                        0.0153676
trainer/Policy Loss                                     1.94955
trainer/Q1 Predictions Mean                            -1.22812
trainer/Q1 Predictions Std                              1.27858
trainer/Q1 Predictions Max                              0.682627
trainer/Q1 Predictions Min                             -6.97033
trainer/Q2 Predictions Mean                            -1.18775
trainer/Q2 Predictions Std                              1.28005
trainer/Q2 Predictions Max                              0.672118
trainer/Q2 Predictions Min                             -6.99233
trainer/Q Targets Mean                                 -1.23149
trainer/Q Targets Std                                   1.2679
trainer/Q Targets Max                                   0.636873
trainer/Q Targets Min                                  -6.94718
trainer/Log Pis Mean                                    0.928145
trainer/Log Pis Std                                     1.28332
trainer/Log Pis Max                                     4.22258
trainer/Log Pis Min                                    -3.11752
trainer/Policy mu Mean                                  0.0961209
trainer/Policy mu Std                                   0.385987
trainer/Policy mu Max                                   1.8759
trainer/Policy mu Min                                  -1.4108
trainer/Policy log std Mean                            -1.68783
trainer/Policy log std Std                              0.601376
trainer/Policy log std Max                             -0.47394
trainer/Policy log std Min                             -3.25792
trainer/Alpha                                           0.0220056
trainer/Alpha Loss                                     -4.08902
exploration/num steps total                          1400
exploration/num paths total                            70
exploration/path length Mean                           20
exploration/path length Std                             0
exploration/path length Max                            20
exploration/path length Min                            20
exploration/Rewards Mean                               -0.255247
exploration/Rewards Std                                 0.131199
exploration/Rewards Max                                -0.0448033
exploration/Rewards Min                                -0.632959
exploration/Returns Mean                               -5.10494
exploration/Returns Std                                 1.4608
exploration/Returns Max                                -3.20254
exploration/Returns Min                                -7.03872
exploration/Actions Mean                                0.0199371
exploration/Actions Std                                 0.156753
exploration/Actions Max                                 0.506388
exploration/Actions Min                                -0.514188
exploration/Num Paths                                   5
exploration/Average Returns                            -5.10494
exploration/env_infos/final/reward_energy Mean         -0.277134
exploration/env_infos/final/reward_energy Std           0.0976207
exploration/env_infos/final/reward_energy Max          -0.173097
exploration/env_infos/final/reward_energy Min          -0.441511
exploration/env_infos/initial/reward_energy Mean       -0.202992
exploration/env_infos/initial/reward_energy Std         0.107091
exploration/env_infos/initial/reward_energy Max        -0.0726944
exploration/env_infos/initial/reward_energy Min        -0.391828
exploration/env_infos/reward_energy Mean               -0.194628
exploration/env_infos/reward_energy Std                 0.109808
exploration/env_infos/reward_energy Max                -0.0272874
exploration/env_infos/reward_energy Min                -0.62741
exploration/env_infos/final/end_effector_loc Mean       0.0661933
exploration/env_infos/final/end_effector_loc Std        0.619621
exploration/env_infos/final/end_effector_loc Max        1
exploration/env_infos/final/end_effector_loc Min       -0.629358
exploration/env_infos/initial/end_effector_loc Mean    -0.000869751
exploration/env_infos/initial/end_effector_loc Std      0.00806762
exploration/env_infos/initial/end_effector_loc Max      0.00959816
exploration/env_infos/initial/end_effector_loc Min     -0.017533
exploration/env_infos/end_effector_loc Mean             0.0283475
exploration/env_infos/end_effector_loc Std              0.359053
exploration/env_infos/end_effector_loc Max              1
exploration/env_infos/end_effector_loc Min             -0.629358
exploration/env_infos/final/reward_safety Mean          0
exploration/env_infos/final/reward_safety Std           0
exploration/env_infos/final/reward_safety Max           0
exploration/env_infos/final/reward_safety Min           0
exploration/env_infos/initial/reward_safety Mean        0
exploration/env_infos/initial/reward_safety Std         0
exploration/env_infos/initial/reward_safety Max         0
exploration/env_infos/initial/reward_safety Min         0
exploration/env_infos/reward_safety Mean                0
exploration/env_infos/reward_safety Std                 0
exploration/env_infos/reward_safety Max                 0
exploration/env_infos/reward_safety Min                 0
exploration/env_infos/final/reward_dist Mean            2.42234e-27
exploration/env_infos/final/reward_dist Std             4.84468e-27
exploration/env_infos/final/reward_dist Max             1.21117e-26
exploration/env_infos/final/reward_dist Min             6.4549e-93
exploration/env_infos/initial/reward_dist Mean          0.00737758
exploration/env_infos/initial/reward_dist Std           0.00855149
exploration/env_infos/initial/reward_dist Max           0.023784
exploration/env_infos/initial/reward_dist Min           5.88774e-07
exploration/env_infos/reward_dist Mean                  0.00434982
exploration/env_infos/reward_dist Std                   0.0160022
exploration/env_infos/reward_dist Max                   0.0899081
exploration/env_infos/reward_dist Min                   6.4549e-93
evaluation/num steps total                           4000
evaluation/num paths total                            200
evaluation/path length Mean                            20
evaluation/path length Std                              0
evaluation/path length Max                             20
evaluation/path length Min                             20
evaluation/Rewards Mean                                -0.173563
evaluation/Rewards Std                                  0.156181
evaluation/Rewards Max                                  0.0811346
evaluation/Rewards Min                                 -1.25419
evaluation/Returns Mean                                -3.47126
evaluation/Returns Std                                  1.92686
evaluation/Returns Max                                 -0.172923
evaluation/Returns Min                                -11.4351
evaluation/Actions Mean                                 0.0203719
evaluation/Actions Std                                  0.121293
evaluation/Actions Max                                  0.555735
evaluation/Actions Min                                 -0.537894
evaluation/Num Paths                                   50
evaluation/Average Returns                             -3.47126
evaluation/env_infos/final/reward_energy Mean          -0.2254
evaluation/env_infos/final/reward_energy Std            0.162926
evaluation/env_infos/final/reward_energy Max           -0.0125389
evaluation/env_infos/final/reward_energy Min           -0.697329
evaluation/env_infos/initial/reward_energy Mean        -0.144821
evaluation/env_infos/initial/reward_energy Std          0.0931701
evaluation/env_infos/initial/reward_energy Max         -0.0225581
evaluation/env_infos/initial/reward_energy Min         -0.419821
evaluation/env_infos/reward_energy Mean                -0.136775
evaluation/env_infos/reward_energy Std                  0.107455
evaluation/env_infos/reward_energy Max                 -0.00429935
evaluation/env_infos/reward_energy Min                 -0.697329
evaluation/env_infos/final/end_effector_loc Mean        0.0587388
evaluation/env_infos/final/end_effector_loc Std         0.594651
evaluation/env_infos/final/end_effector_loc Max         1
evaluation/env_infos/final/end_effector_loc Min        -1
evaluation/env_infos/initial/end_effector_loc Mean     -0.000562591
evaluation/env_infos/initial/end_effector_loc Std       0.00606225
evaluation/env_infos/initial/end_effector_loc Max       0.0207223
evaluation/env_infos/initial/end_effector_loc Min      -0.0163651
evaluation/env_infos/end_effector_loc Mean              0.0146674
evaluation/env_infos/end_effector_loc Std               0.357832
evaluation/env_infos/end_effector_loc Max               1
evaluation/env_infos/end_effector_loc Min              -1
evaluation/env_infos/final/reward_safety Mean           0
evaluation/env_infos/final/reward_safety Std            0
evaluation/env_infos/final/reward_safety Max            0
evaluation/env_infos/final/reward_safety Min            0
evaluation/env_infos/initial/reward_safety Mean         0
evaluation/env_infos/initial/reward_safety Std          0
evaluation/env_infos/initial/reward_safety Max          0
evaluation/env_infos/initial/reward_safety Min          0
evaluation/env_infos/reward_safety Mean                 0
evaluation/env_infos/reward_safety Std                  0
evaluation/env_infos/reward_safety Max                  0
evaluation/env_infos/reward_safety Min                  0
evaluation/env_infos/final/reward_dist Mean             0.00159417
evaluation/env_infos/final/reward_dist Std              0.00760199
evaluation/env_infos/final/reward_dist Max              0.0517326
evaluation/env_infos/final/reward_dist Min              2.40951e-156
evaluation/env_infos/initial/reward_dist Mean           0.00623308
evaluation/env_infos/initial/reward_dist Std            0.0107262
evaluation/env_infos/initial/reward_dist Max            0.0458268
evaluation/env_infos/initial/reward_dist Min            1.00584e-06
evaluation/env_infos/reward_dist Mean                   0.0437722
evaluation/env_infos/reward_dist Std                    0.142023
evaluation/env_infos/reward_dist Max                    0.995823
evaluation/env_infos/reward_dist Min                    2.40951e-156
time/data storing (s)                                   5.29867
time/evaluation sampling (s)                            0.726297
time/exploration sampling (s)                           0.0884666
time/logging (s)                                        0.0148314
time/saving (s)                                         0.131217
time/training (s)                                      33.0739
time/epoch (s)                                         39.3334
time/total (s)                                        149.778
Epoch                                                   3
---------------------------------------------------  ---------------
2021-05-28 23:59:02.390036 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 4 finished
---------------------------------------------------  ---------------
replay_buffer/size                                   2000
trainer/QF1 Loss                                        0.00769091
trainer/QF2 Loss                                        0.00893444
trainer/Policy Loss                                     3.03956
trainer/Q1 Predictions Mean                            -1.73941
trainer/Q1 Predictions Std                              1.46351
trainer/Q1 Predictions Max                              0.221479
trainer/Q1 Predictions Min                             -7.7749
trainer/Q2 Predictions Mean                            -1.74959
trainer/Q2 Predictions Std                              1.47023
trainer/Q2 Predictions Max                              0.179217
trainer/Q2 Predictions Min                             -8.00423
trainer/Q Targets Mean                                 -1.76022
trainer/Q Targets Std                                   1.4835
trainer/Q Targets Max                                   0.199071
trainer/Q Targets Min                                  -7.96439
trainer/Log Pis Mean                                    1.50294
trainer/Log Pis Std                                     1.51387
trainer/Log Pis Max                                     5.46996
trainer/Log Pis Min                                    -6.03645
trainer/Policy mu Mean                                  0.0534343
trainer/Policy mu Std                                   0.572421
trainer/Policy mu Max                                   2.88381
trainer/Policy mu Min                                  -2.08188
trainer/Policy log std Mean                            -1.88335
trainer/Policy log std Std                              0.663485
trainer/Policy log std Max                             -0.124037
trainer/Policy log std Min                             -3.00679
trainer/Alpha                                           0.0124109
trainer/Alpha Loss                                     -2.1813
exploration/num steps total                          1500
exploration/num paths total                            75
exploration/path length Mean                           20
exploration/path length Std                             0
exploration/path length Max                            20
exploration/path length Min                            20
exploration/Rewards Mean                               -0.139997
exploration/Rewards Std                                 0.141612
exploration/Rewards Max                                 0.0879804
exploration/Rewards Min                                -0.737466
exploration/Returns Mean                               -2.79994
exploration/Returns Std                                 1.29371
exploration/Returns Max                                -0.650674
exploration/Returns Min                                -4.62881
exploration/Actions Mean                                0.0103408
exploration/Actions Std                                 0.194118
exploration/Actions Max                                 0.810296
exploration/Actions Min                                -0.849229
exploration/Num Paths                                   5
exploration/Average Returns                            -2.79994
exploration/env_infos/final/reward_energy Mean         -0.363572
exploration/env_infos/final/reward_energy Std           0.112692
exploration/env_infos/final/reward_energy Max          -0.210702
exploration/env_infos/final/reward_energy Min          -0.517439
exploration/env_infos/initial/reward_energy Mean       -0.283026
exploration/env_infos/initial/reward_energy Std         0.168955
exploration/env_infos/initial/reward_energy Max        -0.160229
exploration/env_infos/initial/reward_energy Min        -0.614236
exploration/env_infos/reward_energy Mean               -0.220102
exploration/env_infos/reward_energy Std                 0.16472
exploration/env_infos/reward_energy Max                -0.0152716
exploration/env_infos/reward_energy Min                -0.925983
exploration/env_infos/final/end_effector_loc Mean       0.00799749
exploration/env_infos/final/end_effector_loc Std        0.546671
exploration/env_infos/final/end_effector_loc Max        0.729392
exploration/env_infos/final/end_effector_loc Min       -0.782571
exploration/env_infos/initial/end_effector_loc Mean     0.0033383
exploration/env_infos/initial/end_effector_loc Std      0.0111655
exploration/env_infos/initial/end_effector_loc Max      0.0304904
exploration/env_infos/initial/end_effector_loc Min     -0.0084577
exploration/env_infos/end_effector_loc Mean             0.0184879
exploration/env_infos/end_effector_loc Std              0.306241
exploration/env_infos/end_effector_loc Max              0.729392
exploration/env_infos/end_effector_loc Min             -0.782571
exploration/env_infos/final/reward_safety Mean          0
exploration/env_infos/final/reward_safety Std           0
exploration/env_infos/final/reward_safety Max           0
exploration/env_infos/final/reward_safety Min           0
exploration/env_infos/initial/reward_safety Mean        0
exploration/env_infos/initial/reward_safety Std         0
exploration/env_infos/initial/reward_safety Max         0
exploration/env_infos/initial/reward_safety Min         0
exploration/env_infos/reward_safety Mean                0
exploration/env_infos/reward_safety Std                 0
exploration/env_infos/reward_safety Max                 0
exploration/env_infos/reward_safety Min                 0
exploration/env_infos/final/reward_dist Mean            0.000126348
exploration/env_infos/final/reward_dist Std             0.000229476
exploration/env_infos/final/reward_dist Max             0.000583796
exploration/env_infos/final/reward_dist Min             1.0212e-48
exploration/env_infos/initial/reward_dist Mean          0.000434595
exploration/env_infos/initial/reward_dist Std           0.00071887
exploration/env_infos/initial/reward_dist Max           0.00186398
exploration/env_infos/initial/reward_dist Min           1.41595e-05
exploration/env_infos/reward_dist Mean                  0.118108
exploration/env_infos/reward_dist Std                   0.23
exploration/env_infos/reward_dist Max                   0.994848
exploration/env_infos/reward_dist Min                   1.0212e-48
evaluation/num steps total                           5000
evaluation/num paths total                            250
evaluation/path length Mean                            20
evaluation/path length Std                              0
evaluation/path length Max                             20
evaluation/path length Min                             20
evaluation/Rewards Mean                                -0.189547
evaluation/Rewards Std                                  0.209441
evaluation/Rewards Max                                  0.121296
evaluation/Rewards Min                                 -1.31694
evaluation/Returns Mean                                -3.79094
evaluation/Returns Std                                  2.87587
evaluation/Returns Max                                  0.0622483
evaluation/Returns Min                                -12.0338
evaluation/Actions Mean                                 0.00886551
evaluation/Actions Std                                  0.131902
evaluation/Actions Max                                  0.712955
evaluation/Actions Min                                 -0.738588
evaluation/Num Paths                                   50
evaluation/Average Returns                             -3.79094
evaluation/env_infos/final/reward_energy Mean          -0.1934
evaluation/env_infos/final/reward_energy Std            0.139331
evaluation/env_infos/final/reward_energy Max           -0.00923802
evaluation/env_infos/final/reward_energy Min           -0.666283
evaluation/env_infos/initial/reward_energy Mean        -0.209481
evaluation/env_infos/initial/reward_energy Std          0.189586
evaluation/env_infos/initial/reward_energy Max         -0.0211452
evaluation/env_infos/initial/reward_energy Min         -0.744856
evaluation/env_infos/reward_energy Mean                -0.13226
evaluation/env_infos/reward_energy Std                  0.132139
evaluation/env_infos/reward_energy Max                 -0.00295783
evaluation/env_infos/reward_energy Min                 -0.767975
evaluation/env_infos/final/end_effector_loc Mean        0.0615118
evaluation/env_infos/final/end_effector_loc Std         0.579902
evaluation/env_infos/final/end_effector_loc Max         1
evaluation/env_infos/final/end_effector_loc Min        -1
evaluation/env_infos/initial/end_effector_loc Mean      0.000692408
evaluation/env_infos/initial/end_effector_loc Std       0.00996505
evaluation/env_infos/initial/end_effector_loc Max       0.0319938
evaluation/env_infos/initial/end_effector_loc Min      -0.0369294
evaluation/env_infos/end_effector_loc Mean              0.0392437
evaluation/env_infos/end_effector_loc Std               0.379016
evaluation/env_infos/end_effector_loc Max               1
evaluation/env_infos/end_effector_loc Min              -1
evaluation/env_infos/final/reward_safety Mean           0
evaluation/env_infos/final/reward_safety Std            0
evaluation/env_infos/final/reward_safety Max            0
evaluation/env_infos/final/reward_safety Min            0
evaluation/env_infos/initial/reward_safety Mean         0
evaluation/env_infos/initial/reward_safety Std          0
evaluation/env_infos/initial/reward_safety Max          0
evaluation/env_infos/initial/reward_safety Min          0
evaluation/env_infos/reward_safety Mean                 0
evaluation/env_infos/reward_safety Std                  0
evaluation/env_infos/reward_safety Max                  0
evaluation/env_infos/reward_safety Min                  0
evaluation/env_infos/final/reward_dist Mean             0.0251578
evaluation/env_infos/final/reward_dist Std              0.121897
evaluation/env_infos/final/reward_dist Max              0.818753
evaluation/env_infos/final/reward_dist Min              2.38441e-159
evaluation/env_infos/initial/reward_dist Mean           0.00606024
evaluation/env_infos/initial/reward_dist Std            0.00901925
evaluation/env_infos/initial/reward_dist Max            0.0348807
evaluation/env_infos/initial/reward_dist Min            1.50168e-06
evaluation/env_infos/reward_dist Mean                   0.050635
evaluation/env_infos/reward_dist Std                    0.143633
evaluation/env_infos/reward_dist Max                    0.9495
evaluation/env_infos/reward_dist Min                    2.38441e-159
time/data storing (s)                                   5.73611
time/evaluation sampling (s)                            0.719919
time/exploration sampling (s)                           0.0869436
time/logging (s)                                        0.0142938
time/saving (s)                                         0.138048
time/training (s)                                      33.2402
time/epoch (s)                                         39.9355
time/total (s)                                        189.779
Epoch                                                   4
---------------------------------------------------  ---------------
2021-05-28 23:59:42.523061 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 5 finished
---------------------------------------------------  ---------------
replay_buffer/size                                   2000
trainer/QF1 Loss                                        0.0103743
trainer/QF2 Loss                                        0.00550327
trainer/Policy Loss                                     3.85417
trainer/Q1 Predictions Mean                            -1.785
trainer/Q1 Predictions Std                              1.42794
trainer/Q1 Predictions Max                              0.27181
trainer/Q1 Predictions Min                             -7.34863
trainer/Q2 Predictions Mean                            -1.79566
trainer/Q2 Predictions Std                              1.45142
trainer/Q2 Predictions Max                              0.29802
trainer/Q2 Predictions Min                             -7.4062
trainer/Q Targets Mean                                 -1.82395
trainer/Q Targets Std                                   1.4682
trainer/Q Targets Max                                   0.281619
trainer/Q Targets Min                                  -7.51364
trainer/Log Pis Mean                                    2.24335
trainer/Log Pis Std                                     1.40436
trainer/Log Pis Max                                     8.49694
trainer/Log Pis Min                                    -1.84932
trainer/Policy mu Mean                                  0.0351601
trainer/Policy mu Std                                   0.672337
trainer/Policy mu Max                                   3.57717
trainer/Policy mu Min                                  -3.4666
trainer/Policy log std Mean                            -2.14945
trainer/Policy log std Std                              0.658633
trainer/Policy log std Max                             -0.0518764
trainer/Policy log std Min                             -3.45699
trainer/Alpha                                           0.00995494
trainer/Alpha Loss                                      1.12178
exploration/num steps total                          1600
exploration/num paths total                            80
exploration/path length Mean                           20
exploration/path length Std                             0
exploration/path length Max                            20
exploration/path length Min                            20
exploration/Rewards Mean                               -0.178672
exploration/Rewards Std                                 0.0729565
exploration/Rewards Max                                -0.0751649
exploration/Rewards Min                                -0.519191
exploration/Returns Mean                               -3.57344
exploration/Returns Std                                 0.843602
exploration/Returns Max                                -2.75097
exploration/Returns Min                                -5.08241
exploration/Actions Mean                                0.0325382
exploration/Actions Std                                 0.163424
exploration/Actions Max                                 0.724499
exploration/Actions Min                                -0.728169
exploration/Num Paths                                   5
exploration/Average Returns                            -3.57344
exploration/env_infos/final/reward_energy Mean         -0.246424
exploration/env_infos/final/reward_energy Std           0.201302
exploration/env_infos/final/reward_energy Max          -0.116302
exploration/env_infos/final/reward_energy Min          -0.646697
exploration/env_infos/initial/reward_energy Mean       -0.0931878
exploration/env_infos/initial/reward_energy Std         0.020748
exploration/env_infos/initial/reward_energy Max        -0.0665822
exploration/env_infos/initial/reward_energy Min        -0.123151
exploration/env_infos/reward_energy Mean               -0.174336
exploration/env_infos/reward_energy Std                 0.158554
exploration/env_infos/reward_energy Max                -0.0136249
exploration/env_infos/reward_energy Min                -0.985279
exploration/env_infos/final/end_effector_loc Mean       0.380284
exploration/env_infos/final/end_effector_loc Std        0.371404
exploration/env_infos/final/end_effector_loc Max        1
exploration/env_infos/final/end_effector_loc Min       -0.139208
exploration/env_infos/initial/end_effector_loc Mean     0.000887953
exploration/env_infos/initial/end_effector_loc Std      0.00325647
exploration/env_infos/initial/end_effector_loc Max      0.00482186
exploration/env_infos/initial/end_effector_loc Min     -0.00402134
exploration/env_infos/end_effector_loc Mean             0.168297
exploration/env_infos/end_effector_loc Std              0.236032
exploration/env_infos/end_effector_loc Max              1
exploration/env_infos/end_effector_loc Min             -0.139208
exploration/env_infos/final/reward_safety Mean          0
exploration/env_infos/final/reward_safety Std           0
exploration/env_infos/final/reward_safety Max           0
exploration/env_infos/final/reward_safety Min           0
exploration/env_infos/initial/reward_safety Mean        0
exploration/env_infos/initial/reward_safety Std         0
exploration/env_infos/initial/reward_safety Max         0
exploration/env_infos/initial/reward_safety Min         0
exploration/env_infos/reward_safety Mean                0
exploration/env_infos/reward_safety Std                 0
exploration/env_infos/reward_safety Max                 0
exploration/env_infos/reward_safety Min                 0
exploration/env_infos/final/reward_dist Mean            0.0287401
exploration/env_infos/final/reward_dist Std             0.0574777
exploration/env_infos/final/reward_dist Max             0.143696
exploration/env_infos/final/reward_dist Min             1.93114e-128
exploration/env_infos/initial/reward_dist Mean          0.000747906
exploration/env_infos/initial/reward_dist Std           0.00111404
exploration/env_infos/initial/reward_dist Max           0.00294177
exploration/env_infos/initial/reward_dist Min           6.04505e-06
exploration/env_infos/reward_dist Mean                  0.036689
exploration/env_infos/reward_dist Std                   0.12529
exploration/env_infos/reward_dist Max                   0.744137
exploration/env_infos/reward_dist Min                   1.93114e-128
evaluation/num steps total                           6000
evaluation/num paths total                            300
evaluation/path length Mean                            20
evaluation/path length Std                              0
evaluation/path length Max                             20
evaluation/path length Min                             20
evaluation/Rewards Mean                                -0.160196
evaluation/Rewards Std                                  0.169241
evaluation/Rewards Max                                  0.141727
evaluation/Rewards Min                                 -0.858659
evaluation/Returns Mean                                -3.20391
evaluation/Returns Std                                  2.25013
evaluation/Returns Max                                  1.30769
evaluation/Returns Min                                 -9.16941
evaluation/Actions Mean                                 0.0256822
evaluation/Actions Std                                  0.119425
evaluation/Actions Max                                  0.889713
evaluation/Actions Min                                 -0.734076
evaluation/Num Paths                                   50
evaluation/Average Returns                             -3.20391
evaluation/env_infos/final/reward_energy Mean          -0.148311
evaluation/env_infos/final/reward_energy Std            0.130142
evaluation/env_infos/final/reward_energy Max           -0.0265569
evaluation/env_infos/final/reward_energy Min           -0.717477
evaluation/env_infos/initial/reward_energy Mean        -0.216586
evaluation/env_infos/initial/reward_energy Std          0.191562
evaluation/env_infos/initial/reward_energy Max         -0.0061511
evaluation/env_infos/initial/reward_energy Min         -1.0181
evaluation/env_infos/reward_energy Mean                -0.127304
evaluation/env_infos/reward_energy Std                  0.11678
evaluation/env_infos/reward_energy Max                 -0.00428276
evaluation/env_infos/reward_energy Min                 -1.0181
evaluation/env_infos/final/end_effector_loc Mean        0.194895
evaluation/env_infos/final/end_effector_loc Std         0.549439
evaluation/env_infos/final/end_effector_loc Max         1
evaluation/env_infos/final/end_effector_loc Min        -0.996245
evaluation/env_infos/initial/end_effector_loc Mean      0.00298101
evaluation/env_infos/initial/end_effector_loc Std       0.00977856
evaluation/env_infos/initial/end_effector_loc Max       0.0444857
evaluation/env_infos/initial/end_effector_loc Min      -0.0186936
evaluation/env_infos/end_effector_loc Mean              0.102754
evaluation/env_infos/end_effector_loc Std               0.347898
evaluation/env_infos/end_effector_loc Max               1
evaluation/env_infos/end_effector_loc Min              -0.996245
evaluation/env_infos/final/reward_safety Mean           0
evaluation/env_infos/final/reward_safety Std            0
evaluation/env_infos/final/reward_safety Max            0
evaluation/env_infos/final/reward_safety Min            0
evaluation/env_infos/initial/reward_safety Mean         0
evaluation/env_infos/initial/reward_safety Std          0
evaluation/env_infos/initial/reward_safety Max          0
evaluation/env_infos/initial/reward_safety Min          0
evaluation/env_infos/reward_safety Mean                 0
evaluation/env_infos/reward_safety Std                  0
evaluation/env_infos/reward_safety Max                  0
evaluation/env_infos/reward_safety Min                  0
evaluation/env_infos/final/reward_dist Mean             0.0257513
evaluation/env_infos/final/reward_dist Std              0.0911609
evaluation/env_infos/final/reward_dist Max              0.526668
evaluation/env_infos/final/reward_dist Min              1.46606e-131
evaluation/env_infos/initial/reward_dist Mean           0.00665007
evaluation/env_infos/initial/reward_dist Std            0.0103027
evaluation/env_infos/initial/reward_dist Max            0.0440829
evaluation/env_infos/initial/reward_dist Min            1.9067e-06
evaluation/env_infos/reward_dist Mean                   0.0554159
evaluation/env_infos/reward_dist Std                    0.146507
evaluation/env_infos/reward_dist Max                    0.996286
evaluation/env_infos/reward_dist Min                    1.46606e-131
time/data storing (s)                                   6.13232
time/evaluation sampling (s)                            0.658824
time/exploration sampling (s)                           0.0906557
time/logging (s)                                        0.014445
time/saving (s)                                         0.146286
time/training (s)                                      33.0119
time/epoch (s)                                         40.0544
time/total (s)                                        229.91
Epoch                                                   5
---------------------------------------------------  ---------------
2021-05-29 00:00:23.547355 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 6 finished
---------------------------------------------------  ---------------
replay_buffer/size                                   2000
trainer/QF1 Loss                                        0.0107013
trainer/QF2 Loss                                        0.0266847
trainer/Policy Loss                                     3.79493
trainer/Q1 Predictions Mean                            -1.95958
trainer/Q1 Predictions Std                              1.46632
trainer/Q1 Predictions Max                              0.279688
trainer/Q1 Predictions Min                             -7.53885
trainer/Q2 Predictions Mean                            -1.91741
trainer/Q2 Predictions Std                              1.46081
trainer/Q2 Predictions Max                              0.284837
trainer/Q2 Predictions Min                             -7.69746
trainer/Q Targets Mean                                 -1.98958
trainer/Q Targets Std                                   1.48819
trainer/Q Targets Max                                   0.347854
trainer/Q Targets Min                                  -7.65952
trainer/Log Pis Mean                                    2.05167
trainer/Log Pis Std                                     1.48036
trainer/Log Pis Max                                     8.7404
trainer/Log Pis Min                                    -2.6952
trainer/Policy mu Mean                                 -0.0263762
trainer/Policy mu Std                                   0.576901
trainer/Policy mu Max                                   2.08291
trainer/Policy mu Min                                  -3.98762
trainer/Policy log std Mean                            -2.21775
trainer/Policy log std Std                              0.638186
trainer/Policy log std Max                             -0.128437
trainer/Policy log std Min                             -3.26276
trainer/Alpha                                           0.00965377
trainer/Alpha Loss                                      0.239779
exploration/num steps total                          1700
exploration/num paths total                            85
exploration/path length Mean                           20
exploration/path length Std                             0
exploration/path length Max                            20
exploration/path length Min                            20
exploration/Rewards Mean                               -0.267217
exploration/Rewards Std                                 0.22321
exploration/Rewards Max                                 0.029718
exploration/Rewards Min                                -0.761505
exploration/Returns Mean                               -5.34434
exploration/Returns Std                                 3.27383
exploration/Returns Max                                -1.23882
exploration/Returns Min                               -10.4483
exploration/Actions Mean                                0.0409176
exploration/Actions Std                                 0.254313
exploration/Actions Max                                 0.67309
exploration/Actions Min                                -0.787527
exploration/Num Paths                                   5
exploration/Average Returns                            -5.34434
exploration/env_infos/final/reward_energy Mean         -0.250442
exploration/env_infos/final/reward_energy Std           0.143995
exploration/env_infos/final/reward_energy Max          -0.0992181
exploration/env_infos/final/reward_energy Min          -0.476017
exploration/env_infos/initial/reward_energy Mean       -0.514545
exploration/env_infos/initial/reward_energy Std         0.142946
exploration/env_infos/initial/reward_energy Max        -0.258451
exploration/env_infos/initial/reward_energy Min        -0.674705
exploration/env_infos/reward_energy Mean               -0.322573
exploration/env_infos/reward_energy Std                 0.169249
exploration/env_infos/reward_energy Max                -0.00695765
exploration/env_infos/reward_energy Min                -0.832056
exploration/env_infos/final/end_effector_loc Mean       0.356975
exploration/env_infos/final/end_effector_loc Std        0.55377
exploration/env_infos/final/end_effector_loc Max        1
exploration/env_infos/final/end_effector_loc Min       -0.388152
exploration/env_infos/initial/end_effector_loc Mean     0.00467396
exploration/env_infos/initial/end_effector_loc Std      0.0182932
exploration/env_infos/initial/end_effector_loc Max      0.0336545
exploration/env_infos/initial/end_effector_loc Min     -0.0220868
exploration/env_infos/end_effector_loc Mean             0.182063
exploration/env_infos/end_effector_loc Std              0.436558
exploration/env_infos/end_effector_loc Max              1
exploration/env_infos/end_effector_loc Min             -0.826188
exploration/env_infos/final/reward_safety Mean          0
exploration/env_infos/final/reward_safety Std           0
exploration/env_infos/final/reward_safety Max           0
exploration/env_infos/final/reward_safety Min           0
exploration/env_infos/initial/reward_safety Mean        0
exploration/env_infos/initial/reward_safety Std         0
exploration/env_infos/initial/reward_safety Max         0
exploration/env_infos/initial/reward_safety Min         0
exploration/env_infos/reward_safety Mean                0
exploration/env_infos/reward_safety Std                 0
exploration/env_infos/reward_safety Max                 0
exploration/env_infos/reward_safety Min                 0
exploration/env_infos/final/reward_dist Mean            7.48716e-09
exploration/env_infos/final/reward_dist Std             1.49743e-08
exploration/env_infos/final/reward_dist Max             3.74358e-08
exploration/env_infos/final/reward_dist Min             1.69218e-155
exploration/env_infos/initial/reward_dist Mean          0.00414613
exploration/env_infos/initial/reward_dist Std           0.00421741
exploration/env_infos/initial/reward_dist Max           0.0116398
exploration/env_infos/initial/reward_dist Min           3.64635e-06
exploration/env_infos/reward_dist Mean                  0.0274269
exploration/env_infos/reward_dist Std                   0.0831841
exploration/env_infos/reward_dist Max                   0.454288
exploration/env_infos/reward_dist Min                   1.69218e-155
evaluation/num steps total                           7000
evaluation/num paths total                            350
evaluation/path length Mean                            20
evaluation/path length Std                              0
evaluation/path length Max                             20
evaluation/path length Min                             20
evaluation/Rewards Mean                                -0.149189
evaluation/Rewards Std                                  0.125238
evaluation/Rewards Max                                  0.0519395
evaluation/Rewards Min                                 -0.768247
evaluation/Returns Mean                                -2.98378
evaluation/Returns Std                                  1.96046
evaluation/Returns Max                                 -0.57971
evaluation/Returns Min                                -11.222
evaluation/Actions Mean                                 0.00315894
evaluation/Actions Std                                  0.101866
evaluation/Actions Max                                  0.80508
evaluation/Actions Min                                 -0.925592
evaluation/Num Paths                                   50
evaluation/Average Returns                             -2.98378
evaluation/env_infos/final/reward_energy Mean          -0.135639
evaluation/env_infos/final/reward_energy Std            0.147232
evaluation/env_infos/final/reward_energy Max           -0.0190808
evaluation/env_infos/final/reward_energy Min           -0.948736
evaluation/env_infos/initial/reward_energy Mean        -0.162175
evaluation/env_infos/initial/reward_energy Std          0.145227
evaluation/env_infos/initial/reward_energy Max         -0.0221877
evaluation/env_infos/initial/reward_energy Min         -0.891769
evaluation/env_infos/reward_energy Mean                -0.0950462
evaluation/env_infos/reward_energy Std                  0.10835
evaluation/env_infos/reward_energy Max                 -0.00171199
evaluation/env_infos/reward_energy Min                 -0.948736
evaluation/env_infos/final/end_effector_loc Mean        0.0626287
evaluation/env_infos/final/end_effector_loc Std         0.506895
evaluation/env_infos/final/end_effector_loc Max         1
evaluation/env_infos/final/end_effector_loc Min        -1
evaluation/env_infos/initial/end_effector_loc Mean      0.000786798
evaluation/env_infos/initial/end_effector_loc Std       0.0076564
evaluation/env_infos/initial/end_effector_loc Max       0.0389578
evaluation/env_infos/initial/end_effector_loc Min      -0.0207516
evaluation/env_infos/end_effector_loc Mean              0.0322224
evaluation/env_infos/end_effector_loc Std               0.303651
evaluation/env_infos/end_effector_loc Max               1
evaluation/env_infos/end_effector_loc Min              -1
evaluation/env_infos/final/reward_safety Mean           0
evaluation/env_infos/final/reward_safety Std            0
evaluation/env_infos/final/reward_safety Max            0
evaluation/env_infos/final/reward_safety Min            0
evaluation/env_infos/initial/reward_safety Mean         0
evaluation/env_infos/initial/reward_safety Std          0
evaluation/env_infos/initial/reward_safety Max          0
evaluation/env_infos/initial/reward_safety Min          0
evaluation/env_infos/reward_safety Mean                 0
evaluation/env_infos/reward_safety Std                  0
evaluation/env_infos/reward_safety Max                  0
evaluation/env_infos/reward_safety Min                  0
evaluation/env_infos/final/reward_dist Mean             0.000116284
evaluation/env_infos/final/reward_dist Std              0.00069748
evaluation/env_infos/final/reward_dist Max              0.00495262
evaluation/env_infos/final/reward_dist Min              1.85492e-159
evaluation/env_infos/initial/reward_dist Mean           0.00489971
evaluation/env_infos/initial/reward_dist Std            0.00783201
evaluation/env_infos/initial/reward_dist Max            0.0345731
evaluation/env_infos/initial/reward_dist Min            1.06195e-06
evaluation/env_infos/reward_dist Mean                   0.037644
evaluation/env_infos/reward_dist Std                    0.1334
evaluation/env_infos/reward_dist Max                    0.968508
evaluation/env_infos/reward_dist Min                    1.85492e-159
time/data storing (s)                                   6.53905
time/evaluation sampling (s)                            0.659134
time/exploration sampling (s)                           0.0907366
time/logging (s)                                        0.0146263
time/saving (s)                                         0.162606
time/training (s)                                      33.4577
time/epoch (s)                                         40.9238
time/total (s)                                        270.933
Epoch                                                   6
---------------------------------------------------  ---------------
2021-05-29 00:01:04.661805 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 7 finished
---------------------------------------------------  --------------
replay_buffer/size                                   2000
trainer/QF1 Loss                                        0.00829713
trainer/QF2 Loss                                        0.0100976
trainer/Policy Loss                                     3.81166
trainer/Q1 Predictions Mean                            -1.79624
trainer/Q1 Predictions Std                              1.36149
trainer/Q1 Predictions Max                              0.00762506
trainer/Q1 Predictions Min                             -7.83814
trainer/Q2 Predictions Mean                            -1.77497
trainer/Q2 Predictions Std                              1.35702
trainer/Q2 Predictions Max                             -0.0220335
trainer/Q2 Predictions Min                             -7.85423
trainer/Q Targets Mean                                 -1.82286
trainer/Q Targets Std                                   1.36208
trainer/Q Targets Max                                  -0.0193429
trainer/Q Targets Min                                  -7.89132
trainer/Log Pis Mean                                    2.1526
trainer/Log Pis Std                                     1.4177
trainer/Log Pis Max                                    10.3382
trainer/Log Pis Min                                    -2.31065
trainer/Policy mu Mean                                 -0.0843277
trainer/Policy mu Std                                   0.646338
trainer/Policy mu Max                                   3.41926
trainer/Policy mu Min                                  -5.23906
trainer/Policy log std Mean                            -2.18616
trainer/Policy log std Std                              0.660003
trainer/Policy log std Max                              0.418624
trainer/Policy log std Min                             -3.46982
trainer/Alpha                                           0.00949874
trainer/Alpha Loss                                      0.710613
exploration/num steps total                          1800
exploration/num paths total                            90
exploration/path length Mean                           20
exploration/path length Std                             0
exploration/path length Max                            20
exploration/path length Min                            20
exploration/Rewards Mean                               -0.195249
exploration/Rewards Std                                 0.171868
exploration/Rewards Max                                 0.0261506
exploration/Rewards Min                                -0.732078
exploration/Returns Mean                               -3.90499
exploration/Returns Std                                 2.1795
exploration/Returns Max                                -1.94552
exploration/Returns Min                                -7.56595
exploration/Actions Mean                                0.0159945
exploration/Actions Std                                 0.132454
exploration/Actions Max                                 0.542248
exploration/Actions Min                                -0.324788
exploration/Num Paths                                   5
exploration/Average Returns                            -3.90499
exploration/env_infos/final/reward_energy Mean         -0.241431
exploration/env_infos/final/reward_energy Std           0.129949
exploration/env_infos/final/reward_energy Max          -0.0459116
exploration/env_infos/final/reward_energy Min          -0.425992
exploration/env_infos/initial/reward_energy Mean       -0.218347
exploration/env_infos/initial/reward_energy Std         0.166584
exploration/env_infos/initial/reward_energy Max        -0.122815
exploration/env_infos/initial/reward_energy Min        -0.55098
exploration/env_infos/reward_energy Mean               -0.15674
exploration/env_infos/reward_energy Std                 0.105036
exploration/env_infos/reward_energy Max                -0.0141924
exploration/env_infos/reward_energy Min                -0.55098
exploration/env_infos/final/end_effector_loc Mean       0.231583
exploration/env_infos/final/end_effector_loc Std        0.51881
exploration/env_infos/final/end_effector_loc Max        1
exploration/env_infos/final/end_effector_loc Min       -0.549045
exploration/env_infos/initial/end_effector_loc Mean     0.0021293
exploration/env_infos/initial/end_effector_loc Std      0.00947354
exploration/env_infos/initial/end_effector_loc Max      0.0271124
exploration/env_infos/initial/end_effector_loc Min     -0.0073203
exploration/env_infos/end_effector_loc Mean             0.119362
exploration/env_infos/end_effector_loc Std              0.322541
exploration/env_infos/end_effector_loc Max              1
exploration/env_infos/end_effector_loc Min             -0.549045
exploration/env_infos/final/reward_safety Mean          0
exploration/env_infos/final/reward_safety Std           0
exploration/env_infos/final/reward_safety Max           0
exploration/env_infos/final/reward_safety Min           0
exploration/env_infos/initial/reward_safety Mean        0
exploration/env_infos/initial/reward_safety Std         0
exploration/env_infos/initial/reward_safety Max         0
exploration/env_infos/initial/reward_safety Min         0
exploration/env_infos/reward_safety Mean                0
exploration/env_infos/reward_safety Std                 0
exploration/env_infos/reward_safety Max                 0
exploration/env_infos/reward_safety Min                 0
exploration/env_infos/final/reward_dist Mean            3.80991e-11
exploration/env_infos/final/reward_dist Std             7.61983e-11
exploration/env_infos/final/reward_dist Max             1.90496e-10
exploration/env_infos/final/reward_dist Min             2.92812e-57
exploration/env_infos/initial/reward_dist Mean          0.00460009
exploration/env_infos/initial/reward_dist Std           0.00578025
exploration/env_infos/initial/reward_dist Max           0.0154774
exploration/env_infos/initial/reward_dist Min           2.54758e-06
exploration/env_infos/reward_dist Mean                  0.0258623
exploration/env_infos/reward_dist Std                   0.0857296
exploration/env_infos/reward_dist Max                   0.561523
exploration/env_infos/reward_dist Min                   2.92812e-57
evaluation/num steps total                           8000
evaluation/num paths total                            400
evaluation/path length Mean                            20
evaluation/path length Std                              0
evaluation/path length Max                             20
evaluation/path length Min                             20
evaluation/Rewards Mean                                -0.144938
evaluation/Rewards Std                                  0.181625
evaluation/Rewards Max                                  0.147661
evaluation/Rewards Min                                 -1.12396
evaluation/Returns Mean                                -2.89875
evaluation/Returns Std                                  2.93863
evaluation/Returns Max                                  1.37831
evaluation/Returns Min                                -16.2209
evaluation/Actions Mean                                 0.01615
evaluation/Actions Std                                  0.130143
evaluation/Actions Max                                  0.79249
evaluation/Actions Min                                 -0.947284
evaluation/Num Paths                                   50
evaluation/Average Returns                             -2.89875
evaluation/env_infos/final/reward_energy Mean          -0.159924
evaluation/env_infos/final/reward_energy Std            0.12268
evaluation/env_infos/final/reward_energy Max           -0.012436
evaluation/env_infos/final/reward_energy Min           -0.501763
evaluation/env_infos/initial/reward_energy Mean        -0.190044
evaluation/env_infos/initial/reward_energy Std          0.166538
evaluation/env_infos/initial/reward_energy Max         -0.0154679
evaluation/env_infos/initial/reward_energy Min         -0.82767
evaluation/env_infos/reward_energy Mean                -0.123525
evaluation/env_infos/reward_energy Std                  0.138339
evaluation/env_infos/reward_energy Max                 -0.000639587
evaluation/env_infos/reward_energy Min                 -1.17895
evaluation/env_infos/final/end_effector_loc Mean        0.207222
evaluation/env_infos/final/end_effector_loc Std         0.388361
evaluation/env_infos/final/end_effector_loc Max         1
evaluation/env_infos/final/end_effector_loc Min        -0.514713
evaluation/env_infos/initial/end_effector_loc Mean      0.00296645
evaluation/env_infos/initial/end_effector_loc Std       0.00842703
evaluation/env_infos/initial/end_effector_loc Max       0.0345291
evaluation/env_infos/initial/end_effector_loc Min      -0.0235855
evaluation/env_infos/end_effector_loc Mean              0.10746
evaluation/env_infos/end_effector_loc Std               0.266723
evaluation/env_infos/end_effector_loc Max               1
evaluation/env_infos/end_effector_loc Min              -0.750073
evaluation/env_infos/final/reward_safety Mean           0
evaluation/env_infos/final/reward_safety Std            0
evaluation/env_infos/final/reward_safety Max            0
evaluation/env_infos/final/reward_safety Min            0
evaluation/env_infos/initial/reward_safety Mean         0
evaluation/env_infos/initial/reward_safety Std          0
evaluation/env_infos/initial/reward_safety Max          0
evaluation/env_infos/initial/reward_safety Min          0
evaluation/env_infos/reward_safety Mean                 0
evaluation/env_infos/reward_safety Std                  0
evaluation/env_infos/reward_safety Max                  0
evaluation/env_infos/reward_safety Min                  0
evaluation/env_infos/final/reward_dist Mean             0.0628598
evaluation/env_infos/final/reward_dist Std              0.21283
evaluation/env_infos/final/reward_dist Max              0.982735
evaluation/env_infos/final/reward_dist Min              1.2305e-150
evaluation/env_infos/initial/reward_dist Mean           0.00614908
evaluation/env_infos/initial/reward_dist Std            0.00887843
evaluation/env_infos/initial/reward_dist Max            0.0290698
evaluation/env_infos/initial/reward_dist Min            3.48652e-06
evaluation/env_infos/reward_dist Mean                   0.0622547
evaluation/env_infos/reward_dist Std                    0.154527
evaluation/env_infos/reward_dist Max                    0.984216
evaluation/env_infos/reward_dist Min                    1.2305e-150
time/data storing (s)                                   6.87126
time/evaluation sampling (s)                            0.680695
time/exploration sampling (s)                           0.0918361
time/logging (s)                                        0.0144512
time/saving (s)                                         0.161622
time/training (s)                                      33.1923
time/epoch (s)                                         41.0121
time/total (s)                                        312.045
Epoch                                                   7
---------------------------------------------------  --------------
2021-05-29 00:01:46.492564 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 8 finished
---------------------------------------------------  ---------------
replay_buffer/size                                   2000
trainer/QF1 Loss                                        0.00508669
trainer/QF2 Loss                                        0.00455272
trainer/Policy Loss                                     3.75857
trainer/Q1 Predictions Mean                            -1.9069
trainer/Q1 Predictions Std                              1.47281
trainer/Q1 Predictions Max                              0.0157359
trainer/Q1 Predictions Min                             -7.27746
trainer/Q2 Predictions Mean                            -1.89974
trainer/Q2 Predictions Std                              1.44585
trainer/Q2 Predictions Max                             -0.0291364
trainer/Q2 Predictions Min                             -7.1904
trainer/Q Targets Mean                                 -1.88702
trainer/Q Targets Std                                   1.45484
trainer/Q Targets Max                                  -0.0193429
trainer/Q Targets Min                                  -7.11228
trainer/Log Pis Mean                                    1.9501
trainer/Log Pis Std                                     1.40541
trainer/Log Pis Max                                     6.76468
trainer/Log Pis Min                                    -2.75323
trainer/Policy mu Mean                                 -0.0674558
trainer/Policy mu Std                                   0.449642
trainer/Policy mu Max                                   2.64965
trainer/Policy mu Min                                  -2.45912
trainer/Policy log std Mean                            -2.21486
trainer/Policy log std Std                              0.582563
trainer/Policy log std Max                             -0.50731
trainer/Policy log std Min                             -3.49794
trainer/Alpha                                           0.0099651
trainer/Alpha Loss                                     -0.229994
exploration/num steps total                          1900
exploration/num paths total                            95
exploration/path length Mean                           20
exploration/path length Std                             0
exploration/path length Max                            20
exploration/path length Min                            20
exploration/Rewards Mean                               -0.209315
exploration/Rewards Std                                 0.105421
exploration/Rewards Max                                -0.0484522
exploration/Rewards Min                                -0.450571
exploration/Returns Mean                               -4.1863
exploration/Returns Std                                 1.49426
exploration/Returns Max                                -3.29909
exploration/Returns Min                                -7.16632
exploration/Actions Mean                                0.00780403
exploration/Actions Std                                 0.214449
exploration/Actions Max                                 0.841285
exploration/Actions Min                                -0.937973
exploration/Num Paths                                   5
exploration/Average Returns                            -4.1863
exploration/env_infos/final/reward_energy Mean         -0.202704
exploration/env_infos/final/reward_energy Std           0.148816
exploration/env_infos/final/reward_energy Max          -0.0743324
exploration/env_infos/final/reward_energy Min          -0.454889
exploration/env_infos/initial/reward_energy Mean       -0.322359
exploration/env_infos/initial/reward_energy Std         0.0933954
exploration/env_infos/initial/reward_energy Max        -0.200329
exploration/env_infos/initial/reward_energy Min        -0.479994
exploration/env_infos/reward_energy Mean               -0.231686
exploration/env_infos/reward_energy Std                 0.196009
exploration/env_infos/reward_energy Max                -0.00966939
exploration/env_infos/reward_energy Min                -1.05312
exploration/env_infos/final/end_effector_loc Mean       0.28736
exploration/env_infos/final/end_effector_loc Std        0.409789
exploration/env_infos/final/end_effector_loc Max        0.768278
exploration/env_infos/final/end_effector_loc Min       -0.622138
exploration/env_infos/initial/end_effector_loc Mean     0.0060687
exploration/env_infos/initial/end_effector_loc Std      0.0101965
exploration/env_infos/initial/end_effector_loc Max      0.0239918
exploration/env_infos/initial/end_effector_loc Min     -0.00998613
exploration/env_infos/end_effector_loc Mean             0.161492
exploration/env_infos/end_effector_loc Std              0.261771
exploration/env_infos/end_effector_loc Max              0.768278
exploration/env_infos/end_effector_loc Min             -0.628234
exploration/env_infos/final/reward_safety Mean          0
exploration/env_infos/final/reward_safety Std           0
exploration/env_infos/final/reward_safety Max           0
exploration/env_infos/final/reward_safety Min           0
exploration/env_infos/initial/reward_safety Mean        0
exploration/env_infos/initial/reward_safety Std         0
exploration/env_infos/initial/reward_safety Max         0
exploration/env_infos/initial/reward_safety Min         0
exploration/env_infos/reward_safety Mean                0
exploration/env_infos/reward_safety Std                 0
exploration/env_infos/reward_safety Max                 0
exploration/env_infos/reward_safety Min                 0
exploration/env_infos/final/reward_dist Mean            4.68638e-14
exploration/env_infos/final/reward_dist Std             9.37247e-14
exploration/env_infos/final/reward_dist Max             2.34313e-13
exploration/env_infos/final/reward_dist Min             3.40453e-49
exploration/env_infos/initial/reward_dist Mean          0.00594475
exploration/env_infos/initial/reward_dist Std           0.0106359
exploration/env_infos/initial/reward_dist Max           0.0271601
exploration/env_infos/initial/reward_dist Min           8.63229e-06
exploration/env_infos/reward_dist Mean                  0.0312681
exploration/env_infos/reward_dist Std                   0.102699
exploration/env_infos/reward_dist Max                   0.675287
exploration/env_infos/reward_dist Min                   3.40453e-49
evaluation/num steps total                           9000
evaluation/num paths total                            450
evaluation/path length Mean                            20
evaluation/path length Std                              0
evaluation/path length Max                             20
evaluation/path length Min                             20
evaluation/Rewards Mean                                -0.153598
evaluation/Rewards Std                                  0.177562
evaluation/Rewards Max                                  0.0689211
evaluation/Rewards Min                                 -1.16082
evaluation/Returns Mean                                -3.07196
evaluation/Returns Std                                  2.64184
evaluation/Returns Max                                  0.230573
evaluation/Returns Min                                -17.1116
evaluation/Actions Mean                                 0.00367665
evaluation/Actions Std                                  0.137206
evaluation/Actions Max                                  0.852784
evaluation/Actions Min                                 -0.601568
evaluation/Num Paths                                   50
evaluation/Average Returns                             -3.07196
evaluation/env_infos/final/reward_energy Mean          -0.223763
evaluation/env_infos/final/reward_energy Std            0.196889
evaluation/env_infos/final/reward_energy Max           -0.0276544
evaluation/env_infos/final/reward_energy Min           -0.778757
evaluation/env_infos/initial/reward_energy Mean        -0.209239
evaluation/env_infos/initial/reward_energy Std          0.229598
evaluation/env_infos/initial/reward_energy Max         -0.00323085
evaluation/env_infos/initial/reward_energy Min         -1.18276
evaluation/env_infos/reward_energy Mean                -0.130058
evaluation/env_infos/reward_energy Std                  0.144094
evaluation/env_infos/reward_energy Max                 -0.00144505
evaluation/env_infos/reward_energy Min                 -1.18276
evaluation/env_infos/final/end_effector_loc Mean       -0.00358054
evaluation/env_infos/final/end_effector_loc Std         0.427289
evaluation/env_infos/final/end_effector_loc Max         1
evaluation/env_infos/final/end_effector_loc Min        -1
evaluation/env_infos/initial/end_effector_loc Mean      0.00165764
evaluation/env_infos/initial/end_effector_loc Std       0.0108569
evaluation/env_infos/initial/end_effector_loc Max       0.0426392
evaluation/env_infos/initial/end_effector_loc Min      -0.0185654
evaluation/env_infos/end_effector_loc Mean              0.0161234
evaluation/env_infos/end_effector_loc Std               0.294605
evaluation/env_infos/end_effector_loc Max               1
evaluation/env_infos/end_effector_loc Min              -1
evaluation/env_infos/final/reward_safety Mean           0
evaluation/env_infos/final/reward_safety Std            0
evaluation/env_infos/final/reward_safety Max            0
evaluation/env_infos/final/reward_safety Min            0
evaluation/env_infos/initial/reward_safety Mean         0
evaluation/env_infos/initial/reward_safety Std          0
evaluation/env_infos/initial/reward_safety Max          0
evaluation/env_infos/initial/reward_safety Min          0
evaluation/env_infos/reward_safety Mean                 0
evaluation/env_infos/reward_safety Std                  0
evaluation/env_infos/reward_safety Max                  0
evaluation/env_infos/reward_safety Min                  0
evaluation/env_infos/final/reward_dist Mean             0.0419281
evaluation/env_infos/final/reward_dist Std              0.128869
evaluation/env_infos/final/reward_dist Max              0.725458
evaluation/env_infos/final/reward_dist Min              6.85376e-133
evaluation/env_infos/initial/reward_dist Mean           0.00624377
evaluation/env_infos/initial/reward_dist Std            0.0101983
evaluation/env_infos/initial/reward_dist Max            0.0420595
evaluation/env_infos/initial/reward_dist Min            1.30923e-06
evaluation/env_infos/reward_dist Mean                   0.078762
evaluation/env_infos/reward_dist Std                    0.173483
evaluation/env_infos/reward_dist Max                    0.93864
evaluation/env_infos/reward_dist Min                    4.54887e-140
time/data storing (s)                                   7.30847
time/evaluation sampling (s)                            0.678926
time/exploration sampling (s)                           0.0945428
time/logging (s)                                        0.01506
time/saving (s)                                         0.169466
time/training (s)                                      33.4319
time/epoch (s)                                         41.6984
time/total (s)                                        353.875
Epoch                                                   8
---------------------------------------------------  ---------------
2021-05-29 00:02:29.100617 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 9 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00646645
trainer/QF2 Loss                                         0.00481899
trainer/Policy Loss                                      3.64546
trainer/Q1 Predictions Mean                             -1.6998
trainer/Q1 Predictions Std                               1.26784
trainer/Q1 Predictions Max                               0.00230383
trainer/Q1 Predictions Min                              -6.85262
trainer/Q2 Predictions Mean                             -1.72033
trainer/Q2 Predictions Std                               1.28175
trainer/Q2 Predictions Max                               0.0403595
trainer/Q2 Predictions Min                              -6.93354
trainer/Q Targets Mean                                  -1.72794
trainer/Q Targets Std                                    1.28143
trainer/Q Targets Max                                    0.0163552
trainer/Q Targets Min                                   -6.92891
trainer/Log Pis Mean                                     2.00669
trainer/Log Pis Std                                      1.31588
trainer/Log Pis Max                                      5.9851
trainer/Log Pis Min                                     -3.51362
trainer/Policy mu Mean                                  -0.0465711
trainer/Policy mu Std                                    0.502353
trainer/Policy mu Max                                    2.03397
trainer/Policy mu Min                                   -3.44765
trainer/Policy log std Mean                             -2.28666
trainer/Policy log std Std                               0.546918
trainer/Policy log std Max                               0.276019
trainer/Policy log std Min                              -3.44285
trainer/Alpha                                            0.010872
trainer/Alpha Loss                                       0.0302625
exploration/num steps total                           2000
exploration/num paths total                            100
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.190975
exploration/Rewards Std                                  0.0781518
exploration/Rewards Max                                 -0.0463109
exploration/Rewards Min                                 -0.390921
exploration/Returns Mean                                -3.81951
exploration/Returns Std                                  1.0462
exploration/Returns Max                                 -2.23385
exploration/Returns Min                                 -5.53325
exploration/Actions Mean                                 0.010782
exploration/Actions Std                                  0.186604
exploration/Actions Max                                  0.547946
exploration/Actions Min                                 -0.651603
exploration/Num Paths                                    5
exploration/Average Returns                             -3.81951
exploration/env_infos/final/reward_energy Mean          -0.165582
exploration/env_infos/final/reward_energy Std            0.0930828
exploration/env_infos/final/reward_energy Max           -0.035548
exploration/env_infos/final/reward_energy Min           -0.31209
exploration/env_infos/initial/reward_energy Mean        -0.36912
exploration/env_infos/initial/reward_energy Std          0.253025
exploration/env_infos/initial/reward_energy Max         -0.127492
exploration/env_infos/initial/reward_energy Min         -0.85137
exploration/env_infos/reward_energy Mean                -0.214054
exploration/env_infos/reward_energy Std                  0.155098
exploration/env_infos/reward_energy Max                 -0.00891978
exploration/env_infos/reward_energy Min                 -0.85137
exploration/env_infos/final/end_effector_loc Mean        0.255886
exploration/env_infos/final/end_effector_loc Std         0.416576
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.524939
exploration/env_infos/initial/end_effector_loc Mean      0.0020242
exploration/env_infos/initial/end_effector_loc Std       0.0156921
exploration/env_infos/initial/end_effector_loc Max       0.0273973
exploration/env_infos/initial/end_effector_loc Min      -0.0325801
exploration/env_infos/end_effector_loc Mean              0.125961
exploration/env_infos/end_effector_loc Std               0.337519
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.742331
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             4.93233e-06
exploration/env_infos/final/reward_dist Std              9.86462e-06
exploration/env_infos/final/reward_dist Max              2.46616e-05
exploration/env_infos/final/reward_dist Min              2.89829e-102
exploration/env_infos/initial/reward_dist Mean           0.00525559
exploration/env_infos/initial/reward_dist Std            0.00760984
exploration/env_infos/initial/reward_dist Max            0.0195922
exploration/env_infos/initial/reward_dist Min            1.04275e-06
exploration/env_infos/reward_dist Mean                   0.00755661
exploration/env_infos/reward_dist Std                    0.0444197
exploration/env_infos/reward_dist Max                    0.389095
exploration/env_infos/reward_dist Min                    2.89829e-102
evaluation/num steps total                           10000
evaluation/num paths total                             500
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.157955
evaluation/Rewards Std                                   0.166441
evaluation/Rewards Max                                   0.130049
evaluation/Rewards Min                                  -0.868189
evaluation/Returns Mean                                 -3.15911
evaluation/Returns Std                                   2.25327
evaluation/Returns Max                                   0.0818691
evaluation/Returns Min                                 -10.79
evaluation/Actions Mean                                  0.011492
evaluation/Actions Std                                   0.121584
evaluation/Actions Max                                   0.912679
evaluation/Actions Min                                  -0.571087
evaluation/Num Paths                                    50
evaluation/Average Returns                              -3.15911
evaluation/env_infos/final/reward_energy Mean           -0.187415
evaluation/env_infos/final/reward_energy Std             0.150394
evaluation/env_infos/final/reward_energy Max            -0.0148081
evaluation/env_infos/final/reward_energy Min            -0.8428
evaluation/env_infos/initial/reward_energy Mean         -0.187859
evaluation/env_infos/initial/reward_energy Std           0.186526
evaluation/env_infos/initial/reward_energy Max          -0.00486612
evaluation/env_infos/initial/reward_energy Min          -1.10996
evaluation/env_infos/reward_energy Mean                 -0.123923
evaluation/env_infos/reward_energy Std                   0.120303
evaluation/env_infos/reward_energy Max                  -0.00133795
evaluation/env_infos/reward_energy Min                  -1.10996
evaluation/env_infos/final/end_effector_loc Mean         0.125068
evaluation/env_infos/final/end_effector_loc Std          0.495144
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00213145
evaluation/env_infos/initial/end_effector_loc Std        0.00911374
evaluation/env_infos/initial/end_effector_loc Max        0.045634
evaluation/env_infos/initial/end_effector_loc Min       -0.0189262
evaluation/env_infos/end_effector_loc Mean               0.0625986
evaluation/env_infos/end_effector_loc Std                0.307873
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0175662
evaluation/env_infos/final/reward_dist Std               0.0951576
evaluation/env_infos/final/reward_dist Max               0.663129
evaluation/env_infos/final/reward_dist Min               1.02492e-108
evaluation/env_infos/initial/reward_dist Mean            0.00588686
evaluation/env_infos/initial/reward_dist Std             0.00878803
evaluation/env_infos/initial/reward_dist Max             0.0314336
evaluation/env_infos/initial/reward_dist Min             1.62339e-06
evaluation/env_infos/reward_dist Mean                    0.0560175
evaluation/env_infos/reward_dist Std                     0.160072
evaluation/env_infos/reward_dist Max                     0.997602
evaluation/env_infos/reward_dist Min                     1.02492e-108
time/data storing (s)                                    7.63995
time/evaluation sampling (s)                             0.655202
time/exploration sampling (s)                            0.0895354
time/logging (s)                                         0.015073
time/saving (s)                                          0.175157
time/training (s)                                       33.9139
time/epoch (s)                                          42.4888
time/total (s)                                         396.481
Epoch                                                    9
---------------------------------------------------  ----------------
2021-05-29 00:03:12.588123 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 10 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00386767
trainer/QF2 Loss                                         0.00323167
trainer/Policy Loss                                      3.56249
trainer/Q1 Predictions Mean                             -1.73864
trainer/Q1 Predictions Std                               1.22118
trainer/Q1 Predictions Max                               0.0579258
trainer/Q1 Predictions Min                              -7.33933
trainer/Q2 Predictions Mean                             -1.74597
trainer/Q2 Predictions Std                               1.23966
trainer/Q2 Predictions Max                               0.0542644
trainer/Q2 Predictions Min                              -7.44396
trainer/Q Targets Mean                                  -1.745
trainer/Q Targets Std                                    1.23634
trainer/Q Targets Max                                    0.0889614
trainer/Q Targets Min                                   -7.36006
trainer/Log Pis Mean                                     1.91896
trainer/Log Pis Std                                      1.09478
trainer/Log Pis Max                                      4.66784
trainer/Log Pis Min                                     -2.88782
trainer/Policy mu Mean                                  -0.0336667
trainer/Policy mu Std                                    0.365569
trainer/Policy mu Max                                    1.62979
trainer/Policy mu Min                                   -2.3804
trainer/Policy log std Mean                             -2.26396
trainer/Policy log std Std                               0.422758
trainer/Policy log std Max                              -0.635702
trainer/Policy log std Min                              -3.21455
trainer/Alpha                                            0.012396
trainer/Alpha Loss                                      -0.355819
exploration/num steps total                           2100
exploration/num paths total                            105
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.163431
exploration/Rewards Std                                  0.120662
exploration/Rewards Max                                 -0.0273473
exploration/Rewards Min                                 -0.469374
exploration/Returns Mean                                -3.26862
exploration/Returns Std                                  1.8409
exploration/Returns Max                                 -1.20493
exploration/Returns Min                                 -6.27387
exploration/Actions Mean                                 0.00432091
exploration/Actions Std                                  0.268601
exploration/Actions Max                                  0.808606
exploration/Actions Min                                 -0.925645
exploration/Num Paths                                    5
exploration/Average Returns                             -3.26862
exploration/env_infos/final/reward_energy Mean          -0.270936
exploration/env_infos/final/reward_energy Std            0.116328
exploration/env_infos/final/reward_energy Max           -0.128114
exploration/env_infos/final/reward_energy Min           -0.456492
exploration/env_infos/initial/reward_energy Mean        -0.492589
exploration/env_infos/initial/reward_energy Std          0.338365
exploration/env_infos/initial/reward_energy Max         -0.12172
exploration/env_infos/initial/reward_energy Min         -0.911894
exploration/env_infos/reward_energy Mean                -0.274508
exploration/env_infos/reward_energy Std                  0.262632
exploration/env_infos/reward_energy Max                 -0.0177013
exploration/env_infos/reward_energy Min                 -1.29011
exploration/env_infos/final/end_effector_loc Mean       -0.00429295
exploration/env_infos/final/end_effector_loc Std         0.444009
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.428389
exploration/env_infos/initial/end_effector_loc Mean     -0.0115238
exploration/env_infos/initial/end_effector_loc Std       0.0177093
exploration/env_infos/initial/end_effector_loc Max       0.0144433
exploration/env_infos/initial/end_effector_loc Min      -0.0431408
exploration/env_infos/end_effector_loc Mean             -0.0555377
exploration/env_infos/end_effector_loc Std               0.31893
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.646898
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             4.41403e-07
exploration/env_infos/final/reward_dist Std              8.45912e-07
exploration/env_infos/final/reward_dist Max              2.13224e-06
exploration/env_infos/final/reward_dist Min              2.32592e-55
exploration/env_infos/initial/reward_dist Mean           0.00531846
exploration/env_infos/initial/reward_dist Std            0.00928482
exploration/env_infos/initial/reward_dist Max            0.0238633
exploration/env_infos/initial/reward_dist Min            1.92254e-07
exploration/env_infos/reward_dist Mean                   0.0213925
exploration/env_infos/reward_dist Std                    0.056459
exploration/env_infos/reward_dist Max                    0.368723
exploration/env_infos/reward_dist Min                    2.32592e-55
evaluation/num steps total                           11000
evaluation/num paths total                             550
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.139173
evaluation/Rewards Std                                   0.16016
evaluation/Rewards Max                                   0.129351
evaluation/Rewards Min                                  -1.19472
evaluation/Returns Mean                                 -2.78346
evaluation/Returns Std                                   2.65171
evaluation/Returns Max                                   0.490346
evaluation/Returns Min                                 -17.5469
evaluation/Actions Mean                                  0.00444447
evaluation/Actions Std                                   0.118837
evaluation/Actions Max                                   0.750964
evaluation/Actions Min                                  -0.881765
evaluation/Num Paths                                    50
evaluation/Average Returns                              -2.78346
evaluation/env_infos/final/reward_energy Mean           -0.119019
evaluation/env_infos/final/reward_energy Std             0.110962
evaluation/env_infos/final/reward_energy Max            -0.00776183
evaluation/env_infos/final/reward_energy Min            -0.591616
evaluation/env_infos/initial/reward_energy Mean         -0.243469
evaluation/env_infos/initial/reward_energy Std           0.231431
evaluation/env_infos/initial/reward_energy Max          -0.0249463
evaluation/env_infos/initial/reward_energy Min          -0.938468
evaluation/env_infos/reward_energy Mean                 -0.115427
evaluation/env_infos/reward_energy Std                   0.122314
evaluation/env_infos/reward_energy Max                  -0.00204847
evaluation/env_infos/reward_energy Min                  -1.03631
evaluation/env_infos/final/end_effector_loc Mean         0.0850943
evaluation/env_infos/final/end_effector_loc Std          0.411726
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00114839
evaluation/env_infos/initial/end_effector_loc Std        0.0118206
evaluation/env_infos/initial/end_effector_loc Max        0.0346237
evaluation/env_infos/initial/end_effector_loc Min       -0.0440883
evaluation/env_infos/end_effector_loc Mean               0.0456993
evaluation/env_infos/end_effector_loc Std                0.27899
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0386248
evaluation/env_infos/final/reward_dist Std               0.130526
evaluation/env_infos/final/reward_dist Max               0.659661
evaluation/env_infos/final/reward_dist Min               2.28411e-131
evaluation/env_infos/initial/reward_dist Mean            0.00261421
evaluation/env_infos/initial/reward_dist Std             0.00488117
evaluation/env_infos/initial/reward_dist Max             0.0241651
evaluation/env_infos/initial/reward_dist Min             4.2237e-07
evaluation/env_infos/reward_dist Mean                    0.057366
evaluation/env_infos/reward_dist Std                     0.16405
evaluation/env_infos/reward_dist Max                     0.998249
evaluation/env_infos/reward_dist Min                     2.28411e-131
time/data storing (s)                                    8.17971
time/evaluation sampling (s)                             0.654653
time/exploration sampling (s)                            0.0947188
time/logging (s)                                         0.0153
time/saving (s)                                          0.189635
time/training (s)                                       34.1864
time/epoch (s)                                          43.3205
time/total (s)                                         439.967
Epoch                                                   10
---------------------------------------------------  ----------------
2021-05-29 00:03:55.070499 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 11 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00529531
trainer/QF2 Loss                                         0.0045209
trainer/Policy Loss                                      3.33305
trainer/Q1 Predictions Mean                             -1.3539
trainer/Q1 Predictions Std                               0.916082
trainer/Q1 Predictions Max                               0.266496
trainer/Q1 Predictions Min                              -4.22597
trainer/Q2 Predictions Mean                             -1.36741
trainer/Q2 Predictions Std                               0.91169
trainer/Q2 Predictions Max                               0.307611
trainer/Q2 Predictions Min                              -4.27181
trainer/Q Targets Mean                                  -1.39322
trainer/Q Targets Std                                    0.92149
trainer/Q Targets Max                                    0.25076
trainer/Q Targets Min                                   -4.34424
trainer/Log Pis Mean                                     2.00936
trainer/Log Pis Std                                      1.2751
trainer/Log Pis Max                                      7.2115
trainer/Log Pis Min                                     -2.76747
trainer/Policy mu Mean                                  -0.0637537
trainer/Policy mu Std                                    0.472391
trainer/Policy mu Max                                    1.77639
trainer/Policy mu Min                                   -2.75743
trainer/Policy log std Mean                             -2.21302
trainer/Policy log std Std                               0.462733
trainer/Policy log std Max                              -0.279134
trainer/Policy log std Min                              -3.28734
trainer/Alpha                                            0.0127927
trainer/Alpha Loss                                       0.0407854
exploration/num steps total                           2200
exploration/num paths total                            110
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.14003
exploration/Rewards Std                                  0.137195
exploration/Rewards Max                                  0.132234
exploration/Rewards Min                                 -0.559722
exploration/Returns Mean                                -2.80061
exploration/Returns Std                                  1.237
exploration/Returns Max                                 -0.973074
exploration/Returns Min                                 -4.51606
exploration/Actions Mean                                -0.00701851
exploration/Actions Std                                  0.135585
exploration/Actions Max                                  0.571948
exploration/Actions Min                                 -0.492968
exploration/Num Paths                                    5
exploration/Average Returns                             -2.80061
exploration/env_infos/final/reward_energy Mean          -0.232621
exploration/env_infos/final/reward_energy Std            0.165877
exploration/env_infos/final/reward_energy Max           -0.0789651
exploration/env_infos/final/reward_energy Min           -0.549325
exploration/env_infos/initial/reward_energy Mean        -0.144429
exploration/env_infos/initial/reward_energy Std          0.0689264
exploration/env_infos/initial/reward_energy Max         -0.0346935
exploration/env_infos/initial/reward_energy Min         -0.230218
exploration/env_infos/reward_energy Mean                -0.151032
exploration/env_infos/reward_energy Std                  0.118552
exploration/env_infos/reward_energy Max                 -0.0134996
exploration/env_infos/reward_energy Min                 -0.602096
exploration/env_infos/final/end_effector_loc Mean       -0.220927
exploration/env_infos/final/end_effector_loc Std         0.338806
exploration/env_infos/final/end_effector_loc Max         0.14522
exploration/env_infos/final/end_effector_loc Min        -0.909788
exploration/env_infos/initial/end_effector_loc Mean     -0.00311971
exploration/env_infos/initial/end_effector_loc Std       0.00472024
exploration/env_infos/initial/end_effector_loc Max       0.00161949
exploration/env_infos/initial/end_effector_loc Min      -0.0114264
exploration/env_infos/end_effector_loc Mean             -0.108288
exploration/env_infos/end_effector_loc Std               0.217916
exploration/env_infos/end_effector_loc Max               0.284327
exploration/env_infos/end_effector_loc Min              -0.909788
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00253621
exploration/env_infos/final/reward_dist Std              0.00506593
exploration/env_infos/final/reward_dist Max              0.0126681
exploration/env_infos/final/reward_dist Min              1.34205e-40
exploration/env_infos/initial/reward_dist Mean           0.00887392
exploration/env_infos/initial/reward_dist Std            0.0114519
exploration/env_infos/initial/reward_dist Max            0.0302252
exploration/env_infos/initial/reward_dist Min            1.60277e-06
exploration/env_infos/reward_dist Mean                   0.0320645
exploration/env_infos/reward_dist Std                    0.123757
exploration/env_infos/reward_dist Max                    0.95272
exploration/env_infos/reward_dist Min                    1.34205e-40
evaluation/num steps total                           12000
evaluation/num paths total                             600
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.14179
evaluation/Rewards Std                                   0.136454
evaluation/Rewards Max                                   0.091728
evaluation/Rewards Min                                  -0.82859
evaluation/Returns Mean                                 -2.83581
evaluation/Returns Std                                   2.13946
evaluation/Returns Max                                  -0.225931
evaluation/Returns Min                                 -11.3657
evaluation/Actions Mean                                  0.00817326
evaluation/Actions Std                                   0.112406
evaluation/Actions Max                                   0.910201
evaluation/Actions Min                                  -0.408841
evaluation/Num Paths                                    50
evaluation/Average Returns                              -2.83581
evaluation/env_infos/final/reward_energy Mean           -0.100055
evaluation/env_infos/final/reward_energy Std             0.111297
evaluation/env_infos/final/reward_energy Max            -0.00790734
evaluation/env_infos/final/reward_energy Min            -0.620007
evaluation/env_infos/initial/reward_energy Mean         -0.245173
evaluation/env_infos/initial/reward_energy Std           0.234442
evaluation/env_infos/initial/reward_energy Max          -0.0127712
evaluation/env_infos/initial/reward_energy Min          -1.08664
evaluation/env_infos/reward_energy Mean                 -0.108778
evaluation/env_infos/reward_energy Std                   0.116495
evaluation/env_infos/reward_energy Max                  -0.00161064
evaluation/env_infos/reward_energy Min                  -1.14347
evaluation/env_infos/final/end_effector_loc Mean         0.165701
evaluation/env_infos/final/end_effector_loc Std          0.449017
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.686507
evaluation/env_infos/initial/end_effector_loc Mean       0.00462898
evaluation/env_infos/initial/end_effector_loc Std        0.0110641
evaluation/env_infos/initial/end_effector_loc Max        0.0455101
evaluation/env_infos/initial/end_effector_loc Min       -0.020442
evaluation/env_infos/end_effector_loc Mean               0.11121
evaluation/env_infos/end_effector_loc Std                0.307873
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.686507
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.00817674
evaluation/env_infos/final/reward_dist Std               0.0339838
evaluation/env_infos/final/reward_dist Max               0.227306
evaluation/env_infos/final/reward_dist Min               2.98509e-159
evaluation/env_infos/initial/reward_dist Mean            0.00668653
evaluation/env_infos/initial/reward_dist Std             0.0120215
evaluation/env_infos/initial/reward_dist Max             0.0602302
evaluation/env_infos/initial/reward_dist Min             1.5313e-06
evaluation/env_infos/reward_dist Mean                    0.0468068
evaluation/env_infos/reward_dist Std                     0.135049
evaluation/env_infos/reward_dist Max                     0.983632
evaluation/env_infos/reward_dist Min                     2.98509e-159
time/data storing (s)                                    8.42663
time/evaluation sampling (s)                             0.651199
time/exploration sampling (s)                            0.0895228
time/logging (s)                                         0.0144526
time/saving (s)                                          0.226755
time/training (s)                                       32.9267
time/epoch (s)                                          42.3353
time/total (s)                                         482.446
Epoch                                                   11
---------------------------------------------------  ----------------
2021-05-29 00:04:38.974360 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 12 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00175095
trainer/QF2 Loss                                         0.00206241
trainer/Policy Loss                                      3.35992
trainer/Q1 Predictions Mean                             -1.47799
trainer/Q1 Predictions Std                               0.99351
trainer/Q1 Predictions Max                               0.217001
trainer/Q1 Predictions Min                              -5.32712
trainer/Q2 Predictions Mean                             -1.4752
trainer/Q2 Predictions Std                               0.980857
trainer/Q2 Predictions Max                               0.225164
trainer/Q2 Predictions Min                              -5.21265
trainer/Q Targets Mean                                  -1.46583
trainer/Q Targets Std                                    0.984671
trainer/Q Targets Max                                    0.258597
trainer/Q Targets Min                                   -5.40526
trainer/Log Pis Mean                                     1.92005
trainer/Log Pis Std                                      1.17458
trainer/Log Pis Max                                      6.95676
trainer/Log Pis Min                                     -1.07323
trainer/Policy mu Mean                                  -0.0645223
trainer/Policy mu Std                                    0.517308
trainer/Policy mu Max                                    2.48706
trainer/Policy mu Min                                   -2.46902
trainer/Policy log std Mean                             -2.14787
trainer/Policy log std Std                               0.580763
trainer/Policy log std Max                              -0.0603789
trainer/Policy log std Min                              -3.36286
trainer/Alpha                                            0.0143705
trainer/Alpha Loss                                      -0.339187
exploration/num steps total                           2300
exploration/num paths total                            115
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.152051
exploration/Rewards Std                                  0.0966231
exploration/Rewards Max                                  0.0795783
exploration/Rewards Min                                 -0.47167
exploration/Returns Mean                                -3.04101
exploration/Returns Std                                  1.36337
exploration/Returns Max                                 -1.04763
exploration/Returns Min                                 -5.05685
exploration/Actions Mean                                 0.0183094
exploration/Actions Std                                  0.16358
exploration/Actions Max                                  0.808918
exploration/Actions Min                                 -0.622419
exploration/Num Paths                                    5
exploration/Average Returns                             -3.04101
exploration/env_infos/final/reward_energy Mean          -0.152061
exploration/env_infos/final/reward_energy Std            0.0682361
exploration/env_infos/final/reward_energy Max           -0.044994
exploration/env_infos/final/reward_energy Min           -0.23742
exploration/env_infos/initial/reward_energy Mean        -0.31827
exploration/env_infos/initial/reward_energy Std          0.29118
exploration/env_infos/initial/reward_energy Max         -0.0882212
exploration/env_infos/initial/reward_energy Min         -0.87686
exploration/env_infos/reward_energy Mean                -0.186695
exploration/env_infos/reward_energy Std                  0.13904
exploration/env_infos/reward_energy Max                 -0.0216913
exploration/env_infos/reward_energy Min                 -0.87686
exploration/env_infos/final/end_effector_loc Mean        0.199337
exploration/env_infos/final/end_effector_loc Std         0.457454
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.448079
exploration/env_infos/initial/end_effector_loc Mean      0.00919508
exploration/env_infos/initial/end_effector_loc Std       0.0121677
exploration/env_infos/initial/end_effector_loc Max       0.0404459
exploration/env_infos/initial/end_effector_loc Min      -0.00454744
exploration/env_infos/end_effector_loc Mean              0.113915
exploration/env_infos/end_effector_loc Std               0.298304
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.448079
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.000139133
exploration/env_infos/final/reward_dist Std              0.000182709
exploration/env_infos/final/reward_dist Max              0.000452145
exploration/env_infos/final/reward_dist Min              1.40286e-61
exploration/env_infos/initial/reward_dist Mean           0.0245675
exploration/env_infos/initial/reward_dist Std            0.0300331
exploration/env_infos/initial/reward_dist Max            0.0810954
exploration/env_infos/initial/reward_dist Min            5.30078e-06
exploration/env_infos/reward_dist Mean                   0.095641
exploration/env_infos/reward_dist Std                    0.1963
exploration/env_infos/reward_dist Max                    0.957554
exploration/env_infos/reward_dist Min                    1.40286e-61
evaluation/num steps total                           13000
evaluation/num paths total                             650
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0973101
evaluation/Rewards Std                                   0.0863025
evaluation/Rewards Max                                   0.11236
evaluation/Rewards Min                                  -0.613893
evaluation/Returns Mean                                 -1.9462
evaluation/Returns Std                                   1.44836
evaluation/Returns Max                                   0.807913
evaluation/Returns Min                                  -7.69593
evaluation/Actions Mean                                  0.00559016
evaluation/Actions Std                                   0.0865201
evaluation/Actions Max                                   0.732702
evaluation/Actions Min                                  -0.412964
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.9462
evaluation/env_infos/final/reward_energy Mean           -0.0918193
evaluation/env_infos/final/reward_energy Std             0.0785202
evaluation/env_infos/final/reward_energy Max            -0.00862406
evaluation/env_infos/final/reward_energy Min            -0.406562
evaluation/env_infos/initial/reward_energy Mean         -0.178636
evaluation/env_infos/initial/reward_energy Std           0.177393
evaluation/env_infos/initial/reward_energy Max          -0.0111315
evaluation/env_infos/initial/reward_energy Min          -0.920337
evaluation/env_infos/reward_energy Mean                 -0.0885217
evaluation/env_infos/reward_energy Std                   0.0848402
evaluation/env_infos/reward_energy Max                  -0.00164775
evaluation/env_infos/reward_energy Min                  -0.920337
evaluation/env_infos/final/end_effector_loc Mean         0.0952843
evaluation/env_infos/final/end_effector_loc Std          0.320702
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.514858
evaluation/env_infos/initial/end_effector_loc Mean       0.00204379
evaluation/env_infos/initial/end_effector_loc Std        0.00866296
evaluation/env_infos/initial/end_effector_loc Max        0.0366351
evaluation/env_infos/initial/end_effector_loc Min       -0.0145822
evaluation/env_infos/end_effector_loc Mean               0.0542179
evaluation/env_infos/end_effector_loc Std                0.213963
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.514858
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0221077
evaluation/env_infos/final/reward_dist Std               0.073885
evaluation/env_infos/final/reward_dist Max               0.4239
evaluation/env_infos/final/reward_dist Min               9.03087e-155
evaluation/env_infos/initial/reward_dist Mean            0.00540434
evaluation/env_infos/initial/reward_dist Std             0.00925081
evaluation/env_infos/initial/reward_dist Max             0.0421358
evaluation/env_infos/initial/reward_dist Min             1.34646e-06
evaluation/env_infos/reward_dist Mean                    0.0537068
evaluation/env_infos/reward_dist Std                     0.132516
evaluation/env_infos/reward_dist Max                     0.993787
evaluation/env_infos/reward_dist Min                     9.03087e-155
time/data storing (s)                                    8.93085
time/evaluation sampling (s)                             0.646016
time/exploration sampling (s)                            0.0914421
time/logging (s)                                         0.0140505
time/saving (s)                                          0.203956
time/training (s)                                       33.8499
time/epoch (s)                                          43.7362
time/total (s)                                         526.348
Epoch                                                   12
---------------------------------------------------  ----------------
2021-05-29 00:05:23.067255 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 13 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00192006
trainer/QF2 Loss                                         0.00346712
trainer/Policy Loss                                      3.24269
trainer/Q1 Predictions Mean                             -1.34211
trainer/Q1 Predictions Std                               0.919576
trainer/Q1 Predictions Max                               0.345886
trainer/Q1 Predictions Min                              -4.47782
trainer/Q2 Predictions Mean                             -1.34576
trainer/Q2 Predictions Std                               0.910146
trainer/Q2 Predictions Max                               0.221611
trainer/Q2 Predictions Min                              -4.59298
trainer/Q Targets Mean                                  -1.34909
trainer/Q Targets Std                                    0.922302
trainer/Q Targets Max                                    0.344815
trainer/Q Targets Min                                   -4.49738
trainer/Log Pis Mean                                     1.92953
trainer/Log Pis Std                                      1.31095
trainer/Log Pis Max                                      8.37989
trainer/Log Pis Min                                     -3.41902
trainer/Policy mu Mean                                   0.00776175
trainer/Policy mu Std                                    0.491343
trainer/Policy mu Max                                    3.80518
trainer/Policy mu Min                                   -3.26725
trainer/Policy log std Mean                             -2.20667
trainer/Policy log std Std                               0.560081
trainer/Policy log std Max                               0.0511473
trainer/Policy log std Min                              -3.33955
trainer/Alpha                                            0.013669
trainer/Alpha Loss                                      -0.302468
exploration/num steps total                           2400
exploration/num paths total                            120
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.141204
exploration/Rewards Std                                  0.0748686
exploration/Rewards Max                                 -0.00725285
exploration/Rewards Min                                 -0.366797
exploration/Returns Mean                                -2.82407
exploration/Returns Std                                  1.07613
exploration/Returns Max                                 -1.38161
exploration/Returns Min                                 -4.32338
exploration/Actions Mean                                -0.00432933
exploration/Actions Std                                  0.150865
exploration/Actions Max                                  0.585428
exploration/Actions Min                                 -0.815147
exploration/Num Paths                                    5
exploration/Average Returns                             -2.82407
exploration/env_infos/final/reward_energy Mean          -0.151546
exploration/env_infos/final/reward_energy Std            0.0626553
exploration/env_infos/final/reward_energy Max           -0.0691743
exploration/env_infos/final/reward_energy Min           -0.243593
exploration/env_infos/initial/reward_energy Mean        -0.324653
exploration/env_infos/initial/reward_energy Std          0.345032
exploration/env_infos/initial/reward_energy Max         -0.0782055
exploration/env_infos/initial/reward_energy Min         -1.00359
exploration/env_infos/reward_energy Mean                -0.169262
exploration/env_infos/reward_energy Std                  0.130032
exploration/env_infos/reward_energy Max                 -0.0058261
exploration/env_infos/reward_energy Min                 -1.00359
exploration/env_infos/final/end_effector_loc Mean       -0.0516454
exploration/env_infos/final/end_effector_loc Std         0.211902
exploration/env_infos/final/end_effector_loc Max         0.522661
exploration/env_infos/final/end_effector_loc Min        -0.23305
exploration/env_infos/initial/end_effector_loc Mean      0.000954861
exploration/env_infos/initial/end_effector_loc Std       0.0167226
exploration/env_infos/initial/end_effector_loc Max       0.0292714
exploration/env_infos/initial/end_effector_loc Min      -0.0407573
exploration/env_infos/end_effector_loc Mean             -0.0229777
exploration/env_infos/end_effector_loc Std               0.157423
exploration/env_infos/end_effector_loc Max               0.522661
exploration/env_infos/end_effector_loc Min              -0.395834
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00179875
exploration/env_infos/final/reward_dist Std              0.00355651
exploration/env_infos/final/reward_dist Max              0.0089115
exploration/env_infos/final/reward_dist Min              2.03559e-32
exploration/env_infos/initial/reward_dist Mean           0.00588604
exploration/env_infos/initial/reward_dist Std            0.00714784
exploration/env_infos/initial/reward_dist Max            0.0154973
exploration/env_infos/initial/reward_dist Min            8.80245e-06
exploration/env_infos/reward_dist Mean                   0.0316129
exploration/env_infos/reward_dist Std                    0.138902
exploration/env_infos/reward_dist Max                    0.97615
exploration/env_infos/reward_dist Min                    2.03559e-32
evaluation/num steps total                           14000
evaluation/num paths total                             700
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.113038
evaluation/Rewards Std                                   0.0884407
evaluation/Rewards Max                                   0.0487014
evaluation/Rewards Min                                  -0.771276
evaluation/Returns Mean                                 -2.26076
evaluation/Returns Std                                   1.26724
evaluation/Returns Max                                   0.0157727
evaluation/Returns Min                                  -8.12202
evaluation/Actions Mean                                  0.0128145
evaluation/Actions Std                                   0.0813973
evaluation/Actions Max                                   0.695188
evaluation/Actions Min                                  -0.590974
evaluation/Num Paths                                    50
evaluation/Average Returns                              -2.26076
evaluation/env_infos/final/reward_energy Mean           -0.0750114
evaluation/env_infos/final/reward_energy Std             0.0788753
evaluation/env_infos/final/reward_energy Max            -0.00847904
evaluation/env_infos/final/reward_energy Min            -0.459945
evaluation/env_infos/initial/reward_energy Mean         -0.15631
evaluation/env_infos/initial/reward_energy Std           0.168373
evaluation/env_infos/initial/reward_energy Max          -0.0212986
evaluation/env_infos/initial/reward_energy Min          -0.729944
evaluation/env_infos/reward_energy Mean                 -0.0824245
evaluation/env_infos/reward_energy Std                   0.0823752
evaluation/env_infos/reward_energy Max                  -0.00481205
evaluation/env_infos/reward_energy Min                  -0.729944
evaluation/env_infos/final/end_effector_loc Mean         0.197304
evaluation/env_infos/final/end_effector_loc Std          0.304378
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.389984
evaluation/env_infos/initial/end_effector_loc Mean       0.00241775
evaluation/env_infos/initial/end_effector_loc Std        0.0077545
evaluation/env_infos/initial/end_effector_loc Max        0.0347594
evaluation/env_infos/initial/end_effector_loc Min       -0.0295487
evaluation/env_infos/end_effector_loc Mean               0.0886527
evaluation/env_infos/end_effector_loc Std                0.190171
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.389984
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0176867
evaluation/env_infos/final/reward_dist Std               0.0565622
evaluation/env_infos/final/reward_dist Max               0.358292
evaluation/env_infos/final/reward_dist Min               1.59219e-109
evaluation/env_infos/initial/reward_dist Mean            0.0058618
evaluation/env_infos/initial/reward_dist Std             0.00968996
evaluation/env_infos/initial/reward_dist Max             0.0404013
evaluation/env_infos/initial/reward_dist Min             1.61498e-06
evaluation/env_infos/reward_dist Mean                    0.0609772
evaluation/env_infos/reward_dist Std                     0.164686
evaluation/env_infos/reward_dist Max                     0.985252
evaluation/env_infos/reward_dist Min                     1.59219e-109
time/data storing (s)                                    9.2139
time/evaluation sampling (s)                             0.648164
time/exploration sampling (s)                            0.0876119
time/logging (s)                                         0.014611
time/saving (s)                                          0.206361
time/training (s)                                       33.7483
time/epoch (s)                                          43.9189
time/total (s)                                         570.439
Epoch                                                   13
---------------------------------------------------  ----------------
2021-05-29 00:06:07.838376 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 14 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00281228
trainer/QF2 Loss                                         0.00322789
trainer/Policy Loss                                      3.38695
trainer/Q1 Predictions Mean                             -1.25808
trainer/Q1 Predictions Std                               0.899347
trainer/Q1 Predictions Max                               0.229089
trainer/Q1 Predictions Min                              -5.75855
trainer/Q2 Predictions Mean                             -1.29978
trainer/Q2 Predictions Std                               0.911463
trainer/Q2 Predictions Max                               0.240056
trainer/Q2 Predictions Min                              -5.76577
trainer/Q Targets Mean                                  -1.27803
trainer/Q Targets Std                                    0.911606
trainer/Q Targets Max                                    0.269721
trainer/Q Targets Min                                   -5.80167
trainer/Log Pis Mean                                     2.12778
trainer/Log Pis Std                                      1.25238
trainer/Log Pis Max                                      6.28097
trainer/Log Pis Min                                     -3.68263
trainer/Policy mu Mean                                  -0.0184511
trainer/Policy mu Std                                    0.50882
trainer/Policy mu Max                                    2.03249
trainer/Policy mu Min                                   -2.82859
trainer/Policy log std Mean                             -2.27963
trainer/Policy log std Std                               0.593886
trainer/Policy log std Max                              -0.322065
trainer/Policy log std Min                              -3.63902
trainer/Alpha                                            0.0126283
trainer/Alpha Loss                                       0.558633
exploration/num steps total                           2500
exploration/num paths total                            125
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.148883
exploration/Rewards Std                                  0.0895044
exploration/Rewards Max                                  0.0232214
exploration/Rewards Min                                 -0.352088
exploration/Returns Mean                                -2.97766
exploration/Returns Std                                  1.49455
exploration/Returns Max                                 -1.20346
exploration/Returns Min                                 -5.73749
exploration/Actions Mean                                 0.000716124
exploration/Actions Std                                  0.100933
exploration/Actions Max                                  0.356035
exploration/Actions Min                                 -0.284268
exploration/Num Paths                                    5
exploration/Average Returns                             -2.97766
exploration/env_infos/final/reward_energy Mean          -0.0967843
exploration/env_infos/final/reward_energy Std            0.0889146
exploration/env_infos/final/reward_energy Max           -0.0275227
exploration/env_infos/final/reward_energy Min           -0.268318
exploration/env_infos/initial/reward_energy Mean        -0.10125
exploration/env_infos/initial/reward_energy Std          0.035006
exploration/env_infos/initial/reward_energy Max         -0.0557749
exploration/env_infos/initial/reward_energy Min         -0.154963
exploration/env_infos/reward_energy Mean                -0.11519
exploration/env_infos/reward_energy Std                  0.0843054
exploration/env_infos/reward_energy Max                 -0.0112882
exploration/env_infos/reward_energy Min                 -0.408972
exploration/env_infos/final/end_effector_loc Mean        0.0544677
exploration/env_infos/final/end_effector_loc Std         0.328782
exploration/env_infos/final/end_effector_loc Max         0.500433
exploration/env_infos/final/end_effector_loc Min        -0.46459
exploration/env_infos/initial/end_effector_loc Mean     -0.000626684
exploration/env_infos/initial/end_effector_loc Std       0.00373545
exploration/env_infos/initial/end_effector_loc Max       0.00563766
exploration/env_infos/initial/end_effector_loc Min      -0.00663069
exploration/env_infos/end_effector_loc Mean              0.0335523
exploration/env_infos/end_effector_loc Std               0.190184
exploration/env_infos/end_effector_loc Max               0.500433
exploration/env_infos/end_effector_loc Min              -0.46459
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.000683956
exploration/env_infos/final/reward_dist Std              0.00136739
exploration/env_infos/final/reward_dist Max              0.00341873
exploration/env_infos/final/reward_dist Min              1.60369e-34
exploration/env_infos/initial/reward_dist Mean           0.00325041
exploration/env_infos/initial/reward_dist Std            0.00328587
exploration/env_infos/initial/reward_dist Max            0.00844226
exploration/env_infos/initial/reward_dist Min            1.15457e-06
exploration/env_infos/reward_dist Mean                   0.0927991
exploration/env_infos/reward_dist Std                    0.213091
exploration/env_infos/reward_dist Max                    0.945033
exploration/env_infos/reward_dist Min                    1.60369e-34
evaluation/num steps total                           15000
evaluation/num paths total                             750
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.080129
evaluation/Rewards Std                                   0.0860715
evaluation/Rewards Max                                   0.159771
evaluation/Rewards Min                                  -0.436649
evaluation/Returns Mean                                 -1.60258
evaluation/Returns Std                                   1.46453
evaluation/Returns Max                                   1.48354
evaluation/Returns Min                                  -5.91543
evaluation/Actions Mean                                 -0.00244183
evaluation/Actions Std                                   0.0822584
evaluation/Actions Max                                   0.543426
evaluation/Actions Min                                  -0.513207
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.60258
evaluation/env_infos/final/reward_energy Mean           -0.0829766
evaluation/env_infos/final/reward_energy Std             0.0721934
evaluation/env_infos/final/reward_energy Max            -0.00774944
evaluation/env_infos/final/reward_energy Min            -0.311491
evaluation/env_infos/initial/reward_energy Mean         -0.127067
evaluation/env_infos/initial/reward_energy Std           0.123259
evaluation/env_infos/initial/reward_energy Max          -0.00634751
evaluation/env_infos/initial/reward_energy Min          -0.647234
evaluation/env_infos/reward_energy Mean                 -0.0841032
evaluation/env_infos/reward_energy Std                   0.0804454
evaluation/env_infos/reward_energy Max                  -0.00328579
evaluation/env_infos/reward_energy Min                  -0.647234
evaluation/env_infos/final/end_effector_loc Mean         0.0648334
evaluation/env_infos/final/end_effector_loc Std          0.308125
evaluation/env_infos/final/end_effector_loc Max          0.945998
evaluation/env_infos/final/end_effector_loc Min         -0.731493
evaluation/env_infos/initial/end_effector_loc Mean       0.000863185
evaluation/env_infos/initial/end_effector_loc Std        0.00619907
evaluation/env_infos/initial/end_effector_loc Max        0.0271713
evaluation/env_infos/initial/end_effector_loc Min       -0.0256603
evaluation/env_infos/end_effector_loc Mean               0.0415732
evaluation/env_infos/end_effector_loc Std                0.183659
evaluation/env_infos/end_effector_loc Max                0.945998
evaluation/env_infos/end_effector_loc Min               -0.731493
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0763276
evaluation/env_infos/final/reward_dist Std               0.185702
evaluation/env_infos/final/reward_dist Max               0.875993
evaluation/env_infos/final/reward_dist Min               1.27799e-60
evaluation/env_infos/initial/reward_dist Mean            0.00661394
evaluation/env_infos/initial/reward_dist Std             0.013427
evaluation/env_infos/initial/reward_dist Max             0.075611
evaluation/env_infos/initial/reward_dist Min             1.14945e-06
evaluation/env_infos/reward_dist Mean                    0.0996683
evaluation/env_infos/reward_dist Std                     0.206637
evaluation/env_infos/reward_dist Max                     0.994511
evaluation/env_infos/reward_dist Min                     1.27799e-60
time/data storing (s)                                    9.65792
time/evaluation sampling (s)                             0.910482
time/exploration sampling (s)                            0.0946925
time/logging (s)                                         0.0177431
time/saving (s)                                          0.218665
time/training (s)                                       33.6578
time/epoch (s)                                          44.5573
time/total (s)                                         615.212
Epoch                                                   14
---------------------------------------------------  ---------------
2021-05-29 00:06:52.569183 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 15 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00308619
trainer/QF2 Loss                                         0.00554636
trainer/Policy Loss                                      3.42921
trainer/Q1 Predictions Mean                             -1.34065
trainer/Q1 Predictions Std                               0.940613
trainer/Q1 Predictions Max                               0.49563
trainer/Q1 Predictions Min                              -4.43159
trainer/Q2 Predictions Mean                             -1.30751
trainer/Q2 Predictions Std                               0.917404
trainer/Q2 Predictions Max                               0.463624
trainer/Q2 Predictions Min                              -4.35222
trainer/Q Targets Mean                                  -1.31439
trainer/Q Targets Std                                    0.935419
trainer/Q Targets Max                                    0.445645
trainer/Q Targets Min                                   -4.43786
trainer/Log Pis Mean                                     2.11731
trainer/Log Pis Std                                      1.48298
trainer/Log Pis Max                                      7.30162
trainer/Log Pis Min                                     -1.95633
trainer/Policy mu Mean                                  -0.00487451
trainer/Policy mu Std                                    0.518859
trainer/Policy mu Max                                    2.84266
trainer/Policy mu Min                                   -2.95707
trainer/Policy log std Mean                             -2.29767
trainer/Policy log std Std                               0.594047
trainer/Policy log std Max                              -0.313489
trainer/Policy log std Min                              -3.74029
trainer/Alpha                                            0.0136707
trainer/Alpha Loss                                       0.503619
exploration/num steps total                           2600
exploration/num paths total                            130
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.115225
exploration/Rewards Std                                  0.0849793
exploration/Rewards Max                                  0.0999731
exploration/Rewards Min                                 -0.380122
exploration/Returns Mean                                -2.30451
exploration/Returns Std                                  0.926251
exploration/Returns Max                                 -0.811557
exploration/Returns Min                                 -3.22014
exploration/Actions Mean                                -0.00774631
exploration/Actions Std                                  0.112595
exploration/Actions Max                                  0.355372
exploration/Actions Min                                 -0.342408
exploration/Num Paths                                    5
exploration/Average Returns                             -2.30451
exploration/env_infos/final/reward_energy Mean          -0.218347
exploration/env_infos/final/reward_energy Std            0.146457
exploration/env_infos/final/reward_energy Max           -0.0644677
exploration/env_infos/final/reward_energy Min           -0.49349
exploration/env_infos/initial/reward_energy Mean        -0.122139
exploration/env_infos/initial/reward_energy Std          0.0451321
exploration/env_infos/initial/reward_energy Max         -0.0671358
exploration/env_infos/initial/reward_energy Min         -0.200109
exploration/env_infos/reward_energy Mean                -0.127542
exploration/env_infos/reward_energy Std                  0.0959608
exploration/env_infos/reward_energy Max                 -0.00805193
exploration/env_infos/reward_energy Min                 -0.49349
exploration/env_infos/final/end_effector_loc Mean       -0.0791478
exploration/env_infos/final/end_effector_loc Std         0.343611
exploration/env_infos/final/end_effector_loc Max         0.616173
exploration/env_infos/final/end_effector_loc Min        -0.555671
exploration/env_infos/initial/end_effector_loc Mean     -0.00230484
exploration/env_infos/initial/end_effector_loc Std       0.00398513
exploration/env_infos/initial/end_effector_loc Max       0.00644471
exploration/env_infos/initial/end_effector_loc Min      -0.00729156
exploration/env_infos/end_effector_loc Mean             -0.0358347
exploration/env_infos/end_effector_loc Std               0.193358
exploration/env_infos/end_effector_loc Max               0.616173
exploration/env_infos/end_effector_loc Min              -0.555671
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             1.2322e-05
exploration/env_infos/final/reward_dist Std              2.4644e-05
exploration/env_infos/final/reward_dist Max              6.16099e-05
exploration/env_infos/final/reward_dist Min              2.55293e-26
exploration/env_infos/initial/reward_dist Mean           0.000796886
exploration/env_infos/initial/reward_dist Std            0.00126718
exploration/env_infos/initial/reward_dist Max            0.00332117
exploration/env_infos/initial/reward_dist Min            4.80289e-06
exploration/env_infos/reward_dist Mean                   0.033512
exploration/env_infos/reward_dist Std                    0.092066
exploration/env_infos/reward_dist Max                    0.398306
exploration/env_infos/reward_dist Min                    2.55293e-26
evaluation/num steps total                           16000
evaluation/num paths total                             800
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0788561
evaluation/Rewards Std                                   0.0693884
evaluation/Rewards Max                                   0.141162
evaluation/Rewards Min                                  -0.475337
evaluation/Returns Mean                                 -1.57712
evaluation/Returns Std                                   1.02879
evaluation/Returns Max                                   0.381957
evaluation/Returns Min                                  -4.5267
evaluation/Actions Mean                                  0.00422067
evaluation/Actions Std                                   0.0828517
evaluation/Actions Max                                   0.759615
evaluation/Actions Min                                  -0.412697
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.57712
evaluation/env_infos/final/reward_energy Mean           -0.0818541
evaluation/env_infos/final/reward_energy Std             0.0604987
evaluation/env_infos/final/reward_energy Max            -0.00659272
evaluation/env_infos/final/reward_energy Min            -0.276972
evaluation/env_infos/initial/reward_energy Mean         -0.157412
evaluation/env_infos/initial/reward_energy Std           0.150565
evaluation/env_infos/initial/reward_energy Max          -0.00807021
evaluation/env_infos/initial/reward_energy Min          -0.860326
evaluation/env_infos/reward_energy Mean                 -0.0803425
evaluation/env_infos/reward_energy Std                   0.0854957
evaluation/env_infos/reward_energy Max                  -0.0018439
evaluation/env_infos/reward_energy Min                  -0.860326
evaluation/env_infos/final/end_effector_loc Mean         0.0773903
evaluation/env_infos/final/end_effector_loc Std          0.294206
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.651816
evaluation/env_infos/initial/end_effector_loc Mean       0.00182634
evaluation/env_infos/initial/end_effector_loc Std        0.00748165
evaluation/env_infos/initial/end_effector_loc Max        0.0379808
evaluation/env_infos/initial/end_effector_loc Min       -0.014389
evaluation/env_infos/end_effector_loc Mean               0.0460674
evaluation/env_infos/end_effector_loc Std                0.193232
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.651816
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0634437
evaluation/env_infos/final/reward_dist Std               0.143631
evaluation/env_infos/final/reward_dist Max               0.581277
evaluation/env_infos/final/reward_dist Min               2.22066e-59
evaluation/env_infos/initial/reward_dist Mean            0.00787646
evaluation/env_infos/initial/reward_dist Std             0.0157304
evaluation/env_infos/initial/reward_dist Max             0.0855427
evaluation/env_infos/initial/reward_dist Min             1.22604e-06
evaluation/env_infos/reward_dist Mean                    0.0912154
evaluation/env_infos/reward_dist Std                     0.199066
evaluation/env_infos/reward_dist Max                     0.974861
evaluation/env_infos/reward_dist Min                     2.22066e-59
time/data storing (s)                                    9.96882
time/evaluation sampling (s)                             0.671968
time/exploration sampling (s)                            0.0971353
time/logging (s)                                         0.0148344
time/saving (s)                                          0.22041
time/training (s)                                       33.5632
time/epoch (s)                                          44.5363
time/total (s)                                         659.937
Epoch                                                   15
---------------------------------------------------  ---------------
2021-05-29 00:07:38.148049 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 16 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00268808
trainer/QF2 Loss                                         0.00179939
trainer/Policy Loss                                      2.96328
trainer/Q1 Predictions Mean                             -1.16146
trainer/Q1 Predictions Std                               0.857054
trainer/Q1 Predictions Max                               0.367167
trainer/Q1 Predictions Min                              -4.76769
trainer/Q2 Predictions Mean                             -1.15114
trainer/Q2 Predictions Std                               0.847783
trainer/Q2 Predictions Max                               0.40024
trainer/Q2 Predictions Min                              -4.71283
trainer/Q Targets Mean                                  -1.17046
trainer/Q Targets Std                                    0.851963
trainer/Q Targets Max                                    0.348887
trainer/Q Targets Min                                   -4.68462
trainer/Log Pis Mean                                     1.82964
trainer/Log Pis Std                                      1.42975
trainer/Log Pis Max                                      6.9841
trainer/Log Pis Min                                     -3.00971
trainer/Policy mu Mean                                   0.00461208
trainer/Policy mu Std                                    0.546088
trainer/Policy mu Max                                    3.04551
trainer/Policy mu Min                                   -3.1557
trainer/Policy log std Mean                             -2.12817
trainer/Policy log std Std                               0.640878
trainer/Policy log std Max                              -0.0265167
trainer/Policy log std Min                              -3.36916
trainer/Alpha                                            0.0140515
trainer/Alpha Loss                                      -0.726729
exploration/num steps total                           2700
exploration/num paths total                            135
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.170359
exploration/Rewards Std                                  0.167335
exploration/Rewards Max                                  0.0575446
exploration/Rewards Min                                 -0.775444
exploration/Returns Mean                                -3.40717
exploration/Returns Std                                  2.53428
exploration/Returns Max                                 -0.132866
exploration/Returns Min                                 -7.78877
exploration/Actions Mean                                 0.00776483
exploration/Actions Std                                  0.154436
exploration/Actions Max                                  0.493456
exploration/Actions Min                                 -0.401302
exploration/Num Paths                                    5
exploration/Average Returns                             -3.40717
exploration/env_infos/final/reward_energy Mean          -0.244127
exploration/env_infos/final/reward_energy Std            0.122994
exploration/env_infos/final/reward_energy Max           -0.14262
exploration/env_infos/final/reward_energy Min           -0.479293
exploration/env_infos/initial/reward_energy Mean        -0.135539
exploration/env_infos/initial/reward_energy Std          0.0953212
exploration/env_infos/initial/reward_energy Max         -0.0270702
exploration/env_infos/initial/reward_energy Min         -0.297982
exploration/env_infos/reward_energy Mean                -0.173071
exploration/env_infos/reward_energy Std                  0.133671
exploration/env_infos/reward_energy Max                 -0.00882001
exploration/env_infos/reward_energy Min                 -0.533367
exploration/env_infos/final/end_effector_loc Mean        0.175718
exploration/env_infos/final/end_effector_loc Std         0.425579
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.54599
exploration/env_infos/initial/end_effector_loc Mean      0.000208753
exploration/env_infos/initial/end_effector_loc Std       0.00585471
exploration/env_infos/initial/end_effector_loc Max       0.0119387
exploration/env_infos/initial/end_effector_loc Min      -0.00891355
exploration/env_infos/end_effector_loc Mean              0.0796776
exploration/env_infos/end_effector_loc Std               0.251649
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.54599
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.04938
exploration/env_infos/final/reward_dist Std              0.0987598
exploration/env_infos/final/reward_dist Max              0.2469
exploration/env_infos/final/reward_dist Min              4.15989e-122
exploration/env_infos/initial/reward_dist Mean           0.000899827
exploration/env_infos/initial/reward_dist Std            0.00136364
exploration/env_infos/initial/reward_dist Max            0.00360675
exploration/env_infos/initial/reward_dist Min            2.19971e-05
exploration/env_infos/reward_dist Mean                   0.070891
exploration/env_infos/reward_dist Std                    0.180564
exploration/env_infos/reward_dist Max                    0.989385
exploration/env_infos/reward_dist Min                    4.15989e-122
evaluation/num steps total                           17000
evaluation/num paths total                             850
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0896932
evaluation/Rewards Std                                   0.0980894
evaluation/Rewards Max                                   0.14956
evaluation/Rewards Min                                  -0.644598
evaluation/Returns Mean                                 -1.79386
evaluation/Returns Std                                   1.64481
evaluation/Returns Max                                   2.11592
evaluation/Returns Min                                  -8.07031
evaluation/Actions Mean                                 -0.00478584
evaluation/Actions Std                                   0.0852927
evaluation/Actions Max                                   0.749278
evaluation/Actions Min                                  -0.795548
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.79386
evaluation/env_infos/final/reward_energy Mean           -0.0725478
evaluation/env_infos/final/reward_energy Std             0.0552457
evaluation/env_infos/final/reward_energy Max            -0.00540382
evaluation/env_infos/final/reward_energy Min            -0.283347
evaluation/env_infos/initial/reward_energy Mean         -0.18296
evaluation/env_infos/initial/reward_energy Std           0.219463
evaluation/env_infos/initial/reward_energy Max          -0.00443637
evaluation/env_infos/initial/reward_energy Min          -1.05589
evaluation/env_infos/reward_energy Mean                 -0.075869
evaluation/env_infos/reward_energy Std                   0.0940181
evaluation/env_infos/reward_energy Max                  -0.00148835
evaluation/env_infos/reward_energy Min                  -1.07726
evaluation/env_infos/final/end_effector_loc Mean         0.0297733
evaluation/env_infos/final/end_effector_loc Std          0.289124
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.813575
evaluation/env_infos/initial/end_effector_loc Mean       0.000178458
evaluation/env_infos/initial/end_effector_loc Std        0.0101003
evaluation/env_infos/initial/end_effector_loc Max        0.0371328
evaluation/env_infos/initial/end_effector_loc Min       -0.0397774
evaluation/env_infos/end_effector_loc Mean               0.0228048
evaluation/env_infos/end_effector_loc Std                0.187666
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.813575
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.09464
evaluation/env_infos/final/reward_dist Std               0.214138
evaluation/env_infos/final/reward_dist Max               0.869503
evaluation/env_infos/final/reward_dist Min               7.025e-104
evaluation/env_infos/initial/reward_dist Mean            0.00905923
evaluation/env_infos/initial/reward_dist Std             0.0185618
evaluation/env_infos/initial/reward_dist Max             0.115482
evaluation/env_infos/initial/reward_dist Min             1.25253e-06
evaluation/env_infos/reward_dist Mean                    0.0893384
evaluation/env_infos/reward_dist Std                     0.189393
evaluation/env_infos/reward_dist Max                     0.988731
evaluation/env_infos/reward_dist Min                     7.025e-104
time/data storing (s)                                   10.343
time/evaluation sampling (s)                             0.65762
time/exploration sampling (s)                            0.0926016
time/logging (s)                                         0.0162928
time/saving (s)                                          0.230266
time/training (s)                                       34.0307
time/epoch (s)                                          45.3705
time/total (s)                                         705.515
Epoch                                                   16
---------------------------------------------------  ----------------
2021-05-29 00:08:25.047740 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 17 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00147738
trainer/QF2 Loss                                         0.00365836
trainer/Policy Loss                                      3.09475
trainer/Q1 Predictions Mean                             -1.13424
trainer/Q1 Predictions Std                               0.8136
trainer/Q1 Predictions Max                               0.489282
trainer/Q1 Predictions Min                              -3.37317
trainer/Q2 Predictions Mean                             -1.12874
trainer/Q2 Predictions Std                               0.811246
trainer/Q2 Predictions Max                               0.47531
trainer/Q2 Predictions Min                              -3.36387
trainer/Q Targets Mean                                  -1.13435
trainer/Q Targets Std                                    0.810818
trainer/Q Targets Max                                    0.476257
trainer/Q Targets Min                                   -3.38096
trainer/Log Pis Mean                                     1.98639
trainer/Log Pis Std                                      1.41202
trainer/Log Pis Max                                      8.02408
trainer/Log Pis Min                                     -2.49393
trainer/Policy mu Mean                                  -0.0293352
trainer/Policy mu Std                                    0.468312
trainer/Policy mu Max                                    2.90301
trainer/Policy mu Min                                   -2.69302
trainer/Policy log std Mean                             -2.21269
trainer/Policy log std Std                               0.637899
trainer/Policy log std Max                              -0.207183
trainer/Policy log std Min                              -3.32433
trainer/Alpha                                            0.014616
trainer/Alpha Loss                                      -0.0575161
exploration/num steps total                           2800
exploration/num paths total                            140
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.142358
exploration/Rewards Std                                  0.0642074
exploration/Rewards Max                                 -0.0276794
exploration/Rewards Min                                 -0.382236
exploration/Returns Mean                                -2.84717
exploration/Returns Std                                  0.802891
exploration/Returns Max                                 -1.54688
exploration/Returns Min                                 -4.01553
exploration/Actions Mean                                 0.00664833
exploration/Actions Std                                  0.0966151
exploration/Actions Max                                  0.324613
exploration/Actions Min                                 -0.239457
exploration/Num Paths                                    5
exploration/Average Returns                             -2.84717
exploration/env_infos/final/reward_energy Mean          -0.192438
exploration/env_infos/final/reward_energy Std            0.0880079
exploration/env_infos/final/reward_energy Max           -0.122663
exploration/env_infos/final/reward_energy Min           -0.361593
exploration/env_infos/initial/reward_energy Mean        -0.199502
exploration/env_infos/initial/reward_energy Std          0.0717892
exploration/env_infos/initial/reward_energy Max         -0.122186
exploration/env_infos/initial/reward_energy Min         -0.322203
exploration/env_infos/reward_energy Mean                -0.117175
exploration/env_infos/reward_energy Std                  0.0709036
exploration/env_infos/reward_energy Max                 -0.0107252
exploration/env_infos/reward_energy Min                 -0.361593
exploration/env_infos/final/end_effector_loc Mean        0.0150325
exploration/env_infos/final/end_effector_loc Std         0.221717
exploration/env_infos/final/end_effector_loc Max         0.331862
exploration/env_infos/final/end_effector_loc Min        -0.436018
exploration/env_infos/initial/end_effector_loc Mean      0.000563542
exploration/env_infos/initial/end_effector_loc Std       0.007475
exploration/env_infos/initial/end_effector_loc Max       0.0107791
exploration/env_infos/initial/end_effector_loc Min      -0.0119729
exploration/env_infos/end_effector_loc Mean             -0.00657659
exploration/env_infos/end_effector_loc Std               0.144006
exploration/env_infos/end_effector_loc Max               0.331862
exploration/env_infos/end_effector_loc Min              -0.436018
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00247879
exploration/env_infos/final/reward_dist Std              0.00493575
exploration/env_infos/final/reward_dist Max              0.0123502
exploration/env_infos/final/reward_dist Min              4.98365e-16
exploration/env_infos/initial/reward_dist Mean           0.00499239
exploration/env_infos/initial/reward_dist Std            0.0092066
exploration/env_infos/initial/reward_dist Max            0.0233742
exploration/env_infos/initial/reward_dist Min            2.39327e-06
exploration/env_infos/reward_dist Mean                   0.00259024
exploration/env_infos/reward_dist Std                    0.00652426
exploration/env_infos/reward_dist Max                    0.0363747
exploration/env_infos/reward_dist Min                    4.98365e-16
evaluation/num steps total                           18000
evaluation/num paths total                             900
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0946991
evaluation/Rewards Std                                   0.101627
evaluation/Rewards Max                                   0.118912
evaluation/Rewards Min                                  -0.671056
evaluation/Returns Mean                                 -1.89398
evaluation/Returns Std                                   1.65975
evaluation/Returns Max                                   0.57594
evaluation/Returns Min                                  -7.87489
evaluation/Actions Mean                                  0.00490074
evaluation/Actions Std                                   0.0904653
evaluation/Actions Max                                   0.830755
evaluation/Actions Min                                  -0.828248
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.89398
evaluation/env_infos/final/reward_energy Mean           -0.0667122
evaluation/env_infos/final/reward_energy Std             0.0543114
evaluation/env_infos/final/reward_energy Max            -0.0127109
evaluation/env_infos/final/reward_energy Min            -0.321893
evaluation/env_infos/initial/reward_energy Mean         -0.203156
evaluation/env_infos/initial/reward_energy Std           0.241926
evaluation/env_infos/initial/reward_energy Max          -0.0147449
evaluation/env_infos/initial/reward_energy Min          -1.17309
evaluation/env_infos/reward_energy Mean                 -0.0825463
evaluation/env_infos/reward_energy Std                   0.0979901
evaluation/env_infos/reward_energy Max                  -0.00124947
evaluation/env_infos/reward_energy Min                  -1.17309
evaluation/env_infos/final/end_effector_loc Mean         0.105954
evaluation/env_infos/final/end_effector_loc Std          0.341742
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.970178
evaluation/env_infos/initial/end_effector_loc Mean       0.00299337
evaluation/env_infos/initial/end_effector_loc Std        0.0107606
evaluation/env_infos/initial/end_effector_loc Max        0.0415378
evaluation/env_infos/initial/end_effector_loc Min       -0.0414124
evaluation/env_infos/end_effector_loc Mean               0.0579198
evaluation/env_infos/end_effector_loc Std                0.220012
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.970178
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0713868
evaluation/env_infos/final/reward_dist Std               0.170471
evaluation/env_infos/final/reward_dist Max               0.977702
evaluation/env_infos/final/reward_dist Min               1.00445e-133
evaluation/env_infos/initial/reward_dist Mean            0.00675571
evaluation/env_infos/initial/reward_dist Std             0.0134737
evaluation/env_infos/initial/reward_dist Max             0.0591013
evaluation/env_infos/initial/reward_dist Min             9.35952e-07
evaluation/env_infos/reward_dist Mean                    0.0976278
evaluation/env_infos/reward_dist Std                     0.207639
evaluation/env_infos/reward_dist Max                     0.996541
evaluation/env_infos/reward_dist Min                     1.00445e-133
time/data storing (s)                                   10.8876
time/evaluation sampling (s)                             0.729572
time/exploration sampling (s)                            0.08959
time/logging (s)                                         0.0150867
time/saving (s)                                          0.237524
time/training (s)                                       34.6987
time/epoch (s)                                          46.658
time/total (s)                                         752.412
Epoch                                                   17
---------------------------------------------------  ----------------
2021-05-29 00:09:11.196769 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 18 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00129008
trainer/QF2 Loss                                         0.00107955
trainer/Policy Loss                                      2.98708
trainer/Q1 Predictions Mean                             -1.01686
trainer/Q1 Predictions Std                               0.819712
trainer/Q1 Predictions Max                               0.581313
trainer/Q1 Predictions Min                              -3.34847
trainer/Q2 Predictions Mean                             -1.01777
trainer/Q2 Predictions Std                               0.822987
trainer/Q2 Predictions Max                               0.56475
trainer/Q2 Predictions Min                              -3.36625
trainer/Q Targets Mean                                  -1.02039
trainer/Q Targets Std                                    0.830774
trainer/Q Targets Max                                    0.588037
trainer/Q Targets Min                                   -3.4221
trainer/Log Pis Mean                                     1.98883
trainer/Log Pis Std                                      1.359
trainer/Log Pis Max                                      5.08547
trainer/Log Pis Min                                     -1.90996
trainer/Policy mu Mean                                  -0.026354
trainer/Policy mu Std                                    0.529559
trainer/Policy mu Max                                    2.478
trainer/Policy mu Min                                   -3.14021
trainer/Policy log std Mean                             -2.22235
trainer/Policy log std Std                               0.671305
trainer/Policy log std Max                              -0.266256
trainer/Policy log std Min                              -3.41167
trainer/Alpha                                            0.0160063
trainer/Alpha Loss                                      -0.0461671
exploration/num steps total                           2900
exploration/num paths total                            145
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.123684
exploration/Rewards Std                                  0.109785
exploration/Rewards Max                                  0.0559207
exploration/Rewards Min                                 -0.448132
exploration/Returns Mean                                -2.47369
exploration/Returns Std                                  1.55643
exploration/Returns Max                                 -0.252146
exploration/Returns Min                                 -4.94995
exploration/Actions Mean                                -0.0174689
exploration/Actions Std                                  0.196084
exploration/Actions Max                                  0.858561
exploration/Actions Min                                 -0.698091
exploration/Num Paths                                    5
exploration/Average Returns                             -2.47369
exploration/env_infos/final/reward_energy Mean          -0.167156
exploration/env_infos/final/reward_energy Std            0.19176
exploration/env_infos/final/reward_energy Max           -0.0103043
exploration/env_infos/final/reward_energy Min           -0.541374
exploration/env_infos/initial/reward_energy Mean        -0.300358
exploration/env_infos/initial/reward_energy Std          0.290219
exploration/env_infos/initial/reward_energy Max         -0.0197105
exploration/env_infos/initial/reward_energy Min         -0.859015
exploration/env_infos/reward_energy Mean                -0.190412
exploration/env_infos/reward_energy Std                  0.203105
exploration/env_infos/reward_energy Max                 -0.00566947
exploration/env_infos/reward_energy Min                 -0.859015
exploration/env_infos/final/end_effector_loc Mean       -0.0341753
exploration/env_infos/final/end_effector_loc Std         0.237009
exploration/env_infos/final/end_effector_loc Max         0.221869
exploration/env_infos/final/end_effector_loc Min        -0.526279
exploration/env_infos/initial/end_effector_loc Mean      0.00598665
exploration/env_infos/initial/end_effector_loc Std       0.0134986
exploration/env_infos/initial/end_effector_loc Max       0.042928
exploration/env_infos/initial/end_effector_loc Min      -0.00521315
exploration/env_infos/end_effector_loc Mean              0.0451774
exploration/env_infos/end_effector_loc Std               0.204602
exploration/env_infos/end_effector_loc Max               0.619614
exploration/env_infos/end_effector_loc Min              -0.526279
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0798265
exploration/env_infos/final/reward_dist Std              0.159262
exploration/env_infos/final/reward_dist Max              0.398351
exploration/env_infos/final/reward_dist Min              5.24001e-31
exploration/env_infos/initial/reward_dist Mean           0.000907796
exploration/env_infos/initial/reward_dist Std            0.000796571
exploration/env_infos/initial/reward_dist Max            0.00208172
exploration/env_infos/initial/reward_dist Min            1.35304e-05
exploration/env_infos/reward_dist Mean                   0.0888385
exploration/env_infos/reward_dist Std                    0.223323
exploration/env_infos/reward_dist Max                    0.880778
exploration/env_infos/reward_dist Min                    5.24001e-31
evaluation/num steps total                           19000
evaluation/num paths total                             950
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0526399
evaluation/Rewards Std                                   0.0939878
evaluation/Rewards Max                                   0.163096
evaluation/Rewards Min                                  -0.655207
evaluation/Returns Mean                                 -1.0528
evaluation/Returns Std                                   1.44706
evaluation/Returns Max                                   1.7177
evaluation/Returns Min                                  -5.90592
evaluation/Actions Mean                                  0.00856774
evaluation/Actions Std                                   0.0951388
evaluation/Actions Max                                   0.86988
evaluation/Actions Min                                  -0.592597
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.0528
evaluation/env_infos/final/reward_energy Mean           -0.0658299
evaluation/env_infos/final/reward_energy Std             0.112707
evaluation/env_infos/final/reward_energy Max            -0.00061943
evaluation/env_infos/final/reward_energy Min            -0.715032
evaluation/env_infos/initial/reward_energy Mean         -0.244421
evaluation/env_infos/initial/reward_energy Std           0.260093
evaluation/env_infos/initial/reward_energy Max          -0.00606391
evaluation/env_infos/initial/reward_energy Min          -0.97211
evaluation/env_infos/reward_energy Mean                 -0.0759178
evaluation/env_infos/reward_energy Std                   0.111741
evaluation/env_infos/reward_energy Max                  -0.00061943
evaluation/env_infos/reward_energy Min                  -0.97211
evaluation/env_infos/final/end_effector_loc Mean         0.0701846
evaluation/env_infos/final/end_effector_loc Std          0.309331
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.549175
evaluation/env_infos/initial/end_effector_loc Mean       0.00161414
evaluation/env_infos/initial/end_effector_loc Std        0.0125153
evaluation/env_infos/initial/end_effector_loc Max        0.043494
evaluation/env_infos/initial/end_effector_loc Min       -0.0296298
evaluation/env_infos/end_effector_loc Mean               0.0271104
evaluation/env_infos/end_effector_loc Std                0.198672
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.549175
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.107966
evaluation/env_infos/final/reward_dist Std               0.222414
evaluation/env_infos/final/reward_dist Max               0.938856
evaluation/env_infos/final/reward_dist Min               9.48855e-78
evaluation/env_infos/initial/reward_dist Mean            0.00515761
evaluation/env_infos/initial/reward_dist Std             0.00891765
evaluation/env_infos/initial/reward_dist Max             0.0343505
evaluation/env_infos/initial/reward_dist Min             1.62433e-06
evaluation/env_infos/reward_dist Mean                    0.125706
evaluation/env_infos/reward_dist Std                     0.231592
evaluation/env_infos/reward_dist Max                     0.999685
evaluation/env_infos/reward_dist Min                     9.48855e-78
time/data storing (s)                                   11.0906
time/evaluation sampling (s)                             0.653634
time/exploration sampling (s)                            0.0878918
time/logging (s)                                         0.0145234
time/saving (s)                                          0.245433
time/training (s)                                       33.801
time/epoch (s)                                          45.8931
time/total (s)                                         798.558
Epoch                                                   18
---------------------------------------------------  ---------------
2021-05-29 00:09:57.789633 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 19 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00201428
trainer/QF2 Loss                                         0.00241295
trainer/Policy Loss                                      2.82011
trainer/Q1 Predictions Mean                             -0.999996
trainer/Q1 Predictions Std                               0.802083
trainer/Q1 Predictions Max                               0.594816
trainer/Q1 Predictions Min                              -3.37004
trainer/Q2 Predictions Mean                             -0.99502
trainer/Q2 Predictions Std                               0.795715
trainer/Q2 Predictions Max                               0.618535
trainer/Q2 Predictions Min                              -3.4098
trainer/Q Targets Mean                                  -0.99545
trainer/Q Targets Std                                    0.798014
trainer/Q Targets Max                                    0.622037
trainer/Q Targets Min                                   -3.38817
trainer/Log Pis Mean                                     1.84445
trainer/Log Pis Std                                      1.41287
trainer/Log Pis Max                                      6.30523
trainer/Log Pis Min                                     -3.24468
trainer/Policy mu Mean                                   0.0117803
trainer/Policy mu Std                                    0.590445
trainer/Policy mu Max                                    2.59108
trainer/Policy mu Min                                   -2.65228
trainer/Policy log std Mean                             -2.07923
trainer/Policy log std Std                               0.718634
trainer/Policy log std Max                              -0.191025
trainer/Policy log std Min                              -3.43264
trainer/Alpha                                            0.0157408
trainer/Alpha Loss                                      -0.645715
exploration/num steps total                           3000
exploration/num paths total                            150
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.114043
exploration/Rewards Std                                  0.0815065
exploration/Rewards Max                                  0.0645619
exploration/Rewards Min                                 -0.358362
exploration/Returns Mean                                -2.28085
exploration/Returns Std                                  1.16183
exploration/Returns Max                                 -0.404236
exploration/Returns Min                                 -3.58623
exploration/Actions Mean                                 0.00796116
exploration/Actions Std                                  0.140138
exploration/Actions Max                                  0.586227
exploration/Actions Min                                 -0.57457
exploration/Num Paths                                    5
exploration/Average Returns                             -2.28085
exploration/env_infos/final/reward_energy Mean          -0.133135
exploration/env_infos/final/reward_energy Std            0.0926813
exploration/env_infos/final/reward_energy Max           -0.0521454
exploration/env_infos/final/reward_energy Min           -0.309369
exploration/env_infos/initial/reward_energy Mean        -0.276077
exploration/env_infos/initial/reward_energy Std          0.275036
exploration/env_infos/initial/reward_energy Max         -0.0682377
exploration/env_infos/initial/reward_energy Min         -0.820849
exploration/env_infos/reward_energy Mean                -0.137176
exploration/env_infos/reward_energy Std                  0.143481
exploration/env_infos/reward_energy Max                 -0.00634827
exploration/env_infos/reward_energy Min                 -0.820849
exploration/env_infos/final/end_effector_loc Mean        0.0317896
exploration/env_infos/final/end_effector_loc Std         0.306974
exploration/env_infos/final/end_effector_loc Max         0.746745
exploration/env_infos/final/end_effector_loc Min        -0.394152
exploration/env_infos/initial/end_effector_loc Mean      0.000286668
exploration/env_infos/initial/end_effector_loc Std       0.0137749
exploration/env_infos/initial/end_effector_loc Max       0.0293114
exploration/env_infos/initial/end_effector_loc Min      -0.0287285
exploration/env_infos/end_effector_loc Mean             -0.0101413
exploration/env_infos/end_effector_loc Std               0.192719
exploration/env_infos/end_effector_loc Max               0.746745
exploration/env_infos/end_effector_loc Min              -0.444099
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.132908
exploration/env_infos/final/reward_dist Std              0.196836
exploration/env_infos/final/reward_dist Max              0.509581
exploration/env_infos/final/reward_dist Min              5.38133e-33
exploration/env_infos/initial/reward_dist Mean           0.018647
exploration/env_infos/initial/reward_dist Std            0.0235182
exploration/env_infos/initial/reward_dist Max            0.0566976
exploration/env_infos/initial/reward_dist Min            3.84671e-06
exploration/env_infos/reward_dist Mean                   0.109481
exploration/env_infos/reward_dist Std                    0.22478
exploration/env_infos/reward_dist Max                    0.997486
exploration/env_infos/reward_dist Min                    5.38133e-33
evaluation/num steps total                           20000
evaluation/num paths total                            1000
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0781373
evaluation/Rewards Std                                   0.0631728
evaluation/Rewards Max                                   0.0748916
evaluation/Rewards Min                                  -0.336029
evaluation/Returns Mean                                 -1.56275
evaluation/Returns Std                                   0.973706
evaluation/Returns Max                                   0.387834
evaluation/Returns Min                                  -4.27072
evaluation/Actions Mean                                  0.0032176
evaluation/Actions Std                                   0.0816304
evaluation/Actions Max                                   0.983881
evaluation/Actions Min                                  -0.746065
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.56275
evaluation/env_infos/final/reward_energy Mean           -0.0459561
evaluation/env_infos/final/reward_energy Std             0.0495404
evaluation/env_infos/final/reward_energy Max            -0.000565328
evaluation/env_infos/final/reward_energy Min            -0.219441
evaluation/env_infos/initial/reward_energy Mean         -0.212889
evaluation/env_infos/initial/reward_energy Std           0.25856
evaluation/env_infos/initial/reward_energy Max          -0.0109887
evaluation/env_infos/initial/reward_energy Min          -1.1587
evaluation/env_infos/reward_energy Mean                 -0.0633708
evaluation/env_infos/reward_energy Std                   0.0966017
evaluation/env_infos/reward_energy Max                  -0.000565328
evaluation/env_infos/reward_energy Min                  -1.1587
evaluation/env_infos/final/end_effector_loc Mean         0.033199
evaluation/env_infos/final/end_effector_loc Std          0.285095
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.655942
evaluation/env_infos/initial/end_effector_loc Mean       0.00157086
evaluation/env_infos/initial/end_effector_loc Std        0.0117367
evaluation/env_infos/initial/end_effector_loc Max        0.049194
evaluation/env_infos/initial/end_effector_loc Min       -0.0373032
evaluation/env_infos/end_effector_loc Mean               0.017358
evaluation/env_infos/end_effector_loc Std                0.185358
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.655942
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.090961
evaluation/env_infos/final/reward_dist Std               0.168587
evaluation/env_infos/final/reward_dist Max               0.724131
evaluation/env_infos/final/reward_dist Min               6.98095e-53
evaluation/env_infos/initial/reward_dist Mean            0.0114437
evaluation/env_infos/initial/reward_dist Std             0.0221174
evaluation/env_infos/initial/reward_dist Max             0.124045
evaluation/env_infos/initial/reward_dist Min             9.44405e-07
evaluation/env_infos/reward_dist Mean                    0.109924
evaluation/env_infos/reward_dist Std                     0.197426
evaluation/env_infos/reward_dist Max                     0.986167
evaluation/env_infos/reward_dist Min                     6.98095e-53
time/data storing (s)                                   11.588
time/evaluation sampling (s)                             0.648353
time/exploration sampling (s)                            0.0881582
time/logging (s)                                         0.0145997
time/saving (s)                                          0.25406
time/training (s)                                       33.7747
time/epoch (s)                                          46.3679
time/total (s)                                         845.149
Epoch                                                   19
---------------------------------------------------  ---------------
2021-05-29 00:10:45.108754 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 20 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00190449
trainer/QF2 Loss                                         0.00372907
trainer/Policy Loss                                      3.0134
trainer/Q1 Predictions Mean                             -1.05343
trainer/Q1 Predictions Std                               0.792939
trainer/Q1 Predictions Max                               0.548169
trainer/Q1 Predictions Min                              -3.4989
trainer/Q2 Predictions Mean                             -1.04544
trainer/Q2 Predictions Std                               0.771389
trainer/Q2 Predictions Max                               0.488254
trainer/Q2 Predictions Min                              -3.39781
trainer/Q Targets Mean                                  -1.04896
trainer/Q Targets Std                                    0.792375
trainer/Q Targets Max                                    0.541893
trainer/Q Targets Min                                   -3.47838
trainer/Log Pis Mean                                     1.97986
trainer/Log Pis Std                                      1.4483
trainer/Log Pis Max                                      5.94949
trainer/Log Pis Min                                     -2.9791
trainer/Policy mu Mean                                   0.0131048
trainer/Policy mu Std                                    0.548237
trainer/Policy mu Max                                    2.2629
trainer/Policy mu Min                                   -2.37635
trainer/Policy log std Mean                             -2.16006
trainer/Policy log std Std                               0.704007
trainer/Policy log std Max                               0.0994747
trainer/Policy log std Min                              -3.28008
trainer/Alpha                                            0.0170808
trainer/Alpha Loss                                      -0.0819728
exploration/num steps total                           3100
exploration/num paths total                            155
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0718206
exploration/Rewards Std                                  0.0921691
exploration/Rewards Max                                  0.14723
exploration/Rewards Min                                 -0.366402
exploration/Returns Mean                                -1.43641
exploration/Returns Std                                  1.46406
exploration/Returns Max                                  1.34734
exploration/Returns Min                                 -2.5711
exploration/Actions Mean                                 0.00623949
exploration/Actions Std                                  0.0898618
exploration/Actions Max                                  0.217416
exploration/Actions Min                                 -0.276991
exploration/Num Paths                                    5
exploration/Average Returns                             -1.43641
exploration/env_infos/final/reward_energy Mean          -0.161903
exploration/env_infos/final/reward_energy Std            0.114184
exploration/env_infos/final/reward_energy Max           -0.0586631
exploration/env_infos/final/reward_energy Min           -0.342962
exploration/env_infos/initial/reward_energy Mean        -0.147201
exploration/env_infos/initial/reward_energy Std          0.0789437
exploration/env_infos/initial/reward_energy Max         -0.0797927
exploration/env_infos/initial/reward_energy Min         -0.281372
exploration/env_infos/reward_energy Mean                -0.1077
exploration/env_infos/reward_energy Std                  0.0680356
exploration/env_infos/reward_energy Max                 -0.00427484
exploration/env_infos/reward_energy Min                 -0.342962
exploration/env_infos/final/end_effector_loc Mean        0.0555497
exploration/env_infos/final/end_effector_loc Std         0.227734
exploration/env_infos/final/end_effector_loc Max         0.426903
exploration/env_infos/final/end_effector_loc Min        -0.400872
exploration/env_infos/initial/end_effector_loc Mean     -0.00105119
exploration/env_infos/initial/end_effector_loc Std       0.00581121
exploration/env_infos/initial/end_effector_loc Max       0.00469576
exploration/env_infos/initial/end_effector_loc Min      -0.0132618
exploration/env_infos/end_effector_loc Mean              0.0134343
exploration/env_infos/end_effector_loc Std               0.146616
exploration/env_infos/end_effector_loc Max               0.426903
exploration/env_infos/end_effector_loc Min              -0.400872
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0629111
exploration/env_infos/final/reward_dist Std              0.125287
exploration/env_infos/final/reward_dist Max              0.313483
exploration/env_infos/final/reward_dist Min              8.08736e-07
exploration/env_infos/initial/reward_dist Mean           0.0170159
exploration/env_infos/initial/reward_dist Std            0.015389
exploration/env_infos/initial/reward_dist Max            0.0386049
exploration/env_infos/initial/reward_dist Min            2.21113e-05
exploration/env_infos/reward_dist Mean                   0.185248
exploration/env_infos/reward_dist Std                    0.262921
exploration/env_infos/reward_dist Max                    0.975499
exploration/env_infos/reward_dist Min                    8.08736e-07
evaluation/num steps total                           21000
evaluation/num paths total                            1050
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0595831
evaluation/Rewards Std                                   0.0841467
evaluation/Rewards Max                                   0.156028
evaluation/Rewards Min                                  -0.394135
evaluation/Returns Mean                                 -1.19166
evaluation/Returns Std                                   1.31756
evaluation/Returns Max                                   1.45633
evaluation/Returns Min                                  -3.85573
evaluation/Actions Mean                                 -0.000826557
evaluation/Actions Std                                   0.103736
evaluation/Actions Max                                   0.987891
evaluation/Actions Min                                  -0.930832
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.19166
evaluation/env_infos/final/reward_energy Mean           -0.0721999
evaluation/env_infos/final/reward_energy Std             0.0826572
evaluation/env_infos/final/reward_energy Max            -0.00307973
evaluation/env_infos/final/reward_energy Min            -0.344779
evaluation/env_infos/initial/reward_energy Mean         -0.29409
evaluation/env_infos/initial/reward_energy Std           0.326796
evaluation/env_infos/initial/reward_energy Max          -0.0107585
evaluation/env_infos/initial/reward_energy Min          -1.24889
evaluation/env_infos/reward_energy Mean                 -0.085908
evaluation/env_infos/reward_energy Std                   0.118927
evaluation/env_infos/reward_energy Max                  -0.00103947
evaluation/env_infos/reward_energy Min                  -1.24889
evaluation/env_infos/final/end_effector_loc Mean         0.0262291
evaluation/env_infos/final/end_effector_loc Std          0.30639
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.730063
evaluation/env_infos/initial/end_effector_loc Mean       0.00194681
evaluation/env_infos/initial/end_effector_loc Std        0.0154213
evaluation/env_infos/initial/end_effector_loc Max        0.0493945
evaluation/env_infos/initial/end_effector_loc Min       -0.0465416
evaluation/env_infos/end_effector_loc Mean               0.0209548
evaluation/env_infos/end_effector_loc Std                0.203904
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.730063
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.178764
evaluation/env_infos/final/reward_dist Std               0.271381
evaluation/env_infos/final/reward_dist Max               0.972363
evaluation/env_infos/final/reward_dist Min               1.53746e-52
evaluation/env_infos/initial/reward_dist Mean            0.0106195
evaluation/env_infos/initial/reward_dist Std             0.0188443
evaluation/env_infos/initial/reward_dist Max             0.0814351
evaluation/env_infos/initial/reward_dist Min             1.91286e-06
evaluation/env_infos/reward_dist Mean                    0.182977
evaluation/env_infos/reward_dist Std                     0.270075
evaluation/env_infos/reward_dist Max                     0.999139
evaluation/env_infos/reward_dist Min                     1.53746e-52
time/data storing (s)                                   11.9417
time/evaluation sampling (s)                             0.649543
time/exploration sampling (s)                            0.088425
time/logging (s)                                         0.0140949
time/saving (s)                                          0.260401
time/training (s)                                       34.1278
time/epoch (s)                                          47.082
time/total (s)                                         892.466
Epoch                                                   20
---------------------------------------------------  ---------------
2021-05-29 00:11:32.608412 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 21 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00185988
trainer/QF2 Loss                                         0.00134585
trainer/Policy Loss                                      2.95855
trainer/Q1 Predictions Mean                             -0.984061
trainer/Q1 Predictions Std                               0.807014
trainer/Q1 Predictions Max                               0.555362
trainer/Q1 Predictions Min                              -3.18533
trainer/Q2 Predictions Mean                             -0.980664
trainer/Q2 Predictions Std                               0.806301
trainer/Q2 Predictions Max                               0.605688
trainer/Q2 Predictions Min                              -3.20566
trainer/Q Targets Mean                                  -0.984642
trainer/Q Targets Std                                    0.811589
trainer/Q Targets Max                                    0.592088
trainer/Q Targets Min                                   -3.22275
trainer/Log Pis Mean                                     1.9878
trainer/Log Pis Std                                      1.51509
trainer/Log Pis Max                                      6.74736
trainer/Log Pis Min                                     -4.15085
trainer/Policy mu Mean                                  -0.055626
trainer/Policy mu Std                                    0.531986
trainer/Policy mu Max                                    2.01069
trainer/Policy mu Min                                   -2.59955
trainer/Policy log std Mean                             -2.18987
trainer/Policy log std Std                               0.739253
trainer/Policy log std Max                               0.00931287
trainer/Policy log std Min                              -3.45096
trainer/Alpha                                            0.0186754
trainer/Alpha Loss                                      -0.0485622
exploration/num steps total                           3200
exploration/num paths total                            160
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0738897
exploration/Rewards Std                                  0.0805704
exploration/Rewards Max                                  0.122955
exploration/Rewards Min                                 -0.271741
exploration/Returns Mean                                -1.47779
exploration/Returns Std                                  0.600137
exploration/Returns Max                                 -0.39046
exploration/Returns Min                                 -2.16331
exploration/Actions Mean                                -0.00280994
exploration/Actions Std                                  0.136113
exploration/Actions Max                                  0.354153
exploration/Actions Min                                 -0.599345
exploration/Num Paths                                    5
exploration/Average Returns                             -1.47779
exploration/env_infos/final/reward_energy Mean          -0.121242
exploration/env_infos/final/reward_energy Std            0.106285
exploration/env_infos/final/reward_energy Max           -0.00606989
exploration/env_infos/final/reward_energy Min           -0.288395
exploration/env_infos/initial/reward_energy Mean        -0.216034
exploration/env_infos/initial/reward_energy Std          0.227638
exploration/env_infos/initial/reward_energy Max         -0.0423914
exploration/env_infos/initial/reward_energy Min         -0.661229
exploration/env_infos/reward_energy Mean                -0.150788
exploration/env_infos/reward_energy Std                  0.119718
exploration/env_infos/reward_energy Max                 -0.00606989
exploration/env_infos/reward_energy Min                 -0.661229
exploration/env_infos/final/end_effector_loc Mean        0.0294767
exploration/env_infos/final/end_effector_loc Std         0.305651
exploration/env_infos/final/end_effector_loc Max         0.486812
exploration/env_infos/final/end_effector_loc Min        -0.49093
exploration/env_infos/initial/end_effector_loc Mean     -6.04154e-05
exploration/env_infos/initial/end_effector_loc Std       0.0110954
exploration/env_infos/initial/end_effector_loc Max       0.0139651
exploration/env_infos/initial/end_effector_loc Min      -0.0299673
exploration/env_infos/end_effector_loc Mean              0.0261709
exploration/env_infos/end_effector_loc Std               0.197621
exploration/env_infos/end_effector_loc Max               0.486812
exploration/env_infos/end_effector_loc Min              -0.49093
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             7.80327e-08
exploration/env_infos/final/reward_dist Std              1.45794e-07
exploration/env_infos/final/reward_dist Max              3.69309e-07
exploration/env_infos/final/reward_dist Min              6.11145e-20
exploration/env_infos/initial/reward_dist Mean           0.00389019
exploration/env_infos/initial/reward_dist Std            0.00534056
exploration/env_infos/initial/reward_dist Max            0.014569
exploration/env_infos/initial/reward_dist Min            0.00109512
exploration/env_infos/reward_dist Mean                   0.14907
exploration/env_infos/reward_dist Std                    0.275424
exploration/env_infos/reward_dist Max                    0.987125
exploration/env_infos/reward_dist Min                    6.11145e-20
evaluation/num steps total                           22000
evaluation/num paths total                            1100
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0650738
evaluation/Rewards Std                                   0.0784512
evaluation/Rewards Max                                   0.122986
evaluation/Rewards Min                                  -0.634069
evaluation/Returns Mean                                 -1.30148
evaluation/Returns Std                                   1.11398
evaluation/Returns Max                                   1.30532
evaluation/Returns Min                                  -4.70675
evaluation/Actions Mean                                  0.0061909
evaluation/Actions Std                                   0.0917243
evaluation/Actions Max                                   0.970037
evaluation/Actions Min                                  -0.746877
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.30148
evaluation/env_infos/final/reward_energy Mean           -0.0660909
evaluation/env_infos/final/reward_energy Std             0.0723434
evaluation/env_infos/final/reward_energy Max            -0.00446303
evaluation/env_infos/final/reward_energy Min            -0.313517
evaluation/env_infos/initial/reward_energy Mean         -0.260819
evaluation/env_infos/initial/reward_energy Std           0.310488
evaluation/env_infos/initial/reward_energy Max          -0.00709362
evaluation/env_infos/initial/reward_energy Min          -1.22425
evaluation/env_infos/reward_energy Mean                 -0.0722388
evaluation/env_infos/reward_energy Std                   0.108097
evaluation/env_infos/reward_energy Max                  -0.00336447
evaluation/env_infos/reward_energy Min                  -1.22425
evaluation/env_infos/final/end_effector_loc Mean         0.0841531
evaluation/env_infos/final/end_effector_loc Std          0.282837
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.585736
evaluation/env_infos/initial/end_effector_loc Mean       0.00249253
evaluation/env_infos/initial/end_effector_loc Std        0.0141182
evaluation/env_infos/initial/end_effector_loc Max        0.0485018
evaluation/env_infos/initial/end_effector_loc Min       -0.0373438
evaluation/env_infos/end_effector_loc Mean               0.0367053
evaluation/env_infos/end_effector_loc Std                0.182328
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.585736
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0770687
evaluation/env_infos/final/reward_dist Std               0.173248
evaluation/env_infos/final/reward_dist Max               0.7296
evaluation/env_infos/final/reward_dist Min               1.60894e-56
evaluation/env_infos/initial/reward_dist Mean            0.0110441
evaluation/env_infos/initial/reward_dist Std             0.0167227
evaluation/env_infos/initial/reward_dist Max             0.0787778
evaluation/env_infos/initial/reward_dist Min             1.27339e-06
evaluation/env_infos/reward_dist Mean                    0.12976
evaluation/env_infos/reward_dist Std                     0.222514
evaluation/env_infos/reward_dist Max                     0.99861
evaluation/env_infos/reward_dist Min                     1.60894e-56
time/data storing (s)                                   12.2069
time/evaluation sampling (s)                             0.644677
time/exploration sampling (s)                            0.0901476
time/logging (s)                                         0.0146576
time/saving (s)                                          0.273804
time/training (s)                                       33.9919
time/epoch (s)                                          47.2221
time/total (s)                                         939.963
Epoch                                                   21
---------------------------------------------------  ---------------
2021-05-29 00:12:22.226025 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 22 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00105136
trainer/QF2 Loss                                         0.00122829
trainer/Policy Loss                                      3.22529
trainer/Q1 Predictions Mean                             -0.979322
trainer/Q1 Predictions Std                               0.733864
trainer/Q1 Predictions Max                               0.653027
trainer/Q1 Predictions Min                              -3.11867
trainer/Q2 Predictions Mean                             -0.961443
trainer/Q2 Predictions Std                               0.734289
trainer/Q2 Predictions Max                               0.63981
trainer/Q2 Predictions Min                              -3.11815
trainer/Q Targets Mean                                  -0.96927
trainer/Q Targets Std                                    0.736184
trainer/Q Targets Max                                    0.646629
trainer/Q Targets Min                                   -3.0763
trainer/Log Pis Mean                                     2.27181
trainer/Log Pis Std                                      1.46474
trainer/Log Pis Max                                      7.3595
trainer/Log Pis Min                                     -2.48734
trainer/Policy mu Mean                                  -0.00138335
trainer/Policy mu Std                                    0.492855
trainer/Policy mu Max                                    2.42591
trainer/Policy mu Min                                   -2.62406
trainer/Policy log std Mean                             -2.34412
trainer/Policy log std Std                               0.651171
trainer/Policy log std Max                               0.00410344
trainer/Policy log std Min                              -3.41868
trainer/Alpha                                            0.0176895
trainer/Alpha Loss                                       1.09658
exploration/num steps total                           3300
exploration/num paths total                            165
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.11739
exploration/Rewards Std                                  0.0824916
exploration/Rewards Max                                  0.0316852
exploration/Rewards Min                                 -0.346594
exploration/Returns Mean                                -2.3478
exploration/Returns Std                                  1.38078
exploration/Returns Max                                 -0.889293
exploration/Returns Min                                 -4.91302
exploration/Actions Mean                                -0.0183525
exploration/Actions Std                                  0.227321
exploration/Actions Max                                  0.605029
exploration/Actions Min                                 -0.663376
exploration/Num Paths                                    5
exploration/Average Returns                             -2.3478
exploration/env_infos/final/reward_energy Mean          -0.16934
exploration/env_infos/final/reward_energy Std            0.0864612
exploration/env_infos/final/reward_energy Max           -0.0906614
exploration/env_infos/final/reward_energy Min           -0.31926
exploration/env_infos/initial/reward_energy Mean        -0.470122
exploration/env_infos/initial/reward_energy Std          0.150513
exploration/env_infos/initial/reward_energy Max         -0.227855
exploration/env_infos/initial/reward_energy Min         -0.680445
exploration/env_infos/reward_energy Mean                -0.276506
exploration/env_infos/reward_energy Std                  0.166036
exploration/env_infos/reward_energy Max                 -0.00390834
exploration/env_infos/reward_energy Min                 -0.688909
exploration/env_infos/final/end_effector_loc Mean       -0.108955
exploration/env_infos/final/end_effector_loc Std         0.460246
exploration/env_infos/final/end_effector_loc Max         0.635878
exploration/env_infos/final/end_effector_loc Min        -1
exploration/env_infos/initial/end_effector_loc Mean     -0.000514335
exploration/env_infos/initial/end_effector_loc Std       0.0174448
exploration/env_infos/initial/end_effector_loc Max       0.0302515
exploration/env_infos/initial/end_effector_loc Min      -0.0235456
exploration/env_infos/end_effector_loc Mean             -0.0397052
exploration/env_infos/end_effector_loc Std               0.282122
exploration/env_infos/end_effector_loc Max               0.635878
exploration/env_infos/end_effector_loc Min              -1
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0372587
exploration/env_infos/final/reward_dist Std              0.0518189
exploration/env_infos/final/reward_dist Max              0.13217
exploration/env_infos/final/reward_dist Min              1.9919e-67
exploration/env_infos/initial/reward_dist Mean           0.0094056
exploration/env_infos/initial/reward_dist Std            0.0167744
exploration/env_infos/initial/reward_dist Max            0.0428899
exploration/env_infos/initial/reward_dist Min            3.00376e-06
exploration/env_infos/reward_dist Mean                   0.0968263
exploration/env_infos/reward_dist Std                    0.189795
exploration/env_infos/reward_dist Max                    0.934984
exploration/env_infos/reward_dist Min                    1.9919e-67
evaluation/num steps total                           23000
evaluation/num paths total                            1150
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0728996
evaluation/Rewards Std                                   0.0935141
evaluation/Rewards Max                                   0.128434
evaluation/Rewards Min                                  -1.02131
evaluation/Returns Mean                                 -1.45799
evaluation/Returns Std                                   1.30905
evaluation/Returns Max                                   1.95398
evaluation/Returns Min                                  -4.99575
evaluation/Actions Mean                                  0.00371226
evaluation/Actions Std                                   0.087813
evaluation/Actions Max                                   0.801275
evaluation/Actions Min                                  -0.890609
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.45799
evaluation/env_infos/final/reward_energy Mean           -0.0973637
evaluation/env_infos/final/reward_energy Std             0.121002
evaluation/env_infos/final/reward_energy Max            -0.00782161
evaluation/env_infos/final/reward_energy Min            -0.615574
evaluation/env_infos/initial/reward_energy Mean         -0.24601
evaluation/env_infos/initial/reward_energy Std           0.28234
evaluation/env_infos/initial/reward_energy Max          -0.0155568
evaluation/env_infos/initial/reward_energy Min          -1.21973
evaluation/env_infos/reward_energy Mean                 -0.0737372
evaluation/env_infos/reward_energy Std                   0.100063
evaluation/env_infos/reward_energy Max                  -0.00138416
evaluation/env_infos/reward_energy Min                  -1.21973
evaluation/env_infos/final/end_effector_loc Mean         0.0648417
evaluation/env_infos/final/end_effector_loc Std          0.355937
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.000114052
evaluation/env_infos/initial/end_effector_loc Std        0.0132395
evaluation/env_infos/initial/end_effector_loc Max        0.0400637
evaluation/env_infos/initial/end_effector_loc Min       -0.0445304
evaluation/env_infos/end_effector_loc Mean               0.0236238
evaluation/env_infos/end_effector_loc Std                0.216908
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.146835
evaluation/env_infos/final/reward_dist Std               0.249658
evaluation/env_infos/final/reward_dist Max               0.792636
evaluation/env_infos/final/reward_dist Min               8.09198e-92
evaluation/env_infos/initial/reward_dist Mean            0.00559615
evaluation/env_infos/initial/reward_dist Std             0.0124709
evaluation/env_infos/initial/reward_dist Max             0.0767865
evaluation/env_infos/initial/reward_dist Min             1.29359e-06
evaluation/env_infos/reward_dist Mean                    0.129542
evaluation/env_infos/reward_dist Std                     0.22217
evaluation/env_infos/reward_dist Max                     0.993359
evaluation/env_infos/reward_dist Min                     8.09198e-92
time/data storing (s)                                   13.2942
time/evaluation sampling (s)                             0.688739
time/exploration sampling (s)                            0.0870856
time/logging (s)                                         0.0151522
time/saving (s)                                          0.282146
time/training (s)                                       34.9562
time/epoch (s)                                          49.3235
time/total (s)                                         989.579
Epoch                                                   22
---------------------------------------------------  ---------------
2021-05-29 00:13:14.241268 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 23 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00377436
trainer/QF2 Loss                                         0.00342975
trainer/Policy Loss                                      2.77707
trainer/Q1 Predictions Mean                             -0.89241
trainer/Q1 Predictions Std                               0.748421
trainer/Q1 Predictions Max                               0.74508
trainer/Q1 Predictions Min                              -2.96856
trainer/Q2 Predictions Mean                             -0.914434
trainer/Q2 Predictions Std                               0.754065
trainer/Q2 Predictions Max                               0.745582
trainer/Q2 Predictions Min                              -2.93692
trainer/Q Targets Mean                                  -0.913958
trainer/Q Targets Std                                    0.741052
trainer/Q Targets Max                                    0.718702
trainer/Q Targets Min                                   -2.9202
trainer/Log Pis Mean                                     1.88305
trainer/Log Pis Std                                      1.60761
trainer/Log Pis Max                                      7.79013
trainer/Log Pis Min                                     -6.86633
trainer/Policy mu Mean                                  -0.0313691
trainer/Policy mu Std                                    0.505925
trainer/Policy mu Max                                    2.63533
trainer/Policy mu Min                                   -2.71574
trainer/Policy log std Mean                             -2.15321
trainer/Policy log std Std                               0.776775
trainer/Policy log std Max                               0.583988
trainer/Policy log std Min                              -3.65132
trainer/Alpha                                            0.0146957
trainer/Alpha Loss                                      -0.493528
exploration/num steps total                           3400
exploration/num paths total                            170
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.143127
exploration/Rewards Std                                  0.0985906
exploration/Rewards Max                                  0.0292871
exploration/Rewards Min                                 -0.458718
exploration/Returns Mean                                -2.86255
exploration/Returns Std                                  1.00042
exploration/Returns Max                                 -1.4298
exploration/Returns Min                                 -4.20018
exploration/Actions Mean                                -0.0151596
exploration/Actions Std                                  0.164817
exploration/Actions Max                                  0.445176
exploration/Actions Min                                 -0.973095
exploration/Num Paths                                    5
exploration/Average Returns                             -2.86255
exploration/env_infos/final/reward_energy Mean          -0.188206
exploration/env_infos/final/reward_energy Std            0.0992005
exploration/env_infos/final/reward_energy Max           -0.0364597
exploration/env_infos/final/reward_energy Min           -0.323216
exploration/env_infos/initial/reward_energy Mean        -0.505718
exploration/env_infos/initial/reward_energy Std          0.301655
exploration/env_infos/initial/reward_energy Max         -0.182626
exploration/env_infos/initial/reward_energy Min         -1.01098
exploration/env_infos/reward_energy Mean                -0.183706
exploration/env_infos/reward_energy Std                  0.145057
exploration/env_infos/reward_energy Max                 -0.0130422
exploration/env_infos/reward_energy Min                 -1.01098
exploration/env_infos/final/end_effector_loc Mean       -0.152093
exploration/env_infos/final/end_effector_loc Std         0.363489
exploration/env_infos/final/end_effector_loc Max         0.371809
exploration/env_infos/final/end_effector_loc Min        -0.715629
exploration/env_infos/initial/end_effector_loc Mean     -0.00745286
exploration/env_infos/initial/end_effector_loc Std       0.0194393
exploration/env_infos/initial/end_effector_loc Max       0.0198104
exploration/env_infos/initial/end_effector_loc Min      -0.0486548
exploration/env_infos/end_effector_loc Mean             -0.0737797
exploration/env_infos/end_effector_loc Std               0.220754
exploration/env_infos/end_effector_loc Max               0.371809
exploration/env_infos/end_effector_loc Min              -0.715629
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0302345
exploration/env_infos/final/reward_dist Std              0.0467979
exploration/env_infos/final/reward_dist Max              0.120832
exploration/env_infos/final/reward_dist Min              1.88972e-22
exploration/env_infos/initial/reward_dist Mean           0.0100172
exploration/env_infos/initial/reward_dist Std            0.0165634
exploration/env_infos/initial/reward_dist Max            0.0429959
exploration/env_infos/initial/reward_dist Min            2.38493e-05
exploration/env_infos/reward_dist Mean                   0.0665537
exploration/env_infos/reward_dist Std                    0.139853
exploration/env_infos/reward_dist Max                    0.842489
exploration/env_infos/reward_dist Min                    1.88972e-22
evaluation/num steps total                           24000
evaluation/num paths total                            1200
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.100822
evaluation/Rewards Std                                   0.136508
evaluation/Rewards Max                                   0.109996
evaluation/Rewards Min                                  -0.970038
evaluation/Returns Mean                                 -2.01644
evaluation/Returns Std                                   2.19573
evaluation/Returns Max                                  -0.0415985
evaluation/Returns Min                                 -10.5634
evaluation/Actions Mean                                 -0.00734843
evaluation/Actions Std                                   0.0984453
evaluation/Actions Max                                   0.951332
evaluation/Actions Min                                  -0.799022
evaluation/Num Paths                                    50
evaluation/Average Returns                              -2.01644
evaluation/env_infos/final/reward_energy Mean           -0.145241
evaluation/env_infos/final/reward_energy Std             0.1564
evaluation/env_infos/final/reward_energy Max            -0.00447747
evaluation/env_infos/final/reward_energy Min            -0.508878
evaluation/env_infos/initial/reward_energy Mean         -0.259863
evaluation/env_infos/initial/reward_energy Std           0.267986
evaluation/env_infos/initial/reward_energy Max          -0.000818182
evaluation/env_infos/initial/reward_energy Min          -0.962582
evaluation/env_infos/reward_energy Mean                 -0.0820741
evaluation/env_infos/reward_energy Std                   0.112937
evaluation/env_infos/reward_energy Max                  -0.000818182
evaluation/env_infos/reward_energy Min                  -0.962582
evaluation/env_infos/final/end_effector_loc Mean        -0.0075982
evaluation/env_infos/final/end_effector_loc Std          0.414649
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00160909
evaluation/env_infos/initial/end_effector_loc Std        0.0130993
evaluation/env_infos/initial/end_effector_loc Max        0.0475666
evaluation/env_infos/initial/end_effector_loc Min       -0.0399511
evaluation/env_infos/end_effector_loc Mean              -0.00694943
evaluation/env_infos/end_effector_loc Std                0.249459
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0314578
evaluation/env_infos/final/reward_dist Std               0.083607
evaluation/env_infos/final/reward_dist Max               0.363601
evaluation/env_infos/final/reward_dist Min               4.08444e-152
evaluation/env_infos/initial/reward_dist Mean            0.0102511
evaluation/env_infos/initial/reward_dist Std             0.01913
evaluation/env_infos/initial/reward_dist Max             0.0897197
evaluation/env_infos/initial/reward_dist Min             3.86574e-06
evaluation/env_infos/reward_dist Mean                    0.0782364
evaluation/env_infos/reward_dist Std                     0.171793
evaluation/env_infos/reward_dist Max                     0.999547
evaluation/env_infos/reward_dist Min                     4.08444e-152
time/data storing (s)                                   13.6332
time/evaluation sampling (s)                             0.749482
time/exploration sampling (s)                            0.0912563
time/logging (s)                                         0.0157213
time/saving (s)                                          0.303575
time/training (s)                                       36.9023
time/epoch (s)                                          51.6955
time/total (s)                                        1041.59
Epoch                                                   23
---------------------------------------------------  ----------------
2021-05-29 00:14:05.480426 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 24 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00173132
trainer/QF2 Loss                                         0.0019035
trainer/Policy Loss                                      2.85381
trainer/Q1 Predictions Mean                             -0.90103
trainer/Q1 Predictions Std                               0.711387
trainer/Q1 Predictions Max                               0.571243
trainer/Q1 Predictions Min                              -2.81159
trainer/Q2 Predictions Mean                             -0.910554
trainer/Q2 Predictions Std                               0.712861
trainer/Q2 Predictions Max                               0.563955
trainer/Q2 Predictions Min                              -2.81489
trainer/Q Targets Mean                                  -0.899162
trainer/Q Targets Std                                    0.712908
trainer/Q Targets Max                                    0.563904
trainer/Q Targets Min                                   -2.84052
trainer/Log Pis Mean                                     1.962
trainer/Log Pis Std                                      1.59876
trainer/Log Pis Max                                      7.58342
trainer/Log Pis Min                                     -3.57832
trainer/Policy mu Mean                                  -0.0565391
trainer/Policy mu Std                                    0.550114
trainer/Policy mu Max                                    2.1837
trainer/Policy mu Min                                   -3.25884
trainer/Policy log std Mean                             -2.16335
trainer/Policy log std Std                               0.849395
trainer/Policy log std Max                               0.242499
trainer/Policy log std Min                              -3.5135
trainer/Alpha                                            0.0171747
trainer/Alpha Loss                                      -0.154375
exploration/num steps total                           3500
exploration/num paths total                            175
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.110766
exploration/Rewards Std                                  0.0516866
exploration/Rewards Max                                 -0.0198568
exploration/Rewards Min                                 -0.306944
exploration/Returns Mean                                -2.21532
exploration/Returns Std                                  0.407826
exploration/Returns Max                                 -1.5354
exploration/Returns Min                                 -2.68289
exploration/Actions Mean                                -0.0125562
exploration/Actions Std                                  0.135221
exploration/Actions Max                                  0.386268
exploration/Actions Min                                 -0.853575
exploration/Num Paths                                    5
exploration/Average Returns                             -2.21532
exploration/env_infos/final/reward_energy Mean          -0.129005
exploration/env_infos/final/reward_energy Std            0.0427354
exploration/env_infos/final/reward_energy Max           -0.052158
exploration/env_infos/final/reward_energy Min           -0.169143
exploration/env_infos/initial/reward_energy Mean        -0.326941
exploration/env_infos/initial/reward_energy Std          0.291134
exploration/env_infos/initial/reward_energy Max         -0.0926263
exploration/env_infos/initial/reward_energy Min         -0.858275
exploration/env_infos/reward_energy Mean                -0.141961
exploration/env_infos/reward_energy Std                  0.129352
exploration/env_infos/reward_energy Max                 -0.014577
exploration/env_infos/reward_energy Min                 -0.858275
exploration/env_infos/final/end_effector_loc Mean       -0.191217
exploration/env_infos/final/end_effector_loc Std         0.200547
exploration/env_infos/final/end_effector_loc Max         0.253065
exploration/env_infos/final/end_effector_loc Min        -0.48537
exploration/env_infos/initial/end_effector_loc Mean     -0.00809482
exploration/env_infos/initial/end_effector_loc Std       0.0131923
exploration/env_infos/initial/end_effector_loc Max       0.00356039
exploration/env_infos/initial/end_effector_loc Min      -0.0426787
exploration/env_infos/end_effector_loc Mean             -0.106236
exploration/env_infos/end_effector_loc Std               0.13856
exploration/env_infos/end_effector_loc Max               0.253065
exploration/env_infos/end_effector_loc Min              -0.48537
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00787248
exploration/env_infos/final/reward_dist Std              0.00983397
exploration/env_infos/final/reward_dist Max              0.0254683
exploration/env_infos/final/reward_dist Min              5.5616e-08
exploration/env_infos/initial/reward_dist Mean           0.00721071
exploration/env_infos/initial/reward_dist Std            0.0116251
exploration/env_infos/initial/reward_dist Max            0.0304241
exploration/env_infos/initial/reward_dist Min            0.00028653
exploration/env_infos/reward_dist Mean                   0.0876266
exploration/env_infos/reward_dist Std                    0.158488
exploration/env_infos/reward_dist Max                    0.825915
exploration/env_infos/reward_dist Min                    5.5616e-08
evaluation/num steps total                           25000
evaluation/num paths total                            1250
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0613793
evaluation/Rewards Std                                   0.0673593
evaluation/Rewards Max                                   0.148615
evaluation/Rewards Min                                  -0.575628
evaluation/Returns Mean                                 -1.22759
evaluation/Returns Std                                   0.87025
evaluation/Returns Max                                   0.77654
evaluation/Returns Min                                  -2.58581
evaluation/Actions Mean                                  0.000801042
evaluation/Actions Std                                   0.0716804
evaluation/Actions Max                                   0.516492
evaluation/Actions Min                                  -0.83106
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.22759
evaluation/env_infos/final/reward_energy Mean           -0.116309
evaluation/env_infos/final/reward_energy Std             0.175447
evaluation/env_infos/final/reward_energy Max            -0.00137719
evaluation/env_infos/final/reward_energy Min            -0.861005
evaluation/env_infos/initial/reward_energy Mean         -0.162817
evaluation/env_infos/initial/reward_energy Std           0.168473
evaluation/env_infos/initial/reward_energy Max          -0.00175429
evaluation/env_infos/initial/reward_energy Min          -0.755386
evaluation/env_infos/reward_energy Mean                 -0.0553335
evaluation/env_infos/reward_energy Std                   0.084945
evaluation/env_infos/reward_energy Max                  -0.00021918
evaluation/env_infos/reward_energy Min                  -0.861005
evaluation/env_infos/final/end_effector_loc Mean         0.0695451
evaluation/env_infos/final/end_effector_loc Std          0.239335
evaluation/env_infos/final/end_effector_loc Max          0.672068
evaluation/env_infos/final/end_effector_loc Min         -0.387399
evaluation/env_infos/initial/end_effector_loc Mean       0.00174916
evaluation/env_infos/initial/end_effector_loc Std        0.00809666
evaluation/env_infos/initial/end_effector_loc Max        0.0258246
evaluation/env_infos/initial/end_effector_loc Min       -0.0360379
evaluation/env_infos/end_effector_loc Mean               0.0343138
evaluation/env_infos/end_effector_loc Std                0.148739
evaluation/env_infos/end_effector_loc Max                0.672068
evaluation/env_infos/end_effector_loc Min               -0.457004
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0806802
evaluation/env_infos/final/reward_dist Std               0.123624
evaluation/env_infos/final/reward_dist Max               0.431462
evaluation/env_infos/final/reward_dist Min               4.07494e-16
evaluation/env_infos/initial/reward_dist Mean            0.0049434
evaluation/env_infos/initial/reward_dist Std             0.0117555
evaluation/env_infos/initial/reward_dist Max             0.0604859
evaluation/env_infos/initial/reward_dist Min             1.383e-06
evaluation/env_infos/reward_dist Mean                    0.119945
evaluation/env_infos/reward_dist Std                     0.21708
evaluation/env_infos/reward_dist Max                     0.976908
evaluation/env_infos/reward_dist Min                     4.07494e-16
time/data storing (s)                                   13.8557
time/evaluation sampling (s)                             0.814367
time/exploration sampling (s)                            0.0906666
time/logging (s)                                         0.0159235
time/saving (s)                                          0.297673
time/training (s)                                       35.8552
time/epoch (s)                                          50.9295
time/total (s)                                        1092.83
Epoch                                                   24
---------------------------------------------------  ---------------
2021-05-29 00:14:55.058706 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 25 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.000990717
trainer/QF2 Loss                                         0.00106343
trainer/Policy Loss                                      2.76218
trainer/Q1 Predictions Mean                             -0.81527
trainer/Q1 Predictions Std                               0.677889
trainer/Q1 Predictions Max                               0.56367
trainer/Q1 Predictions Min                              -2.61666
trainer/Q2 Predictions Mean                             -0.806313
trainer/Q2 Predictions Std                               0.674993
trainer/Q2 Predictions Max                               0.611963
trainer/Q2 Predictions Min                              -2.57005
trainer/Q Targets Mean                                  -0.817235
trainer/Q Targets Std                                    0.681218
trainer/Q Targets Max                                    0.607859
trainer/Q Targets Min                                   -2.61216
trainer/Log Pis Mean                                     1.95164
trainer/Log Pis Std                                      1.48272
trainer/Log Pis Max                                      5.72261
trainer/Log Pis Min                                     -3.52417
trainer/Policy mu Mean                                   0.0330925
trainer/Policy mu Std                                    0.421755
trainer/Policy mu Max                                    2.37553
trainer/Policy mu Min                                   -2.28979
trainer/Policy log std Mean                             -2.22023
trainer/Policy log std Std                               0.710243
trainer/Policy log std Max                              -0.00247192
trainer/Policy log std Min                              -3.33183
trainer/Alpha                                            0.0173558
trainer/Alpha Loss                                      -0.196104
exploration/num steps total                           3600
exploration/num paths total                            180
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.122802
exploration/Rewards Std                                  0.135933
exploration/Rewards Max                                  0.0580813
exploration/Rewards Min                                 -0.884832
exploration/Returns Mean                                -2.45604
exploration/Returns Std                                  1.45755
exploration/Returns Max                                 -0.0807103
exploration/Returns Min                                 -4.61232
exploration/Actions Mean                                -0.0216756
exploration/Actions Std                                  0.204349
exploration/Actions Max                                  0.610111
exploration/Actions Min                                 -0.862609
exploration/Num Paths                                    5
exploration/Average Returns                             -2.45604
exploration/env_infos/final/reward_energy Mean          -0.324161
exploration/env_infos/final/reward_energy Std            0.388754
exploration/env_infos/final/reward_energy Max           -0.109736
exploration/env_infos/final/reward_energy Min           -1.10071
exploration/env_infos/initial/reward_energy Mean        -0.238512
exploration/env_infos/initial/reward_energy Std          0.238214
exploration/env_infos/initial/reward_energy Max         -0.087764
exploration/env_infos/initial/reward_energy Min         -0.713266
exploration/env_infos/reward_energy Mean                -0.197527
exploration/env_infos/reward_energy Std                  0.213166
exploration/env_infos/reward_energy Max                 -0.004038
exploration/env_infos/reward_energy Min                 -1.10071
exploration/env_infos/final/end_effector_loc Mean       -0.000707584
exploration/env_infos/final/end_effector_loc Std         0.417782
exploration/env_infos/final/end_effector_loc Max         0.456053
exploration/env_infos/final/end_effector_loc Min        -1
exploration/env_infos/initial/end_effector_loc Mean     -0.00257818
exploration/env_infos/initial/end_effector_loc Std       0.0116359
exploration/env_infos/initial/end_effector_loc Max       0.00697804
exploration/env_infos/initial/end_effector_loc Min      -0.0355525
exploration/env_infos/end_effector_loc Mean              0.00786442
exploration/env_infos/end_effector_loc Std               0.230147
exploration/env_infos/end_effector_loc Max               0.456053
exploration/env_infos/end_effector_loc Min              -1
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.045387
exploration/env_infos/final/reward_dist Std              0.0907729
exploration/env_infos/final/reward_dist Max              0.226933
exploration/env_infos/final/reward_dist Min              1.12059e-47
exploration/env_infos/initial/reward_dist Mean           0.000760803
exploration/env_infos/initial/reward_dist Std            0.00107869
exploration/env_infos/initial/reward_dist Max            0.0028714
exploration/env_infos/initial/reward_dist Min            5.704e-05
exploration/env_infos/reward_dist Mean                   0.115968
exploration/env_infos/reward_dist Std                    0.206252
exploration/env_infos/reward_dist Max                    0.777862
exploration/env_infos/reward_dist Min                    1.12059e-47
evaluation/num steps total                           26000
evaluation/num paths total                            1300
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0712903
evaluation/Rewards Std                                   0.100009
evaluation/Rewards Max                                   0.145242
evaluation/Rewards Min                                  -0.655649
evaluation/Returns Mean                                 -1.42581
evaluation/Returns Std                                   1.49056
evaluation/Returns Max                                   0.93756
evaluation/Returns Min                                  -7.15526
evaluation/Actions Mean                                  0.000671818
evaluation/Actions Std                                   0.0931587
evaluation/Actions Max                                   0.93634
evaluation/Actions Min                                  -0.950606
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.42581
evaluation/env_infos/final/reward_energy Mean           -0.0817836
evaluation/env_infos/final/reward_energy Std             0.104825
evaluation/env_infos/final/reward_energy Max            -0.00128342
evaluation/env_infos/final/reward_energy Min            -0.569984
evaluation/env_infos/initial/reward_energy Mean         -0.281984
evaluation/env_infos/initial/reward_energy Std           0.275192
evaluation/env_infos/initial/reward_energy Max          -0.0140728
evaluation/env_infos/initial/reward_energy Min          -1.08576
evaluation/env_infos/reward_energy Mean                 -0.0730581
evaluation/env_infos/reward_energy Std                   0.109638
evaluation/env_infos/reward_energy Max                  -0.000335331
evaluation/env_infos/reward_energy Min                  -1.08576
evaluation/env_infos/final/end_effector_loc Mean         0.0320755
evaluation/env_infos/final/end_effector_loc Std          0.337286
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.629237
evaluation/env_infos/initial/end_effector_loc Mean       0.00196402
evaluation/env_infos/initial/end_effector_loc Std        0.0137913
evaluation/env_infos/initial/end_effector_loc Max        0.046817
evaluation/env_infos/initial/end_effector_loc Min       -0.0475303
evaluation/env_infos/end_effector_loc Mean               0.0141464
evaluation/env_infos/end_effector_loc Std                0.215655
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.629237
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0827141
evaluation/env_infos/final/reward_dist Std               0.208942
evaluation/env_infos/final/reward_dist Max               0.803019
evaluation/env_infos/final/reward_dist Min               4.20479e-69
evaluation/env_infos/initial/reward_dist Mean            0.00978915
evaluation/env_infos/initial/reward_dist Std             0.0231051
evaluation/env_infos/initial/reward_dist Max             0.12132
evaluation/env_infos/initial/reward_dist Min             1.34348e-06
evaluation/env_infos/reward_dist Mean                    0.13755
evaluation/env_infos/reward_dist Std                     0.240964
evaluation/env_infos/reward_dist Max                     0.989802
evaluation/env_infos/reward_dist Min                     4.20479e-69
time/data storing (s)                                   13.7018
time/evaluation sampling (s)                             0.651349
time/exploration sampling (s)                            0.0882788
time/logging (s)                                         0.0145109
time/saving (s)                                          0.297005
time/training (s)                                       34.5174
time/epoch (s)                                          49.2703
time/total (s)                                        1142.4
Epoch                                                   25
---------------------------------------------------  ---------------
2021-05-29 00:15:45.548653 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 26 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00256888
trainer/QF2 Loss                                         0.0055274
trainer/Policy Loss                                      2.93381
trainer/Q1 Predictions Mean                             -0.956288
trainer/Q1 Predictions Std                               0.753692
trainer/Q1 Predictions Max                               0.765012
trainer/Q1 Predictions Min                              -3.17985
trainer/Q2 Predictions Mean                             -0.957502
trainer/Q2 Predictions Std                               0.744303
trainer/Q2 Predictions Max                               0.715139
trainer/Q2 Predictions Min                              -3.17411
trainer/Q Targets Mean                                  -0.956041
trainer/Q Targets Std                                    0.763485
trainer/Q Targets Max                                    0.745799
trainer/Q Targets Min                                   -3.21519
trainer/Log Pis Mean                                     1.98712
trainer/Log Pis Std                                      1.40857
trainer/Log Pis Max                                      5.2738
trainer/Log Pis Min                                     -3.78404
trainer/Policy mu Mean                                  -0.00588626
trainer/Policy mu Std                                    0.452469
trainer/Policy mu Max                                    2.39043
trainer/Policy mu Min                                   -2.58427
trainer/Policy log std Mean                             -2.21413
trainer/Policy log std Std                               0.74548
trainer/Policy log std Max                              -0.168467
trainer/Policy log std Min                              -3.40965
trainer/Alpha                                            0.0179196
trainer/Alpha Loss                                      -0.0517683
exploration/num steps total                           3700
exploration/num paths total                            185
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.115664
exploration/Rewards Std                                  0.170768
exploration/Rewards Max                                  0.131906
exploration/Rewards Min                                 -0.53192
exploration/Returns Mean                                -2.31327
exploration/Returns Std                                  3.02236
exploration/Returns Max                                  0.360088
exploration/Returns Min                                 -7.83955
exploration/Actions Mean                                 0.0126351
exploration/Actions Std                                  0.137707
exploration/Actions Max                                  0.90183
exploration/Actions Min                                 -0.401353
exploration/Num Paths                                    5
exploration/Average Returns                             -2.31327
exploration/env_infos/final/reward_energy Mean          -0.141184
exploration/env_infos/final/reward_energy Std            0.120983
exploration/env_infos/final/reward_energy Max           -0.0149473
exploration/env_infos/final/reward_energy Min           -0.323393
exploration/env_infos/initial/reward_energy Mean        -0.423978
exploration/env_infos/initial/reward_energy Std          0.362999
exploration/env_infos/initial/reward_energy Max         -0.0792864
exploration/env_infos/initial/reward_energy Min         -1.09943
exploration/env_infos/reward_energy Mean                -0.138056
exploration/env_infos/reward_energy Std                  0.138514
exploration/env_infos/reward_energy Max                 -0.00185297
exploration/env_infos/reward_energy Min                 -1.09943
exploration/env_infos/final/end_effector_loc Mean        0.131954
exploration/env_infos/final/end_effector_loc Std         0.49717
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.38566
exploration/env_infos/initial/end_effector_loc Mean      0.00465769
exploration/env_infos/initial/end_effector_loc Std       0.0191758
exploration/env_infos/initial/end_effector_loc Max       0.0450915
exploration/env_infos/initial/end_effector_loc Min      -0.0200676
exploration/env_infos/end_effector_loc Mean              0.0941259
exploration/env_infos/end_effector_loc Std               0.369482
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.38566
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0217879
exploration/env_infos/final/reward_dist Std              0.0274004
exploration/env_infos/final/reward_dist Max              0.0643395
exploration/env_infos/final/reward_dist Min              6.4242e-112
exploration/env_infos/initial/reward_dist Mean           0.00439564
exploration/env_infos/initial/reward_dist Std            0.00706865
exploration/env_infos/initial/reward_dist Max            0.0183086
exploration/env_infos/initial/reward_dist Min            1.62066e-05
exploration/env_infos/reward_dist Mean                   0.160678
exploration/env_infos/reward_dist Std                    0.276449
exploration/env_infos/reward_dist Max                    0.991804
exploration/env_infos/reward_dist Min                    6.4242e-112
evaluation/num steps total                           27000
evaluation/num paths total                            1350
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0504501
evaluation/Rewards Std                                   0.0814475
evaluation/Rewards Max                                   0.185712
evaluation/Rewards Min                                  -0.400452
evaluation/Returns Mean                                 -1.009
evaluation/Returns Std                                   1.36492
evaluation/Returns Max                                   1.99403
evaluation/Returns Min                                  -3.6106
evaluation/Actions Mean                                  0.00204274
evaluation/Actions Std                                   0.0900039
evaluation/Actions Max                                   0.65696
evaluation/Actions Min                                  -0.907586
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.009
evaluation/env_infos/final/reward_energy Mean           -0.11502
evaluation/env_infos/final/reward_energy Std             0.178581
evaluation/env_infos/final/reward_energy Max            -0.00300057
evaluation/env_infos/final/reward_energy Min            -0.952289
evaluation/env_infos/initial/reward_energy Mean         -0.223162
evaluation/env_infos/initial/reward_energy Std           0.202925
evaluation/env_infos/initial/reward_energy Max          -0.0356875
evaluation/env_infos/initial/reward_energy Min          -1.1389
evaluation/env_infos/reward_energy Mean                 -0.0719452
evaluation/env_infos/reward_energy Std                   0.105041
evaluation/env_infos/reward_energy Max                  -0.000943247
evaluation/env_infos/reward_energy Min                  -1.1389
evaluation/env_infos/final/end_effector_loc Mean         0.0594322
evaluation/env_infos/final/end_effector_loc Std          0.288335
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.632372
evaluation/env_infos/initial/end_effector_loc Mean      -8.14564e-05
evaluation/env_infos/initial/end_effector_loc Std        0.0106639
evaluation/env_infos/initial/end_effector_loc Max        0.032848
evaluation/env_infos/initial/end_effector_loc Min       -0.0453314
evaluation/env_infos/end_effector_loc Mean               0.0226341
evaluation/env_infos/end_effector_loc Std                0.181331
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.632372
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.136688
evaluation/env_infos/final/reward_dist Std               0.241735
evaluation/env_infos/final/reward_dist Max               0.932897
evaluation/env_infos/final/reward_dist Min               4.04785e-78
evaluation/env_infos/initial/reward_dist Mean            0.00854417
evaluation/env_infos/initial/reward_dist Std             0.0135259
evaluation/env_infos/initial/reward_dist Max             0.0511415
evaluation/env_infos/initial/reward_dist Min             1.58699e-06
evaluation/env_infos/reward_dist Mean                    0.160773
evaluation/env_infos/reward_dist Std                     0.237033
evaluation/env_infos/reward_dist Max                     0.993369
evaluation/env_infos/reward_dist Min                     4.04785e-78
time/data storing (s)                                   14.1988
time/evaluation sampling (s)                             0.64192
time/exploration sampling (s)                            0.0893599
time/logging (s)                                         0.0146029
time/saving (s)                                          0.305814
time/training (s)                                       34.9118
time/epoch (s)                                          50.1623
time/total (s)                                        1192.89
Epoch                                                   26
---------------------------------------------------  ---------------
2021-05-29 00:16:36.299177 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 27 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00142268
trainer/QF2 Loss                                         0.00244838
trainer/Policy Loss                                      2.89685
trainer/Q1 Predictions Mean                             -0.828986
trainer/Q1 Predictions Std                               0.727361
trainer/Q1 Predictions Max                               0.465638
trainer/Q1 Predictions Min                              -2.81122
trainer/Q2 Predictions Mean                             -0.820822
trainer/Q2 Predictions Std                               0.720882
trainer/Q2 Predictions Max                               0.441161
trainer/Q2 Predictions Min                              -2.79646
trainer/Q Targets Mean                                  -0.821503
trainer/Q Targets Std                                    0.719346
trainer/Q Targets Max                                    0.44077
trainer/Q Targets Min                                   -2.7598
trainer/Log Pis Mean                                     2.07916
trainer/Log Pis Std                                      1.46107
trainer/Log Pis Max                                      5.41291
trainer/Log Pis Min                                     -3.14792
trainer/Policy mu Mean                                  -0.0252368
trainer/Policy mu Std                                    0.408809
trainer/Policy mu Max                                    2.75129
trainer/Policy mu Min                                   -2.04234
trainer/Policy log std Mean                             -2.29557
trainer/Policy log std Std                               0.716462
trainer/Policy log std Max                              -0.027258
trainer/Policy log std Min                              -3.51937
trainer/Alpha                                            0.0172733
trainer/Alpha Loss                                       0.321308
exploration/num steps total                           3800
exploration/num paths total                            190
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.116149
exploration/Rewards Std                                  0.0706602
exploration/Rewards Max                                  0.035057
exploration/Rewards Min                                 -0.486348
exploration/Returns Mean                                -2.32297
exploration/Returns Std                                  0.790998
exploration/Returns Max                                 -0.905272
exploration/Returns Min                                 -3.09958
exploration/Actions Mean                                -0.0275098
exploration/Actions Std                                  0.259539
exploration/Actions Max                                  0.897794
exploration/Actions Min                                 -0.971782
exploration/Num Paths                                    5
exploration/Average Returns                             -2.32297
exploration/env_infos/final/reward_energy Mean          -0.458837
exploration/env_infos/final/reward_energy Std            0.379279
exploration/env_infos/final/reward_energy Max           -0.0601363
exploration/env_infos/final/reward_energy Min           -0.915336
exploration/env_infos/initial/reward_energy Mean        -0.234247
exploration/env_infos/initial/reward_energy Std          0.151712
exploration/env_infos/initial/reward_energy Max         -0.0701433
exploration/env_infos/initial/reward_energy Min         -0.472133
exploration/env_infos/reward_energy Mean                -0.262583
exploration/env_infos/reward_energy Std                  0.259392
exploration/env_infos/reward_energy Max                 -0.024571
exploration/env_infos/reward_energy Min                 -1.32302
exploration/env_infos/final/end_effector_loc Mean       -0.0406708
exploration/env_infos/final/end_effector_loc Std         0.184266
exploration/env_infos/final/end_effector_loc Max         0.27937
exploration/env_infos/final/end_effector_loc Min        -0.333382
exploration/env_infos/initial/end_effector_loc Mean     -0.00502901
exploration/env_infos/initial/end_effector_loc Std       0.00848935
exploration/env_infos/initial/end_effector_loc Max       0.0105395
exploration/env_infos/initial/end_effector_loc Min      -0.0173234
exploration/env_infos/end_effector_loc Mean             -0.00748492
exploration/env_infos/end_effector_loc Std               0.0980472
exploration/env_infos/end_effector_loc Max               0.27937
exploration/env_infos/end_effector_loc Min              -0.333382
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00440308
exploration/env_infos/final/reward_dist Std              0.00563737
exploration/env_infos/final/reward_dist Max              0.013684
exploration/env_infos/final/reward_dist Min              5.53234e-16
exploration/env_infos/initial/reward_dist Mean           0.0158988
exploration/env_infos/initial/reward_dist Std            0.0197201
exploration/env_infos/initial/reward_dist Max            0.053836
exploration/env_infos/initial/reward_dist Min            9.12996e-06
exploration/env_infos/reward_dist Mean                   0.109225
exploration/env_infos/reward_dist Std                    0.220292
exploration/env_infos/reward_dist Max                    0.887605
exploration/env_infos/reward_dist Min                    5.53234e-16
evaluation/num steps total                           28000
evaluation/num paths total                            1400
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0648377
evaluation/Rewards Std                                   0.0808143
evaluation/Rewards Max                                   0.180696
evaluation/Rewards Min                                  -0.684663
evaluation/Returns Mean                                 -1.29675
evaluation/Returns Std                                   1.26329
evaluation/Returns Max                                   2.71096
evaluation/Returns Min                                  -4.5324
evaluation/Actions Mean                                  2.4775e-05
evaluation/Actions Std                                   0.114099
evaluation/Actions Max                                   0.832901
evaluation/Actions Min                                  -0.996133
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.29675
evaluation/env_infos/final/reward_energy Mean           -0.0864528
evaluation/env_infos/final/reward_energy Std             0.15235
evaluation/env_infos/final/reward_energy Max            -0.00222
evaluation/env_infos/final/reward_energy Min            -0.779462
evaluation/env_infos/initial/reward_energy Mean         -0.293437
evaluation/env_infos/initial/reward_energy Std           0.380235
evaluation/env_infos/initial/reward_energy Max          -0.0125348
evaluation/env_infos/initial/reward_energy Min          -1.30586
evaluation/env_infos/reward_energy Mean                 -0.0773468
evaluation/env_infos/reward_energy Std                   0.141614
evaluation/env_infos/reward_energy Max                  -0.000552791
evaluation/env_infos/reward_energy Min                  -1.30586
evaluation/env_infos/final/end_effector_loc Mean        -0.0144167
evaluation/env_infos/final/end_effector_loc Std          0.247643
evaluation/env_infos/final/end_effector_loc Max          0.806665
evaluation/env_infos/final/end_effector_loc Min         -0.670033
evaluation/env_infos/initial/end_effector_loc Mean      -0.00494791
evaluation/env_infos/initial/end_effector_loc Std        0.0162442
evaluation/env_infos/initial/end_effector_loc Max        0.0416451
evaluation/env_infos/initial/end_effector_loc Min       -0.0498066
evaluation/env_infos/end_effector_loc Mean              -0.0245479
evaluation/env_infos/end_effector_loc Std                0.168173
evaluation/env_infos/end_effector_loc Max                0.806665
evaluation/env_infos/end_effector_loc Min               -0.670033
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0460598
evaluation/env_infos/final/reward_dist Std               0.121941
evaluation/env_infos/final/reward_dist Max               0.726164
evaluation/env_infos/final/reward_dist Min               3.55268e-31
evaluation/env_infos/initial/reward_dist Mean            0.00630769
evaluation/env_infos/initial/reward_dist Std             0.010959
evaluation/env_infos/initial/reward_dist Max             0.0410333
evaluation/env_infos/initial/reward_dist Min             1.32746e-06
evaluation/env_infos/reward_dist Mean                    0.108066
evaluation/env_infos/reward_dist Std                     0.20844
evaluation/env_infos/reward_dist Max                     0.964859
evaluation/env_infos/reward_dist Min                     3.55268e-31
time/data storing (s)                                   14.4169
time/evaluation sampling (s)                             0.644854
time/exploration sampling (s)                            0.0891406
time/logging (s)                                         0.0141713
time/saving (s)                                          0.310828
time/training (s)                                       34.9621
time/epoch (s)                                          50.4379
time/total (s)                                        1243.64
Epoch                                                   27
---------------------------------------------------  ---------------
2021-05-29 00:17:27.161920 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 28 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00170012
trainer/QF2 Loss                                         0.0019003
trainer/Policy Loss                                      2.67966
trainer/Q1 Predictions Mean                             -0.760351
trainer/Q1 Predictions Std                               0.729432
trainer/Q1 Predictions Max                               0.658396
trainer/Q1 Predictions Min                              -2.67949
trainer/Q2 Predictions Mean                             -0.770501
trainer/Q2 Predictions Std                               0.730266
trainer/Q2 Predictions Max                               0.649165
trainer/Q2 Predictions Min                              -2.71014
trainer/Q Targets Mean                                  -0.778567
trainer/Q Targets Std                                    0.72763
trainer/Q Targets Max                                    0.621257
trainer/Q Targets Min                                   -2.69435
trainer/Log Pis Mean                                     1.92577
trainer/Log Pis Std                                      1.50944
trainer/Log Pis Max                                      5.61388
trainer/Log Pis Min                                     -4.38758
trainer/Policy mu Mean                                   0.0241947
trainer/Policy mu Std                                    0.500132
trainer/Policy mu Max                                    2.01082
trainer/Policy mu Min                                   -2.09816
trainer/Policy log std Mean                             -2.16535
trainer/Policy log std Std                               0.839761
trainer/Policy log std Max                               0.0305248
trainer/Policy log std Min                              -3.82614
trainer/Alpha                                            0.0162683
trainer/Alpha Loss                                      -0.305749
exploration/num steps total                           3900
exploration/num paths total                            195
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.182321
exploration/Rewards Std                                  0.132825
exploration/Rewards Max                                  0.0726852
exploration/Rewards Min                                 -0.542503
exploration/Returns Mean                                -3.64643
exploration/Returns Std                                  1.33061
exploration/Returns Max                                 -1.6115
exploration/Returns Min                                 -5.02717
exploration/Actions Mean                                 0.00571826
exploration/Actions Std                                  0.181625
exploration/Actions Max                                  0.831256
exploration/Actions Min                                 -0.980851
exploration/Num Paths                                    5
exploration/Average Returns                             -3.64643
exploration/env_infos/final/reward_energy Mean          -0.089425
exploration/env_infos/final/reward_energy Std            0.0387142
exploration/env_infos/final/reward_energy Max           -0.0432506
exploration/env_infos/final/reward_energy Min           -0.159762
exploration/env_infos/initial/reward_energy Mean        -0.463657
exploration/env_infos/initial/reward_energy Std          0.364039
exploration/env_infos/initial/reward_energy Max         -0.0691395
exploration/env_infos/initial/reward_energy Min         -0.984373
exploration/env_infos/reward_energy Mean                -0.175283
exploration/env_infos/reward_energy Std                  0.187927
exploration/env_infos/reward_energy Max                 -0.0175626
exploration/env_infos/reward_energy Min                 -0.984373
exploration/env_infos/final/end_effector_loc Mean        0.0704588
exploration/env_infos/final/end_effector_loc Std         0.349458
exploration/env_infos/final/end_effector_loc Max         0.786956
exploration/env_infos/final/end_effector_loc Min        -0.570439
exploration/env_infos/initial/end_effector_loc Mean     -0.00422753
exploration/env_infos/initial/end_effector_loc Std       0.0204085
exploration/env_infos/initial/end_effector_loc Max       0.0278106
exploration/env_infos/initial/end_effector_loc Min      -0.0490426
exploration/env_infos/end_effector_loc Mean              0.00716414
exploration/env_infos/end_effector_loc Std               0.23255
exploration/env_infos/end_effector_loc Max               0.786956
exploration/env_infos/end_effector_loc Min              -0.570439
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             9.6568e-07
exploration/env_infos/final/reward_dist Std              1.93124e-06
exploration/env_infos/final/reward_dist Max              4.82815e-06
exploration/env_infos/final/reward_dist Min              1.40916e-48
exploration/env_infos/initial/reward_dist Mean           0.00743892
exploration/env_infos/initial/reward_dist Std            0.0141916
exploration/env_infos/initial/reward_dist Max            0.0358052
exploration/env_infos/initial/reward_dist Min            9.70761e-06
exploration/env_infos/reward_dist Mean                   0.0229167
exploration/env_infos/reward_dist Std                    0.0783724
exploration/env_infos/reward_dist Max                    0.508282
exploration/env_infos/reward_dist Min                    1.40916e-48
evaluation/num steps total                           29000
evaluation/num paths total                            1450
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0533165
evaluation/Rewards Std                                   0.0743524
evaluation/Rewards Max                                   0.132233
evaluation/Rewards Min                                  -0.606466
evaluation/Returns Mean                                 -1.06633
evaluation/Returns Std                                   1.08486
evaluation/Returns Max                                   1.55015
evaluation/Returns Min                                  -3.08281
evaluation/Actions Mean                                 -0.00409526
evaluation/Actions Std                                   0.0762259
evaluation/Actions Max                                   0.76067
evaluation/Actions Min                                  -0.882432
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.06633
evaluation/env_infos/final/reward_energy Mean           -0.0633599
evaluation/env_infos/final/reward_energy Std             0.0977469
evaluation/env_infos/final/reward_energy Max            -0.00165994
evaluation/env_infos/final/reward_energy Min            -0.642776
evaluation/env_infos/initial/reward_energy Mean         -0.209321
evaluation/env_infos/initial/reward_energy Std           0.254026
evaluation/env_infos/initial/reward_energy Max          -0.0120505
evaluation/env_infos/initial/reward_energy Min          -1.16503
evaluation/env_infos/reward_energy Mean                 -0.0566852
evaluation/env_infos/reward_energy Std                   0.0918755
evaluation/env_infos/reward_energy Max                  -0.000656513
evaluation/env_infos/reward_energy Min                  -1.16503
evaluation/env_infos/final/end_effector_loc Mean        -0.0427833
evaluation/env_infos/final/end_effector_loc Std          0.263186
evaluation/env_infos/final/end_effector_loc Max          0.630866
evaluation/env_infos/final/end_effector_loc Min         -0.645641
evaluation/env_infos/initial/end_effector_loc Mean      -0.00289643
evaluation/env_infos/initial/end_effector_loc Std        0.0112713
evaluation/env_infos/initial/end_effector_loc Max        0.0380335
evaluation/env_infos/initial/end_effector_loc Min       -0.0441216
evaluation/env_infos/end_effector_loc Mean              -0.0244617
evaluation/env_infos/end_effector_loc Std                0.165365
evaluation/env_infos/end_effector_loc Max                0.630866
evaluation/env_infos/end_effector_loc Min               -0.645641
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.123447
evaluation/env_infos/final/reward_dist Std               0.213704
evaluation/env_infos/final/reward_dist Max               0.78114
evaluation/env_infos/final/reward_dist Min               3.18723e-31
evaluation/env_infos/initial/reward_dist Mean            0.00658805
evaluation/env_infos/initial/reward_dist Std             0.01184
evaluation/env_infos/initial/reward_dist Max             0.0461713
evaluation/env_infos/initial/reward_dist Min             9.50185e-07
evaluation/env_infos/reward_dist Mean                    0.14916
evaluation/env_infos/reward_dist Std                     0.253685
evaluation/env_infos/reward_dist Max                     0.994562
evaluation/env_infos/reward_dist Min                     3.18723e-31
time/data storing (s)                                   14.828
time/evaluation sampling (s)                             0.640394
time/exploration sampling (s)                            0.0904367
time/logging (s)                                         0.0148186
time/saving (s)                                          0.319063
time/training (s)                                       34.6013
time/epoch (s)                                          50.494
time/total (s)                                        1294.5
Epoch                                                   28
---------------------------------------------------  ---------------
2021-05-29 00:18:19.503808 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 29 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00155242
trainer/QF2 Loss                                         0.00160182
trainer/Policy Loss                                      2.71754
trainer/Q1 Predictions Mean                             -0.813278
trainer/Q1 Predictions Std                               0.719249
trainer/Q1 Predictions Max                               0.545047
trainer/Q1 Predictions Min                              -3.31221
trainer/Q2 Predictions Mean                             -0.810123
trainer/Q2 Predictions Std                               0.715331
trainer/Q2 Predictions Max                               0.573651
trainer/Q2 Predictions Min                              -3.35715
trainer/Q Targets Mean                                  -0.817299
trainer/Q Targets Std                                    0.724502
trainer/Q Targets Max                                    0.572278
trainer/Q Targets Min                                   -3.2824
trainer/Log Pis Mean                                     1.90879
trainer/Log Pis Std                                      1.46702
trainer/Log Pis Max                                      5.48663
trainer/Log Pis Min                                     -5.29564
trainer/Policy mu Mean                                  -0.03123
trainer/Policy mu Std                                    0.375663
trainer/Policy mu Max                                    1.44835
trainer/Policy mu Min                                   -2.50675
trainer/Policy log std Mean                             -2.23882
trainer/Policy log std Std                               0.721397
trainer/Policy log std Max                               0.629605
trainer/Policy log std Min                              -3.69041
trainer/Alpha                                            0.0164699
trainer/Alpha Loss                                      -0.374521
exploration/num steps total                           4000
exploration/num paths total                            200
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0562913
exploration/Rewards Std                                  0.0760527
exploration/Rewards Max                                  0.0996466
exploration/Rewards Min                                 -0.24079
exploration/Returns Mean                                -1.12583
exploration/Returns Std                                  0.893124
exploration/Returns Max                                 -0.0925359
exploration/Returns Min                                 -2.46057
exploration/Actions Mean                                 0.0150888
exploration/Actions Std                                  0.167727
exploration/Actions Max                                  0.92253
exploration/Actions Min                                 -0.876121
exploration/Num Paths                                    5
exploration/Average Returns                             -1.12583
exploration/env_infos/final/reward_energy Mean          -0.0750338
exploration/env_infos/final/reward_energy Std            0.0499078
exploration/env_infos/final/reward_energy Max           -0.0235655
exploration/env_infos/final/reward_energy Min           -0.166725
exploration/env_infos/initial/reward_energy Mean        -0.381705
exploration/env_infos/initial/reward_energy Std          0.462606
exploration/env_infos/initial/reward_energy Max         -0.0417417
exploration/env_infos/initial/reward_energy Min         -1.27226
exploration/env_infos/reward_energy Mean                -0.158422
exploration/env_infos/reward_energy Std                  0.177828
exploration/env_infos/reward_energy Max                 -0.0184523
exploration/env_infos/reward_energy Min                 -1.27226
exploration/env_infos/final/end_effector_loc Mean       -0.0112078
exploration/env_infos/final/end_effector_loc Std         0.279695
exploration/env_infos/final/end_effector_loc Max         0.532295
exploration/env_infos/final/end_effector_loc Min        -0.310535
exploration/env_infos/initial/end_effector_loc Mean      0.0034256
exploration/env_infos/initial/end_effector_loc Std       0.0209259
exploration/env_infos/initial/end_effector_loc Max       0.0461265
exploration/env_infos/initial/end_effector_loc Min      -0.0438061
exploration/env_infos/end_effector_loc Mean             -0.0355994
exploration/env_infos/end_effector_loc Std               0.211422
exploration/env_infos/end_effector_loc Max               0.532295
exploration/env_infos/end_effector_loc Min              -0.473684
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00590101
exploration/env_infos/final/reward_dist Std              0.0100209
exploration/env_infos/final/reward_dist Max              0.0258354
exploration/env_infos/final/reward_dist Min              6.88208e-05
exploration/env_infos/initial/reward_dist Mean           0.00818563
exploration/env_infos/initial/reward_dist Std            0.01063
exploration/env_infos/initial/reward_dist Max            0.0288663
exploration/env_infos/initial/reward_dist Min            3.1857e-06
exploration/env_infos/reward_dist Mean                   0.141058
exploration/env_infos/reward_dist Std                    0.234006
exploration/env_infos/reward_dist Max                    0.938263
exploration/env_infos/reward_dist Min                    1.20384e-14
evaluation/num steps total                           30000
evaluation/num paths total                            1500
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0655984
evaluation/Rewards Std                                   0.0689453
evaluation/Rewards Max                                   0.139818
evaluation/Rewards Min                                  -0.379927
evaluation/Returns Mean                                 -1.31197
evaluation/Returns Std                                   1.02669
evaluation/Returns Max                                   1.46167
evaluation/Returns Min                                  -3.47499
evaluation/Actions Mean                                 -0.00493643
evaluation/Actions Std                                   0.0730629
evaluation/Actions Max                                   0.603843
evaluation/Actions Min                                  -0.990022
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.31197
evaluation/env_infos/final/reward_energy Mean           -0.0532333
evaluation/env_infos/final/reward_energy Std             0.0524768
evaluation/env_infos/final/reward_energy Max            -0.00165311
evaluation/env_infos/final/reward_energy Min            -0.32741
evaluation/env_infos/initial/reward_energy Mean         -0.168705
evaluation/env_infos/initial/reward_energy Std           0.238418
evaluation/env_infos/initial/reward_energy Max          -0.00315876
evaluation/env_infos/initial/reward_energy Min          -1.36242
evaluation/env_infos/reward_energy Mean                 -0.0564059
evaluation/env_infos/reward_energy Std                   0.0868533
evaluation/env_infos/reward_energy Max                  -0.000118712
evaluation/env_infos/reward_energy Min                  -1.36242
evaluation/env_infos/final/end_effector_loc Mean        -0.0435251
evaluation/env_infos/final/end_effector_loc Std          0.252857
evaluation/env_infos/final/end_effector_loc Max          0.556964
evaluation/env_infos/final/end_effector_loc Min         -0.503211
evaluation/env_infos/initial/end_effector_loc Mean      -0.00198892
evaluation/env_infos/initial/end_effector_loc Std        0.0101329
evaluation/env_infos/initial/end_effector_loc Max        0.0301922
evaluation/env_infos/initial/end_effector_loc Min       -0.0495011
evaluation/env_infos/end_effector_loc Mean              -0.0203582
evaluation/env_infos/end_effector_loc Std                0.153733
evaluation/env_infos/end_effector_loc Max                0.556964
evaluation/env_infos/end_effector_loc Min               -0.503211
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.133277
evaluation/env_infos/final/reward_dist Std               0.261942
evaluation/env_infos/final/reward_dist Max               0.973684
evaluation/env_infos/final/reward_dist Min               1.503e-38
evaluation/env_infos/initial/reward_dist Mean            0.00707834
evaluation/env_infos/initial/reward_dist Std             0.0151172
evaluation/env_infos/initial/reward_dist Max             0.0949451
evaluation/env_infos/initial/reward_dist Min             1.00076e-06
evaluation/env_infos/reward_dist Mean                    0.132742
evaluation/env_infos/reward_dist Std                     0.236342
evaluation/env_infos/reward_dist Max                     0.995825
evaluation/env_infos/reward_dist Min                     1.503e-38
time/data storing (s)                                   15.5655
time/evaluation sampling (s)                             0.642008
time/exploration sampling (s)                            0.0888375
time/logging (s)                                         0.0149159
time/saving (s)                                          0.334472
time/training (s)                                       35.3395
time/epoch (s)                                          51.9853
time/total (s)                                        1346.84
Epoch                                                   29
---------------------------------------------------  ---------------
2021-05-29 00:19:13.259544 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 30 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00192278
trainer/QF2 Loss                                         0.00272531
trainer/Policy Loss                                      2.64844
trainer/Q1 Predictions Mean                             -0.814228
trainer/Q1 Predictions Std                               0.755907
trainer/Q1 Predictions Max                               0.505513
trainer/Q1 Predictions Min                              -3.70734
trainer/Q2 Predictions Mean                             -0.801583
trainer/Q2 Predictions Std                               0.750531
trainer/Q2 Predictions Max                               0.561567
trainer/Q2 Predictions Min                              -3.59028
trainer/Q Targets Mean                                  -0.804619
trainer/Q Targets Std                                    0.75268
trainer/Q Targets Max                                    0.544798
trainer/Q Targets Min                                   -3.66431
trainer/Log Pis Mean                                     1.84337
trainer/Log Pis Std                                      1.54721
trainer/Log Pis Max                                      6.00855
trainer/Log Pis Min                                     -4.92863
trainer/Policy mu Mean                                  -0.0843271
trainer/Policy mu Std                                    0.521656
trainer/Policy mu Max                                    1.95676
trainer/Policy mu Min                                   -2.76168
trainer/Policy log std Mean                             -2.17729
trainer/Policy log std Std                               0.739035
trainer/Policy log std Max                               0.332739
trainer/Policy log std Min                              -3.35448
trainer/Alpha                                            0.0152432
trainer/Alpha Loss                                      -0.655161
exploration/num steps total                           4100
exploration/num paths total                            205
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0745179
exploration/Rewards Std                                  0.0572987
exploration/Rewards Max                                  0.0425821
exploration/Rewards Min                                 -0.24764
exploration/Returns Mean                                -1.49036
exploration/Returns Std                                  0.795343
exploration/Returns Max                                 -0.034197
exploration/Returns Min                                 -2.2262
exploration/Actions Mean                                 0.00227601
exploration/Actions Std                                  0.104356
exploration/Actions Max                                  0.396768
exploration/Actions Min                                 -0.372858
exploration/Num Paths                                    5
exploration/Average Returns                             -1.49036
exploration/env_infos/final/reward_energy Mean          -0.110143
exploration/env_infos/final/reward_energy Std            0.0244956
exploration/env_infos/final/reward_energy Max           -0.0696149
exploration/env_infos/final/reward_energy Min           -0.133067
exploration/env_infos/initial/reward_energy Mean        -0.121
exploration/env_infos/initial/reward_energy Std          0.123172
exploration/env_infos/initial/reward_energy Max         -0.032407
exploration/env_infos/initial/reward_energy Min         -0.362917
exploration/env_infos/reward_energy Mean                -0.117627
exploration/env_infos/reward_energy Std                  0.0891897
exploration/env_infos/reward_energy Max                 -0.00409725
exploration/env_infos/reward_energy Min                 -0.471169
exploration/env_infos/final/end_effector_loc Mean        0.0736943
exploration/env_infos/final/end_effector_loc Std         0.202823
exploration/env_infos/final/end_effector_loc Max         0.414978
exploration/env_infos/final/end_effector_loc Min        -0.414491
exploration/env_infos/initial/end_effector_loc Mean      0.00233766
exploration/env_infos/initial/end_effector_loc Std       0.0056392
exploration/env_infos/initial/end_effector_loc Max       0.0161738
exploration/env_infos/initial/end_effector_loc Min      -0.00249874
exploration/env_infos/end_effector_loc Mean              0.0316922
exploration/env_infos/end_effector_loc Std               0.123015
exploration/env_infos/end_effector_loc Max               0.414978
exploration/env_infos/end_effector_loc Min              -0.414491
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.204097
exploration/env_infos/final/reward_dist Std              0.278849
exploration/env_infos/final/reward_dist Max              0.706643
exploration/env_infos/final/reward_dist Min              4.46268e-12
exploration/env_infos/initial/reward_dist Mean           0.00732589
exploration/env_infos/initial/reward_dist Std            0.00899259
exploration/env_infos/initial/reward_dist Max            0.0236376
exploration/env_infos/initial/reward_dist Min            6.78381e-05
exploration/env_infos/reward_dist Mean                   0.105623
exploration/env_infos/reward_dist Std                    0.184963
exploration/env_infos/reward_dist Max                    0.706643
exploration/env_infos/reward_dist Min                    4.46268e-12
evaluation/num steps total                           31000
evaluation/num paths total                            1550
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0617764
evaluation/Rewards Std                                   0.0775135
evaluation/Rewards Max                                   0.124661
evaluation/Rewards Min                                  -0.455331
evaluation/Returns Mean                                 -1.23553
evaluation/Returns Std                                   1.1434
evaluation/Returns Max                                   1.06701
evaluation/Returns Min                                  -3.51286
evaluation/Actions Mean                                 -0.00541846
evaluation/Actions Std                                   0.131324
evaluation/Actions Max                                   0.874128
evaluation/Actions Min                                  -0.958517
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.23553
evaluation/env_infos/final/reward_energy Mean           -0.0917908
evaluation/env_infos/final/reward_energy Std             0.155619
evaluation/env_infos/final/reward_energy Max            -0.0057005
evaluation/env_infos/final/reward_energy Min            -0.768024
evaluation/env_infos/initial/reward_energy Mean         -0.28903
evaluation/env_infos/initial/reward_energy Std           0.333831
evaluation/env_infos/initial/reward_energy Max          -0.014411
evaluation/env_infos/initial/reward_energy Min          -1.1314
evaluation/env_infos/reward_energy Mean                 -0.0871374
evaluation/env_infos/reward_energy Std                   0.164188
evaluation/env_infos/reward_energy Max                  -0.00198045
evaluation/env_infos/reward_energy Min                  -1.2499
evaluation/env_infos/final/end_effector_loc Mean        -0.0792414
evaluation/env_infos/final/end_effector_loc Std          0.283586
evaluation/env_infos/final/end_effector_loc Max          0.536138
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00564838
evaluation/env_infos/initial/end_effector_loc Std        0.0145541
evaluation/env_infos/initial/end_effector_loc Max        0.0256396
evaluation/env_infos/initial/end_effector_loc Min       -0.0479259
evaluation/env_infos/end_effector_loc Mean              -0.0514562
evaluation/env_infos/end_effector_loc Std                0.174776
evaluation/env_infos/end_effector_loc Max                0.536138
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0956121
evaluation/env_infos/final/reward_dist Std               0.199062
evaluation/env_infos/final/reward_dist Max               0.700569
evaluation/env_infos/final/reward_dist Min               5.67975e-61
evaluation/env_infos/initial/reward_dist Mean            0.00853517
evaluation/env_infos/initial/reward_dist Std             0.0130511
evaluation/env_infos/initial/reward_dist Max             0.0602443
evaluation/env_infos/initial/reward_dist Min             1.21947e-06
evaluation/env_infos/reward_dist Mean                    0.123243
evaluation/env_infos/reward_dist Std                     0.219436
evaluation/env_infos/reward_dist Max                     0.998081
evaluation/env_infos/reward_dist Min                     5.67975e-61
time/data storing (s)                                   16.0619
time/evaluation sampling (s)                             0.652846
time/exploration sampling (s)                            0.0875977
time/logging (s)                                         0.0170005
time/saving (s)                                          0.365271
time/training (s)                                       36.1829
time/epoch (s)                                          53.3676
time/total (s)                                        1400.59
Epoch                                                   30
---------------------------------------------------  ---------------
2021-05-29 00:20:07.235292 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 31 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00466064
trainer/QF2 Loss                                         0.00636452
trainer/Policy Loss                                      2.95953
trainer/Q1 Predictions Mean                             -0.733382
trainer/Q1 Predictions Std                               0.682255
trainer/Q1 Predictions Max                               0.521425
trainer/Q1 Predictions Min                              -2.83552
trainer/Q2 Predictions Mean                             -0.735153
trainer/Q2 Predictions Std                               0.685025
trainer/Q2 Predictions Max                               0.489033
trainer/Q2 Predictions Min                              -2.87113
trainer/Q Targets Mean                                  -0.72453
trainer/Q Targets Std                                    0.673583
trainer/Q Targets Max                                    0.52163
trainer/Q Targets Min                                   -2.71027
trainer/Log Pis Mean                                     2.24196
trainer/Log Pis Std                                      2.23752
trainer/Log Pis Max                                     13.8057
trainer/Log Pis Min                                     -3.86789
trainer/Policy mu Mean                                  -0.0676852
trainer/Policy mu Std                                    0.880224
trainer/Policy mu Max                                    4.85467
trainer/Policy mu Min                                   -3.94795
trainer/Policy log std Mean                             -2.02008
trainer/Policy log std Std                               0.86465
trainer/Policy log std Max                               1.2333
trainer/Policy log std Min                              -3.37688
trainer/Alpha                                            0.0160159
trainer/Alpha Loss                                       1.00084
exploration/num steps total                           4200
exploration/num paths total                            210
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0908467
exploration/Rewards Std                                  0.059017
exploration/Rewards Max                                  0.0778041
exploration/Rewards Min                                 -0.325619
exploration/Returns Mean                                -1.81693
exploration/Returns Std                                  0.381999
exploration/Returns Max                                 -1.27274
exploration/Returns Min                                 -2.26915
exploration/Actions Mean                                 0.00919652
exploration/Actions Std                                  0.10107
exploration/Actions Max                                  0.533895
exploration/Actions Min                                 -0.307136
exploration/Num Paths                                    5
exploration/Average Returns                             -1.81693
exploration/env_infos/final/reward_energy Mean          -0.103101
exploration/env_infos/final/reward_energy Std            0.0240081
exploration/env_infos/final/reward_energy Max           -0.0574223
exploration/env_infos/final/reward_energy Min           -0.121085
exploration/env_infos/initial/reward_energy Mean        -0.163406
exploration/env_infos/initial/reward_energy Std          0.10594
exploration/env_infos/initial/reward_energy Max         -0.0668225
exploration/env_infos/initial/reward_energy Min         -0.318644
exploration/env_infos/reward_energy Mean                -0.105876
exploration/env_infos/reward_energy Std                  0.096901
exploration/env_infos/reward_energy Max                 -0.012373
exploration/env_infos/reward_energy Min                 -0.699902
exploration/env_infos/final/end_effector_loc Mean        0.059873
exploration/env_infos/final/end_effector_loc Std         0.253777
exploration/env_infos/final/end_effector_loc Max         0.563623
exploration/env_infos/final/end_effector_loc Min        -0.308839
exploration/env_infos/initial/end_effector_loc Mean     -0.000696885
exploration/env_infos/initial/end_effector_loc Std       0.00684986
exploration/env_infos/initial/end_effector_loc Max       0.0121987
exploration/env_infos/initial/end_effector_loc Min      -0.0153568
exploration/env_infos/end_effector_loc Mean              0.00571863
exploration/env_infos/end_effector_loc Std               0.1588
exploration/env_infos/end_effector_loc Max               0.563623
exploration/env_infos/end_effector_loc Min              -0.319657
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0105465
exploration/env_infos/final/reward_dist Std              0.0187061
exploration/env_infos/final/reward_dist Max              0.0477847
exploration/env_infos/final/reward_dist Min              1.59419e-24
exploration/env_infos/initial/reward_dist Mean           0.000894177
exploration/env_infos/initial/reward_dist Std            0.00173432
exploration/env_infos/initial/reward_dist Max            0.00436244
exploration/env_infos/initial/reward_dist Min            4.44645e-06
exploration/env_infos/reward_dist Mean                   0.0497746
exploration/env_infos/reward_dist Std                    0.144818
exploration/env_infos/reward_dist Max                    0.887827
exploration/env_infos/reward_dist Min                    1.59419e-24
evaluation/num steps total                           32000
evaluation/num paths total                            1600
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0629027
evaluation/Rewards Std                                   0.0933173
evaluation/Rewards Max                                   0.156638
evaluation/Rewards Min                                  -0.858533
evaluation/Returns Mean                                 -1.25805
evaluation/Returns Std                                   1.37796
evaluation/Returns Max                                   1.7669
evaluation/Returns Min                                  -5.00201
evaluation/Actions Mean                                  0.000961917
evaluation/Actions Std                                   0.102014
evaluation/Actions Max                                   0.987598
evaluation/Actions Min                                  -0.981985
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.25805
evaluation/env_infos/final/reward_energy Mean           -0.0511244
evaluation/env_infos/final/reward_energy Std             0.0472708
evaluation/env_infos/final/reward_energy Max            -0.0111437
evaluation/env_infos/final/reward_energy Min            -0.246382
evaluation/env_infos/initial/reward_energy Mean         -0.299182
evaluation/env_infos/initial/reward_energy Std           0.389888
evaluation/env_infos/initial/reward_energy Max          -0.00948325
evaluation/env_infos/initial/reward_energy Min          -1.38702
evaluation/env_infos/reward_energy Mean                 -0.0672736
evaluation/env_infos/reward_energy Std                   0.127632
evaluation/env_infos/reward_energy Max                  -0.00147192
evaluation/env_infos/reward_energy Min                  -1.38702
evaluation/env_infos/final/end_effector_loc Mean        -0.0172026
evaluation/env_infos/final/end_effector_loc Std          0.28404
evaluation/env_infos/final/end_effector_loc Max          0.945335
evaluation/env_infos/final/end_effector_loc Min         -0.701356
evaluation/env_infos/initial/end_effector_loc Mean      -0.00256544
evaluation/env_infos/initial/end_effector_loc Std        0.0171849
evaluation/env_infos/initial/end_effector_loc Max        0.0493799
evaluation/env_infos/initial/end_effector_loc Min       -0.0490992
evaluation/env_infos/end_effector_loc Mean              -0.0207461
evaluation/env_infos/end_effector_loc Std                0.177495
evaluation/env_infos/end_effector_loc Max                0.945335
evaluation/env_infos/end_effector_loc Min               -0.701356
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0701259
evaluation/env_infos/final/reward_dist Std               0.156416
evaluation/env_infos/final/reward_dist Max               0.777367
evaluation/env_infos/final/reward_dist Min               3.96637e-57
evaluation/env_infos/initial/reward_dist Mean            0.0106624
evaluation/env_infos/initial/reward_dist Std             0.0213196
evaluation/env_infos/initial/reward_dist Max             0.121417
evaluation/env_infos/initial/reward_dist Min             3.49273e-06
evaluation/env_infos/reward_dist Mean                    0.118836
evaluation/env_infos/reward_dist Std                     0.229104
evaluation/env_infos/reward_dist Max                     0.99165
evaluation/env_infos/reward_dist Min                     3.96637e-57
time/data storing (s)                                   16.6101
time/evaluation sampling (s)                             0.725815
time/exploration sampling (s)                            0.0894547
time/logging (s)                                         0.0167827
time/saving (s)                                          0.356663
time/training (s)                                       35.8013
time/epoch (s)                                          53.6001
time/total (s)                                        1454.57
Epoch                                                   31
---------------------------------------------------  ---------------
2021-05-29 00:21:01.620764 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 32 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.0040998
trainer/QF2 Loss                                         0.00357863
trainer/Policy Loss                                      2.55693
trainer/Q1 Predictions Mean                             -0.766714
trainer/Q1 Predictions Std                               0.674843
trainer/Q1 Predictions Max                               0.482779
trainer/Q1 Predictions Min                              -2.63893
trainer/Q2 Predictions Mean                             -0.760184
trainer/Q2 Predictions Std                               0.674272
trainer/Q2 Predictions Max                               0.522798
trainer/Q2 Predictions Min                              -2.69577
trainer/Q Targets Mean                                  -0.746521
trainer/Q Targets Std                                    0.678613
trainer/Q Targets Max                                    0.514045
trainer/Q Targets Min                                   -2.61819
trainer/Log Pis Mean                                     1.80377
trainer/Log Pis Std                                      1.39121
trainer/Log Pis Max                                      5.98655
trainer/Log Pis Min                                     -2.83475
trainer/Policy mu Mean                                  -0.0318364
trainer/Policy mu Std                                    0.606747
trainer/Policy mu Max                                    2.48518
trainer/Policy mu Min                                   -2.868
trainer/Policy log std Mean                             -2.06088
trainer/Policy log std Std                               0.727253
trainer/Policy log std Max                               0.125297
trainer/Policy log std Min                              -3.28388
trainer/Alpha                                            0.0178497
trainer/Alpha Loss                                      -0.789664
exploration/num steps total                           4300
exploration/num paths total                            215
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0638457
exploration/Rewards Std                                  0.098759
exploration/Rewards Max                                  0.156837
exploration/Rewards Min                                 -0.269435
exploration/Returns Mean                                -1.27691
exploration/Returns Std                                  1.59087
exploration/Returns Max                                  1.53358
exploration/Returns Min                                 -3.34758
exploration/Actions Mean                                 0.00803889
exploration/Actions Std                                  0.13349
exploration/Actions Max                                  0.611383
exploration/Actions Min                                 -0.490307
exploration/Num Paths                                    5
exploration/Average Returns                             -1.27691
exploration/env_infos/final/reward_energy Mean          -0.12118
exploration/env_infos/final/reward_energy Std            0.0869412
exploration/env_infos/final/reward_energy Max           -0.0307508
exploration/env_infos/final/reward_energy Min           -0.265955
exploration/env_infos/initial/reward_energy Mean        -0.202479
exploration/env_infos/initial/reward_energy Std          0.120152
exploration/env_infos/initial/reward_energy Max         -0.0411215
exploration/env_infos/initial/reward_energy Min         -0.311055
exploration/env_infos/reward_energy Mean                -0.151156
exploration/env_infos/reward_energy Std                  0.113666
exploration/env_infos/reward_energy Max                 -0.00657888
exploration/env_infos/reward_energy Min                 -0.617333
exploration/env_infos/final/end_effector_loc Mean        0.0292489
exploration/env_infos/final/end_effector_loc Std         0.322652
exploration/env_infos/final/end_effector_loc Max         0.481981
exploration/env_infos/final/end_effector_loc Min        -0.459484
exploration/env_infos/initial/end_effector_loc Mean     -0.00238888
exploration/env_infos/initial/end_effector_loc Std       0.0079741
exploration/env_infos/initial/end_effector_loc Max       0.0101735
exploration/env_infos/initial/end_effector_loc Min      -0.0145357
exploration/env_infos/end_effector_loc Mean             -0.0203066
exploration/env_infos/end_effector_loc Std               0.182674
exploration/env_infos/end_effector_loc Max               0.481981
exploration/env_infos/end_effector_loc Min              -0.459484
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0457369
exploration/env_infos/final/reward_dist Std              0.0656027
exploration/env_infos/final/reward_dist Max              0.168331
exploration/env_infos/final/reward_dist Min              1.33322e-14
exploration/env_infos/initial/reward_dist Mean           0.0111038
exploration/env_infos/initial/reward_dist Std            0.0104892
exploration/env_infos/initial/reward_dist Max            0.0282763
exploration/env_infos/initial/reward_dist Min            1.61971e-05
exploration/env_infos/reward_dist Mean                   0.161431
exploration/env_infos/reward_dist Std                    0.254359
exploration/env_infos/reward_dist Max                    0.959135
exploration/env_infos/reward_dist Min                    1.33322e-14
evaluation/num steps total                           33000
evaluation/num paths total                            1650
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0753072
evaluation/Rewards Std                                   0.100568
evaluation/Rewards Max                                   0.127294
evaluation/Rewards Min                                  -0.746652
evaluation/Returns Mean                                 -1.50614
evaluation/Returns Std                                   1.63125
evaluation/Returns Max                                   1.15458
evaluation/Returns Min                                  -7.89914
evaluation/Actions Mean                                  0.0129822
evaluation/Actions Std                                   0.0995668
evaluation/Actions Max                                   0.723889
evaluation/Actions Min                                  -0.937917
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.50614
evaluation/env_infos/final/reward_energy Mean           -0.061177
evaluation/env_infos/final/reward_energy Std             0.0633062
evaluation/env_infos/final/reward_energy Max            -0.00441227
evaluation/env_infos/final/reward_energy Min            -0.438144
evaluation/env_infos/initial/reward_energy Mean         -0.282138
evaluation/env_infos/initial/reward_energy Std           0.36573
evaluation/env_infos/initial/reward_energy Max          -0.00452556
evaluation/env_infos/initial/reward_energy Min          -1.31394
evaluation/env_infos/reward_energy Mean                 -0.0766377
evaluation/env_infos/reward_energy Std                   0.119544
evaluation/env_infos/reward_energy Max                  -0.000510358
evaluation/env_infos/reward_energy Min                  -1.31394
evaluation/env_infos/final/end_effector_loc Mean         0.0958634
evaluation/env_infos/final/end_effector_loc Std          0.370388
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.788618
evaluation/env_infos/initial/end_effector_loc Mean      -0.000751891
evaluation/env_infos/initial/end_effector_loc Std        0.0163137
evaluation/env_infos/initial/end_effector_loc Max        0.0361944
evaluation/env_infos/initial/end_effector_loc Min       -0.0468959
evaluation/env_infos/end_effector_loc Mean               0.0398081
evaluation/env_infos/end_effector_loc Std                0.243856
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.788618
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.059334
evaluation/env_infos/final/reward_dist Std               0.144761
evaluation/env_infos/final/reward_dist Max               0.768419
evaluation/env_infos/final/reward_dist Min               8.94638e-110
evaluation/env_infos/initial/reward_dist Mean            0.00960936
evaluation/env_infos/initial/reward_dist Std             0.0327773
evaluation/env_infos/initial/reward_dist Max             0.21409
evaluation/env_infos/initial/reward_dist Min             8.7673e-07
evaluation/env_infos/reward_dist Mean                    0.114487
evaluation/env_infos/reward_dist Std                     0.215482
evaluation/env_infos/reward_dist Max                     0.995196
evaluation/env_infos/reward_dist Min                     8.94638e-110
time/data storing (s)                                   16.6326
time/evaluation sampling (s)                             0.679426
time/exploration sampling (s)                            0.0904591
time/logging (s)                                         0.0146611
time/saving (s)                                          0.357377
time/training (s)                                       36.2293
time/epoch (s)                                          54.0038
time/total (s)                                        1508.95
Epoch                                                   32
---------------------------------------------------  ----------------
2021-05-29 00:21:55.707777 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 33 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00442555
trainer/QF2 Loss                                         0.00382346
trainer/Policy Loss                                      2.74739
trainer/Q1 Predictions Mean                             -0.739484
trainer/Q1 Predictions Std                               0.751877
trainer/Q1 Predictions Max                               0.534594
trainer/Q1 Predictions Min                              -4.09028
trainer/Q2 Predictions Mean                             -0.736604
trainer/Q2 Predictions Std                               0.754446
trainer/Q2 Predictions Max                               0.527976
trainer/Q2 Predictions Min                              -4.14423
trainer/Q Targets Mean                                  -0.743142
trainer/Q Targets Std                                    0.751148
trainer/Q Targets Max                                    0.527485
trainer/Q Targets Min                                   -3.88866
trainer/Log Pis Mean                                     2.03038
trainer/Log Pis Std                                      1.68623
trainer/Log Pis Max                                      7.81917
trainer/Log Pis Min                                     -2.92989
trainer/Policy mu Mean                                  -0.0131423
trainer/Policy mu Std                                    0.750877
trainer/Policy mu Max                                    2.95489
trainer/Policy mu Min                                   -2.97216
trainer/Policy log std Mean                             -2.0192
trainer/Policy log std Std                               0.802362
trainer/Policy log std Max                               1.34078
trainer/Policy log std Min                              -3.30936
trainer/Alpha                                            0.0188483
trainer/Alpha Loss                                       0.120676
exploration/num steps total                           4400
exploration/num paths total                            220
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.182935
exploration/Rewards Std                                  0.113525
exploration/Rewards Max                                  0.0548903
exploration/Rewards Min                                 -0.599992
exploration/Returns Mean                                -3.65869
exploration/Returns Std                                  1.51957
exploration/Returns Max                                 -1.96381
exploration/Returns Min                                 -6.36596
exploration/Actions Mean                                -0.0129507
exploration/Actions Std                                  0.160596
exploration/Actions Max                                  0.488342
exploration/Actions Min                                 -0.971752
exploration/Num Paths                                    5
exploration/Average Returns                             -3.65869
exploration/env_infos/final/reward_energy Mean          -0.135334
exploration/env_infos/final/reward_energy Std            0.0357885
exploration/env_infos/final/reward_energy Max           -0.0986661
exploration/env_infos/final/reward_energy Min           -0.18989
exploration/env_infos/initial/reward_energy Mean        -0.427441
exploration/env_infos/initial/reward_energy Std          0.501494
exploration/env_infos/initial/reward_energy Max         -0.0260489
exploration/env_infos/initial/reward_energy Min         -1.33046
exploration/env_infos/reward_energy Mean                -0.158009
exploration/env_infos/reward_energy Std                  0.164168
exploration/env_infos/reward_energy Max                 -0.00306743
exploration/env_infos/reward_energy Min                 -1.33046
exploration/env_infos/final/end_effector_loc Mean       -0.109542
exploration/env_infos/final/end_effector_loc Std         0.542066
exploration/env_infos/final/end_effector_loc Max         0.730473
exploration/env_infos/final/end_effector_loc Min        -1
exploration/env_infos/initial/end_effector_loc Mean     -0.0132356
exploration/env_infos/initial/end_effector_loc Std       0.0191722
exploration/env_infos/initial/end_effector_loc Max       0.00448919
exploration/env_infos/initial/end_effector_loc Min      -0.0485876
exploration/env_infos/end_effector_loc Mean             -0.100307
exploration/env_infos/end_effector_loc Std               0.37073
exploration/env_infos/end_effector_loc Max               0.730473
exploration/env_infos/end_effector_loc Min              -1
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.141018
exploration/env_infos/final/reward_dist Std              0.189536
exploration/env_infos/final/reward_dist Max              0.475982
exploration/env_infos/final/reward_dist Min              7.34895e-192
exploration/env_infos/initial/reward_dist Mean           0.00129525
exploration/env_infos/initial/reward_dist Std            0.00250763
exploration/env_infos/initial/reward_dist Max            0.00630919
exploration/env_infos/initial/reward_dist Min            1.37907e-06
exploration/env_infos/reward_dist Mean                   0.0808869
exploration/env_infos/reward_dist Std                    0.170642
exploration/env_infos/reward_dist Max                    0.662047
exploration/env_infos/reward_dist Min                    7.34895e-192
evaluation/num steps total                           34000
evaluation/num paths total                            1700
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.118238
evaluation/Rewards Std                                   0.124726
evaluation/Rewards Max                                   0.114543
evaluation/Rewards Min                                  -0.996987
evaluation/Returns Mean                                 -2.36476
evaluation/Returns Std                                   1.85807
evaluation/Returns Max                                   0.765192
evaluation/Returns Min                                  -7.04855
evaluation/Actions Mean                                  0.00146993
evaluation/Actions Std                                   0.142217
evaluation/Actions Max                                   0.92818
evaluation/Actions Min                                  -0.988556
evaluation/Num Paths                                    50
evaluation/Average Returns                              -2.36476
evaluation/env_infos/final/reward_energy Mean           -0.058267
evaluation/env_infos/final/reward_energy Std             0.0391198
evaluation/env_infos/final/reward_energy Max            -0.00295498
evaluation/env_infos/final/reward_energy Min            -0.164474
evaluation/env_infos/initial/reward_energy Mean         -0.512993
evaluation/env_infos/initial/reward_energy Std           0.443268
evaluation/env_infos/initial/reward_energy Max          -0.00869459
evaluation/env_infos/initial/reward_energy Min          -1.34781
evaluation/env_infos/reward_energy Mean                 -0.104577
evaluation/env_infos/reward_energy Std                   0.171812
evaluation/env_infos/reward_energy Max                  -0.00199567
evaluation/env_infos/reward_energy Min                  -1.34781
evaluation/env_infos/final/end_effector_loc Mean        -0.0606956
evaluation/env_infos/final/end_effector_loc Std          0.453771
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.962156
evaluation/env_infos/initial/end_effector_loc Mean      -0.00523845
evaluation/env_infos/initial/end_effector_loc Std        0.0233906
evaluation/env_infos/initial/end_effector_loc Max        0.046409
evaluation/env_infos/initial/end_effector_loc Min       -0.0494278
evaluation/env_infos/end_effector_loc Mean              -0.0293117
evaluation/env_infos/end_effector_loc Std                0.315064
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.962156
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0358775
evaluation/env_infos/final/reward_dist Std               0.111278
evaluation/env_infos/final/reward_dist Max               0.677298
evaluation/env_infos/final/reward_dist Min               1.25974e-107
evaluation/env_infos/initial/reward_dist Mean            0.0155133
evaluation/env_infos/initial/reward_dist Std             0.038046
evaluation/env_infos/initial/reward_dist Max             0.223332
evaluation/env_infos/initial/reward_dist Min             1.41807e-07
evaluation/env_infos/reward_dist Mean                    0.0778606
evaluation/env_infos/reward_dist Std                     0.1847
evaluation/env_infos/reward_dist Max                     0.997347
evaluation/env_infos/reward_dist Min                     1.25974e-107
time/data storing (s)                                   17.1335
time/evaluation sampling (s)                             0.655474
time/exploration sampling (s)                            0.094549
time/logging (s)                                         0.0167739
time/saving (s)                                          0.359358
time/training (s)                                       35.3823
time/epoch (s)                                          53.6419
time/total (s)                                        1563.03
Epoch                                                   33
---------------------------------------------------  ----------------
2021-05-29 00:22:49.637256 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 34 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00128052
trainer/QF2 Loss                                         0.000788214
trainer/Policy Loss                                      2.78556
trainer/Q1 Predictions Mean                             -0.764606
trainer/Q1 Predictions Std                               0.727999
trainer/Q1 Predictions Max                               0.462377
trainer/Q1 Predictions Min                              -3.61682
trainer/Q2 Predictions Mean                             -0.761128
trainer/Q2 Predictions Std                               0.72531
trainer/Q2 Predictions Max                               0.506559
trainer/Q2 Predictions Min                              -3.70036
trainer/Q Targets Mean                                  -0.756354
trainer/Q Targets Std                                    0.72553
trainer/Q Targets Max                                    0.494412
trainer/Q Targets Min                                   -3.65049
trainer/Log Pis Mean                                     2.03057
trainer/Log Pis Std                                      1.34566
trainer/Log Pis Max                                      6.5552
trainer/Log Pis Min                                     -2.13466
trainer/Policy mu Mean                                  -0.0121733
trainer/Policy mu Std                                    0.461425
trainer/Policy mu Max                                    2.00126
trainer/Policy mu Min                                   -2.54714
trainer/Policy log std Mean                             -2.25045
trainer/Policy log std Std                               0.64435
trainer/Policy log std Max                               0.471773
trainer/Policy log std Min                              -3.35991
trainer/Alpha                                            0.0176471
trainer/Alpha Loss                                       0.123402
exploration/num steps total                           4500
exploration/num paths total                            225
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.180588
exploration/Rewards Std                                  0.14995
exploration/Rewards Max                                  0.00778662
exploration/Rewards Min                                 -0.646506
exploration/Returns Mean                                -3.61176
exploration/Returns Std                                  2.46461
exploration/Returns Max                                 -1.37822
exploration/Returns Min                                 -8.31469
exploration/Actions Mean                                 0.0140572
exploration/Actions Std                                  0.176151
exploration/Actions Max                                  0.784446
exploration/Actions Min                                 -0.369583
exploration/Num Paths                                    5
exploration/Average Returns                             -3.61176
exploration/env_infos/final/reward_energy Mean          -0.219729
exploration/env_infos/final/reward_energy Std            0.141876
exploration/env_infos/final/reward_energy Max           -0.0364003
exploration/env_infos/final/reward_energy Min           -0.384079
exploration/env_infos/initial/reward_energy Mean        -0.321984
exploration/env_infos/initial/reward_energy Std          0.203834
exploration/env_infos/initial/reward_energy Max         -0.0715299
exploration/env_infos/initial/reward_energy Min         -0.656407
exploration/env_infos/reward_energy Mean                -0.189153
exploration/env_infos/reward_energy Std                  0.163324
exploration/env_infos/reward_energy Max                 -0.00419346
exploration/env_infos/reward_energy Min                 -0.909123
exploration/env_infos/final/end_effector_loc Mean        0.0651543
exploration/env_infos/final/end_effector_loc Std         0.544712
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.601653
exploration/env_infos/initial/end_effector_loc Mean      0.000427791
exploration/env_infos/initial/end_effector_loc Std       0.0134664
exploration/env_infos/initial/end_effector_loc Max       0.0317952
exploration/env_infos/initial/end_effector_loc Min      -0.0152463
exploration/env_infos/end_effector_loc Mean              0.0730004
exploration/env_infos/end_effector_loc Std               0.386605
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.601653
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.236472
exploration/env_infos/final/reward_dist Std              0.291686
exploration/env_infos/final/reward_dist Max              0.646011
exploration/env_infos/final/reward_dist Min              3.91453e-89
exploration/env_infos/initial/reward_dist Mean           0.00103856
exploration/env_infos/initial/reward_dist Std            0.00086698
exploration/env_infos/initial/reward_dist Max            0.00213233
exploration/env_infos/initial/reward_dist Min            1.70635e-05
exploration/env_infos/reward_dist Mean                   0.0803328
exploration/env_infos/reward_dist Std                    0.172452
exploration/env_infos/reward_dist Max                    0.846263
exploration/env_infos/reward_dist Min                    3.91453e-89
evaluation/num steps total                           35000
evaluation/num paths total                            1750
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0688988
evaluation/Rewards Std                                   0.0725139
evaluation/Rewards Max                                   0.166777
evaluation/Rewards Min                                  -0.718948
evaluation/Returns Mean                                 -1.37798
evaluation/Returns Std                                   1.0519
evaluation/Returns Max                                   0.969411
evaluation/Returns Min                                  -5.01103
evaluation/Actions Mean                                 -0.0051005
evaluation/Actions Std                                   0.0913281
evaluation/Actions Max                                   0.896939
evaluation/Actions Min                                  -0.986289
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.37798
evaluation/env_infos/final/reward_energy Mean           -0.0519747
evaluation/env_infos/final/reward_energy Std             0.0379612
evaluation/env_infos/final/reward_energy Max            -0.00480816
evaluation/env_infos/final/reward_energy Min            -0.169362
evaluation/env_infos/initial/reward_energy Mean         -0.259611
evaluation/env_infos/initial/reward_energy Std           0.335208
evaluation/env_infos/initial/reward_energy Max          -0.00380745
evaluation/env_infos/initial/reward_energy Min          -1.33314
evaluation/env_infos/reward_energy Mean                 -0.0671991
evaluation/env_infos/reward_energy Std                   0.110535
evaluation/env_infos/reward_energy Max                  -0.000528651
evaluation/env_infos/reward_energy Min                  -1.33314
evaluation/env_infos/final/end_effector_loc Mean        -0.125293
evaluation/env_infos/final/end_effector_loc Std          0.34943
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00273596
evaluation/env_infos/initial/end_effector_loc Std        0.0147383
evaluation/env_infos/initial/end_effector_loc Max        0.0448469
evaluation/env_infos/initial/end_effector_loc Min       -0.0493144
evaluation/env_infos/end_effector_loc Mean              -0.0643432
evaluation/env_infos/end_effector_loc Std                0.243036
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0504293
evaluation/env_infos/final/reward_dist Std               0.129835
evaluation/env_infos/final/reward_dist Max               0.672357
evaluation/env_infos/final/reward_dist Min               5.65597e-167
evaluation/env_infos/initial/reward_dist Mean            0.0101431
evaluation/env_infos/initial/reward_dist Std             0.0250457
evaluation/env_infos/initial/reward_dist Max             0.165913
evaluation/env_infos/initial/reward_dist Min             8.45951e-07
evaluation/env_infos/reward_dist Mean                    0.0915129
evaluation/env_infos/reward_dist Std                     0.189259
evaluation/env_infos/reward_dist Max                     0.995297
evaluation/env_infos/reward_dist Min                     5.65597e-167
time/data storing (s)                                   17.2995
time/evaluation sampling (s)                             0.643874
time/exploration sampling (s)                            0.0909083
time/logging (s)                                         0.0143862
time/saving (s)                                          0.366695
time/training (s)                                       35.1212
time/epoch (s)                                          53.5366
time/total (s)                                        1616.96
Epoch                                                   34
---------------------------------------------------  ----------------
2021-05-29 00:23:44.966549 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 35 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00178264
trainer/QF2 Loss                                         0.00225939
trainer/Policy Loss                                      2.98043
trainer/Q1 Predictions Mean                             -0.83562
trainer/Q1 Predictions Std                               0.718449
trainer/Q1 Predictions Max                               0.440826
trainer/Q1 Predictions Min                              -3.85436
trainer/Q2 Predictions Mean                             -0.841472
trainer/Q2 Predictions Std                               0.723362
trainer/Q2 Predictions Max                               0.47412
trainer/Q2 Predictions Min                              -3.84887
trainer/Q Targets Mean                                  -0.84587
trainer/Q Targets Std                                    0.716702
trainer/Q Targets Max                                    0.469198
trainer/Q Targets Min                                   -3.90685
trainer/Log Pis Mean                                     2.14651
trainer/Log Pis Std                                      1.59266
trainer/Log Pis Max                                     11.0038
trainer/Log Pis Min                                     -2.98869
trainer/Policy mu Mean                                  -0.0509142
trainer/Policy mu Std                                    0.521677
trainer/Policy mu Max                                    1.82126
trainer/Policy mu Min                                   -2.98713
trainer/Policy log std Mean                             -2.20349
trainer/Policy log std Std                               0.766796
trainer/Policy log std Max                               2
trainer/Policy log std Min                              -3.44169
trainer/Alpha                                            0.017386
trainer/Alpha Loss                                       0.594092
exploration/num steps total                           4600
exploration/num paths total                            230
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0695525
exploration/Rewards Std                                  0.071796
exploration/Rewards Max                                  0.100291
exploration/Rewards Min                                 -0.273007
exploration/Returns Mean                                -1.39105
exploration/Returns Std                                  1.12786
exploration/Returns Max                                  0.618634
exploration/Returns Min                                 -2.71594
exploration/Actions Mean                                -0.0029557
exploration/Actions Std                                  0.0879437
exploration/Actions Max                                  0.22487
exploration/Actions Min                                 -0.395929
exploration/Num Paths                                    5
exploration/Average Returns                             -1.39105
exploration/env_infos/final/reward_energy Mean          -0.127455
exploration/env_infos/final/reward_energy Std            0.0380439
exploration/env_infos/final/reward_energy Max           -0.0888776
exploration/env_infos/final/reward_energy Min           -0.178812
exploration/env_infos/initial/reward_energy Mean        -0.215882
exploration/env_infos/initial/reward_energy Std          0.119409
exploration/env_infos/initial/reward_energy Max         -0.0918246
exploration/env_infos/initial/reward_energy Min         -0.397412
exploration/env_infos/reward_energy Mean                -0.10453
exploration/env_infos/reward_energy Std                  0.0675216
exploration/env_infos/reward_energy Max                 -0.00611069
exploration/env_infos/reward_energy Min                 -0.397412
exploration/env_infos/final/end_effector_loc Mean       -0.0385662
exploration/env_infos/final/end_effector_loc Std         0.207837
exploration/env_infos/final/end_effector_loc Max         0.166477
exploration/env_infos/final/end_effector_loc Min        -0.424926
exploration/env_infos/initial/end_effector_loc Mean     -0.000842064
exploration/env_infos/initial/end_effector_loc Std       0.00868161
exploration/env_infos/initial/end_effector_loc Max       0.00925452
exploration/env_infos/initial/end_effector_loc Min      -0.0197964
exploration/env_infos/end_effector_loc Mean             -0.0283658
exploration/env_infos/end_effector_loc Std               0.14307
exploration/env_infos/end_effector_loc Max               0.184436
exploration/env_infos/end_effector_loc Min              -0.424926
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.328385
exploration/env_infos/final/reward_dist Std              0.332551
exploration/env_infos/final/reward_dist Max              0.800738
exploration/env_infos/final/reward_dist Min              4.95057e-09
exploration/env_infos/initial/reward_dist Mean           0.00257116
exploration/env_infos/initial/reward_dist Std            0.00292357
exploration/env_infos/initial/reward_dist Max            0.00778656
exploration/env_infos/initial/reward_dist Min            1.0543e-05
exploration/env_infos/reward_dist Mean                   0.145278
exploration/env_infos/reward_dist Std                    0.228746
exploration/env_infos/reward_dist Max                    0.800738
exploration/env_infos/reward_dist Min                    4.95057e-09
evaluation/num steps total                           36000
evaluation/num paths total                            1800
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0618052
evaluation/Rewards Std                                   0.0675512
evaluation/Rewards Max                                   0.143072
evaluation/Rewards Min                                  -0.504591
evaluation/Returns Mean                                 -1.2361
evaluation/Returns Std                                   1.07693
evaluation/Returns Max                                   1.87708
evaluation/Returns Min                                  -2.91537
evaluation/Actions Mean                                 -0.00619946
evaluation/Actions Std                                   0.0653199
evaluation/Actions Max                                   0.58834
evaluation/Actions Min                                  -0.716758
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.2361
evaluation/env_infos/final/reward_energy Mean           -0.0462968
evaluation/env_infos/final/reward_energy Std             0.0584682
evaluation/env_infos/final/reward_energy Max            -0.0068656
evaluation/env_infos/final/reward_energy Min            -0.390143
evaluation/env_infos/initial/reward_energy Mean         -0.15798
evaluation/env_infos/initial/reward_energy Std           0.211007
evaluation/env_infos/initial/reward_energy Max          -0.0100515
evaluation/env_infos/initial/reward_energy Min          -0.902873
evaluation/env_infos/reward_energy Mean                 -0.0527832
evaluation/env_infos/reward_energy Std                   0.0763163
evaluation/env_infos/reward_energy Max                  -0.000598588
evaluation/env_infos/reward_energy Min                  -0.902873
evaluation/env_infos/final/end_effector_loc Mean        -0.081234
evaluation/env_infos/final/end_effector_loc Std          0.214202
evaluation/env_infos/final/end_effector_loc Max          0.382411
evaluation/env_infos/final/end_effector_loc Min         -0.639165
evaluation/env_infos/initial/end_effector_loc Mean      -0.00322391
evaluation/env_infos/initial/end_effector_loc Std        0.00874407
evaluation/env_infos/initial/end_effector_loc Max        0.0212065
evaluation/env_infos/initial/end_effector_loc Min       -0.0358379
evaluation/env_infos/end_effector_loc Mean              -0.0417925
evaluation/env_infos/end_effector_loc Std                0.132331
evaluation/env_infos/end_effector_loc Max                0.382411
evaluation/env_infos/end_effector_loc Min               -0.639165
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.101804
evaluation/env_infos/final/reward_dist Std               0.230666
evaluation/env_infos/final/reward_dist Max               0.906963
evaluation/env_infos/final/reward_dist Min               1.51548e-22
evaluation/env_infos/initial/reward_dist Mean            0.00549253
evaluation/env_infos/initial/reward_dist Std             0.0100171
evaluation/env_infos/initial/reward_dist Max             0.0427837
evaluation/env_infos/initial/reward_dist Min             9.52047e-07
evaluation/env_infos/reward_dist Mean                    0.10216
evaluation/env_infos/reward_dist Std                     0.211767
evaluation/env_infos/reward_dist Max                     0.999005
evaluation/env_infos/reward_dist Min                     1.51548e-22
time/data storing (s)                                   17.9787
time/evaluation sampling (s)                             0.54931
time/exploration sampling (s)                            0.0942196
time/logging (s)                                         0.0149104
time/saving (s)                                          0.376492
time/training (s)                                       35.9234
time/epoch (s)                                          54.937
time/total (s)                                        1672.29
Epoch                                                   35
---------------------------------------------------  ---------------
2021-05-29 00:24:40.006749 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 36 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00119692
trainer/QF2 Loss                                         0.00127345
trainer/Policy Loss                                      2.77878
trainer/Q1 Predictions Mean                             -0.746927
trainer/Q1 Predictions Std                               0.646199
trainer/Q1 Predictions Max                               0.651742
trainer/Q1 Predictions Min                              -2.87847
trainer/Q2 Predictions Mean                             -0.75635
trainer/Q2 Predictions Std                               0.652323
trainer/Q2 Predictions Max                               0.655184
trainer/Q2 Predictions Min                              -2.77398
trainer/Q Targets Mean                                  -0.756814
trainer/Q Targets Std                                    0.654725
trainer/Q Targets Max                                    0.64143
trainer/Q Targets Min                                   -2.89066
trainer/Log Pis Mean                                     2.0428
trainer/Log Pis Std                                      1.35854
trainer/Log Pis Max                                      6.19822
trainer/Log Pis Min                                     -2.15236
trainer/Policy mu Mean                                   0.0373644
trainer/Policy mu Std                                    0.465677
trainer/Policy mu Max                                    2.16319
trainer/Policy mu Min                                   -2.9465
trainer/Policy log std Mean                             -2.26374
trainer/Policy log std Std                               0.648904
trainer/Policy log std Max                              -0.321058
trainer/Policy log std Min                              -3.42405
trainer/Alpha                                            0.0184512
trainer/Alpha Loss                                       0.1709
exploration/num steps total                           4700
exploration/num paths total                            235
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.108175
exploration/Rewards Std                                  0.0797894
exploration/Rewards Max                                  0.0734586
exploration/Rewards Min                                 -0.47628
exploration/Returns Mean                                -2.1635
exploration/Returns Std                                  0.81711
exploration/Returns Max                                 -1.02231
exploration/Returns Min                                 -3.37843
exploration/Actions Mean                                -0.0123567
exploration/Actions Std                                  0.132279
exploration/Actions Max                                  0.362303
exploration/Actions Min                                 -0.4155
exploration/Num Paths                                    5
exploration/Average Returns                             -2.1635
exploration/env_infos/final/reward_energy Mean          -0.234886
exploration/env_infos/final/reward_energy Std            0.174753
exploration/env_infos/final/reward_energy Max           -0.0607561
exploration/env_infos/final/reward_energy Min           -0.507429
exploration/env_infos/initial/reward_energy Mean        -0.165868
exploration/env_infos/initial/reward_energy Std          0.122482
exploration/env_infos/initial/reward_energy Max         -0.0564787
exploration/env_infos/initial/reward_energy Min         -0.387894
exploration/env_infos/reward_energy Mean                -0.157438
exploration/env_infos/reward_energy Std                  0.102537
exploration/env_infos/reward_energy Max                 -0.0220603
exploration/env_infos/reward_energy Min                 -0.507429
exploration/env_infos/final/end_effector_loc Mean       -0.0119094
exploration/env_infos/final/end_effector_loc Std         0.204621
exploration/env_infos/final/end_effector_loc Max         0.294435
exploration/env_infos/final/end_effector_loc Min        -0.354335
exploration/env_infos/initial/end_effector_loc Mean      0.000688609
exploration/env_infos/initial/end_effector_loc Std       0.0072573
exploration/env_infos/initial/end_effector_loc Max       0.0176977
exploration/env_infos/initial/end_effector_loc Min      -0.00937595
exploration/env_infos/end_effector_loc Mean              0.01395
exploration/env_infos/end_effector_loc Std               0.152798
exploration/env_infos/end_effector_loc Max               0.445333
exploration/env_infos/end_effector_loc Min              -0.354335
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00584782
exploration/env_infos/final/reward_dist Std              0.00717169
exploration/env_infos/final/reward_dist Max              0.0152163
exploration/env_infos/final/reward_dist Min              1.39569e-07
exploration/env_infos/initial/reward_dist Mean           0.00387268
exploration/env_infos/initial/reward_dist Std            0.00335919
exploration/env_infos/initial/reward_dist Max            0.00942526
exploration/env_infos/initial/reward_dist Min            1.64946e-06
exploration/env_infos/reward_dist Mean                   0.0403517
exploration/env_infos/reward_dist Std                    0.0851984
exploration/env_infos/reward_dist Max                    0.404571
exploration/env_infos/reward_dist Min                    5.3718e-08
evaluation/num steps total                           37000
evaluation/num paths total                            1850
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0770866
evaluation/Rewards Std                                   0.075537
evaluation/Rewards Max                                   0.0952777
evaluation/Rewards Min                                  -0.426874
evaluation/Returns Mean                                 -1.54173
evaluation/Returns Std                                   1.20143
evaluation/Returns Max                                   0.768874
evaluation/Returns Min                                  -5.12837
evaluation/Actions Mean                                  0.000224954
evaluation/Actions Std                                   0.0770583
evaluation/Actions Max                                   0.784493
evaluation/Actions Min                                  -0.650949
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.54173
evaluation/env_infos/final/reward_energy Mean           -0.0578871
evaluation/env_infos/final/reward_energy Std             0.0663452
evaluation/env_infos/final/reward_energy Max            -0.00475325
evaluation/env_infos/final/reward_energy Min            -0.283151
evaluation/env_infos/initial/reward_energy Mean         -0.16672
evaluation/env_infos/initial/reward_energy Std           0.206282
evaluation/env_infos/initial/reward_energy Max          -0.00550524
evaluation/env_infos/initial/reward_energy Min          -0.996914
evaluation/env_infos/reward_energy Mean                 -0.0662531
evaluation/env_infos/reward_energy Std                   0.0865252
evaluation/env_infos/reward_energy Max                  -0.00190109
evaluation/env_infos/reward_energy Min                  -0.996914
evaluation/env_infos/final/end_effector_loc Mean        -0.00546201
evaluation/env_infos/final/end_effector_loc Std          0.298914
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.576986
evaluation/env_infos/initial/end_effector_loc Mean       0.000370896
evaluation/env_infos/initial/end_effector_loc Std        0.00937001
evaluation/env_infos/initial/end_effector_loc Max        0.0392247
evaluation/env_infos/initial/end_effector_loc Min       -0.0325475
evaluation/env_infos/end_effector_loc Mean               0.00375711
evaluation/env_infos/end_effector_loc Std                0.197238
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.576986
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.118963
evaluation/env_infos/final/reward_dist Std               0.23386
evaluation/env_infos/final/reward_dist Max               0.920624
evaluation/env_infos/final/reward_dist Min               3.23386e-94
evaluation/env_infos/initial/reward_dist Mean            0.0039123
evaluation/env_infos/initial/reward_dist Std             0.00797709
evaluation/env_infos/initial/reward_dist Max             0.0365354
evaluation/env_infos/initial/reward_dist Min             1.95294e-06
evaluation/env_infos/reward_dist Mean                    0.079913
evaluation/env_infos/reward_dist Std                     0.176526
evaluation/env_infos/reward_dist Max                     0.935407
evaluation/env_infos/reward_dist Min                     3.23386e-94
time/data storing (s)                                   18.1401
time/evaluation sampling (s)                             0.653495
time/exploration sampling (s)                            0.0895177
time/logging (s)                                         0.0145035
time/saving (s)                                          0.403068
time/training (s)                                       35.3295
time/epoch (s)                                          54.6302
time/total (s)                                        1727.32
Epoch                                                   36
---------------------------------------------------  ---------------
2021-05-29 00:25:35.413990 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 37 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00121082
trainer/QF2 Loss                                         0.00119537
trainer/Policy Loss                                      2.84209
trainer/Q1 Predictions Mean                             -0.74526
trainer/Q1 Predictions Std                               0.722017
trainer/Q1 Predictions Max                               0.739527
trainer/Q1 Predictions Min                              -2.91511
trainer/Q2 Predictions Mean                             -0.745263
trainer/Q2 Predictions Std                               0.719612
trainer/Q2 Predictions Max                               0.751967
trainer/Q2 Predictions Min                              -2.89957
trainer/Q Targets Mean                                  -0.743155
trainer/Q Targets Std                                    0.717618
trainer/Q Targets Max                                    0.747594
trainer/Q Targets Min                                   -2.85027
trainer/Log Pis Mean                                     2.10431
trainer/Log Pis Std                                      1.58096
trainer/Log Pis Max                                      9.09075
trainer/Log Pis Min                                     -4.0464
trainer/Policy mu Mean                                   0.00846417
trainer/Policy mu Std                                    0.587897
trainer/Policy mu Max                                    2.87059
trainer/Policy mu Min                                   -3.07958
trainer/Policy log std Mean                             -2.29249
trainer/Policy log std Std                               0.65906
trainer/Policy log std Max                              -0.0483744
trainer/Policy log std Min                              -3.38751
trainer/Alpha                                            0.0179939
trainer/Alpha Loss                                       0.419207
exploration/num steps total                           4800
exploration/num paths total                            240
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0971871
exploration/Rewards Std                                  0.104422
exploration/Rewards Max                                  0.0200884
exploration/Rewards Min                                 -0.852096
exploration/Returns Mean                                -1.94374
exploration/Returns Std                                  1.21327
exploration/Returns Max                                 -0.508275
exploration/Returns Min                                 -4.00596
exploration/Actions Mean                                 0.00176422
exploration/Actions Std                                  0.159155
exploration/Actions Max                                  0.753444
exploration/Actions Min                                 -0.572852
exploration/Num Paths                                    5
exploration/Average Returns                             -1.94374
exploration/env_infos/final/reward_energy Mean          -0.110889
exploration/env_infos/final/reward_energy Std            0.0511878
exploration/env_infos/final/reward_energy Max           -0.0288922
exploration/env_infos/final/reward_energy Min           -0.171625
exploration/env_infos/initial/reward_energy Mean        -0.352025
exploration/env_infos/initial/reward_energy Std          0.33175
exploration/env_infos/initial/reward_energy Max         -0.0466519
exploration/env_infos/initial/reward_energy Min         -0.946487
exploration/env_infos/reward_energy Mean                -0.160285
exploration/env_infos/reward_energy Std                  0.158037
exploration/env_infos/reward_energy Max                 -0.008322
exploration/env_infos/reward_energy Min                 -0.946487
exploration/env_infos/final/end_effector_loc Mean        0.059287
exploration/env_infos/final/end_effector_loc Std         0.2797
exploration/env_infos/final/end_effector_loc Max         0.550805
exploration/env_infos/final/end_effector_loc Min        -0.507813
exploration/env_infos/initial/end_effector_loc Mean      0.000416858
exploration/env_infos/initial/end_effector_loc Std       0.0170968
exploration/env_infos/initial/end_effector_loc Max       0.0376722
exploration/env_infos/initial/end_effector_loc Min      -0.0286426
exploration/env_infos/end_effector_loc Mean              0.0225334
exploration/env_infos/end_effector_loc Std               0.215204
exploration/env_infos/end_effector_loc Max               0.550805
exploration/env_infos/end_effector_loc Min              -0.507813
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.162133
exploration/env_infos/final/reward_dist Std              0.21416
exploration/env_infos/final/reward_dist Max              0.575921
exploration/env_infos/final/reward_dist Min              6.07464e-43
exploration/env_infos/initial/reward_dist Mean           0.00757686
exploration/env_infos/initial/reward_dist Std            0.00686501
exploration/env_infos/initial/reward_dist Max            0.0180802
exploration/env_infos/initial/reward_dist Min            1.74159e-06
exploration/env_infos/reward_dist Mean                   0.0414448
exploration/env_infos/reward_dist Std                    0.0973331
exploration/env_infos/reward_dist Max                    0.575921
exploration/env_infos/reward_dist Min                    6.07464e-43
evaluation/num steps total                           38000
evaluation/num paths total                            1900
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0667878
evaluation/Rewards Std                                   0.0901898
evaluation/Rewards Max                                   0.143744
evaluation/Rewards Min                                  -0.786432
evaluation/Returns Mean                                 -1.33576
evaluation/Returns Std                                   1.32013
evaluation/Returns Max                                   0.864856
evaluation/Returns Min                                  -5.40361
evaluation/Actions Mean                                  0.00248704
evaluation/Actions Std                                   0.082677
evaluation/Actions Max                                   0.876637
evaluation/Actions Min                                  -0.883626
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.33576
evaluation/env_infos/final/reward_energy Mean           -0.0542634
evaluation/env_infos/final/reward_energy Std             0.0727295
evaluation/env_infos/final/reward_energy Max            -0.0012923
evaluation/env_infos/final/reward_energy Min            -0.461266
evaluation/env_infos/initial/reward_energy Mean         -0.228148
evaluation/env_infos/initial/reward_energy Std           0.267677
evaluation/env_infos/initial/reward_energy Max          -0.00479126
evaluation/env_infos/initial/reward_energy Min          -0.913594
evaluation/env_infos/reward_energy Mean                 -0.0619553
evaluation/env_infos/reward_energy Std                   0.0992215
evaluation/env_infos/reward_energy Max                  -0.00106539
evaluation/env_infos/reward_energy Min                  -0.913594
evaluation/env_infos/final/end_effector_loc Mean         0.0341418
evaluation/env_infos/final/end_effector_loc Std          0.352287
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00100728
evaluation/env_infos/initial/end_effector_loc Std        0.0123941
evaluation/env_infos/initial/end_effector_loc Max        0.0437086
evaluation/env_infos/initial/end_effector_loc Min       -0.0441813
evaluation/env_infos/end_effector_loc Mean               0.0142951
evaluation/env_infos/end_effector_loc Std                0.220447
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0860548
evaluation/env_infos/final/reward_dist Std               0.211379
evaluation/env_infos/final/reward_dist Max               0.858948
evaluation/env_infos/final/reward_dist Min               8.83719e-90
evaluation/env_infos/initial/reward_dist Mean            0.00392331
evaluation/env_infos/initial/reward_dist Std             0.00854008
evaluation/env_infos/initial/reward_dist Max             0.0409336
evaluation/env_infos/initial/reward_dist Min             9.22339e-07
evaluation/env_infos/reward_dist Mean                    0.0808321
evaluation/env_infos/reward_dist Std                     0.19282
evaluation/env_infos/reward_dist Max                     0.992228
evaluation/env_infos/reward_dist Min                     8.83719e-90
time/data storing (s)                                   18.3541
time/evaluation sampling (s)                             0.62153
time/exploration sampling (s)                            0.0852532
time/logging (s)                                         0.0146562
time/saving (s)                                          0.439366
time/training (s)                                       35.4733
time/epoch (s)                                          54.9882
time/total (s)                                        1782.73
Epoch                                                   37
---------------------------------------------------  ---------------
2021-05-29 00:26:31.512950 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 38 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00399946
trainer/QF2 Loss                                         0.00486239
trainer/Policy Loss                                      2.82462
trainer/Q1 Predictions Mean                             -0.856629
trainer/Q1 Predictions Std                               0.742166
trainer/Q1 Predictions Max                               0.770079
trainer/Q1 Predictions Min                              -3.11991
trainer/Q2 Predictions Mean                             -0.875347
trainer/Q2 Predictions Std                               0.738723
trainer/Q2 Predictions Max                               0.749789
trainer/Q2 Predictions Min                              -3.04588
trainer/Q Targets Mean                                  -0.864197
trainer/Q Targets Std                                    0.741493
trainer/Q Targets Max                                    0.78895
trainer/Q Targets Min                                   -3.22529
trainer/Log Pis Mean                                     1.95837
trainer/Log Pis Std                                      1.3232
trainer/Log Pis Max                                      7.06885
trainer/Log Pis Min                                     -4.72617
trainer/Policy mu Mean                                   0.100143
trainer/Policy mu Std                                    0.442635
trainer/Policy mu Max                                    2.52728
trainer/Policy mu Min                                   -2.24792
trainer/Policy log std Mean                             -2.24619
trainer/Policy log std Std                               0.594337
trainer/Policy log std Max                              -0.326848
trainer/Policy log std Min                              -3.28663
trainer/Alpha                                            0.0184518
trainer/Alpha Loss                                      -0.166159
exploration/num steps total                           4900
exploration/num paths total                            245
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.188765
exploration/Rewards Std                                  0.18616
exploration/Rewards Max                                  0.0724155
exploration/Rewards Min                                 -0.839151
exploration/Returns Mean                                -3.7753
exploration/Returns Std                                  2.78184
exploration/Returns Max                                 -0.553819
exploration/Returns Min                                 -7.39045
exploration/Actions Mean                                 0.0289106
exploration/Actions Std                                  0.138226
exploration/Actions Max                                  0.66173
exploration/Actions Min                                 -0.331585
exploration/Num Paths                                    5
exploration/Average Returns                             -3.7753
exploration/env_infos/final/reward_energy Mean          -0.263904
exploration/env_infos/final/reward_energy Std            0.250626
exploration/env_infos/final/reward_energy Max           -0.0399238
exploration/env_infos/final/reward_energy Min           -0.736567
exploration/env_infos/initial/reward_energy Mean        -0.193606
exploration/env_infos/initial/reward_energy Std          0.153457
exploration/env_infos/initial/reward_energy Max         -0.0369547
exploration/env_infos/initial/reward_energy Min         -0.407925
exploration/env_infos/reward_energy Mean                -0.154777
exploration/env_infos/reward_energy Std                  0.126209
exploration/env_infos/reward_energy Max                 -0.0103417
exploration/env_infos/reward_energy Min                 -0.736567
exploration/env_infos/final/end_effector_loc Mean        0.292847
exploration/env_infos/final/end_effector_loc Std         0.361581
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.257459
exploration/env_infos/initial/end_effector_loc Mean      0.00156251
exploration/env_infos/initial/end_effector_loc Std       0.00859353
exploration/env_infos/initial/end_effector_loc Max       0.0162074
exploration/env_infos/initial/end_effector_loc Min      -0.0165792
exploration/env_infos/end_effector_loc Mean              0.132353
exploration/env_infos/end_effector_loc Std               0.269784
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.331687
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.170324
exploration/env_infos/final/reward_dist Std              0.340631
exploration/env_infos/final/reward_dist Max              0.851586
exploration/env_infos/final/reward_dist Min              6.92515e-70
exploration/env_infos/initial/reward_dist Mean           0.00125071
exploration/env_infos/initial/reward_dist Std            0.00203082
exploration/env_infos/initial/reward_dist Max            0.0052448
exploration/env_infos/initial/reward_dist Min            4.0991e-06
exploration/env_infos/reward_dist Mean                   0.0935274
exploration/env_infos/reward_dist Std                    0.22234
exploration/env_infos/reward_dist Max                    0.99998
exploration/env_infos/reward_dist Min                    5.60976e-71
evaluation/num steps total                           39000
evaluation/num paths total                            1950
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0612994
evaluation/Rewards Std                                   0.0842644
evaluation/Rewards Max                                   0.156838
evaluation/Rewards Min                                  -0.324666
evaluation/Returns Mean                                 -1.22599
evaluation/Returns Std                                   1.46768
evaluation/Returns Max                                   1.68849
evaluation/Returns Min                                  -5.31284
evaluation/Actions Mean                                  0.000301343
evaluation/Actions Std                                   0.0518022
evaluation/Actions Max                                   0.325663
evaluation/Actions Min                                  -0.590743
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.22599
evaluation/env_infos/final/reward_energy Mean           -0.0458612
evaluation/env_infos/final/reward_energy Std             0.0413189
evaluation/env_infos/final/reward_energy Max            -0.00628105
evaluation/env_infos/final/reward_energy Min            -0.250177
evaluation/env_infos/initial/reward_energy Mean         -0.133465
evaluation/env_infos/initial/reward_energy Std           0.130915
evaluation/env_infos/initial/reward_energy Max          -0.0123459
evaluation/env_infos/initial/reward_energy Min          -0.59912
evaluation/env_infos/reward_energy Mean                 -0.049474
evaluation/env_infos/reward_energy Std                   0.054032
evaluation/env_infos/reward_energy Max                  -0.000996041
evaluation/env_infos/reward_energy Min                  -0.59912
evaluation/env_infos/final/end_effector_loc Mean         0.0124223
evaluation/env_infos/final/end_effector_loc Std          0.273612
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.815654
evaluation/env_infos/initial/end_effector_loc Mean      -0.00147051
evaluation/env_infos/initial/end_effector_loc Std        0.00644417
evaluation/env_infos/initial/end_effector_loc Max        0.0141824
evaluation/env_infos/initial/end_effector_loc Min       -0.0295372
evaluation/env_infos/end_effector_loc Mean               0.000398733
evaluation/env_infos/end_effector_loc Std                0.159144
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.815654
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0722347
evaluation/env_infos/final/reward_dist Std               0.164326
evaluation/env_infos/final/reward_dist Max               0.846826
evaluation/env_infos/final/reward_dist Min               7.77563e-57
evaluation/env_infos/initial/reward_dist Mean            0.00457653
evaluation/env_infos/initial/reward_dist Std             0.00625768
evaluation/env_infos/initial/reward_dist Max             0.0246149
evaluation/env_infos/initial/reward_dist Min             9.0804e-07
evaluation/env_infos/reward_dist Mean                    0.102494
evaluation/env_infos/reward_dist Std                     0.208611
evaluation/env_infos/reward_dist Max                     0.995912
evaluation/env_infos/reward_dist Min                     7.77563e-57
time/data storing (s)                                   18.7815
time/evaluation sampling (s)                             0.659318
time/exploration sampling (s)                            0.0905072
time/logging (s)                                         0.0141057
time/saving (s)                                          0.392294
time/training (s)                                       35.7322
time/epoch (s)                                          55.6699
time/total (s)                                        1838.82
Epoch                                                   38
---------------------------------------------------  ---------------
2021-05-29 00:27:27.970236 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 39 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.0060813
trainer/QF2 Loss                                         0.00220031
trainer/Policy Loss                                      2.77696
trainer/Q1 Predictions Mean                             -0.883689
trainer/Q1 Predictions Std                               0.67014
trainer/Q1 Predictions Max                               0.668791
trainer/Q1 Predictions Min                              -3.39472
trainer/Q2 Predictions Mean                             -0.884626
trainer/Q2 Predictions Std                               0.678325
trainer/Q2 Predictions Max                               0.642634
trainer/Q2 Predictions Min                              -3.43409
trainer/Q Targets Mean                                  -0.887577
trainer/Q Targets Std                                    0.694648
trainer/Q Targets Max                                    0.68165
trainer/Q Targets Min                                   -3.49145
trainer/Log Pis Mean                                     1.89946
trainer/Log Pis Std                                      1.35018
trainer/Log Pis Max                                      4.7482
trainer/Log Pis Min                                     -3.32284
trainer/Policy mu Mean                                   0.157349
trainer/Policy mu Std                                    0.437206
trainer/Policy mu Max                                    2.49741
trainer/Policy mu Min                                   -1.89148
trainer/Policy log std Mean                             -2.20471
trainer/Policy log std Std                               0.673755
trainer/Policy log std Max                               0.203829
trainer/Policy log std Min                              -3.39183
trainer/Alpha                                            0.0193557
trainer/Alpha Loss                                      -0.396678
exploration/num steps total                           5000
exploration/num paths total                            250
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.19818
exploration/Rewards Std                                  0.163054
exploration/Rewards Max                                  0.00150531
exploration/Rewards Min                                 -0.742958
exploration/Returns Mean                                -3.9636
exploration/Returns Std                                  2.80675
exploration/Returns Max                                 -1.60708
exploration/Returns Min                                 -9.32542
exploration/Actions Mean                                 0.0175463
exploration/Actions Std                                  0.200299
exploration/Actions Max                                  0.787115
exploration/Actions Min                                 -0.67958
exploration/Num Paths                                    5
exploration/Average Returns                             -3.9636
exploration/env_infos/final/reward_energy Mean          -0.0561669
exploration/env_infos/final/reward_energy Std            0.0114889
exploration/env_infos/final/reward_energy Max           -0.0428979
exploration/env_infos/final/reward_energy Min           -0.0698098
exploration/env_infos/initial/reward_energy Mean        -0.47016
exploration/env_infos/initial/reward_energy Std          0.208533
exploration/env_infos/initial/reward_energy Max         -0.0636749
exploration/env_infos/initial/reward_energy Min         -0.662046
exploration/env_infos/reward_energy Mean                -0.222066
exploration/env_infos/reward_energy Std                  0.177599
exploration/env_infos/reward_energy Max                 -0.0339926
exploration/env_infos/reward_energy Min                 -0.810707
exploration/env_infos/final/end_effector_loc Mean        0.19472
exploration/env_infos/final/end_effector_loc Std         0.538212
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.572378
exploration/env_infos/initial/end_effector_loc Mean      0.00397781
exploration/env_infos/initial/end_effector_loc Std       0.017744
exploration/env_infos/initial/end_effector_loc Max       0.0279273
exploration/env_infos/initial/end_effector_loc Min      -0.0193917
exploration/env_infos/end_effector_loc Mean              0.147134
exploration/env_infos/end_effector_loc Std               0.387892
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.572378
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00923861
exploration/env_infos/final/reward_dist Std              0.0184598
exploration/env_infos/final/reward_dist Max              0.0461581
exploration/env_infos/final/reward_dist Min              5.27138e-104
exploration/env_infos/initial/reward_dist Mean           0.00835951
exploration/env_infos/initial/reward_dist Std            0.00963861
exploration/env_infos/initial/reward_dist Max            0.0203877
exploration/env_infos/initial/reward_dist Min            1.12076e-07
exploration/env_infos/reward_dist Mean                   0.0794439
exploration/env_infos/reward_dist Std                    0.162547
exploration/env_infos/reward_dist Max                    0.777929
exploration/env_infos/reward_dist Min                    2.31663e-105
evaluation/num steps total                           40000
evaluation/num paths total                            2000
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0827454
evaluation/Rewards Std                                   0.110428
evaluation/Rewards Max                                   0.144571
evaluation/Rewards Min                                  -0.833372
evaluation/Returns Mean                                 -1.65491
evaluation/Returns Std                                   1.64449
evaluation/Returns Max                                   1.75628
evaluation/Returns Min                                  -7.7477
evaluation/Actions Mean                                  0.0113344
evaluation/Actions Std                                   0.108343
evaluation/Actions Max                                   0.952655
evaluation/Actions Min                                  -0.725009
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.65491
evaluation/env_infos/final/reward_energy Mean           -0.0556417
evaluation/env_infos/final/reward_energy Std             0.0482867
evaluation/env_infos/final/reward_energy Max            -0.00454578
evaluation/env_infos/final/reward_energy Min            -0.290265
evaluation/env_infos/initial/reward_energy Mean         -0.258416
evaluation/env_infos/initial/reward_energy Std           0.305857
evaluation/env_infos/initial/reward_energy Max          -0.0144214
evaluation/env_infos/initial/reward_energy Min          -1.11735
evaluation/env_infos/reward_energy Mean                 -0.0813282
evaluation/env_infos/reward_energy Std                   0.13084
evaluation/env_infos/reward_energy Max                  -0.00156244
evaluation/env_infos/reward_energy Min                  -1.12821
evaluation/env_infos/final/end_effector_loc Mean         0.142427
evaluation/env_infos/final/end_effector_loc Std          0.383567
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.648876
evaluation/env_infos/initial/end_effector_loc Mean       0.00299696
evaluation/env_infos/initial/end_effector_loc Std        0.0138357
evaluation/env_infos/initial/end_effector_loc Max        0.0468153
evaluation/env_infos/initial/end_effector_loc Min       -0.0362505
evaluation/env_infos/end_effector_loc Mean               0.0823811
evaluation/env_infos/end_effector_loc Std                0.270826
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.648876
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0773569
evaluation/env_infos/final/reward_dist Std               0.185979
evaluation/env_infos/final/reward_dist Max               0.870052
evaluation/env_infos/final/reward_dist Min               5.72665e-122
evaluation/env_infos/initial/reward_dist Mean            0.00387128
evaluation/env_infos/initial/reward_dist Std             0.00819939
evaluation/env_infos/initial/reward_dist Max             0.0404302
evaluation/env_infos/initial/reward_dist Min             1.07217e-07
evaluation/env_infos/reward_dist Mean                    0.0822319
evaluation/env_infos/reward_dist Std                     0.191829
evaluation/env_infos/reward_dist Max                     0.982574
evaluation/env_infos/reward_dist Min                     5.72665e-122
time/data storing (s)                                   19.1533
time/evaluation sampling (s)                             0.639233
time/exploration sampling (s)                            0.0894682
time/logging (s)                                         0.0152237
time/saving (s)                                          0.418497
time/training (s)                                       35.7041
time/epoch (s)                                          56.0198
time/total (s)                                        1895.28
Epoch                                                   39
---------------------------------------------------  ----------------
2021-05-29 00:28:25.146289 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 40 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00110487
trainer/QF2 Loss                                         0.000906158
trainer/Policy Loss                                      3.04362
trainer/Q1 Predictions Mean                             -0.851419
trainer/Q1 Predictions Std                               0.807523
trainer/Q1 Predictions Max                               1.09173
trainer/Q1 Predictions Min                              -3.67175
trainer/Q2 Predictions Mean                             -0.852887
trainer/Q2 Predictions Std                               0.805878
trainer/Q2 Predictions Max                               1.08923
trainer/Q2 Predictions Min                              -3.57685
trainer/Q Targets Mean                                  -0.863218
trainer/Q Targets Std                                    0.806135
trainer/Q Targets Max                                    1.03275
trainer/Q Targets Min                                   -3.73827
trainer/Log Pis Mean                                     2.2059
trainer/Log Pis Std                                      1.17858
trainer/Log Pis Max                                      5.20284
trainer/Log Pis Min                                     -2.34918
trainer/Policy mu Mean                                   0.0648765
trainer/Policy mu Std                                    0.346364
trainer/Policy mu Max                                    2.65867
trainer/Policy mu Min                                   -2.33838
trainer/Policy log std Mean                             -2.35634
trainer/Policy log std Std                               0.584573
trainer/Policy log std Max                              -0.0736699
trainer/Policy log std Min                              -3.39605
trainer/Alpha                                            0.0195589
trainer/Alpha Loss                                       0.810201
exploration/num steps total                           5100
exploration/num paths total                            255
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0824113
exploration/Rewards Std                                  0.0665283
exploration/Rewards Max                                  0.0697605
exploration/Rewards Min                                 -0.230948
exploration/Returns Mean                                -1.64823
exploration/Returns Std                                  0.905706
exploration/Returns Max                                 -0.285301
exploration/Returns Min                                 -2.51247
exploration/Actions Mean                                 0.0114494
exploration/Actions Std                                  0.0913995
exploration/Actions Max                                  0.27533
exploration/Actions Min                                 -0.290612
exploration/Num Paths                                    5
exploration/Average Returns                             -1.64823
exploration/env_infos/final/reward_energy Mean          -0.0772746
exploration/env_infos/final/reward_energy Std            0.0443423
exploration/env_infos/final/reward_energy Max           -0.0181491
exploration/env_infos/final/reward_energy Min           -0.146225
exploration/env_infos/initial/reward_energy Mean        -0.0939081
exploration/env_infos/initial/reward_energy Std          0.0434864
exploration/env_infos/initial/reward_energy Max         -0.0439267
exploration/env_infos/initial/reward_energy Min         -0.151663
exploration/env_infos/reward_energy Mean                -0.108897
exploration/env_infos/reward_energy Std                  0.0714941
exploration/env_infos/reward_energy Max                 -0.00204674
exploration/env_infos/reward_energy Min                 -0.348965
exploration/env_infos/final/end_effector_loc Mean        0.0371665
exploration/env_infos/final/end_effector_loc Std         0.225315
exploration/env_infos/final/end_effector_loc Max         0.361988
exploration/env_infos/final/end_effector_loc Min        -0.325713
exploration/env_infos/initial/end_effector_loc Mean     -0.000173954
exploration/env_infos/initial/end_effector_loc Std       0.00365472
exploration/env_infos/initial/end_effector_loc Max       0.00668965
exploration/env_infos/initial/end_effector_loc Min      -0.00604469
exploration/env_infos/end_effector_loc Mean             -0.00654068
exploration/env_infos/end_effector_loc Std               0.139943
exploration/env_infos/end_effector_loc Max               0.361988
exploration/env_infos/end_effector_loc Min              -0.325713
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.10727
exploration/env_infos/final/reward_dist Std              0.129953
exploration/env_infos/final/reward_dist Max              0.27962
exploration/env_infos/final/reward_dist Min              1.52701e-10
exploration/env_infos/initial/reward_dist Mean           0.00113822
exploration/env_infos/initial/reward_dist Std            0.000864603
exploration/env_infos/initial/reward_dist Max            0.00280152
exploration/env_infos/initial/reward_dist Min            0.000523439
exploration/env_infos/reward_dist Mean                   0.110697
exploration/env_infos/reward_dist Std                    0.22298
exploration/env_infos/reward_dist Max                    0.956555
exploration/env_infos/reward_dist Min                    1.52701e-10
evaluation/num steps total                           41000
evaluation/num paths total                            2050
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0771942
evaluation/Rewards Std                                   0.110483
evaluation/Rewards Max                                   0.166149
evaluation/Rewards Min                                  -0.785278
evaluation/Returns Mean                                 -1.54388
evaluation/Returns Std                                   1.87218
evaluation/Returns Max                                   0.812318
evaluation/Returns Min                                 -10.056
evaluation/Actions Mean                                  0.00316502
evaluation/Actions Std                                   0.0791279
evaluation/Actions Max                                   0.610258
evaluation/Actions Min                                  -0.872524
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.54388
evaluation/env_infos/final/reward_energy Mean           -0.0704358
evaluation/env_infos/final/reward_energy Std             0.128738
evaluation/env_infos/final/reward_energy Max            -0.00400286
evaluation/env_infos/final/reward_energy Min            -0.920239
evaluation/env_infos/initial/reward_energy Mean         -0.162124
evaluation/env_infos/initial/reward_energy Std           0.205025
evaluation/env_infos/initial/reward_energy Max          -0.0121907
evaluation/env_infos/initial/reward_energy Min          -0.822487
evaluation/env_infos/reward_energy Mean                 -0.061898
evaluation/env_infos/reward_energy Std                   0.0933334
evaluation/env_infos/reward_energy Max                  -0.000965989
evaluation/env_infos/reward_energy Min                  -0.94982
evaluation/env_infos/final/end_effector_loc Mean         0.111406
evaluation/env_infos/final/end_effector_loc Std          0.33124
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.543184
evaluation/env_infos/initial/end_effector_loc Mean       0.00173983
evaluation/env_infos/initial/end_effector_loc Std        0.00907592
evaluation/env_infos/initial/end_effector_loc Max        0.0305129
evaluation/env_infos/initial/end_effector_loc Min       -0.0342663
evaluation/env_infos/end_effector_loc Mean               0.0600656
evaluation/env_infos/end_effector_loc Std                0.212983
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.543184
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.152821
evaluation/env_infos/final/reward_dist Std               0.232624
evaluation/env_infos/final/reward_dist Max               0.847628
evaluation/env_infos/final/reward_dist Min               1.02291e-134
evaluation/env_infos/initial/reward_dist Mean            0.00673258
evaluation/env_infos/initial/reward_dist Std             0.0184569
evaluation/env_infos/initial/reward_dist Max             0.128056
evaluation/env_infos/initial/reward_dist Min             1.00212e-06
evaluation/env_infos/reward_dist Mean                    0.109825
evaluation/env_infos/reward_dist Std                     0.219228
evaluation/env_infos/reward_dist Max                     0.992622
evaluation/env_infos/reward_dist Min                     5.83965e-140
time/data storing (s)                                   19.6725
time/evaluation sampling (s)                             0.565447
time/exploration sampling (s)                            0.0931491
time/logging (s)                                         0.0145646
time/saving (s)                                          0.414074
time/training (s)                                       35.9543
time/epoch (s)                                          56.7141
time/total (s)                                        1952.45
Epoch                                                   40
---------------------------------------------------  ----------------
2021-05-29 00:29:22.215853 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 41 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00237307
trainer/QF2 Loss                                         0.00149642
trainer/Policy Loss                                      2.8025
trainer/Q1 Predictions Mean                             -0.878144
trainer/Q1 Predictions Std                               0.817619
trainer/Q1 Predictions Max                               1.02911
trainer/Q1 Predictions Min                              -3.57178
trainer/Q2 Predictions Mean                             -0.871032
trainer/Q2 Predictions Std                               0.805996
trainer/Q2 Predictions Max                               0.970789
trainer/Q2 Predictions Min                              -3.5249
trainer/Q Targets Mean                                  -0.864013
trainer/Q Targets Std                                    0.802002
trainer/Q Targets Max                                    0.997582
trainer/Q Targets Min                                   -3.6383
trainer/Log Pis Mean                                     1.9376
trainer/Log Pis Std                                      1.37872
trainer/Log Pis Max                                      5.57111
trainer/Log Pis Min                                     -3.59378
trainer/Policy mu Mean                                   0.0512818
trainer/Policy mu Std                                    0.377361
trainer/Policy mu Max                                    2.38853
trainer/Policy mu Min                                   -1.30563
trainer/Policy log std Mean                             -2.27762
trainer/Policy log std Std                               0.513017
trainer/Policy log std Max                              -0.45091
trainer/Policy log std Min                              -3.21809
trainer/Alpha                                            0.0196663
trainer/Alpha Loss                                      -0.245104
exploration/num steps total                           5200
exploration/num paths total                            260
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.122072
exploration/Rewards Std                                  0.0612849
exploration/Rewards Max                                 -0.0124525
exploration/Rewards Min                                 -0.415027
exploration/Returns Mean                                -2.44144
exploration/Returns Std                                  0.622555
exploration/Returns Max                                 -1.7194
exploration/Returns Min                                 -3.4075
exploration/Actions Mean                                -0.00134974
exploration/Actions Std                                  0.0822601
exploration/Actions Max                                  0.345718
exploration/Actions Min                                 -0.417502
exploration/Num Paths                                    5
exploration/Average Returns                             -2.44144
exploration/env_infos/final/reward_energy Mean          -0.0837063
exploration/env_infos/final/reward_energy Std            0.031661
exploration/env_infos/final/reward_energy Max           -0.0517156
exploration/env_infos/final/reward_energy Min           -0.13185
exploration/env_infos/initial/reward_energy Mean        -0.140932
exploration/env_infos/initial/reward_energy Std          0.152922
exploration/env_infos/initial/reward_energy Max         -0.00552353
exploration/env_infos/initial/reward_energy Min         -0.437941
exploration/env_infos/reward_energy Mean                -0.0965224
exploration/env_infos/reward_energy Std                  0.0649654
exploration/env_infos/reward_energy Max                 -0.00552353
exploration/env_infos/reward_energy Min                 -0.437941
exploration/env_infos/final/end_effector_loc Mean       -0.0489489
exploration/env_infos/final/end_effector_loc Std         0.28225
exploration/env_infos/final/end_effector_loc Max         0.334025
exploration/env_infos/final/end_effector_loc Min        -0.482177
exploration/env_infos/initial/end_effector_loc Mean     -0.00227574
exploration/env_infos/initial/end_effector_loc Std       0.00699141
exploration/env_infos/initial/end_effector_loc Max       0.00435021
exploration/env_infos/initial/end_effector_loc Min      -0.0208751
exploration/env_infos/end_effector_loc Mean             -0.0315454
exploration/env_infos/end_effector_loc Std               0.156426
exploration/env_infos/end_effector_loc Max               0.334025
exploration/env_infos/end_effector_loc Min              -0.482177
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0297052
exploration/env_infos/final/reward_dist Std              0.0353446
exploration/env_infos/final/reward_dist Max              0.081194
exploration/env_infos/final/reward_dist Min              4.56143e-16
exploration/env_infos/initial/reward_dist Mean           0.0115214
exploration/env_infos/initial/reward_dist Std            0.00993917
exploration/env_infos/initial/reward_dist Max            0.0248388
exploration/env_infos/initial/reward_dist Min            5.62948e-06
exploration/env_infos/reward_dist Mean                   0.094661
exploration/env_infos/reward_dist Std                    0.160561
exploration/env_infos/reward_dist Max                    0.681077
exploration/env_infos/reward_dist Min                    4.56143e-16
evaluation/num steps total                           42000
evaluation/num paths total                            2100
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0707296
evaluation/Rewards Std                                   0.0942447
evaluation/Rewards Max                                   0.157614
evaluation/Rewards Min                                  -0.72373
evaluation/Returns Mean                                 -1.41459
evaluation/Returns Std                                   1.35389
evaluation/Returns Max                                   1.74647
evaluation/Returns Min                                  -6.60935
evaluation/Actions Mean                                 -0.0122638
evaluation/Actions Std                                   0.108222
evaluation/Actions Max                                   0.57863
evaluation/Actions Min                                  -0.889131
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.41459
evaluation/env_infos/final/reward_energy Mean           -0.113468
evaluation/env_infos/final/reward_energy Std             0.196228
evaluation/env_infos/final/reward_energy Max            -0.012425
evaluation/env_infos/final/reward_energy Min            -1.12307
evaluation/env_infos/initial/reward_energy Mean         -0.192491
evaluation/env_infos/initial/reward_energy Std           0.262749
evaluation/env_infos/initial/reward_energy Max          -0.0116297
evaluation/env_infos/initial/reward_energy Min          -1.24585
evaluation/env_infos/reward_energy Mean                 -0.0838769
evaluation/env_infos/reward_energy Std                   0.129188
evaluation/env_infos/reward_energy Max                  -0.00075183
evaluation/env_infos/reward_energy Min                  -1.24585
evaluation/env_infos/final/end_effector_loc Mean        -0.0198571
evaluation/env_infos/final/end_effector_loc Std          0.366061
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00182689
evaluation/env_infos/initial/end_effector_loc Std        0.0113699
evaluation/env_infos/initial/end_effector_loc Max        0.0289315
evaluation/env_infos/initial/end_effector_loc Min       -0.0444565
evaluation/env_infos/end_effector_loc Mean              -0.00661354
evaluation/env_infos/end_effector_loc Std                0.224361
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.116438
evaluation/env_infos/final/reward_dist Std               0.237023
evaluation/env_infos/final/reward_dist Max               0.923905
evaluation/env_infos/final/reward_dist Min               8.27325e-106
evaluation/env_infos/initial/reward_dist Mean            0.00408728
evaluation/env_infos/initial/reward_dist Std             0.00772182
evaluation/env_infos/initial/reward_dist Max             0.0343223
evaluation/env_infos/initial/reward_dist Min             1.09512e-06
evaluation/env_infos/reward_dist Mean                    0.120178
evaluation/env_infos/reward_dist Std                     0.222568
evaluation/env_infos/reward_dist Max                     0.97985
evaluation/env_infos/reward_dist Min                     8.27325e-106
time/data storing (s)                                   19.9124
time/evaluation sampling (s)                             0.650488
time/exploration sampling (s)                            0.0868964
time/logging (s)                                         0.0144932
time/saving (s)                                          0.423684
time/training (s)                                       35.5169
time/epoch (s)                                          56.6049
time/total (s)                                        2009.52
Epoch                                                   41
---------------------------------------------------  ----------------
2021-05-29 00:30:20.485500 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 42 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00137297
trainer/QF2 Loss                                         0.00128322
trainer/Policy Loss                                      2.89766
trainer/Q1 Predictions Mean                             -0.897067
trainer/Q1 Predictions Std                               0.790705
trainer/Q1 Predictions Max                               0.956897
trainer/Q1 Predictions Min                              -3.66399
trainer/Q2 Predictions Mean                             -0.898327
trainer/Q2 Predictions Std                               0.796764
trainer/Q2 Predictions Max                               0.993004
trainer/Q2 Predictions Min                              -3.62985
trainer/Q Targets Mean                                  -0.896813
trainer/Q Targets Std                                    0.791861
trainer/Q Targets Max                                    1.02936
trainer/Q Targets Min                                   -3.52115
trainer/Log Pis Mean                                     2.00754
trainer/Log Pis Std                                      1.49176
trainer/Log Pis Max                                      7.26105
trainer/Log Pis Min                                     -4.40492
trainer/Policy mu Mean                                   0.00696042
trainer/Policy mu Std                                    0.532979
trainer/Policy mu Max                                    2.33484
trainer/Policy mu Min                                   -3.10881
trainer/Policy log std Mean                             -2.18309
trainer/Policy log std Std                               0.647851
trainer/Policy log std Max                              -0.113214
trainer/Policy log std Min                              -3.31202
trainer/Alpha                                            0.0209329
trainer/Alpha Loss                                       0.0291739
exploration/num steps total                           5300
exploration/num paths total                            265
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.133251
exploration/Rewards Std                                  0.0710113
exploration/Rewards Max                                  0.0238826
exploration/Rewards Min                                 -0.472716
exploration/Returns Mean                                -2.66501
exploration/Returns Std                                  1.01529
exploration/Returns Max                                 -1.42709
exploration/Returns Min                                 -4.21252
exploration/Actions Mean                                 0.0050099
exploration/Actions Std                                  0.100053
exploration/Actions Max                                  0.503801
exploration/Actions Min                                 -0.422001
exploration/Num Paths                                    5
exploration/Average Returns                             -2.66501
exploration/env_infos/final/reward_energy Mean          -0.177213
exploration/env_infos/final/reward_energy Std            0.134394
exploration/env_infos/final/reward_energy Max           -0.058637
exploration/env_infos/final/reward_energy Min           -0.428189
exploration/env_infos/initial/reward_energy Mean        -0.144834
exploration/env_infos/initial/reward_energy Std          0.0784991
exploration/env_infos/initial/reward_energy Max         -0.0950627
exploration/env_infos/initial/reward_energy Min         -0.300732
exploration/env_infos/reward_energy Mean                -0.111103
exploration/env_infos/reward_energy Std                  0.0879062
exploration/env_infos/reward_energy Max                 -0.0091569
exploration/env_infos/reward_energy Min                 -0.615039
exploration/env_infos/final/end_effector_loc Mean        0.149229
exploration/env_infos/final/end_effector_loc Std         0.368883
exploration/env_infos/final/end_effector_loc Max         0.827444
exploration/env_infos/final/end_effector_loc Min        -0.458879
exploration/env_infos/initial/end_effector_loc Mean      0.00220302
exploration/env_infos/initial/end_effector_loc Std       0.00539172
exploration/env_infos/initial/end_effector_loc Max       0.0126681
exploration/env_infos/initial/end_effector_loc Min      -0.00576993
exploration/env_infos/end_effector_loc Mean              0.0767116
exploration/env_infos/end_effector_loc Std               0.216487
exploration/env_infos/end_effector_loc Max               0.827444
exploration/env_infos/end_effector_loc Min              -0.458879
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0299313
exploration/env_infos/final/reward_dist Std              0.0598252
exploration/env_infos/final/reward_dist Max              0.149582
exploration/env_infos/final/reward_dist Min              1.15943e-57
exploration/env_infos/initial/reward_dist Mean           0.000153007
exploration/env_infos/initial/reward_dist Std            0.000104427
exploration/env_infos/initial/reward_dist Max            0.000312494
exploration/env_infos/initial/reward_dist Min            7.2063e-06
exploration/env_infos/reward_dist Mean                   0.02219
exploration/env_infos/reward_dist Std                    0.0560103
exploration/env_infos/reward_dist Max                    0.267403
exploration/env_infos/reward_dist Min                    1.15943e-57
evaluation/num steps total                           43000
evaluation/num paths total                            2150
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0790867
evaluation/Rewards Std                                   0.0922971
evaluation/Rewards Max                                   0.0995154
evaluation/Rewards Min                                  -0.77686
evaluation/Returns Mean                                 -1.58173
evaluation/Returns Std                                   1.34367
evaluation/Returns Max                                   0.515335
evaluation/Returns Min                                  -5.75043
evaluation/Actions Mean                                  0.00148581
evaluation/Actions Std                                   0.081661
evaluation/Actions Max                                   0.633519
evaluation/Actions Min                                  -0.838887
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.58173
evaluation/env_infos/final/reward_energy Mean           -0.0473264
evaluation/env_infos/final/reward_energy Std             0.029775
evaluation/env_infos/final/reward_energy Max            -0.00509924
evaluation/env_infos/final/reward_energy Min            -0.180096
evaluation/env_infos/initial/reward_energy Mean         -0.150096
evaluation/env_infos/initial/reward_energy Std           0.194806
evaluation/env_infos/initial/reward_energy Max          -0.00216275
evaluation/env_infos/initial/reward_energy Min          -0.884229
evaluation/env_infos/reward_energy Mean                 -0.0633937
evaluation/env_infos/reward_energy Std                   0.0965542
evaluation/env_infos/reward_energy Max                  -0.000777087
evaluation/env_infos/reward_energy Min                  -1.05123
evaluation/env_infos/final/end_effector_loc Mean         0.0512208
evaluation/env_infos/final/end_effector_loc Std          0.344918
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.000270825
evaluation/env_infos/initial/end_effector_loc Std        0.00869046
evaluation/env_infos/initial/end_effector_loc Max        0.0256437
evaluation/env_infos/initial/end_effector_loc Min       -0.034458
evaluation/env_infos/end_effector_loc Mean               0.0350259
evaluation/env_infos/end_effector_loc Std                0.216335
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0653153
evaluation/env_infos/final/reward_dist Std               0.165456
evaluation/env_infos/final/reward_dist Max               0.799819
evaluation/env_infos/final/reward_dist Min               6.53886e-167
evaluation/env_infos/initial/reward_dist Mean            0.00414031
evaluation/env_infos/initial/reward_dist Std             0.00799164
evaluation/env_infos/initial/reward_dist Max             0.0326842
evaluation/env_infos/initial/reward_dist Min             1.71236e-06
evaluation/env_infos/reward_dist Mean                    0.0790518
evaluation/env_infos/reward_dist Std                     0.188755
evaluation/env_infos/reward_dist Max                     0.997551
evaluation/env_infos/reward_dist Min                     6.53886e-167
time/data storing (s)                                   20.5798
time/evaluation sampling (s)                             0.665681
time/exploration sampling (s)                            0.0897761
time/logging (s)                                         0.0151401
time/saving (s)                                          0.442244
time/training (s)                                       35.9459
time/epoch (s)                                          57.7385
time/total (s)                                        2067.79
Epoch                                                   42
---------------------------------------------------  ----------------
2021-05-29 00:31:19.265764 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 43 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00114394
trainer/QF2 Loss                                         0.00129289
trainer/Policy Loss                                      2.9979
trainer/Q1 Predictions Mean                             -1.04619
trainer/Q1 Predictions Std                               0.806902
trainer/Q1 Predictions Max                               1.14369
trainer/Q1 Predictions Min                              -3.7693
trainer/Q2 Predictions Mean                             -1.04289
trainer/Q2 Predictions Std                               0.806067
trainer/Q2 Predictions Max                               1.12008
trainer/Q2 Predictions Min                              -3.71265
trainer/Q Targets Mean                                  -1.04259
trainer/Q Targets Std                                    0.802903
trainer/Q Targets Max                                    1.11455
trainer/Q Targets Min                                   -3.72911
trainer/Log Pis Mean                                     1.97552
trainer/Log Pis Std                                      1.29351
trainer/Log Pis Max                                      5.66206
trainer/Log Pis Min                                     -2.83405
trainer/Policy mu Mean                                   0.0574059
trainer/Policy mu Std                                    0.498029
trainer/Policy mu Max                                    2.5504
trainer/Policy mu Min                                   -2.31046
trainer/Policy log std Mean                             -2.20344
trainer/Policy log std Std                               0.599641
trainer/Policy log std Max                               0.201552
trainer/Policy log std Min                              -3.19492
trainer/Alpha                                            0.0211803
trainer/Alpha Loss                                      -0.0943933
exploration/num steps total                           5400
exploration/num paths total                            270
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.141879
exploration/Rewards Std                                  0.0897682
exploration/Rewards Max                                  0.0325172
exploration/Rewards Min                                 -0.381194
exploration/Returns Mean                                -2.83758
exploration/Returns Std                                  1.0981
exploration/Returns Max                                 -1.2745
exploration/Returns Min                                 -4.16026
exploration/Actions Mean                                -0.00911699
exploration/Actions Std                                  0.147169
exploration/Actions Max                                  0.621408
exploration/Actions Min                                 -0.818536
exploration/Num Paths                                    5
exploration/Average Returns                             -2.83758
exploration/env_infos/final/reward_energy Mean          -0.179369
exploration/env_infos/final/reward_energy Std            0.112669
exploration/env_infos/final/reward_energy Max           -0.083173
exploration/env_infos/final/reward_energy Min           -0.381289
exploration/env_infos/initial/reward_energy Mean        -0.198237
exploration/env_infos/initial/reward_energy Std          0.152334
exploration/env_infos/initial/reward_energy Max         -0.033658
exploration/env_infos/initial/reward_energy Min         -0.422785
exploration/env_infos/reward_energy Mean                -0.156339
exploration/env_infos/reward_energy Std                  0.137991
exploration/env_infos/reward_energy Max                 -0.0166123
exploration/env_infos/reward_energy Min                 -0.845625
exploration/env_infos/final/end_effector_loc Mean        0.0333705
exploration/env_infos/final/end_effector_loc Std         0.266303
exploration/env_infos/final/end_effector_loc Max         0.363838
exploration/env_infos/final/end_effector_loc Min        -0.5085
exploration/env_infos/initial/end_effector_loc Mean      0.000759828
exploration/env_infos/initial/end_effector_loc Std       0.00880637
exploration/env_infos/initial/end_effector_loc Max       0.0210594
exploration/env_infos/initial/end_effector_loc Min      -0.011705
exploration/env_infos/end_effector_loc Mean              0.0353361
exploration/env_infos/end_effector_loc Std               0.173081
exploration/env_infos/end_effector_loc Max               0.425422
exploration/env_infos/end_effector_loc Min              -0.5085
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.20121
exploration/env_infos/final/reward_dist Std              0.396719
exploration/env_infos/final/reward_dist Max              0.994616
exploration/env_infos/final/reward_dist Min              9.40835e-27
exploration/env_infos/initial/reward_dist Mean           0.00415777
exploration/env_infos/initial/reward_dist Std            0.00764382
exploration/env_infos/initial/reward_dist Max            0.0194257
exploration/env_infos/initial/reward_dist Min            6.06046e-06
exploration/env_infos/reward_dist Mean                   0.0822282
exploration/env_infos/reward_dist Std                    0.190322
exploration/env_infos/reward_dist Max                    0.994616
exploration/env_infos/reward_dist Min                    9.40835e-27
evaluation/num steps total                           44000
evaluation/num paths total                            2200
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0681618
evaluation/Rewards Std                                   0.0786645
evaluation/Rewards Max                                   0.157822
evaluation/Rewards Min                                  -0.675948
evaluation/Returns Mean                                 -1.36324
evaluation/Returns Std                                   1.18576
evaluation/Returns Max                                   1.27378
evaluation/Returns Min                                  -5.03585
evaluation/Actions Mean                                 -0.00715338
evaluation/Actions Std                                   0.102622
evaluation/Actions Max                                   0.842874
evaluation/Actions Min                                  -0.779944
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.36324
evaluation/env_infos/final/reward_energy Mean           -0.0800999
evaluation/env_infos/final/reward_energy Std             0.0970405
evaluation/env_infos/final/reward_energy Max            -0.00413457
evaluation/env_infos/final/reward_energy Min            -0.495584
evaluation/env_infos/initial/reward_energy Mean         -0.224545
evaluation/env_infos/initial/reward_energy Std           0.288314
evaluation/env_infos/initial/reward_energy Max          -0.0056417
evaluation/env_infos/initial/reward_energy Min          -1.11622
evaluation/env_infos/reward_energy Mean                 -0.0783707
evaluation/env_infos/reward_energy Std                   0.122568
evaluation/env_infos/reward_energy Max                  -0.000636236
evaluation/env_infos/reward_energy Min                  -1.11622
evaluation/env_infos/final/end_effector_loc Mean        -0.0452624
evaluation/env_infos/final/end_effector_loc Std          0.31395
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.0012545
evaluation/env_infos/initial/end_effector_loc Std        0.0128591
evaluation/env_infos/initial/end_effector_loc Max        0.0421437
evaluation/env_infos/initial/end_effector_loc Min       -0.0372887
evaluation/env_infos/end_effector_loc Mean              -0.0147292
evaluation/env_infos/end_effector_loc Std                0.202744
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.117408
evaluation/env_infos/final/reward_dist Std               0.219355
evaluation/env_infos/final/reward_dist Max               0.953674
evaluation/env_infos/final/reward_dist Min               1.06046e-111
evaluation/env_infos/initial/reward_dist Mean            0.00357332
evaluation/env_infos/initial/reward_dist Std             0.00753714
evaluation/env_infos/initial/reward_dist Max             0.0345181
evaluation/env_infos/initial/reward_dist Min             2.75937e-06
evaluation/env_infos/reward_dist Mean                    0.107142
evaluation/env_infos/reward_dist Std                     0.207622
evaluation/env_infos/reward_dist Max                     0.993352
evaluation/env_infos/reward_dist Min                     1.06046e-111
time/data storing (s)                                   20.751
time/evaluation sampling (s)                             0.661316
time/exploration sampling (s)                            0.0932905
time/logging (s)                                         0.0167463
time/saving (s)                                          0.436141
time/training (s)                                       36.3237
time/epoch (s)                                          58.2822
time/total (s)                                        2126.57
Epoch                                                   43
---------------------------------------------------  ----------------
2021-05-29 00:32:19.038278 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 44 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00144336
trainer/QF2 Loss                                         0.00137739
trainer/Policy Loss                                      3.10826
trainer/Q1 Predictions Mean                             -0.979031
trainer/Q1 Predictions Std                               0.758971
trainer/Q1 Predictions Max                               0.884684
trainer/Q1 Predictions Min                              -2.99978
trainer/Q2 Predictions Mean                             -0.96582
trainer/Q2 Predictions Std                               0.758857
trainer/Q2 Predictions Max                               0.8966
trainer/Q2 Predictions Min                              -3.01351
trainer/Q Targets Mean                                  -0.97261
trainer/Q Targets Std                                    0.753749
trainer/Q Targets Max                                    0.844215
trainer/Q Targets Min                                   -2.93144
trainer/Log Pis Mean                                     2.1552
trainer/Log Pis Std                                      1.35167
trainer/Log Pis Max                                      5.62443
trainer/Log Pis Min                                     -2.30972
trainer/Policy mu Mean                                  -0.0229989
trainer/Policy mu Std                                    0.435585
trainer/Policy mu Max                                    2.12246
trainer/Policy mu Min                                   -2.52691
trainer/Policy log std Mean                             -2.26935
trainer/Policy log std Std                               0.647302
trainer/Policy log std Max                              -0.30553
trainer/Policy log std Min                              -3.36474
trainer/Alpha                                            0.0206913
trainer/Alpha Loss                                       0.601968
exploration/num steps total                           5500
exploration/num paths total                            275
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.105318
exploration/Rewards Std                                  0.0677496
exploration/Rewards Max                                  0.0284974
exploration/Rewards Min                                 -0.329505
exploration/Returns Mean                                -2.10637
exploration/Returns Std                                  0.635549
exploration/Returns Max                                 -1.20401
exploration/Returns Min                                 -3.0609
exploration/Actions Mean                                 0.00573061
exploration/Actions Std                                  0.111759
exploration/Actions Max                                  0.47676
exploration/Actions Min                                 -0.278836
exploration/Num Paths                                    5
exploration/Average Returns                             -2.10637
exploration/env_infos/final/reward_energy Mean          -0.0988543
exploration/env_infos/final/reward_energy Std            0.0249518
exploration/env_infos/final/reward_energy Max           -0.07022
exploration/env_infos/final/reward_energy Min           -0.136895
exploration/env_infos/initial/reward_energy Mean        -0.13043
exploration/env_infos/initial/reward_energy Std          0.0897998
exploration/env_infos/initial/reward_energy Max         -0.0287405
exploration/env_infos/initial/reward_energy Min         -0.274245
exploration/env_infos/reward_energy Mean                -0.121633
exploration/env_infos/reward_energy Std                  0.101249
exploration/env_infos/reward_energy Max                 -0.00526915
exploration/env_infos/reward_energy Min                 -0.496148
exploration/env_infos/final/end_effector_loc Mean        0.0941954
exploration/env_infos/final/end_effector_loc Std         0.534215
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -1
exploration/env_infos/initial/end_effector_loc Mean      0.00120569
exploration/env_infos/initial/end_effector_loc Std       0.00546731
exploration/env_infos/initial/end_effector_loc Max       0.00937879
exploration/env_infos/initial/end_effector_loc Min      -0.012526
exploration/env_infos/end_effector_loc Mean              0.0591819
exploration/env_infos/end_effector_loc Std               0.332963
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -1
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.000853789
exploration/env_infos/final/reward_dist Std              0.00169592
exploration/env_infos/final/reward_dist Max              0.00424561
exploration/env_infos/final/reward_dist Min              1.6543e-149
exploration/env_infos/initial/reward_dist Mean           0.00545417
exploration/env_infos/initial/reward_dist Std            0.0108909
exploration/env_infos/initial/reward_dist Max            0.027236
exploration/env_infos/initial/reward_dist Min            2.47713e-06
exploration/env_infos/reward_dist Mean                   0.0377733
exploration/env_infos/reward_dist Std                    0.125061
exploration/env_infos/reward_dist Max                    0.769396
exploration/env_infos/reward_dist Min                    1.6543e-149
evaluation/num steps total                           45000
evaluation/num paths total                            2250
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0857508
evaluation/Rewards Std                                   0.0946252
evaluation/Rewards Max                                   0.119887
evaluation/Rewards Min                                  -0.904
evaluation/Returns Mean                                 -1.71502
evaluation/Returns Std                                   1.35358
evaluation/Returns Max                                   0.47912
evaluation/Returns Min                                  -5.77542
evaluation/Actions Mean                                 -0.00289845
evaluation/Actions Std                                   0.102642
evaluation/Actions Max                                   0.52666
evaluation/Actions Min                                  -0.975094
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.71502
evaluation/env_infos/final/reward_energy Mean           -0.0973805
evaluation/env_infos/final/reward_energy Std             0.228805
evaluation/env_infos/final/reward_energy Max            -0.00315224
evaluation/env_infos/final/reward_energy Min            -1.33991
evaluation/env_infos/initial/reward_energy Mean         -0.174069
evaluation/env_infos/initial/reward_energy Std           0.242795
evaluation/env_infos/initial/reward_energy Max          -0.0168834
evaluation/env_infos/initial/reward_energy Min          -1.20459
evaluation/env_infos/reward_energy Mean                 -0.0707204
evaluation/env_infos/reward_energy Std                   0.126832
evaluation/env_infos/reward_energy Max                  -0.000308154
evaluation/env_infos/reward_energy Min                  -1.33991
evaluation/env_infos/final/end_effector_loc Mean         0.00039167
evaluation/env_infos/final/end_effector_loc Std          0.32663
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00115572
evaluation/env_infos/initial/end_effector_loc Std        0.0104989
evaluation/env_infos/initial/end_effector_loc Max        0.026333
evaluation/env_infos/initial/end_effector_loc Min       -0.0451394
evaluation/env_infos/end_effector_loc Mean               0.0079299
evaluation/env_infos/end_effector_loc Std                0.20181
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.130991
evaluation/env_infos/final/reward_dist Std               0.252602
evaluation/env_infos/final/reward_dist Max               0.98519
evaluation/env_infos/final/reward_dist Min               3.82561e-155
evaluation/env_infos/initial/reward_dist Mean            0.00819927
evaluation/env_infos/initial/reward_dist Std             0.0261004
evaluation/env_infos/initial/reward_dist Max             0.181626
evaluation/env_infos/initial/reward_dist Min             1.23667e-06
evaluation/env_infos/reward_dist Mean                    0.114193
evaluation/env_infos/reward_dist Std                     0.211678
evaluation/env_infos/reward_dist Max                     0.98519
evaluation/env_infos/reward_dist Min                     3.82561e-155
time/data storing (s)                                   21.2386
time/evaluation sampling (s)                             0.665683
time/exploration sampling (s)                            0.099319
time/logging (s)                                         0.0174465
time/saving (s)                                          0.47784
time/training (s)                                       36.7754
time/epoch (s)                                          59.2743
time/total (s)                                        2186.34
Epoch                                                   44
---------------------------------------------------  ----------------
2021-05-29 00:33:22.308212 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 45 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00123636
trainer/QF2 Loss                                         0.00145526
trainer/Policy Loss                                      3.1261
trainer/Q1 Predictions Mean                             -1.02196
trainer/Q1 Predictions Std                               0.756467
trainer/Q1 Predictions Max                               0.578271
trainer/Q1 Predictions Min                              -3.07453
trainer/Q2 Predictions Mean                             -1.00737
trainer/Q2 Predictions Std                               0.761098
trainer/Q2 Predictions Max                               0.580612
trainer/Q2 Predictions Min                              -3.06419
trainer/Q Targets Mean                                  -1.02286
trainer/Q Targets Std                                    0.76434
trainer/Q Targets Max                                    0.564444
trainer/Q Targets Min                                   -3.08146
trainer/Log Pis Mean                                     2.11604
trainer/Log Pis Std                                      1.47413
trainer/Log Pis Max                                      4.72491
trainer/Log Pis Min                                     -3.731
trainer/Policy mu Mean                                  -0.0243176
trainer/Policy mu Std                                    0.395525
trainer/Policy mu Max                                    1.80883
trainer/Policy mu Min                                   -1.68515
trainer/Policy log std Mean                             -2.32832
trainer/Policy log std Std                               0.688244
trainer/Policy log std Max                               0.282817
trainer/Policy log std Min                              -3.3498
trainer/Alpha                                            0.0202467
trainer/Alpha Loss                                       0.452561
exploration/num steps total                           5600
exploration/num paths total                            280
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.103462
exploration/Rewards Std                                  0.084323
exploration/Rewards Max                                  0.0552882
exploration/Rewards Min                                 -0.335045
exploration/Returns Mean                                -2.06924
exploration/Returns Std                                  1.23439
exploration/Returns Max                                 -0.293012
exploration/Returns Min                                 -3.45914
exploration/Actions Mean                                 0.0130827
exploration/Actions Std                                  0.100511
exploration/Actions Max                                  0.418978
exploration/Actions Min                                 -0.293161
exploration/Num Paths                                    5
exploration/Average Returns                             -2.06924
exploration/env_infos/final/reward_energy Mean          -0.124304
exploration/env_infos/final/reward_energy Std            0.0625504
exploration/env_infos/final/reward_energy Max           -0.0285157
exploration/env_infos/final/reward_energy Min           -0.22412
exploration/env_infos/initial/reward_energy Mean        -0.111921
exploration/env_infos/initial/reward_energy Std          0.0631531
exploration/env_infos/initial/reward_energy Max         -0.0377549
exploration/env_infos/initial/reward_energy Min         -0.207314
exploration/env_infos/reward_energy Mean                -0.113981
exploration/env_infos/reward_energy Std                  0.0869214
exploration/env_infos/reward_energy Max                 -0.0125804
exploration/env_infos/reward_energy Min                 -0.459213
exploration/env_infos/final/end_effector_loc Mean        0.247246
exploration/env_infos/final/end_effector_loc Std         0.333973
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.437829
exploration/env_infos/initial/end_effector_loc Mean      0.00114726
exploration/env_infos/initial/end_effector_loc Std       0.00439626
exploration/env_infos/initial/end_effector_loc Max       0.0102645
exploration/env_infos/initial/end_effector_loc Min      -0.00482936
exploration/env_infos/end_effector_loc Mean              0.113322
exploration/env_infos/end_effector_loc Std               0.220876
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.437829
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0561345
exploration/env_infos/final/reward_dist Std              0.0863898
exploration/env_infos/final/reward_dist Max              0.223049
exploration/env_infos/final/reward_dist Min              1.2602e-60
exploration/env_infos/initial/reward_dist Mean           0.0139465
exploration/env_infos/initial/reward_dist Std            0.0151417
exploration/env_infos/initial/reward_dist Max            0.0385859
exploration/env_infos/initial/reward_dist Min            1.67598e-05
exploration/env_infos/reward_dist Mean                   0.082992
exploration/env_infos/reward_dist Std                    0.146369
exploration/env_infos/reward_dist Max                    0.586003
exploration/env_infos/reward_dist Min                    1.2602e-60
evaluation/num steps total                           46000
evaluation/num paths total                            2300
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0734613
evaluation/Rewards Std                                   0.0796351
evaluation/Rewards Max                                   0.136973
evaluation/Rewards Min                                  -0.426199
evaluation/Returns Mean                                 -1.46923
evaluation/Returns Std                                   1.27879
evaluation/Returns Max                                   0.546098
evaluation/Returns Min                                  -5.63686
evaluation/Actions Mean                                  0.00547118
evaluation/Actions Std                                   0.0702442
evaluation/Actions Max                                   0.474884
evaluation/Actions Min                                  -0.77232
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.46923
evaluation/env_infos/final/reward_energy Mean           -0.0435514
evaluation/env_infos/final/reward_energy Std             0.0268971
evaluation/env_infos/final/reward_energy Max            -0.00435761
evaluation/env_infos/final/reward_energy Min            -0.107638
evaluation/env_infos/initial/reward_energy Mean         -0.142102
evaluation/env_infos/initial/reward_energy Std           0.132469
evaluation/env_infos/initial/reward_energy Max          -0.0181677
evaluation/env_infos/initial/reward_energy Min          -0.776699
evaluation/env_infos/reward_energy Mean                 -0.0630635
evaluation/env_infos/reward_energy Std                   0.0771451
evaluation/env_infos/reward_energy Max                  -0.00134788
evaluation/env_infos/reward_energy Min                  -0.776699
evaluation/env_infos/final/end_effector_loc Mean         0.115059
evaluation/env_infos/final/end_effector_loc Std          0.328372
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00144867
evaluation/env_infos/initial/end_effector_loc Std        0.006714
evaluation/env_infos/initial/end_effector_loc Max        0.017034
evaluation/env_infos/initial/end_effector_loc Min       -0.038616
evaluation/env_infos/end_effector_loc Mean               0.0562531
evaluation/env_infos/end_effector_loc Std                0.196085
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.095717
evaluation/env_infos/final/reward_dist Std               0.208013
evaluation/env_infos/final/reward_dist Max               0.875837
evaluation/env_infos/final/reward_dist Min               2.30656e-187
evaluation/env_infos/initial/reward_dist Mean            0.00573172
evaluation/env_infos/initial/reward_dist Std             0.0135446
evaluation/env_infos/initial/reward_dist Max             0.0847215
evaluation/env_infos/initial/reward_dist Min             1.08036e-06
evaluation/env_infos/reward_dist Mean                    0.12421
evaluation/env_infos/reward_dist Std                     0.23144
evaluation/env_infos/reward_dist Max                     0.996061
evaluation/env_infos/reward_dist Min                     2.30656e-187
time/data storing (s)                                   23.4165
time/evaluation sampling (s)                             0.863035
time/exploration sampling (s)                            0.119767
time/logging (s)                                         0.0154995
time/saving (s)                                          0.458823
time/training (s)                                       37.8552
time/epoch (s)                                          62.7289
time/total (s)                                        2249.6
Epoch                                                   45
---------------------------------------------------  ----------------
2021-05-29 00:34:22.275369 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 46 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00136102
trainer/QF2 Loss                                         0.00110963
trainer/Policy Loss                                      3.1988
trainer/Q1 Predictions Mean                             -0.996243
trainer/Q1 Predictions Std                               0.699719
trainer/Q1 Predictions Max                               0.0947109
trainer/Q1 Predictions Min                              -3.0228
trainer/Q2 Predictions Mean                             -0.987476
trainer/Q2 Predictions Std                               0.695836
trainer/Q2 Predictions Max                               0.0857702
trainer/Q2 Predictions Min                              -2.95612
trainer/Q Targets Mean                                  -0.985054
trainer/Q Targets Std                                    0.6976
trainer/Q Targets Max                                    0.100775
trainer/Q Targets Min                                   -2.96016
trainer/Log Pis Mean                                     2.20573
trainer/Log Pis Std                                      1.28556
trainer/Log Pis Max                                      4.95274
trainer/Log Pis Min                                     -2.45776
trainer/Policy mu Mean                                   0.0124109
trainer/Policy mu Std                                    0.287777
trainer/Policy mu Max                                    1.77131
trainer/Policy mu Min                                   -1.8727
trainer/Policy log std Mean                             -2.38382
trainer/Policy log std Std                               0.592575
trainer/Policy log std Max                              -0.339313
trainer/Policy log std Min                              -3.26582
trainer/Alpha                                            0.0211957
trainer/Alpha Loss                                       0.793
exploration/num steps total                           5700
exploration/num paths total                            285
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0923282
exploration/Rewards Std                                  0.0875578
exploration/Rewards Max                                  0.0824552
exploration/Rewards Min                                 -0.300836
exploration/Returns Mean                                -1.84656
exploration/Returns Std                                  1.37773
exploration/Returns Max                                 -0.308599
exploration/Returns Min                                 -4.0121
exploration/Actions Mean                                 0.00453396
exploration/Actions Std                                  0.127676
exploration/Actions Max                                  0.482447
exploration/Actions Min                                 -0.557909
exploration/Num Paths                                    5
exploration/Average Returns                             -1.84656
exploration/env_infos/final/reward_energy Mean          -0.10979
exploration/env_infos/final/reward_energy Std            0.0610168
exploration/env_infos/final/reward_energy Max           -0.0282404
exploration/env_infos/final/reward_energy Min           -0.195779
exploration/env_infos/initial/reward_energy Mean        -0.0703964
exploration/env_infos/initial/reward_energy Std          0.0558735
exploration/env_infos/initial/reward_energy Max         -0.0313334
exploration/env_infos/initial/reward_energy Min         -0.181165
exploration/env_infos/reward_energy Mean                -0.13966
exploration/env_infos/reward_energy Std                  0.114624
exploration/env_infos/reward_energy Max                 -0.00284431
exploration/env_infos/reward_energy Min                 -0.558176
exploration/env_infos/final/end_effector_loc Mean        0.0318623
exploration/env_infos/final/end_effector_loc Std         0.326822
exploration/env_infos/final/end_effector_loc Max         0.70564
exploration/env_infos/final/end_effector_loc Min        -0.630733
exploration/env_infos/initial/end_effector_loc Mean     -0.000959336
exploration/env_infos/initial/end_effector_loc Std       0.00302928
exploration/env_infos/initial/end_effector_loc Max       0.00225331
exploration/env_infos/initial/end_effector_loc Min      -0.00653824
exploration/env_infos/end_effector_loc Mean             -0.00216383
exploration/env_infos/end_effector_loc Std               0.182792
exploration/env_infos/end_effector_loc Max               0.70564
exploration/env_infos/end_effector_loc Min              -0.630733
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.281976
exploration/env_infos/final/reward_dist Std              0.321701
exploration/env_infos/final/reward_dist Max              0.805702
exploration/env_infos/final/reward_dist Min              1.13897e-35
exploration/env_infos/initial/reward_dist Mean           0.00154211
exploration/env_infos/initial/reward_dist Std            0.00258206
exploration/env_infos/initial/reward_dist Max            0.0066931
exploration/env_infos/initial/reward_dist Min            6.31964e-06
exploration/env_infos/reward_dist Mean                   0.167654
exploration/env_infos/reward_dist Std                    0.280155
exploration/env_infos/reward_dist Max                    0.99264
exploration/env_infos/reward_dist Min                    1.13897e-35
evaluation/num steps total                           47000
evaluation/num paths total                            2350
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.083852
evaluation/Rewards Std                                   0.113228
evaluation/Rewards Max                                   0.165574
evaluation/Rewards Min                                  -0.52842
evaluation/Returns Mean                                 -1.67704
evaluation/Returns Std                                   1.98152
evaluation/Returns Max                                   2.24676
evaluation/Returns Min                                  -9.28498
evaluation/Actions Mean                                  0.0125139
evaluation/Actions Std                                   0.101159
evaluation/Actions Max                                   0.575513
evaluation/Actions Min                                  -0.851951
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.67704
evaluation/env_infos/final/reward_energy Mean           -0.0553083
evaluation/env_infos/final/reward_energy Std             0.0797348
evaluation/env_infos/final/reward_energy Max            -0.00264701
evaluation/env_infos/final/reward_energy Min            -0.522364
evaluation/env_infos/initial/reward_energy Mean         -0.174608
evaluation/env_infos/initial/reward_energy Std           0.199628
evaluation/env_infos/initial/reward_energy Max          -0.00439796
evaluation/env_infos/initial/reward_energy Min          -1.02485
evaluation/env_infos/reward_energy Mean                 -0.0865017
evaluation/env_infos/reward_energy Std                   0.115313
evaluation/env_infos/reward_energy Max                  -0.00122484
evaluation/env_infos/reward_energy Min                  -1.02485
evaluation/env_infos/final/end_effector_loc Mean         0.0929814
evaluation/env_infos/final/end_effector_loc Std          0.409216
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.806847
evaluation/env_infos/initial/end_effector_loc Mean       0.0010876
evaluation/env_infos/initial/end_effector_loc Std        0.00931352
evaluation/env_infos/initial/end_effector_loc Max        0.0266733
evaluation/env_infos/initial/end_effector_loc Min       -0.0425975
evaluation/env_infos/end_effector_loc Mean               0.0523278
evaluation/env_infos/end_effector_loc Std                0.27328
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.806847
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.114833
evaluation/env_infos/final/reward_dist Std               0.213194
evaluation/env_infos/final/reward_dist Max               0.735778
evaluation/env_infos/final/reward_dist Min               1.06586e-154
evaluation/env_infos/initial/reward_dist Mean            0.00548144
evaluation/env_infos/initial/reward_dist Std             0.0104716
evaluation/env_infos/initial/reward_dist Max             0.0534384
evaluation/env_infos/initial/reward_dist Min             8.77416e-07
evaluation/env_infos/reward_dist Mean                    0.109201
evaluation/env_infos/reward_dist Std                     0.217595
evaluation/env_infos/reward_dist Max                     0.998231
evaluation/env_infos/reward_dist Min                     1.06586e-154
time/data storing (s)                                   21.9597
time/evaluation sampling (s)                             0.574315
time/exploration sampling (s)                            0.0877589
time/logging (s)                                         0.015171
time/saving (s)                                          0.519391
time/training (s)                                       36.2417
time/epoch (s)                                          59.3981
time/total (s)                                        2309.56
Epoch                                                   46
---------------------------------------------------  ----------------
2021-05-29 00:35:23.340348 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 47 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.0012287
trainer/QF2 Loss                                         0.00117079
trainer/Policy Loss                                      2.94552
trainer/Q1 Predictions Mean                             -1.03398
trainer/Q1 Predictions Std                               0.740189
trainer/Q1 Predictions Max                               0.150471
trainer/Q1 Predictions Min                              -2.96907
trainer/Q2 Predictions Mean                             -1.03528
trainer/Q2 Predictions Std                               0.736355
trainer/Q2 Predictions Max                               0.133698
trainer/Q2 Predictions Min                              -2.98313
trainer/Q Targets Mean                                  -1.04457
trainer/Q Targets Std                                    0.742793
trainer/Q Targets Max                                    0.14081
trainer/Q Targets Min                                   -2.9835
trainer/Log Pis Mean                                     1.9128
trainer/Log Pis Std                                      1.3492
trainer/Log Pis Max                                      6.57381
trainer/Log Pis Min                                     -2.79864
trainer/Policy mu Mean                                  -0.0230794
trainer/Policy mu Std                                    0.393592
trainer/Policy mu Max                                    1.88063
trainer/Policy mu Min                                   -2.86919
trainer/Policy log std Mean                             -2.27687
trainer/Policy log std Std                               0.554481
trainer/Policy log std Max                              -0.126384
trainer/Policy log std Min                              -3.12378
trainer/Alpha                                            0.0227673
trainer/Alpha Loss                                      -0.329714
exploration/num steps total                           5800
exploration/num paths total                            290
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0905339
exploration/Rewards Std                                  0.0803416
exploration/Rewards Max                                  0.114211
exploration/Rewards Min                                 -0.255113
exploration/Returns Mean                                -1.81068
exploration/Returns Std                                  1.42889
exploration/Returns Max                                  0.815473
exploration/Returns Min                                 -3.44232
exploration/Actions Mean                                -0.00530126
exploration/Actions Std                                  0.131824
exploration/Actions Max                                  0.588648
exploration/Actions Min                                 -0.471376
exploration/Num Paths                                    5
exploration/Average Returns                             -1.81068
exploration/env_infos/final/reward_energy Mean          -0.077823
exploration/env_infos/final/reward_energy Std            0.0467726
exploration/env_infos/final/reward_energy Max           -0.0101598
exploration/env_infos/final/reward_energy Min           -0.154891
exploration/env_infos/initial/reward_energy Mean        -0.239276
exploration/env_infos/initial/reward_energy Std          0.269071
exploration/env_infos/initial/reward_energy Max         -0.0529238
exploration/env_infos/initial/reward_energy Min         -0.769135
exploration/env_infos/reward_energy Mean                -0.146537
exploration/env_infos/reward_energy Std                  0.115492
exploration/env_infos/reward_energy Max                 -0.0101598
exploration/env_infos/reward_energy Min                 -0.769135
exploration/env_infos/final/end_effector_loc Mean        0.0777931
exploration/env_infos/final/end_effector_loc Std         0.314293
exploration/env_infos/final/end_effector_loc Max         0.871739
exploration/env_infos/final/end_effector_loc Min        -0.303349
exploration/env_infos/initial/end_effector_loc Mean      0.00694161
exploration/env_infos/initial/end_effector_loc Std       0.0106714
exploration/env_infos/initial/end_effector_loc Max       0.0294324
exploration/env_infos/initial/end_effector_loc Min      -0.00211135
exploration/env_infos/end_effector_loc Mean              0.0679259
exploration/env_infos/end_effector_loc Std               0.181936
exploration/env_infos/end_effector_loc Max               0.871739
exploration/env_infos/end_effector_loc Min              -0.303349
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00265192
exploration/env_infos/final/reward_dist Std              0.00216497
exploration/env_infos/final/reward_dist Max              0.00542502
exploration/env_infos/final/reward_dist Min              4.41081e-36
exploration/env_infos/initial/reward_dist Mean           0.0111122
exploration/env_infos/initial/reward_dist Std            0.00880366
exploration/env_infos/initial/reward_dist Max            0.0242661
exploration/env_infos/initial/reward_dist Min            0.000104941
exploration/env_infos/reward_dist Mean                   0.0651312
exploration/env_infos/reward_dist Std                    0.135602
exploration/env_infos/reward_dist Max                    0.740307
exploration/env_infos/reward_dist Min                    4.41081e-36
evaluation/num steps total                           48000
evaluation/num paths total                            2400
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0531892
evaluation/Rewards Std                                   0.0739174
evaluation/Rewards Max                                   0.147633
evaluation/Rewards Min                                  -0.433951
evaluation/Returns Mean                                 -1.06378
evaluation/Returns Std                                   1.12361
evaluation/Returns Max                                   1.32217
evaluation/Returns Min                                  -3.47951
evaluation/Actions Mean                                 -0.00267195
evaluation/Actions Std                                   0.0667417
evaluation/Actions Max                                   0.512196
evaluation/Actions Min                                  -0.665724
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.06378
evaluation/env_infos/final/reward_energy Mean           -0.0398204
evaluation/env_infos/final/reward_energy Std             0.0361177
evaluation/env_infos/final/reward_energy Max            -0.00756176
evaluation/env_infos/final/reward_energy Min            -0.250499
evaluation/env_infos/initial/reward_energy Mean         -0.129924
evaluation/env_infos/initial/reward_energy Std           0.162028
evaluation/env_infos/initial/reward_energy Max          -0.0136224
evaluation/env_infos/initial/reward_energy Min          -0.713854
evaluation/env_infos/reward_energy Mean                 -0.0532966
evaluation/env_infos/reward_energy Std                   0.0779915
evaluation/env_infos/reward_energy Max                  -0.00192464
evaluation/env_infos/reward_energy Min                  -0.713854
evaluation/env_infos/final/end_effector_loc Mean         0.0499256
evaluation/env_infos/final/end_effector_loc Std          0.31138
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.749831
evaluation/env_infos/initial/end_effector_loc Mean       0.000662918
evaluation/env_infos/initial/end_effector_loc Std        0.00731282
evaluation/env_infos/initial/end_effector_loc Max        0.0256098
evaluation/env_infos/initial/end_effector_loc Min       -0.0332862
evaluation/env_infos/end_effector_loc Mean               0.034152
evaluation/env_infos/end_effector_loc Std                0.190955
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.749831
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.174712
evaluation/env_infos/final/reward_dist Std               0.262716
evaluation/env_infos/final/reward_dist Max               0.928343
evaluation/env_infos/final/reward_dist Min               1.65757e-113
evaluation/env_infos/initial/reward_dist Mean            0.00555549
evaluation/env_infos/initial/reward_dist Std             0.00894982
evaluation/env_infos/initial/reward_dist Max             0.0314521
evaluation/env_infos/initial/reward_dist Min             2.84969e-06
evaluation/env_infos/reward_dist Mean                    0.144963
evaluation/env_infos/reward_dist Std                     0.239078
evaluation/env_infos/reward_dist Max                     0.998896
evaluation/env_infos/reward_dist Min                     1.65757e-113
time/data storing (s)                                   22.7652
time/evaluation sampling (s)                             0.630297
time/exploration sampling (s)                            0.0969761
time/logging (s)                                         0.0152037
time/saving (s)                                          0.468814
time/training (s)                                       36.5508
time/epoch (s)                                          60.5273
time/total (s)                                        2370.63
Epoch                                                   47
---------------------------------------------------  ----------------
2021-05-29 00:36:25.278453 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 48 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.0011724
trainer/QF2 Loss                                         0.00150072
trainer/Policy Loss                                      2.95547
trainer/Q1 Predictions Mean                             -1.05494
trainer/Q1 Predictions Std                               0.757931
trainer/Q1 Predictions Max                               0.216659
trainer/Q1 Predictions Min                              -2.85151
trainer/Q2 Predictions Mean                             -1.05061
trainer/Q2 Predictions Std                               0.759503
trainer/Q2 Predictions Max                               0.219444
trainer/Q2 Predictions Min                              -2.89837
trainer/Q Targets Mean                                  -1.05621
trainer/Q Targets Std                                    0.76371
trainer/Q Targets Max                                    0.251282
trainer/Q Targets Min                                   -2.86982
trainer/Log Pis Mean                                     1.90564
trainer/Log Pis Std                                      1.22491
trainer/Log Pis Max                                      4.2053
trainer/Log Pis Min                                     -2.398
trainer/Policy mu Mean                                   0.00487827
trainer/Policy mu Std                                    0.275931
trainer/Policy mu Max                                    1.46093
trainer/Policy mu Min                                   -1.85108
trainer/Policy log std Mean                             -2.3127
trainer/Policy log std Std                               0.543773
trainer/Policy log std Max                               0.0128952
trainer/Policy log std Min                              -3.09703
trainer/Alpha                                            0.0229107
trainer/Alpha Loss                                      -0.356341
exploration/num steps total                           5900
exploration/num paths total                            295
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.140416
exploration/Rewards Std                                  0.0899846
exploration/Rewards Max                                 -0.00823655
exploration/Rewards Min                                 -0.4366
exploration/Returns Mean                                -2.80831
exploration/Returns Std                                  1.35744
exploration/Returns Max                                 -0.728859
exploration/Returns Min                                 -4.66708
exploration/Actions Mean                                -0.00370852
exploration/Actions Std                                  0.137663
exploration/Actions Max                                  0.892788
exploration/Actions Min                                 -0.330867
exploration/Num Paths                                    5
exploration/Average Returns                             -2.80831
exploration/env_infos/final/reward_energy Mean          -0.132582
exploration/env_infos/final/reward_energy Std            0.0822544
exploration/env_infos/final/reward_energy Max           -0.0384371
exploration/env_infos/final/reward_energy Min           -0.285735
exploration/env_infos/initial/reward_energy Mean        -0.336888
exploration/env_infos/initial/reward_energy Std          0.407849
exploration/env_infos/initial/reward_energy Max         -0.0703493
exploration/env_infos/initial/reward_energy Min         -1.14609
exploration/env_infos/reward_energy Mean                -0.147181
exploration/env_infos/reward_energy Std                  0.127543
exploration/env_infos/reward_energy Max                 -0.00620026
exploration/env_infos/reward_energy Min                 -1.14609
exploration/env_infos/final/end_effector_loc Mean        0.183069
exploration/env_infos/final/end_effector_loc Std         0.359281
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.268549
exploration/env_infos/initial/end_effector_loc Mean      0.0101516
exploration/env_infos/initial/end_effector_loc Std       0.0157078
exploration/env_infos/initial/end_effector_loc Max       0.0446394
exploration/env_infos/initial/end_effector_loc Min      -0.00307739
exploration/env_infos/end_effector_loc Mean              0.138154
exploration/env_infos/end_effector_loc Std               0.241593
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.268549
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.136391
exploration/env_infos/final/reward_dist Std              0.148724
exploration/env_infos/final/reward_dist Max              0.329261
exploration/env_infos/final/reward_dist Min              4.2398e-93
exploration/env_infos/initial/reward_dist Mean           0.00217052
exploration/env_infos/initial/reward_dist Std            0.00372957
exploration/env_infos/initial/reward_dist Max            0.00958931
exploration/env_infos/initial/reward_dist Min            2.92403e-05
exploration/env_infos/reward_dist Mean                   0.0844803
exploration/env_infos/reward_dist Std                    0.181242
exploration/env_infos/reward_dist Max                    0.849956
exploration/env_infos/reward_dist Min                    4.2398e-93
evaluation/num steps total                           49000
evaluation/num paths total                            2450
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0783702
evaluation/Rewards Std                                   0.107941
evaluation/Rewards Max                                   0.128034
evaluation/Rewards Min                                  -0.674712
evaluation/Returns Mean                                 -1.5674
evaluation/Returns Std                                   1.7814
evaluation/Returns Max                                   1.5673
evaluation/Returns Min                                  -6.61697
evaluation/Actions Mean                                 -0.0112831
evaluation/Actions Std                                   0.0969277
evaluation/Actions Max                                   0.538306
evaluation/Actions Min                                  -0.718927
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.5674
evaluation/env_infos/final/reward_energy Mean           -0.0683855
evaluation/env_infos/final/reward_energy Std             0.0671695
evaluation/env_infos/final/reward_energy Max            -0.0117017
evaluation/env_infos/final/reward_energy Min            -0.474085
evaluation/env_infos/initial/reward_energy Mean         -0.187591
evaluation/env_infos/initial/reward_energy Std           0.209383
evaluation/env_infos/initial/reward_energy Max          -0.0105143
evaluation/env_infos/initial/reward_energy Min          -0.864941
evaluation/env_infos/reward_energy Mean                 -0.0812954
evaluation/env_infos/reward_energy Std                   0.111515
evaluation/env_infos/reward_energy Max                  -0.00186321
evaluation/env_infos/reward_energy Min                  -0.864941
evaluation/env_infos/final/end_effector_loc Mean        -0.116102
evaluation/env_infos/final/end_effector_loc Std          0.345306
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00165452
evaluation/env_infos/initial/end_effector_loc Std        0.00980062
evaluation/env_infos/initial/end_effector_loc Max        0.021244
evaluation/env_infos/initial/end_effector_loc Min       -0.0359463
evaluation/env_infos/end_effector_loc Mean              -0.0478726
evaluation/env_infos/end_effector_loc Std                0.228818
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.165441
evaluation/env_infos/final/reward_dist Std               0.283653
evaluation/env_infos/final/reward_dist Max               0.98092
evaluation/env_infos/final/reward_dist Min               1.01165e-132
evaluation/env_infos/initial/reward_dist Mean            0.00553964
evaluation/env_infos/initial/reward_dist Std             0.011296
evaluation/env_infos/initial/reward_dist Max             0.0574006
evaluation/env_infos/initial/reward_dist Min             1.62274e-06
evaluation/env_infos/reward_dist Mean                    0.105847
evaluation/env_infos/reward_dist Std                     0.210967
evaluation/env_infos/reward_dist Max                     0.999848
evaluation/env_infos/reward_dist Min                     1.01165e-132
time/data storing (s)                                   22.9129
time/evaluation sampling (s)                             0.638798
time/exploration sampling (s)                            0.0869403
time/logging (s)                                         0.0171937
time/saving (s)                                          0.475492
time/training (s)                                       37.2717
time/epoch (s)                                          61.403
time/total (s)                                        2432.56
Epoch                                                   48
---------------------------------------------------  ----------------
2021-05-29 00:37:27.265137 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 49 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00159585
trainer/QF2 Loss                                         0.00152702
trainer/Policy Loss                                      2.95685
trainer/Q1 Predictions Mean                             -0.99293
trainer/Q1 Predictions Std                               0.765357
trainer/Q1 Predictions Max                               0.331116
trainer/Q1 Predictions Min                              -3.05838
trainer/Q2 Predictions Mean                             -0.985602
trainer/Q2 Predictions Std                               0.760544
trainer/Q2 Predictions Max                               0.338222
trainer/Q2 Predictions Min                              -3.02481
trainer/Q Targets Mean                                  -0.977374
trainer/Q Targets Std                                    0.760465
trainer/Q Targets Max                                    0.361474
trainer/Q Targets Min                                   -3.00484
trainer/Log Pis Mean                                     1.95862
trainer/Log Pis Std                                      1.27781
trainer/Log Pis Max                                      5.29989
trainer/Log Pis Min                                     -3.4482
trainer/Policy mu Mean                                  -0.0102427
trainer/Policy mu Std                                    0.325252
trainer/Policy mu Max                                    2.02253
trainer/Policy mu Min                                   -1.97238
trainer/Policy log std Mean                             -2.32071
trainer/Policy log std Std                               0.546717
trainer/Policy log std Max                              -0.0957689
trainer/Policy log std Min                              -3.11182
trainer/Alpha                                            0.02231
trainer/Alpha Loss                                      -0.157321
exploration/num steps total                           6000
exploration/num paths total                            300
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0700139
exploration/Rewards Std                                  0.102839
exploration/Rewards Max                                  0.157043
exploration/Rewards Min                                 -0.350745
exploration/Returns Mean                                -1.40028
exploration/Returns Std                                  1.61882
exploration/Returns Max                                  0.972626
exploration/Returns Min                                 -3.86627
exploration/Actions Mean                                -0.00505167
exploration/Actions Std                                  0.141733
exploration/Actions Max                                  0.556088
exploration/Actions Min                                 -0.665617
exploration/Num Paths                                    5
exploration/Average Returns                             -1.40028
exploration/env_infos/final/reward_energy Mean          -0.0702486
exploration/env_infos/final/reward_energy Std            0.0341337
exploration/env_infos/final/reward_energy Max           -0.0343848
exploration/env_infos/final/reward_energy Min           -0.1212
exploration/env_infos/initial/reward_energy Mean        -0.2416
exploration/env_infos/initial/reward_energy Std          0.273022
exploration/env_infos/initial/reward_energy Max         -0.0482013
exploration/env_infos/initial/reward_energy Min         -0.779257
exploration/env_infos/reward_energy Mean                -0.140792
exploration/env_infos/reward_energy Std                  0.142847
exploration/env_infos/reward_energy Max                 -0.00764847
exploration/env_infos/reward_energy Min                 -0.787028
exploration/env_infos/final/end_effector_loc Mean        0.0418188
exploration/env_infos/final/end_effector_loc Std         0.226151
exploration/env_infos/final/end_effector_loc Max         0.393745
exploration/env_infos/final/end_effector_loc Min        -0.282028
exploration/env_infos/initial/end_effector_loc Mean      0.00438567
exploration/env_infos/initial/end_effector_loc Std       0.0121204
exploration/env_infos/initial/end_effector_loc Max       0.0278044
exploration/env_infos/initial/end_effector_loc Min      -0.00633483
exploration/env_infos/end_effector_loc Mean              0.0559005
exploration/env_infos/end_effector_loc Std               0.196757
exploration/env_infos/end_effector_loc Max               0.591466
exploration/env_infos/end_effector_loc Min              -0.282028
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.242019
exploration/env_infos/final/reward_dist Std              0.268121
exploration/env_infos/final/reward_dist Max              0.641698
exploration/env_infos/final/reward_dist Min              3.92042e-08
exploration/env_infos/initial/reward_dist Mean           7.1841e-05
exploration/env_infos/initial/reward_dist Std            8.80675e-05
exploration/env_infos/initial/reward_dist Max            0.000234374
exploration/env_infos/initial/reward_dist Min            4.55507e-06
exploration/env_infos/reward_dist Mean                   0.132565
exploration/env_infos/reward_dist Std                    0.250801
exploration/env_infos/reward_dist Max                    0.906691
exploration/env_infos/reward_dist Min                    6.15409e-37
evaluation/num steps total                           50000
evaluation/num paths total                            2500
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.073593
evaluation/Rewards Std                                   0.0915512
evaluation/Rewards Max                                   0.139003
evaluation/Rewards Min                                  -0.795625
evaluation/Returns Mean                                 -1.47186
evaluation/Returns Std                                   1.29846
evaluation/Returns Max                                   1.18481
evaluation/Returns Min                                  -4.9543
evaluation/Actions Mean                                 -0.00268006
evaluation/Actions Std                                   0.072999
evaluation/Actions Max                                   0.534629
evaluation/Actions Min                                  -0.663705
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.47186
evaluation/env_infos/final/reward_energy Mean           -0.0420626
evaluation/env_infos/final/reward_energy Std             0.017591
evaluation/env_infos/final/reward_energy Max            -0.00971346
evaluation/env_infos/final/reward_energy Min            -0.0966042
evaluation/env_infos/initial/reward_energy Mean         -0.159226
evaluation/env_infos/initial/reward_energy Std           0.141655
evaluation/env_infos/initial/reward_energy Max          -0.00810948
evaluation/env_infos/initial/reward_energy Min          -0.766352
evaluation/env_infos/reward_energy Mean                 -0.0634932
evaluation/env_infos/reward_energy Std                   0.0814904
evaluation/env_infos/reward_energy Max                  -0.000842452
evaluation/env_infos/reward_energy Min                  -0.766352
evaluation/env_infos/final/end_effector_loc Mean         0.016729
evaluation/env_infos/final/end_effector_loc Std          0.432658
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.893473
evaluation/env_infos/initial/end_effector_loc Mean       0.0010625
evaluation/env_infos/initial/end_effector_loc Std        0.00745956
evaluation/env_infos/initial/end_effector_loc Max        0.0191567
evaluation/env_infos/initial/end_effector_loc Min       -0.0331852
evaluation/env_infos/end_effector_loc Mean               0.0188762
evaluation/env_infos/end_effector_loc Std                0.246987
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.893473
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0774058
evaluation/env_infos/final/reward_dist Std               0.181764
evaluation/env_infos/final/reward_dist Max               0.905758
evaluation/env_infos/final/reward_dist Min               1.80093e-96
evaluation/env_infos/initial/reward_dist Mean            0.00400927
evaluation/env_infos/initial/reward_dist Std             0.00785289
evaluation/env_infos/initial/reward_dist Max             0.0383326
evaluation/env_infos/initial/reward_dist Min             6.91808e-07
evaluation/env_infos/reward_dist Mean                    0.114441
evaluation/env_infos/reward_dist Std                     0.219732
evaluation/env_infos/reward_dist Max                     0.98794
evaluation/env_infos/reward_dist Min                     1.80093e-96
time/data storing (s)                                   23.0653
time/evaluation sampling (s)                             0.644853
time/exploration sampling (s)                            0.090956
time/logging (s)                                         0.0178104
time/saving (s)                                          0.524801
time/training (s)                                       37.0882
time/epoch (s)                                          61.432
time/total (s)                                        2494.55
Epoch                                                   49
---------------------------------------------------  ---------------
2021-05-29 00:38:30.781207 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 50 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00132902
trainer/QF2 Loss                                         0.00268843
trainer/Policy Loss                                      2.79092
trainer/Q1 Predictions Mean                             -0.952972
trainer/Q1 Predictions Std                               0.753135
trainer/Q1 Predictions Max                               0.347814
trainer/Q1 Predictions Min                              -3.26902
trainer/Q2 Predictions Mean                             -0.945636
trainer/Q2 Predictions Std                               0.752369
trainer/Q2 Predictions Max                               0.365659
trainer/Q2 Predictions Min                              -3.24212
trainer/Q Targets Mean                                  -0.963505
trainer/Q Targets Std                                    0.753904
trainer/Q Targets Max                                    0.396017
trainer/Q Targets Min                                   -3.27849
trainer/Log Pis Mean                                     1.83683
trainer/Log Pis Std                                      1.28011
trainer/Log Pis Max                                      5.21431
trainer/Log Pis Min                                     -2.69461
trainer/Policy mu Mean                                  -0.00111161
trainer/Policy mu Std                                    0.36982
trainer/Policy mu Max                                    2.04187
trainer/Policy mu Min                                   -2.0883
trainer/Policy log std Mean                             -2.22851
trainer/Policy log std Std                               0.535979
trainer/Policy log std Max                               0.0204771
trainer/Policy log std Min                              -3.03498
trainer/Alpha                                            0.0251828
trainer/Alpha Loss                                      -0.600817
exploration/num steps total                           6100
exploration/num paths total                            305
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.130367
exploration/Rewards Std                                  0.0645766
exploration/Rewards Max                                 -0.0307728
exploration/Rewards Min                                 -0.344117
exploration/Returns Mean                                -2.60734
exploration/Returns Std                                  0.558431
exploration/Returns Max                                 -1.56355
exploration/Returns Min                                 -3.10885
exploration/Actions Mean                                 0.0174409
exploration/Actions Std                                  0.113695
exploration/Actions Max                                  0.539257
exploration/Actions Min                                 -0.317558
exploration/Num Paths                                    5
exploration/Average Returns                             -2.60734
exploration/env_infos/final/reward_energy Mean          -0.144207
exploration/env_infos/final/reward_energy Std            0.0821603
exploration/env_infos/final/reward_energy Max           -0.061719
exploration/env_infos/final/reward_energy Min           -0.243513
exploration/env_infos/initial/reward_energy Mean        -0.205739
exploration/env_infos/initial/reward_energy Std          0.20439
exploration/env_infos/initial/reward_energy Max         -0.0286187
exploration/env_infos/initial/reward_energy Min         -0.604447
exploration/env_infos/reward_energy Mean                -0.128271
exploration/env_infos/reward_energy Std                  0.100041
exploration/env_infos/reward_energy Max                 -0.0188926
exploration/env_infos/reward_energy Min                 -0.604447
exploration/env_infos/final/end_effector_loc Mean        0.207887
exploration/env_infos/final/end_effector_loc Std         0.36563
exploration/env_infos/final/end_effector_loc Max         0.699711
exploration/env_infos/final/end_effector_loc Min        -0.537254
exploration/env_infos/initial/end_effector_loc Mean      0.00122893
exploration/env_infos/initial/end_effector_loc Std       0.0101794
exploration/env_infos/initial/end_effector_loc Max       0.0269628
exploration/env_infos/initial/end_effector_loc Min      -0.0136527
exploration/env_infos/end_effector_loc Mean              0.0710577
exploration/env_infos/end_effector_loc Std               0.210975
exploration/env_infos/end_effector_loc Max               0.699711
exploration/env_infos/end_effector_loc Min              -0.537254
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0197177
exploration/env_infos/final/reward_dist Std              0.0394353
exploration/env_infos/final/reward_dist Max              0.0985883
exploration/env_infos/final/reward_dist Min              3.51718e-35
exploration/env_infos/initial/reward_dist Mean           0.0152959
exploration/env_infos/initial/reward_dist Std            0.016818
exploration/env_infos/initial/reward_dist Max            0.0421356
exploration/env_infos/initial/reward_dist Min            0.000137293
exploration/env_infos/reward_dist Mean                   0.0239948
exploration/env_infos/reward_dist Std                    0.0557022
exploration/env_infos/reward_dist Max                    0.312767
exploration/env_infos/reward_dist Min                    3.51718e-35
evaluation/num steps total                           51000
evaluation/num paths total                            2550
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0652245
evaluation/Rewards Std                                   0.0722076
evaluation/Rewards Max                                   0.148565
evaluation/Rewards Min                                  -0.327743
evaluation/Returns Mean                                 -1.30449
evaluation/Returns Std                                   1.20411
evaluation/Returns Max                                   1.79397
evaluation/Returns Min                                  -4.71359
evaluation/Actions Mean                                 -0.00188218
evaluation/Actions Std                                   0.0816388
evaluation/Actions Max                                   0.735928
evaluation/Actions Min                                  -0.970524
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.30449
evaluation/env_infos/final/reward_energy Mean           -0.0390024
evaluation/env_infos/final/reward_energy Std             0.0166405
evaluation/env_infos/final/reward_energy Max            -0.00486987
evaluation/env_infos/final/reward_energy Min            -0.0750137
evaluation/env_infos/initial/reward_energy Mean         -0.157794
evaluation/env_infos/initial/reward_energy Std           0.20968
evaluation/env_infos/initial/reward_energy Max          -0.0120491
evaluation/env_infos/initial/reward_energy Min          -1.21799
evaluation/env_infos/reward_energy Mean                 -0.0596958
evaluation/env_infos/reward_energy Std                   0.09886
evaluation/env_infos/reward_energy Max                  -0.000299539
evaluation/env_infos/reward_energy Min                  -1.21799
evaluation/env_infos/final/end_effector_loc Mean        -0.0182993
evaluation/env_infos/final/end_effector_loc Std          0.332571
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.806007
evaluation/env_infos/initial/end_effector_loc Mean       0.000341584
evaluation/env_infos/initial/end_effector_loc Std        0.00927168
evaluation/env_infos/initial/end_effector_loc Max        0.0367964
evaluation/env_infos/initial/end_effector_loc Min       -0.0485262
evaluation/env_infos/end_effector_loc Mean              -0.00182105
evaluation/env_infos/end_effector_loc Std                0.212205
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.806007
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.106461
evaluation/env_infos/final/reward_dist Std               0.247553
evaluation/env_infos/final/reward_dist Max               0.99448
evaluation/env_infos/final/reward_dist Min               1.08095e-169
evaluation/env_infos/initial/reward_dist Mean            0.00285596
evaluation/env_infos/initial/reward_dist Std             0.00559131
evaluation/env_infos/initial/reward_dist Max             0.0229382
evaluation/env_infos/initial/reward_dist Min             1.80383e-06
evaluation/env_infos/reward_dist Mean                    0.0984647
evaluation/env_infos/reward_dist Std                     0.213623
evaluation/env_infos/reward_dist Max                     0.99448
evaluation/env_infos/reward_dist Min                     1.08095e-169
time/data storing (s)                                   23.9867
time/evaluation sampling (s)                             0.733372
time/exploration sampling (s)                            0.0891891
time/logging (s)                                         0.015523
time/saving (s)                                          1.04935
time/training (s)                                       37.0129
time/epoch (s)                                          62.8871
time/total (s)                                        2558.06
Epoch                                                   50
---------------------------------------------------  ----------------
2021-05-29 00:39:33.134360 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 51 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.000836731
trainer/QF2 Loss                                         0.000737478
trainer/Policy Loss                                      3.20624
trainer/Q1 Predictions Mean                             -1.01973
trainer/Q1 Predictions Std                               0.752947
trainer/Q1 Predictions Max                               0.495833
trainer/Q1 Predictions Min                              -3.3515
trainer/Q2 Predictions Mean                             -1.02609
trainer/Q2 Predictions Std                               0.744834
trainer/Q2 Predictions Max                               0.469335
trainer/Q2 Predictions Min                              -3.34534
trainer/Q Targets Mean                                  -1.02604
trainer/Q Targets Std                                    0.750678
trainer/Q Targets Max                                    0.453919
trainer/Q Targets Min                                   -3.34786
trainer/Log Pis Mean                                     2.1767
trainer/Log Pis Std                                      1.28605
trainer/Log Pis Max                                      4.43346
trainer/Log Pis Min                                     -4.7851
trainer/Policy mu Mean                                   0.0123896
trainer/Policy mu Std                                    0.250672
trainer/Policy mu Max                                    2.13877
trainer/Policy mu Min                                   -1.76208
trainer/Policy log std Mean                             -2.42068
trainer/Policy log std Std                               0.500006
trainer/Policy log std Max                              -0.587796
trainer/Policy log std Min                              -3.32461
trainer/Alpha                                            0.0229192
trainer/Alpha Loss                                       0.667193
exploration/num steps total                           6200
exploration/num paths total                            310
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.149502
exploration/Rewards Std                                  0.168453
exploration/Rewards Max                                  0.0502299
exploration/Rewards Min                                 -0.777528
exploration/Returns Mean                                -2.99004
exploration/Returns Std                                  1.72346
exploration/Returns Max                                  0.0419615
exploration/Returns Min                                 -5.31523
exploration/Actions Mean                                 0.00542105
exploration/Actions Std                                  0.152159
exploration/Actions Max                                  0.853514
exploration/Actions Min                                 -0.666009
exploration/Num Paths                                    5
exploration/Average Returns                             -2.99004
exploration/env_infos/final/reward_energy Mean          -0.129201
exploration/env_infos/final/reward_energy Std            0.0428483
exploration/env_infos/final/reward_energy Max           -0.0585352
exploration/env_infos/final/reward_energy Min           -0.173537
exploration/env_infos/initial/reward_energy Mean        -0.133443
exploration/env_infos/initial/reward_energy Std          0.0766818
exploration/env_infos/initial/reward_energy Max         -0.0539929
exploration/env_infos/initial/reward_energy Min         -0.247005
exploration/env_infos/reward_energy Mean                -0.163957
exploration/env_infos/reward_energy Std                  0.139577
exploration/env_infos/reward_energy Max                 -0.0028197
exploration/env_infos/reward_energy Min                 -0.91853
exploration/env_infos/final/end_effector_loc Mean        0.0540218
exploration/env_infos/final/end_effector_loc Std         0.39772
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.55476
exploration/env_infos/initial/end_effector_loc Mean     -0.00161251
exploration/env_infos/initial/end_effector_loc Std       0.005197
exploration/env_infos/initial/end_effector_loc Max       0.00591802
exploration/env_infos/initial/end_effector_loc Min      -0.0123485
exploration/env_infos/end_effector_loc Mean              0.0340992
exploration/env_infos/end_effector_loc Std               0.223881
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.55476
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0129591
exploration/env_infos/final/reward_dist Std              0.0259175
exploration/env_infos/final/reward_dist Max              0.0647941
exploration/env_infos/final/reward_dist Min              4.56067e-70
exploration/env_infos/initial/reward_dist Mean           0.007953
exploration/env_infos/initial/reward_dist Std            0.0113751
exploration/env_infos/initial/reward_dist Max            0.030307
exploration/env_infos/initial/reward_dist Min            1.61733e-06
exploration/env_infos/reward_dist Mean                   0.0324401
exploration/env_infos/reward_dist Std                    0.0843251
exploration/env_infos/reward_dist Max                    0.525277
exploration/env_infos/reward_dist Min                    4.56067e-70
evaluation/num steps total                           52000
evaluation/num paths total                            2600
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.075595
evaluation/Rewards Std                                   0.0907485
evaluation/Rewards Max                                   0.130385
evaluation/Rewards Min                                  -0.63176
evaluation/Returns Mean                                 -1.5119
evaluation/Returns Std                                   1.39056
evaluation/Returns Max                                   1.28978
evaluation/Returns Min                                  -5.43265
evaluation/Actions Mean                                  0.0027854
evaluation/Actions Std                                   0.0950768
evaluation/Actions Max                                   0.794296
evaluation/Actions Min                                  -0.940133
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.5119
evaluation/env_infos/final/reward_energy Mean           -0.0321339
evaluation/env_infos/final/reward_energy Std             0.0211852
evaluation/env_infos/final/reward_energy Max            -0.00270826
evaluation/env_infos/final/reward_energy Min            -0.143055
evaluation/env_infos/initial/reward_energy Mean         -0.178775
evaluation/env_infos/initial/reward_energy Std           0.253816
evaluation/env_infos/initial/reward_energy Max          -0.0132926
evaluation/env_infos/initial/reward_energy Min          -1.23075
evaluation/env_infos/reward_energy Mean                 -0.0674792
evaluation/env_infos/reward_energy Std                   0.116367
evaluation/env_infos/reward_energy Max                  -0.00136317
evaluation/env_infos/reward_energy Min                  -1.23075
evaluation/env_infos/final/end_effector_loc Mean         0.049309
evaluation/env_infos/final/end_effector_loc Std          0.29578
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.700968
evaluation/env_infos/initial/end_effector_loc Mean       0.000884604
evaluation/env_infos/initial/end_effector_loc Std        0.0109406
evaluation/env_infos/initial/end_effector_loc Max        0.0397148
evaluation/env_infos/initial/end_effector_loc Min       -0.0470066
evaluation/env_infos/end_effector_loc Mean               0.0240915
evaluation/env_infos/end_effector_loc Std                0.179154
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.700968
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.141579
evaluation/env_infos/final/reward_dist Std               0.249439
evaluation/env_infos/final/reward_dist Max               0.959351
evaluation/env_infos/final/reward_dist Min               3.32659e-154
evaluation/env_infos/initial/reward_dist Mean            0.00265697
evaluation/env_infos/initial/reward_dist Std             0.00576356
evaluation/env_infos/initial/reward_dist Max             0.0239332
evaluation/env_infos/initial/reward_dist Min             1.66894e-06
evaluation/env_infos/reward_dist Mean                    0.120292
evaluation/env_infos/reward_dist Std                     0.225552
evaluation/env_infos/reward_dist Max                     0.982166
evaluation/env_infos/reward_dist Min                     3.32659e-154
time/data storing (s)                                   23.9242
time/evaluation sampling (s)                             0.655013
time/exploration sampling (s)                            0.0902413
time/logging (s)                                         0.0156812
time/saving (s)                                          0.528785
time/training (s)                                       36.5569
time/epoch (s)                                          61.7708
time/total (s)                                        2620.41
Epoch                                                   51
---------------------------------------------------  ----------------
2021-05-29 00:40:37.852248 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 52 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00177116
trainer/QF2 Loss                                         0.00155367
trainer/Policy Loss                                      3.31218
trainer/Q1 Predictions Mean                             -1.01392
trainer/Q1 Predictions Std                               0.801959
trainer/Q1 Predictions Max                               0.530799
trainer/Q1 Predictions Min                              -3.21292
trainer/Q2 Predictions Mean                             -0.997289
trainer/Q2 Predictions Std                               0.798034
trainer/Q2 Predictions Max                               0.539577
trainer/Q2 Predictions Min                              -3.18522
trainer/Q Targets Mean                                  -1.00931
trainer/Q Targets Std                                    0.791648
trainer/Q Targets Max                                    0.540351
trainer/Q Targets Min                                   -3.17032
trainer/Log Pis Mean                                     2.30112
trainer/Log Pis Std                                      1.26589
trainer/Log Pis Max                                      5.40212
trainer/Log Pis Min                                     -5.25424
trainer/Policy mu Mean                                   0.0147455
trainer/Policy mu Std                                    0.306324
trainer/Policy mu Max                                    2.3743
trainer/Policy mu Min                                   -2.21046
trainer/Policy log std Mean                             -2.43466
trainer/Policy log std Std                               0.508947
trainer/Policy log std Max                              -0.360531
trainer/Policy log std Min                              -3.26451
trainer/Alpha                                            0.021393
trainer/Alpha Loss                                       1.15835
exploration/num steps total                           6300
exploration/num paths total                            315
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0978218
exploration/Rewards Std                                  0.0800878
exploration/Rewards Max                                  0.10543
exploration/Rewards Min                                 -0.320108
exploration/Returns Mean                                -1.95644
exploration/Returns Std                                  1.07002
exploration/Returns Max                                 -0.439529
exploration/Returns Min                                 -3.14221
exploration/Actions Mean                                -0.00267539
exploration/Actions Std                                  0.0926917
exploration/Actions Max                                  0.272879
exploration/Actions Min                                 -0.29182
exploration/Num Paths                                    5
exploration/Average Returns                             -1.95644
exploration/env_infos/final/reward_energy Mean          -0.0912145
exploration/env_infos/final/reward_energy Std            0.0335233
exploration/env_infos/final/reward_energy Max           -0.0353909
exploration/env_infos/final/reward_energy Min           -0.12596
exploration/env_infos/initial/reward_energy Mean        -0.133457
exploration/env_infos/initial/reward_energy Std          0.0653376
exploration/env_infos/initial/reward_energy Max         -0.0367912
exploration/env_infos/initial/reward_energy Min         -0.226932
exploration/env_infos/reward_energy Mean                -0.113564
exploration/env_infos/reward_energy Std                  0.0655822
exploration/env_infos/reward_energy Max                 -0.0186031
exploration/env_infos/reward_energy Min                 -0.385411
exploration/env_infos/final/end_effector_loc Mean       -0.0302973
exploration/env_infos/final/end_effector_loc Std         0.262957
exploration/env_infos/final/end_effector_loc Max         0.422379
exploration/env_infos/final/end_effector_loc Min        -0.445292
exploration/env_infos/initial/end_effector_loc Mean      0.000586777
exploration/env_infos/initial/end_effector_loc Std       0.00522068
exploration/env_infos/initial/end_effector_loc Max       0.0106167
exploration/env_infos/initial/end_effector_loc Min      -0.00832096
exploration/env_infos/end_effector_loc Mean             -0.00643046
exploration/env_infos/end_effector_loc Std               0.166974
exploration/env_infos/end_effector_loc Max               0.422588
exploration/env_infos/end_effector_loc Min              -0.445292
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             9.40088e-05
exploration/env_infos/final/reward_dist Std              0.000187177
exploration/env_infos/final/reward_dist Max              0.00046836
exploration/env_infos/final/reward_dist Min              9.57769e-18
exploration/env_infos/initial/reward_dist Mean           0.00642518
exploration/env_infos/initial/reward_dist Std            0.00965459
exploration/env_infos/initial/reward_dist Max            0.0250017
exploration/env_infos/initial/reward_dist Min            3.02899e-05
exploration/env_infos/reward_dist Mean                   0.045002
exploration/env_infos/reward_dist Std                    0.146663
exploration/env_infos/reward_dist Max                    0.944669
exploration/env_infos/reward_dist Min                    9.57769e-18
evaluation/num steps total                           53000
evaluation/num paths total                            2650
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0497777
evaluation/Rewards Std                                   0.078588
evaluation/Rewards Max                                   0.142649
evaluation/Rewards Min                                  -0.436578
evaluation/Returns Mean                                 -0.995553
evaluation/Returns Std                                   1.24603
evaluation/Returns Max                                   1.13693
evaluation/Returns Min                                  -4.17969
evaluation/Actions Mean                                  0.0016993
evaluation/Actions Std                                   0.0569436
evaluation/Actions Max                                   0.671809
evaluation/Actions Min                                  -0.765641
evaluation/Num Paths                                    50
evaluation/Average Returns                              -0.995553
evaluation/env_infos/final/reward_energy Mean           -0.0354598
evaluation/env_infos/final/reward_energy Std             0.0203033
evaluation/env_infos/final/reward_energy Max            -0.00513559
evaluation/env_infos/final/reward_energy Min            -0.0955059
evaluation/env_infos/initial/reward_energy Mean         -0.120577
evaluation/env_infos/initial/reward_energy Std           0.167275
evaluation/env_infos/initial/reward_energy Max          -0.00612437
evaluation/env_infos/initial/reward_energy Min          -1.01859
evaluation/env_infos/reward_energy Mean                 -0.0490733
evaluation/env_infos/reward_energy Std                   0.0638963
evaluation/env_infos/reward_energy Max                  -0.00132589
evaluation/env_infos/reward_energy Min                  -1.01859
evaluation/env_infos/final/end_effector_loc Mean         0.0738832
evaluation/env_infos/final/end_effector_loc Std          0.293867
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00132549
evaluation/env_infos/initial/end_effector_loc Std        0.00716888
evaluation/env_infos/initial/end_effector_loc Max        0.0335905
evaluation/env_infos/initial/end_effector_loc Min       -0.038282
evaluation/env_infos/end_effector_loc Mean               0.0394686
evaluation/env_infos/end_effector_loc Std                0.176261
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.09957
evaluation/env_infos/final/reward_dist Std               0.188929
evaluation/env_infos/final/reward_dist Max               0.878715
evaluation/env_infos/final/reward_dist Min               5.87542e-125
evaluation/env_infos/initial/reward_dist Mean            0.00285895
evaluation/env_infos/initial/reward_dist Std             0.0070142
evaluation/env_infos/initial/reward_dist Max             0.0352704
evaluation/env_infos/initial/reward_dist Min             1.05038e-06
evaluation/env_infos/reward_dist Mean                    0.105434
evaluation/env_infos/reward_dist Std                     0.200195
evaluation/env_infos/reward_dist Max                     0.993735
evaluation/env_infos/reward_dist Min                     5.87542e-125
time/data storing (s)                                   24.8382
time/evaluation sampling (s)                             0.696694
time/exploration sampling (s)                            0.0955421
time/logging (s)                                         0.0154357
time/saving (s)                                          0.527391
time/training (s)                                       37.9263
time/epoch (s)                                          64.0996
time/total (s)                                        2685.12
Epoch                                                   52
---------------------------------------------------  ----------------
2021-05-29 00:41:41.302531 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 53 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00136936
trainer/QF2 Loss                                         0.0011165
trainer/Policy Loss                                      2.77991
trainer/Q1 Predictions Mean                             -0.933921
trainer/Q1 Predictions Std                               0.743197
trainer/Q1 Predictions Max                               0.624086
trainer/Q1 Predictions Min                              -3.14513
trainer/Q2 Predictions Mean                             -0.934067
trainer/Q2 Predictions Std                               0.746994
trainer/Q2 Predictions Max                               0.633891
trainer/Q2 Predictions Min                              -3.17902
trainer/Q Targets Mean                                  -0.930498
trainer/Q Targets Std                                    0.749582
trainer/Q Targets Max                                    0.635598
trainer/Q Targets Min                                   -3.17808
trainer/Log Pis Mean                                     1.84065
trainer/Log Pis Std                                      1.20753
trainer/Log Pis Max                                      4.11806
trainer/Log Pis Min                                     -3.44178
trainer/Policy mu Mean                                   0.0205199
trainer/Policy mu Std                                    0.282654
trainer/Policy mu Max                                    1.79733
trainer/Policy mu Min                                   -1.58489
trainer/Policy log std Mean                             -2.30325
trainer/Policy log std Std                               0.481573
trainer/Policy log std Max                              -0.270591
trainer/Policy log std Min                              -3.24949
trainer/Alpha                                            0.0212396
trainer/Alpha Loss                                      -0.613554
exploration/num steps total                           6400
exploration/num paths total                            320
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.125352
exploration/Rewards Std                                  0.116217
exploration/Rewards Max                                  0.120052
exploration/Rewards Min                                 -0.504807
exploration/Returns Mean                                -2.50705
exploration/Returns Std                                  1.58431
exploration/Returns Max                                 -0.145922
exploration/Returns Min                                 -4.53392
exploration/Actions Mean                                 0.00643455
exploration/Actions Std                                  0.158806
exploration/Actions Max                                  0.576945
exploration/Actions Min                                 -0.607377
exploration/Num Paths                                    5
exploration/Average Returns                             -2.50705
exploration/env_infos/final/reward_energy Mean          -0.153061
exploration/env_infos/final/reward_energy Std            0.0855987
exploration/env_infos/final/reward_energy Max           -0.0548482
exploration/env_infos/final/reward_energy Min           -0.258775
exploration/env_infos/initial/reward_energy Mean        -0.166217
exploration/env_infos/initial/reward_energy Std          0.129744
exploration/env_infos/initial/reward_energy Max         -0.0493659
exploration/env_infos/initial/reward_energy Min         -0.417367
exploration/env_infos/reward_energy Mean                -0.168505
exploration/env_infos/reward_energy Std                  0.148753
exploration/env_infos/reward_energy Max                 -0.0149775
exploration/env_infos/reward_energy Min                 -0.769015
exploration/env_infos/final/end_effector_loc Mean        0.122786
exploration/env_infos/final/end_effector_loc Std         0.595871
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -1
exploration/env_infos/initial/end_effector_loc Mean      0.00335269
exploration/env_infos/initial/end_effector_loc Std       0.00665856
exploration/env_infos/initial/end_effector_loc Max       0.0192623
exploration/env_infos/initial/end_effector_loc Min      -0.00526138
exploration/env_infos/end_effector_loc Mean              0.0613123
exploration/env_infos/end_effector_loc Std               0.399655
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -1
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00245702
exploration/env_infos/final/reward_dist Std              0.00491055
exploration/env_infos/final/reward_dist Max              0.0122781
exploration/env_infos/final/reward_dist Min              1.26582e-113
exploration/env_infos/initial/reward_dist Mean           0.00153686
exploration/env_infos/initial/reward_dist Std            0.00261566
exploration/env_infos/initial/reward_dist Max            0.00675942
exploration/env_infos/initial/reward_dist Min            1.88143e-06
exploration/env_infos/reward_dist Mean                   0.0688357
exploration/env_infos/reward_dist Std                    0.185351
exploration/env_infos/reward_dist Max                    0.860124
exploration/env_infos/reward_dist Min                    1.26582e-113
evaluation/num steps total                           54000
evaluation/num paths total                            2700
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0553901
evaluation/Rewards Std                                   0.0862809
evaluation/Rewards Max                                   0.171359
evaluation/Rewards Min                                  -0.441732
evaluation/Returns Mean                                 -1.1078
evaluation/Returns Std                                   1.39664
evaluation/Returns Max                                   1.92941
evaluation/Returns Min                                  -6.11586
evaluation/Actions Mean                                  0.00287874
evaluation/Actions Std                                   0.046252
evaluation/Actions Max                                   0.398405
evaluation/Actions Min                                  -0.190799
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.1078
evaluation/env_infos/final/reward_energy Mean           -0.039257
evaluation/env_infos/final/reward_energy Std             0.0276785
evaluation/env_infos/final/reward_energy Max            -0.00271606
evaluation/env_infos/final/reward_energy Min            -0.0949199
evaluation/env_infos/initial/reward_energy Mean         -0.109706
evaluation/env_infos/initial/reward_energy Std           0.102739
evaluation/env_infos/initial/reward_energy Max          -0.0105799
evaluation/env_infos/initial/reward_energy Min          -0.433577
evaluation/env_infos/reward_energy Mean                 -0.0470345
evaluation/env_infos/reward_energy Std                   0.045638
evaluation/env_infos/reward_energy Max                  -0.00146857
evaluation/env_infos/reward_energy Min                  -0.433577
evaluation/env_infos/final/end_effector_loc Mean         0.0781349
evaluation/env_infos/final/end_effector_loc Std          0.27078
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.696955
evaluation/env_infos/initial/end_effector_loc Mean       0.00180077
evaluation/env_infos/initial/end_effector_loc Std        0.00499957
evaluation/env_infos/initial/end_effector_loc Max        0.0199203
evaluation/env_infos/initial/end_effector_loc Min       -0.00953995
evaluation/env_infos/end_effector_loc Mean               0.0429989
evaluation/env_infos/end_effector_loc Std                0.16537
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.696955
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.065914
evaluation/env_infos/final/reward_dist Std               0.145914
evaluation/env_infos/final/reward_dist Max               0.677203
evaluation/env_infos/final/reward_dist Min               2.14868e-117
evaluation/env_infos/initial/reward_dist Mean            0.00506653
evaluation/env_infos/initial/reward_dist Std             0.0112225
evaluation/env_infos/initial/reward_dist Max             0.070633
evaluation/env_infos/initial/reward_dist Min             1.48988e-06
evaluation/env_infos/reward_dist Mean                    0.112578
evaluation/env_infos/reward_dist Std                     0.228428
evaluation/env_infos/reward_dist Max                     0.99877
evaluation/env_infos/reward_dist Min                     2.14868e-117
time/data storing (s)                                   25.0395
time/evaluation sampling (s)                             0.712106
time/exploration sampling (s)                            0.0918013
time/logging (s)                                         0.0144737
time/saving (s)                                          0.528189
time/training (s)                                       36.4329
time/epoch (s)                                          62.8189
time/total (s)                                        2748.57
Epoch                                                   53
---------------------------------------------------  ----------------
2021-05-29 00:42:45.435915 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 54 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00184473
trainer/QF2 Loss                                         0.0025293
trainer/Policy Loss                                      2.86271
trainer/Q1 Predictions Mean                             -0.949143
trainer/Q1 Predictions Std                               0.797715
trainer/Q1 Predictions Max                               0.51272
trainer/Q1 Predictions Min                              -3.09012
trainer/Q2 Predictions Mean                             -0.945975
trainer/Q2 Predictions Std                               0.796409
trainer/Q2 Predictions Max                               0.521834
trainer/Q2 Predictions Min                              -3.07255
trainer/Q Targets Mean                                  -0.950084
trainer/Q Targets Std                                    0.798825
trainer/Q Targets Max                                    0.528528
trainer/Q Targets Min                                   -3.08372
trainer/Log Pis Mean                                     1.91276
trainer/Log Pis Std                                      1.26848
trainer/Log Pis Max                                      4.18824
trainer/Log Pis Min                                     -3.25643
trainer/Policy mu Mean                                   0.0175523
trainer/Policy mu Std                                    0.19988
trainer/Policy mu Max                                    1.7029
trainer/Policy mu Min                                   -1.63064
trainer/Policy log std Mean                             -2.32187
trainer/Policy log std Std                               0.443034
trainer/Policy log std Max                              -0.30255
trainer/Policy log std Min                              -3.25523
trainer/Alpha                                            0.020545
trainer/Alpha Loss                                      -0.339158
exploration/num steps total                           6500
exploration/num paths total                            325
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.153683
exploration/Rewards Std                                  0.129443
exploration/Rewards Max                                  0.0426899
exploration/Rewards Min                                 -0.630704
exploration/Returns Mean                                -3.07365
exploration/Returns Std                                  1.61293
exploration/Returns Max                                 -1.35242
exploration/Returns Min                                 -5.75301
exploration/Actions Mean                                 0.00734326
exploration/Actions Std                                  0.141912
exploration/Actions Max                                  0.628671
exploration/Actions Min                                 -0.484263
exploration/Num Paths                                    5
exploration/Average Returns                             -3.07365
exploration/env_infos/final/reward_energy Mean          -0.11197
exploration/env_infos/final/reward_energy Std            0.0391792
exploration/env_infos/final/reward_energy Max           -0.0609854
exploration/env_infos/final/reward_energy Min           -0.178408
exploration/env_infos/initial/reward_energy Mean        -0.272587
exploration/env_infos/initial/reward_energy Std          0.26085
exploration/env_infos/initial/reward_energy Max         -0.0608578
exploration/env_infos/initial/reward_energy Min         -0.78465
exploration/env_infos/reward_energy Mean                -0.153703
exploration/env_infos/reward_energy Std                  0.129465
exploration/env_infos/reward_energy Max                 -0.0137563
exploration/env_infos/reward_energy Min                 -0.78465
exploration/env_infos/final/end_effector_loc Mean        0.202173
exploration/env_infos/final/end_effector_loc Std         0.207044
exploration/env_infos/final/end_effector_loc Max         0.668609
exploration/env_infos/final/end_effector_loc Min        -0.0227877
exploration/env_infos/initial/end_effector_loc Mean      0.00673486
exploration/env_infos/initial/end_effector_loc Std       0.0115141
exploration/env_infos/initial/end_effector_loc Max       0.0314336
exploration/env_infos/initial/end_effector_loc Min      -0.00663606
exploration/env_infos/end_effector_loc Mean              0.115154
exploration/env_infos/end_effector_loc Std               0.149745
exploration/env_infos/end_effector_loc Max               0.668609
exploration/env_infos/end_effector_loc Min              -0.0587337
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.111742
exploration/env_infos/final/reward_dist Std              0.141897
exploration/env_infos/final/reward_dist Max              0.338698
exploration/env_infos/final/reward_dist Min              8.32861e-47
exploration/env_infos/initial/reward_dist Mean           0.0034461
exploration/env_infos/initial/reward_dist Std            0.00521687
exploration/env_infos/initial/reward_dist Max            0.0138044
exploration/env_infos/initial/reward_dist Min            6.25491e-05
exploration/env_infos/reward_dist Mean                   0.14155
exploration/env_infos/reward_dist Std                    0.268914
exploration/env_infos/reward_dist Max                    0.977441
exploration/env_infos/reward_dist Min                    8.32861e-47
evaluation/num steps total                           55000
evaluation/num paths total                            2750
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0775683
evaluation/Rewards Std                                   0.0746729
evaluation/Rewards Max                                   0.143552
evaluation/Rewards Min                                  -0.476208
evaluation/Returns Mean                                 -1.55137
evaluation/Returns Std                                   1.21885
evaluation/Returns Max                                   1.46312
evaluation/Returns Min                                  -5.0967
evaluation/Actions Mean                                  0.00667573
evaluation/Actions Std                                   0.0503804
evaluation/Actions Max                                   0.427987
evaluation/Actions Min                                  -0.221736
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.55137
evaluation/env_infos/final/reward_energy Mean           -0.0366115
evaluation/env_infos/final/reward_energy Std             0.0264015
evaluation/env_infos/final/reward_energy Max            -0.0038771
evaluation/env_infos/final/reward_energy Min            -0.0967137
evaluation/env_infos/initial/reward_energy Mean         -0.108512
evaluation/env_infos/initial/reward_energy Std           0.103367
evaluation/env_infos/initial/reward_energy Max          -0.00700173
evaluation/env_infos/initial/reward_energy Min          -0.482016
evaluation/env_infos/reward_energy Mean                 -0.0490043
evaluation/env_infos/reward_energy Std                   0.0525745
evaluation/env_infos/reward_energy Max                  -0.00145691
evaluation/env_infos/reward_energy Min                  -0.482016
evaluation/env_infos/final/end_effector_loc Mean         0.121288
evaluation/env_infos/final/end_effector_loc Std          0.281296
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.711598
evaluation/env_infos/initial/end_effector_loc Mean       0.00186514
evaluation/env_infos/initial/end_effector_loc Std        0.00495941
evaluation/env_infos/initial/end_effector_loc Max        0.0213993
evaluation/env_infos/initial/end_effector_loc Min       -0.0110868
evaluation/env_infos/end_effector_loc Mean               0.0578422
evaluation/env_infos/end_effector_loc Std                0.171768
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.711598
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0769795
evaluation/env_infos/final/reward_dist Std               0.206223
evaluation/env_infos/final/reward_dist Max               0.996272
evaluation/env_infos/final/reward_dist Min               4.71917e-86
evaluation/env_infos/initial/reward_dist Mean            0.00342735
evaluation/env_infos/initial/reward_dist Std             0.00658206
evaluation/env_infos/initial/reward_dist Max             0.0335185
evaluation/env_infos/initial/reward_dist Min             8.74423e-07
evaluation/env_infos/reward_dist Mean                    0.0849615
evaluation/env_infos/reward_dist Std                     0.188488
evaluation/env_infos/reward_dist Max                     0.996272
evaluation/env_infos/reward_dist Min                     4.71917e-86
time/data storing (s)                                   25.2582
time/evaluation sampling (s)                             0.668275
time/exploration sampling (s)                            0.103731
time/logging (s)                                         0.0149163
time/saving (s)                                          0.529974
time/training (s)                                       36.9542
time/epoch (s)                                          63.5293
time/total (s)                                        2812.7
Epoch                                                   54
---------------------------------------------------  ---------------
2021-05-29 00:43:52.286815 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 55 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00398337
trainer/QF2 Loss                                         0.00198
trainer/Policy Loss                                      2.75718
trainer/Q1 Predictions Mean                             -0.922724
trainer/Q1 Predictions Std                               0.773672
trainer/Q1 Predictions Max                               0.594172
trainer/Q1 Predictions Min                              -2.96473
trainer/Q2 Predictions Mean                             -0.921979
trainer/Q2 Predictions Std                               0.780336
trainer/Q2 Predictions Max                               0.580592
trainer/Q2 Predictions Min                              -2.97425
trainer/Q Targets Mean                                  -0.920778
trainer/Q Targets Std                                    0.78148
trainer/Q Targets Max                                    0.575409
trainer/Q Targets Min                                   -2.99115
trainer/Log Pis Mean                                     1.82594
trainer/Log Pis Std                                      1.20663
trainer/Log Pis Max                                      4.56407
trainer/Log Pis Min                                     -2.8316
trainer/Policy mu Mean                                   0.00822283
trainer/Policy mu Std                                    0.264292
trainer/Policy mu Max                                    1.60733
trainer/Policy mu Min                                   -1.96383
trainer/Policy log std Mean                             -2.24591
trainer/Policy log std Std                               0.49246
trainer/Policy log std Max                              -0.709573
trainer/Policy log std Min                              -3.16648
trainer/Alpha                                            0.0217053
trainer/Alpha Loss                                      -0.66655
exploration/num steps total                           6600
exploration/num paths total                            330
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.109241
exploration/Rewards Std                                  0.058185
exploration/Rewards Max                                 -0.0089336
exploration/Rewards Min                                 -0.29834
exploration/Returns Mean                                -2.18482
exploration/Returns Std                                  0.813006
exploration/Returns Max                                 -1.7149
exploration/Returns Min                                 -3.80544
exploration/Actions Mean                                 0.00466367
exploration/Actions Std                                  0.085006
exploration/Actions Max                                  0.381888
exploration/Actions Min                                 -0.206717
exploration/Num Paths                                    5
exploration/Average Returns                             -2.18482
exploration/env_infos/final/reward_energy Mean          -0.127276
exploration/env_infos/final/reward_energy Std            0.0682992
exploration/env_infos/final/reward_energy Max           -0.0250037
exploration/env_infos/final/reward_energy Min           -0.193245
exploration/env_infos/initial/reward_energy Mean        -0.0843374
exploration/env_infos/initial/reward_energy Std          0.0516594
exploration/env_infos/initial/reward_energy Max         -0.0187978
exploration/env_infos/initial/reward_energy Min         -0.146668
exploration/env_infos/reward_energy Mean                -0.0994899
exploration/env_infos/reward_energy Std                  0.0678035
exploration/env_infos/reward_energy Max                 -0.00920021
exploration/env_infos/reward_energy Min                 -0.408267
exploration/env_infos/final/end_effector_loc Mean        0.0104537
exploration/env_infos/final/end_effector_loc Std         0.277748
exploration/env_infos/final/end_effector_loc Max         0.422374
exploration/env_infos/final/end_effector_loc Min        -0.434069
exploration/env_infos/initial/end_effector_loc Mean     -0.000415181
exploration/env_infos/initial/end_effector_loc Std       0.00347196
exploration/env_infos/initial/end_effector_loc Max       0.00659735
exploration/env_infos/initial/end_effector_loc Min      -0.00581591
exploration/env_infos/end_effector_loc Mean             -0.00869237
exploration/env_infos/end_effector_loc Std               0.162984
exploration/env_infos/end_effector_loc Max               0.422374
exploration/env_infos/end_effector_loc Min              -0.434069
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0239757
exploration/env_infos/final/reward_dist Std              0.0479254
exploration/env_infos/final/reward_dist Max              0.119826
exploration/env_infos/final/reward_dist Min              9.34173e-13
exploration/env_infos/initial/reward_dist Mean           0.000662941
exploration/env_infos/initial/reward_dist Std            0.00107338
exploration/env_infos/initial/reward_dist Max            0.00277051
exploration/env_infos/initial/reward_dist Min            2.66165e-06
exploration/env_infos/reward_dist Mean                   0.0156742
exploration/env_infos/reward_dist Std                    0.027413
exploration/env_infos/reward_dist Max                    0.119826
exploration/env_infos/reward_dist Min                    9.34173e-13
evaluation/num steps total                           56000
evaluation/num paths total                            2800
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0722221
evaluation/Rewards Std                                   0.0868377
evaluation/Rewards Max                                   0.136769
evaluation/Rewards Min                                  -0.790208
evaluation/Returns Mean                                 -1.44444
evaluation/Returns Std                                   1.28896
evaluation/Returns Max                                   0.927059
evaluation/Returns Min                                  -7.11166
evaluation/Actions Mean                                  0.00460885
evaluation/Actions Std                                   0.0591851
evaluation/Actions Max                                   0.513112
evaluation/Actions Min                                  -0.301644
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.44444
evaluation/env_infos/final/reward_energy Mean           -0.0473602
evaluation/env_infos/final/reward_energy Std             0.028298
evaluation/env_infos/final/reward_energy Max            -0.0070375
evaluation/env_infos/final/reward_energy Min            -0.129687
evaluation/env_infos/initial/reward_energy Mean         -0.12617
evaluation/env_infos/initial/reward_energy Std           0.123025
evaluation/env_infos/initial/reward_energy Max          -0.0103357
evaluation/env_infos/initial/reward_energy Min          -0.541055
evaluation/env_infos/reward_energy Mean                 -0.0567909
evaluation/env_infos/reward_energy Std                   0.0618307
evaluation/env_infos/reward_energy Max                  -0.00149685
evaluation/env_infos/reward_energy Min                  -0.541055
evaluation/env_infos/final/end_effector_loc Mean         0.0845399
evaluation/env_infos/final/end_effector_loc Std          0.327694
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00158257
evaluation/env_infos/initial/end_effector_loc Std        0.00602603
evaluation/env_infos/initial/end_effector_loc Max        0.0256556
evaluation/env_infos/initial/end_effector_loc Min       -0.0150822
evaluation/env_infos/end_effector_loc Mean               0.0437046
evaluation/env_infos/end_effector_loc Std                0.196235
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0699174
evaluation/env_infos/final/reward_dist Std               0.165277
evaluation/env_infos/final/reward_dist Max               0.937146
evaluation/env_infos/final/reward_dist Min               1.68738e-145
evaluation/env_infos/initial/reward_dist Mean            0.0057097
evaluation/env_infos/initial/reward_dist Std             0.0103525
evaluation/env_infos/initial/reward_dist Max             0.0524505
evaluation/env_infos/initial/reward_dist Min             1.41509e-06
evaluation/env_infos/reward_dist Mean                    0.0852335
evaluation/env_infos/reward_dist Std                     0.184921
evaluation/env_infos/reward_dist Max                     0.989099
evaluation/env_infos/reward_dist Min                     1.68738e-145
time/data storing (s)                                   26.4647
time/evaluation sampling (s)                             0.708083
time/exploration sampling (s)                            0.102285
time/logging (s)                                         0.0162354
time/saving (s)                                          0.59701
time/training (s)                                       38.3184
time/epoch (s)                                          66.2067
time/total (s)                                        2879.55
Epoch                                                   55
---------------------------------------------------  ----------------
2021-05-29 00:44:59.715374 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 56 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00112699
trainer/QF2 Loss                                         0.001274
trainer/Policy Loss                                      2.94662
trainer/Q1 Predictions Mean                             -0.905041
trainer/Q1 Predictions Std                               0.745625
trainer/Q1 Predictions Max                               0.567226
trainer/Q1 Predictions Min                              -2.85366
trainer/Q2 Predictions Mean                             -0.909783
trainer/Q2 Predictions Std                               0.745075
trainer/Q2 Predictions Max                               0.577559
trainer/Q2 Predictions Min                              -2.85882
trainer/Q Targets Mean                                  -0.900498
trainer/Q Targets Std                                    0.753229
trainer/Q Targets Max                                    0.558988
trainer/Q Targets Min                                   -2.88576
trainer/Log Pis Mean                                     2.05431
trainer/Log Pis Std                                      1.23022
trainer/Log Pis Max                                      5.3082
trainer/Log Pis Min                                     -2.35897
trainer/Policy mu Mean                                   0.00497527
trainer/Policy mu Std                                    0.416652
trainer/Policy mu Max                                    2.0823
trainer/Policy mu Min                                   -2.04503
trainer/Policy log std Mean                             -2.25359
trainer/Policy log std Std                               0.568007
trainer/Policy log std Max                               0.0474878
trainer/Policy log std Min                              -3.3425
trainer/Alpha                                            0.0206288
trainer/Alpha Loss                                       0.210785
exploration/num steps total                           6700
exploration/num paths total                            335
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.155713
exploration/Rewards Std                                  0.0871642
exploration/Rewards Max                                  0.0378788
exploration/Rewards Min                                 -0.347929
exploration/Returns Mean                                -3.11427
exploration/Returns Std                                  1.0596
exploration/Returns Max                                 -1.90116
exploration/Returns Min                                 -4.80116
exploration/Actions Mean                                 0.00742411
exploration/Actions Std                                  0.21491
exploration/Actions Max                                  0.642599
exploration/Actions Min                                 -0.638948
exploration/Num Paths                                    5
exploration/Average Returns                             -3.11427
exploration/env_infos/final/reward_energy Mean          -0.197028
exploration/env_infos/final/reward_energy Std            0.116021
exploration/env_infos/final/reward_energy Max           -0.06278
exploration/env_infos/final/reward_energy Min           -0.336141
exploration/env_infos/initial/reward_energy Mean        -0.374457
exploration/env_infos/initial/reward_energy Std          0.2226
exploration/env_infos/initial/reward_energy Max         -0.0621516
exploration/env_infos/initial/reward_energy Min         -0.691757
exploration/env_infos/reward_energy Mean                -0.234733
exploration/env_infos/reward_energy Std                  0.193348
exploration/env_infos/reward_energy Max                 -0.00796359
exploration/env_infos/reward_energy Min                 -0.765511
exploration/env_infos/final/end_effector_loc Mean       -0.0273266
exploration/env_infos/final/end_effector_loc Std         0.579076
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -1
exploration/env_infos/initial/end_effector_loc Mean      0.00617576
exploration/env_infos/initial/end_effector_loc Std       0.0141092
exploration/env_infos/initial/end_effector_loc Max       0.0293594
exploration/env_infos/initial/end_effector_loc Min      -0.0203253
exploration/env_infos/end_effector_loc Mean              0.0326457
exploration/env_infos/end_effector_loc Std               0.390396
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -1
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00963927
exploration/env_infos/final/reward_dist Std              0.0192785
exploration/env_infos/final/reward_dist Max              0.0481963
exploration/env_infos/final/reward_dist Min              5.61059e-131
exploration/env_infos/initial/reward_dist Mean           0.0150312
exploration/env_infos/initial/reward_dist Std            0.0186393
exploration/env_infos/initial/reward_dist Max            0.0517301
exploration/env_infos/initial/reward_dist Min            2.57272e-05
exploration/env_infos/reward_dist Mean                   0.0887826
exploration/env_infos/reward_dist Std                    0.208256
exploration/env_infos/reward_dist Max                    0.962295
exploration/env_infos/reward_dist Min                    5.61059e-131
evaluation/num steps total                           57000
evaluation/num paths total                            2850
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0747543
evaluation/Rewards Std                                   0.0931521
evaluation/Rewards Max                                   0.151659
evaluation/Rewards Min                                  -0.485614
evaluation/Returns Mean                                 -1.49509
evaluation/Returns Std                                   1.53265
evaluation/Returns Max                                   1.05824
evaluation/Returns Min                                  -5.19365
evaluation/Actions Mean                                 -0.00612404
evaluation/Actions Std                                   0.084681
evaluation/Actions Max                                   0.556747
evaluation/Actions Min                                  -0.370883
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.49509
evaluation/env_infos/final/reward_energy Mean           -0.060464
evaluation/env_infos/final/reward_energy Std             0.024463
evaluation/env_infos/final/reward_energy Max            -0.010085
evaluation/env_infos/final/reward_energy Min            -0.112413
evaluation/env_infos/initial/reward_energy Mean         -0.20651
evaluation/env_infos/initial/reward_energy Std           0.16386
evaluation/env_infos/initial/reward_energy Max          -0.00627249
evaluation/env_infos/initial/reward_energy Min          -0.58076
evaluation/env_infos/reward_energy Mean                 -0.0801043
evaluation/env_infos/reward_energy Std                   0.089443
evaluation/env_infos/reward_energy Max                  -0.000778885
evaluation/env_infos/reward_energy Min                  -0.58076
evaluation/env_infos/final/end_effector_loc Mean        -0.0236085
evaluation/env_infos/final/end_effector_loc Std          0.42431
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00172627
evaluation/env_infos/initial/end_effector_loc Std        0.00915918
evaluation/env_infos/initial/end_effector_loc Max        0.0278374
evaluation/env_infos/initial/end_effector_loc Min       -0.0185442
evaluation/env_infos/end_effector_loc Mean               0.00128224
evaluation/env_infos/end_effector_loc Std                0.266098
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0732906
evaluation/env_infos/final/reward_dist Std               0.170824
evaluation/env_infos/final/reward_dist Max               0.873611
evaluation/env_infos/final/reward_dist Min               1.91518e-104
evaluation/env_infos/initial/reward_dist Mean            0.00738595
evaluation/env_infos/initial/reward_dist Std             0.0145272
evaluation/env_infos/initial/reward_dist Max             0.0733588
evaluation/env_infos/initial/reward_dist Min             9.26608e-07
evaluation/env_infos/reward_dist Mean                    0.103998
evaluation/env_infos/reward_dist Std                     0.206687
evaluation/env_infos/reward_dist Max                     0.985601
evaluation/env_infos/reward_dist Min                     1.91518e-104
time/data storing (s)                                   27.0903
time/evaluation sampling (s)                             0.700768
time/exploration sampling (s)                            0.106357
time/logging (s)                                         0.0146668
time/saving (s)                                          0.563384
time/training (s)                                       38.3325
time/epoch (s)                                          66.808
time/total (s)                                        2946.97
Epoch                                                   56
---------------------------------------------------  ----------------
2021-05-29 00:46:04.914553 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 57 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.0015252
trainer/QF2 Loss                                         0.00199106
trainer/Policy Loss                                      2.58489
trainer/Q1 Predictions Mean                             -0.876822
trainer/Q1 Predictions Std                               0.796143
trainer/Q1 Predictions Max                               0.608691
trainer/Q1 Predictions Min                              -3.1317
trainer/Q2 Predictions Mean                             -0.874905
trainer/Q2 Predictions Std                               0.795968
trainer/Q2 Predictions Max                               0.591361
trainer/Q2 Predictions Min                              -3.14899
trainer/Q Targets Mean                                  -0.878414
trainer/Q Targets Std                                    0.786672
trainer/Q Targets Max                                    0.581071
trainer/Q Targets Min                                   -3.16412
trainer/Log Pis Mean                                     1.72401
trainer/Log Pis Std                                      1.3301
trainer/Log Pis Max                                      4.72952
trainer/Log Pis Min                                     -2.37455
trainer/Policy mu Mean                                  -0.022097
trainer/Policy mu Std                                    0.389318
trainer/Policy mu Max                                    2.56477
trainer/Policy mu Min                                   -2.59236
trainer/Policy log std Mean                             -2.17257
trainer/Policy log std Std                               0.562538
trainer/Policy log std Max                              -0.182951
trainer/Policy log std Min                              -3.38163
trainer/Alpha                                            0.018119
trainer/Alpha Loss                                      -1.10629
exploration/num steps total                           6800
exploration/num paths total                            340
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.069107
exploration/Rewards Std                                  0.0976082
exploration/Rewards Max                                  0.132177
exploration/Rewards Min                                 -0.328995
exploration/Returns Mean                                -1.38214
exploration/Returns Std                                  1.65046
exploration/Returns Max                                  1.27085
exploration/Returns Min                                 -3.93528
exploration/Actions Mean                                 0.0155798
exploration/Actions Std                                  0.129281
exploration/Actions Max                                  0.695769
exploration/Actions Min                                 -0.33187
exploration/Num Paths                                    5
exploration/Average Returns                             -1.38214
exploration/env_infos/final/reward_energy Mean          -0.0941444
exploration/env_infos/final/reward_energy Std            0.0329392
exploration/env_infos/final/reward_energy Max           -0.0344914
exploration/env_infos/final/reward_energy Min           -0.13562
exploration/env_infos/initial/reward_energy Mean        -0.261269
exploration/env_infos/initial/reward_energy Std          0.262701
exploration/env_infos/initial/reward_energy Max         -0.0681465
exploration/env_infos/initial/reward_energy Min         -0.773791
exploration/env_infos/reward_energy Mean                -0.143409
exploration/env_infos/reward_energy Std                  0.115528
exploration/env_infos/reward_energy Max                 -0.00216447
exploration/env_infos/reward_energy Min                 -0.773791
exploration/env_infos/final/end_effector_loc Mean        0.223237
exploration/env_infos/final/end_effector_loc Std         0.329373
exploration/env_infos/final/end_effector_loc Max         0.988753
exploration/env_infos/final/end_effector_loc Min        -0.265507
exploration/env_infos/initial/end_effector_loc Mean      0.00751354
exploration/env_infos/initial/end_effector_loc Std       0.0107302
exploration/env_infos/initial/end_effector_loc Max       0.0347884
exploration/env_infos/initial/end_effector_loc Min      -0.00337827
exploration/env_infos/end_effector_loc Mean              0.109993
exploration/env_infos/end_effector_loc Std               0.195735
exploration/env_infos/end_effector_loc Max               0.988753
exploration/env_infos/end_effector_loc Min              -0.265507
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0214232
exploration/env_infos/final/reward_dist Std              0.0205761
exploration/env_infos/final/reward_dist Max              0.0521717
exploration/env_infos/final/reward_dist Min              2.90554e-101
exploration/env_infos/initial/reward_dist Mean           0.0112588
exploration/env_infos/initial/reward_dist Std            0.0105939
exploration/env_infos/initial/reward_dist Max            0.0270646
exploration/env_infos/initial/reward_dist Min            1.24767e-05
exploration/env_infos/reward_dist Mean                   0.177648
exploration/env_infos/reward_dist Std                    0.241313
exploration/env_infos/reward_dist Max                    0.862559
exploration/env_infos/reward_dist Min                    2.90554e-101
evaluation/num steps total                           58000
evaluation/num paths total                            2900
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0748549
evaluation/Rewards Std                                   0.0895195
evaluation/Rewards Max                                   0.136671
evaluation/Rewards Min                                  -0.660699
evaluation/Returns Mean                                 -1.4971
evaluation/Returns Std                                   1.3766
evaluation/Returns Max                                   1.19569
evaluation/Returns Min                                  -4.07491
evaluation/Actions Mean                                  0.00493608
evaluation/Actions Std                                   0.0835678
evaluation/Actions Max                                   0.713547
evaluation/Actions Min                                  -0.865781
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.4971
evaluation/env_infos/final/reward_energy Mean           -0.0387549
evaluation/env_infos/final/reward_energy Std             0.0434134
evaluation/env_infos/final/reward_energy Max            -0.00460941
evaluation/env_infos/final/reward_energy Min            -0.28594
evaluation/env_infos/initial/reward_energy Mean         -0.224546
evaluation/env_infos/initial/reward_energy Std           0.227706
evaluation/env_infos/initial/reward_energy Max          -0.00803712
evaluation/env_infos/initial/reward_energy Min          -0.884078
evaluation/env_infos/reward_energy Mean                 -0.0726255
evaluation/env_infos/reward_energy Std                   0.0934956
evaluation/env_infos/reward_energy Max                  -5.19056e-05
evaluation/env_infos/reward_energy Min                  -0.884078
evaluation/env_infos/final/end_effector_loc Mean         0.099355
evaluation/env_infos/final/end_effector_loc Std          0.378522
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.0014504
evaluation/env_infos/initial/end_effector_loc Std        0.0112132
evaluation/env_infos/initial/end_effector_loc Max        0.0356774
evaluation/env_infos/initial/end_effector_loc Min       -0.043289
evaluation/env_infos/end_effector_loc Mean               0.0505321
evaluation/env_infos/end_effector_loc Std                0.236566
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0835478
evaluation/env_infos/final/reward_dist Std               0.205111
evaluation/env_infos/final/reward_dist Max               0.866632
evaluation/env_infos/final/reward_dist Min               2.28616e-106
evaluation/env_infos/initial/reward_dist Mean            0.00490173
evaluation/env_infos/initial/reward_dist Std             0.00867089
evaluation/env_infos/initial/reward_dist Max             0.0340211
evaluation/env_infos/initial/reward_dist Min             8.87615e-07
evaluation/env_infos/reward_dist Mean                    0.109176
evaluation/env_infos/reward_dist Std                     0.22388
evaluation/env_infos/reward_dist Max                     0.999981
evaluation/env_infos/reward_dist Min                     2.28616e-106
time/data storing (s)                                   26.6166
time/evaluation sampling (s)                             0.674418
time/exploration sampling (s)                            0.0895655
time/logging (s)                                         0.0146268
time/saving (s)                                          0.554405
time/training (s)                                       36.5778
time/epoch (s)                                          64.5274
time/total (s)                                        3012.17
Epoch                                                   57
---------------------------------------------------  ----------------
2021-05-29 00:47:11.318388 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 58 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00104635
trainer/QF2 Loss                                         0.00275974
trainer/Policy Loss                                      2.74055
trainer/Q1 Predictions Mean                             -0.827442
trainer/Q1 Predictions Std                               0.729596
trainer/Q1 Predictions Max                               0.561196
trainer/Q1 Predictions Min                              -2.92119
trainer/Q2 Predictions Mean                             -0.831702
trainer/Q2 Predictions Std                               0.72421
trainer/Q2 Predictions Max                               0.505618
trainer/Q2 Predictions Min                              -2.8878
trainer/Q Targets Mean                                  -0.822492
trainer/Q Targets Std                                    0.731739
trainer/Q Targets Max                                    0.566898
trainer/Q Targets Min                                   -2.85547
trainer/Log Pis Mean                                     1.91647
trainer/Log Pis Std                                      1.44677
trainer/Log Pis Max                                      5.22499
trainer/Log Pis Min                                     -2.9708
trainer/Policy mu Mean                                   0.00637502
trainer/Policy mu Std                                    0.379263
trainer/Policy mu Max                                    2.40859
trainer/Policy mu Min                                   -2.84328
trainer/Policy log std Mean                             -2.28081
trainer/Policy log std Std                               0.621952
trainer/Policy log std Max                              -0.323828
trainer/Policy log std Min                              -3.3832
trainer/Alpha                                            0.0190927
trainer/Alpha Loss                                      -0.330693
exploration/num steps total                           6900
exploration/num paths total                            345
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.145276
exploration/Rewards Std                                  0.144743
exploration/Rewards Max                                  0.0243041
exploration/Rewards Min                                 -0.745531
exploration/Returns Mean                                -2.90552
exploration/Returns Std                                  1.21483
exploration/Returns Max                                 -1.53348
exploration/Returns Min                                 -4.83652
exploration/Actions Mean                                -0.00416338
exploration/Actions Std                                  0.0999723
exploration/Actions Max                                  0.315416
exploration/Actions Min                                 -0.396723
exploration/Num Paths                                    5
exploration/Average Returns                             -2.90552
exploration/env_infos/final/reward_energy Mean          -0.0704117
exploration/env_infos/final/reward_energy Std            0.0378509
exploration/env_infos/final/reward_energy Max           -0.0294542
exploration/env_infos/final/reward_energy Min           -0.132886
exploration/env_infos/initial/reward_energy Mean        -0.122118
exploration/env_infos/initial/reward_energy Std          0.0677792
exploration/env_infos/initial/reward_energy Max         -0.0659433
exploration/env_infos/initial/reward_energy Min         -0.237826
exploration/env_infos/reward_energy Mean                -0.112652
exploration/env_infos/reward_energy Std                  0.0856334
exploration/env_infos/reward_energy Max                 -0.012265
exploration/env_infos/reward_energy Min                 -0.457416
exploration/env_infos/final/end_effector_loc Mean        0.004808
exploration/env_infos/final/end_effector_loc Std         0.459854
exploration/env_infos/final/end_effector_loc Max         0.905049
exploration/env_infos/final/end_effector_loc Min        -0.920087
exploration/env_infos/initial/end_effector_loc Mean     -0.00031745
exploration/env_infos/initial/end_effector_loc Std       0.00492775
exploration/env_infos/initial/end_effector_loc Max       0.00770654
exploration/env_infos/initial/end_effector_loc Min      -0.00906095
exploration/env_infos/end_effector_loc Mean              0.0027728
exploration/env_infos/end_effector_loc Std               0.244058
exploration/env_infos/end_effector_loc Max               0.905049
exploration/env_infos/end_effector_loc Min              -0.920087
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0133824
exploration/env_infos/final/reward_dist Std              0.0265411
exploration/env_infos/final/reward_dist Max              0.0664635
exploration/env_infos/final/reward_dist Min              1.00977e-62
exploration/env_infos/initial/reward_dist Mean           0.00673372
exploration/env_infos/initial/reward_dist Std            0.0129111
exploration/env_infos/initial/reward_dist Max            0.0325438
exploration/env_infos/initial/reward_dist Min            8.80167e-06
exploration/env_infos/reward_dist Mean                   0.050271
exploration/env_infos/reward_dist Std                    0.11494
exploration/env_infos/reward_dist Max                    0.743288
exploration/env_infos/reward_dist Min                    1.00977e-62
evaluation/num steps total                           59000
evaluation/num paths total                            2950
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0715384
evaluation/Rewards Std                                   0.090493
evaluation/Rewards Max                                   0.15587
evaluation/Rewards Min                                  -0.425311
evaluation/Returns Mean                                 -1.43077
evaluation/Returns Std                                   1.48505
evaluation/Returns Max                                   2.13194
evaluation/Returns Min                                  -5.41501
evaluation/Actions Mean                                  0.00140791
evaluation/Actions Std                                   0.0917467
evaluation/Actions Max                                   0.643871
evaluation/Actions Min                                  -0.591746
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.43077
evaluation/env_infos/final/reward_energy Mean           -0.0411053
evaluation/env_infos/final/reward_energy Std             0.0547789
evaluation/env_infos/final/reward_energy Max            -0.00362076
evaluation/env_infos/final/reward_energy Min            -0.302181
evaluation/env_infos/initial/reward_energy Mean         -0.219136
evaluation/env_infos/initial/reward_energy Std           0.206467
evaluation/env_infos/initial/reward_energy Max          -0.00788773
evaluation/env_infos/initial/reward_energy Min          -0.826713
evaluation/env_infos/reward_energy Mean                 -0.076165
evaluation/env_infos/reward_energy Std                   0.105061
evaluation/env_infos/reward_energy Max                  -0.000767741
evaluation/env_infos/reward_energy Min                  -0.826713
evaluation/env_infos/final/end_effector_loc Mean         0.00330048
evaluation/env_infos/final/end_effector_loc Std          0.326152
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00178483
evaluation/env_infos/initial/end_effector_loc Std        0.0104941
evaluation/env_infos/initial/end_effector_loc Max        0.0318198
evaluation/env_infos/initial/end_effector_loc Min       -0.0237987
evaluation/env_infos/end_effector_loc Mean               0.00275462
evaluation/env_infos/end_effector_loc Std                0.207375
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0783855
evaluation/env_infos/final/reward_dist Std               0.168188
evaluation/env_infos/final/reward_dist Max               0.824841
evaluation/env_infos/final/reward_dist Min               1.25476e-90
evaluation/env_infos/initial/reward_dist Mean            0.0039116
evaluation/env_infos/initial/reward_dist Std             0.00969616
evaluation/env_infos/initial/reward_dist Max             0.0447982
evaluation/env_infos/initial/reward_dist Min             1.41162e-06
evaluation/env_infos/reward_dist Mean                    0.103688
evaluation/env_infos/reward_dist Std                     0.208268
evaluation/env_infos/reward_dist Max                     0.99226
evaluation/env_infos/reward_dist Min                     1.25476e-90
time/data storing (s)                                   27.7624
time/evaluation sampling (s)                             0.682439
time/exploration sampling (s)                            0.0911373
time/logging (s)                                         0.0143719
time/saving (s)                                          0.55546
time/training (s)                                       36.6088
time/epoch (s)                                          65.7147
time/total (s)                                        3078.57
Epoch                                                   58
---------------------------------------------------  ---------------
2021-05-29 00:48:16.636984 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 59 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00455669
trainer/QF2 Loss                                         0.00240625
trainer/Policy Loss                                      2.93544
trainer/Q1 Predictions Mean                             -0.922204
trainer/Q1 Predictions Std                               0.712177
trainer/Q1 Predictions Max                               0.452296
trainer/Q1 Predictions Min                              -2.84874
trainer/Q2 Predictions Mean                             -0.918171
trainer/Q2 Predictions Std                               0.718466
trainer/Q2 Predictions Max                               0.47218
trainer/Q2 Predictions Min                              -2.84367
trainer/Q Targets Mean                                  -0.89554
trainer/Q Targets Std                                    0.709236
trainer/Q Targets Max                                    0.457086
trainer/Q Targets Min                                   -2.77982
trainer/Log Pis Mean                                     2.01807
trainer/Log Pis Std                                      1.32191
trainer/Log Pis Max                                      4.51203
trainer/Log Pis Min                                     -4.09192
trainer/Policy mu Mean                                  -0.0340523
trainer/Policy mu Std                                    0.374877
trainer/Policy mu Max                                    2.48857
trainer/Policy mu Min                                   -1.89978
trainer/Policy log std Mean                             -2.28981
trainer/Policy log std Std                               0.611923
trainer/Policy log std Max                              -0.442356
trainer/Policy log std Min                              -3.25667
trainer/Alpha                                            0.0208907
trainer/Alpha Loss                                       0.069882
exploration/num steps total                           7000
exploration/num paths total                            350
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.112078
exploration/Rewards Std                                  0.16737
exploration/Rewards Max                                  0.146014
exploration/Rewards Min                                 -0.571501
exploration/Returns Mean                                -2.24156
exploration/Returns Std                                  2.40708
exploration/Returns Max                                  1.98078
exploration/Returns Min                                 -5.14329
exploration/Actions Mean                                -0.0119748
exploration/Actions Std                                  0.135765
exploration/Actions Max                                  0.528715
exploration/Actions Min                                 -0.437474
exploration/Num Paths                                    5
exploration/Average Returns                             -2.24156
exploration/env_infos/final/reward_energy Mean          -0.189239
exploration/env_infos/final/reward_energy Std            0.0997194
exploration/env_infos/final/reward_energy Max           -0.0914986
exploration/env_infos/final/reward_energy Min           -0.370598
exploration/env_infos/initial/reward_energy Mean        -0.394734
exploration/env_infos/initial/reward_energy Std          0.178901
exploration/env_infos/initial/reward_energy Max         -0.181224
exploration/env_infos/initial/reward_energy Min         -0.613847
exploration/env_infos/reward_energy Mean                -0.15606
exploration/env_infos/reward_energy Std                  0.113121
exploration/env_infos/reward_energy Max                 -0.00187347
exploration/env_infos/reward_energy Min                 -0.613847
exploration/env_infos/final/end_effector_loc Mean       -0.179336
exploration/env_infos/final/end_effector_loc Std         0.429131
exploration/env_infos/final/end_effector_loc Max         0.649401
exploration/env_infos/final/end_effector_loc Min        -0.80989
exploration/env_infos/initial/end_effector_loc Mean     -0.0037675
exploration/env_infos/initial/end_effector_loc Std       0.014852
exploration/env_infos/initial/end_effector_loc Max       0.0264357
exploration/env_infos/initial/end_effector_loc Min      -0.0218737
exploration/env_infos/end_effector_loc Mean             -0.0771056
exploration/env_infos/end_effector_loc Std               0.267999
exploration/env_infos/end_effector_loc Max               0.649401
exploration/env_infos/end_effector_loc Min              -0.80989
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0529741
exploration/env_infos/final/reward_dist Std              0.105947
exploration/env_infos/final/reward_dist Max              0.264868
exploration/env_infos/final/reward_dist Min              3.79614e-54
exploration/env_infos/initial/reward_dist Mean           0.0111505
exploration/env_infos/initial/reward_dist Std            0.0139411
exploration/env_infos/initial/reward_dist Max            0.0363077
exploration/env_infos/initial/reward_dist Min            1.66745e-05
exploration/env_infos/reward_dist Mean                   0.176692
exploration/env_infos/reward_dist Std                    0.274887
exploration/env_infos/reward_dist Max                    0.961826
exploration/env_infos/reward_dist Min                    3.79614e-54
evaluation/num steps total                           60000
evaluation/num paths total                            3000
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0980619
evaluation/Rewards Std                                   0.104729
evaluation/Rewards Max                                   0.126573
evaluation/Rewards Min                                  -0.608931
evaluation/Returns Mean                                 -1.96124
evaluation/Returns Std                                   1.65981
evaluation/Returns Max                                   0.419928
evaluation/Returns Min                                  -5.57881
evaluation/Actions Mean                                 -0.00482537
evaluation/Actions Std                                   0.0888061
evaluation/Actions Max                                   0.736816
evaluation/Actions Min                                  -0.656817
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.96124
evaluation/env_infos/final/reward_energy Mean           -0.0669434
evaluation/env_infos/final/reward_energy Std             0.0754139
evaluation/env_infos/final/reward_energy Max            -0.00424857
evaluation/env_infos/final/reward_energy Min            -0.306943
evaluation/env_infos/initial/reward_energy Mean         -0.240427
evaluation/env_infos/initial/reward_energy Std           0.223259
evaluation/env_infos/initial/reward_energy Max          -0.00131654
evaluation/env_infos/initial/reward_energy Min          -0.827579
evaluation/env_infos/reward_energy Mean                 -0.0806654
evaluation/env_infos/reward_energy Std                   0.0965024
evaluation/env_infos/reward_energy Max                  -0.00131654
evaluation/env_infos/reward_energy Min                  -0.827579
evaluation/env_infos/final/end_effector_loc Mean        -0.0410483
evaluation/env_infos/final/end_effector_loc Std          0.467019
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.000947831
evaluation/env_infos/initial/end_effector_loc Std        0.0115613
evaluation/env_infos/initial/end_effector_loc Max        0.0368408
evaluation/env_infos/initial/end_effector_loc Min       -0.0328408
evaluation/env_infos/end_effector_loc Mean              -0.0172815
evaluation/env_infos/end_effector_loc Std                0.283675
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0842669
evaluation/env_infos/final/reward_dist Std               0.226255
evaluation/env_infos/final/reward_dist Max               0.999575
evaluation/env_infos/final/reward_dist Min               1.53013e-120
evaluation/env_infos/initial/reward_dist Mean            0.00606863
evaluation/env_infos/initial/reward_dist Std             0.0104295
evaluation/env_infos/initial/reward_dist Max             0.0516407
evaluation/env_infos/initial/reward_dist Min             2.79766e-06
evaluation/env_infos/reward_dist Mean                    0.0942205
evaluation/env_infos/reward_dist Std                     0.198676
evaluation/env_infos/reward_dist Max                     0.999575
evaluation/env_infos/reward_dist Min                     1.53013e-120
time/data storing (s)                                   26.9059
time/evaluation sampling (s)                             0.655209
time/exploration sampling (s)                            0.0897671
time/logging (s)                                         0.0163678
time/saving (s)                                          0.558654
time/training (s)                                       36.4199
time/epoch (s)                                          64.6459
time/total (s)                                        3143.88
Epoch                                                   59
---------------------------------------------------  ----------------
2021-05-29 00:49:22.981597 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 60 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00163374
trainer/QF2 Loss                                         0.00247138
trainer/Policy Loss                                      3.04763
trainer/Q1 Predictions Mean                             -0.957578
trainer/Q1 Predictions Std                               0.834291
trainer/Q1 Predictions Max                               0.746648
trainer/Q1 Predictions Min                              -3.38721
trainer/Q2 Predictions Mean                             -0.972025
trainer/Q2 Predictions Std                               0.825649
trainer/Q2 Predictions Max                               0.700324
trainer/Q2 Predictions Min                              -3.32951
trainer/Q Targets Mean                                  -0.951601
trainer/Q Targets Std                                    0.818772
trainer/Q Targets Max                                    0.719312
trainer/Q Targets Min                                   -3.20151
trainer/Log Pis Mean                                     2.09067
trainer/Log Pis Std                                      1.51434
trainer/Log Pis Max                                      7.42927
trainer/Log Pis Min                                     -3.35835
trainer/Policy mu Mean                                  -0.0623196
trainer/Policy mu Std                                    0.514944
trainer/Policy mu Max                                    2.02564
trainer/Policy mu Min                                   -3.58076
trainer/Policy log std Mean                             -2.23877
trainer/Policy log std Std                               0.608278
trainer/Policy log std Max                              -0.120507
trainer/Policy log std Min                              -3.31123
trainer/Alpha                                            0.0210161
trainer/Alpha Loss                                       0.350288
exploration/num steps total                           7100
exploration/num paths total                            355
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.075786
exploration/Rewards Std                                  0.0728303
exploration/Rewards Max                                  0.0377591
exploration/Rewards Min                                 -0.260715
exploration/Returns Mean                                -1.51572
exploration/Returns Std                                  1.08417
exploration/Returns Max                                 -0.0439693
exploration/Returns Min                                 -2.71968
exploration/Actions Mean                                 0.0097584
exploration/Actions Std                                  0.0935519
exploration/Actions Max                                  0.34577
exploration/Actions Min                                 -0.185499
exploration/Num Paths                                    5
exploration/Average Returns                             -1.51572
exploration/env_infos/final/reward_energy Mean          -0.136867
exploration/env_infos/final/reward_energy Std            0.0898574
exploration/env_infos/final/reward_energy Max           -0.0470799
exploration/env_infos/final/reward_energy Min           -0.303891
exploration/env_infos/initial/reward_energy Mean        -0.203657
exploration/env_infos/initial/reward_energy Std          0.136644
exploration/env_infos/initial/reward_energy Max         -0.0551546
exploration/env_infos/initial/reward_energy Min         -0.392998
exploration/env_infos/reward_energy Mean                -0.109304
exploration/env_infos/reward_energy Std                  0.0758083
exploration/env_infos/reward_energy Max                 -0.00658298
exploration/env_infos/reward_energy Min                 -0.392998
exploration/env_infos/final/end_effector_loc Mean        0.149307
exploration/env_infos/final/end_effector_loc Std         0.382223
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.650021
exploration/env_infos/initial/end_effector_loc Mean      0.0034846
exploration/env_infos/initial/end_effector_loc Std       0.00793991
exploration/env_infos/initial/end_effector_loc Max       0.0172885
exploration/env_infos/initial/end_effector_loc Min      -0.00698388
exploration/env_infos/end_effector_loc Mean              0.0954474
exploration/env_infos/end_effector_loc Std               0.243902
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.650021
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0147803
exploration/env_infos/final/reward_dist Std              0.0295295
exploration/env_infos/final/reward_dist Max              0.0738394
exploration/env_infos/final/reward_dist Min              1.32954e-69
exploration/env_infos/initial/reward_dist Mean           0.00927721
exploration/env_infos/initial/reward_dist Std            0.00839302
exploration/env_infos/initial/reward_dist Max            0.0258323
exploration/env_infos/initial/reward_dist Min            0.00310748
exploration/env_infos/reward_dist Mean                   0.055358
exploration/env_infos/reward_dist Std                    0.0858312
exploration/env_infos/reward_dist Max                    0.3922
exploration/env_infos/reward_dist Min                    1.32954e-69
evaluation/num steps total                           61000
evaluation/num paths total                            3050
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.076997
evaluation/Rewards Std                                   0.119562
evaluation/Rewards Max                                   0.135391
evaluation/Rewards Min                                  -0.857783
evaluation/Returns Mean                                 -1.53994
evaluation/Returns Std                                   1.9908
evaluation/Returns Max                                   1.77673
evaluation/Returns Min                                  -9.82544
evaluation/Actions Mean                                 -0.00449451
evaluation/Actions Std                                   0.0941
evaluation/Actions Max                                   0.798538
evaluation/Actions Min                                  -0.853045
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.53994
evaluation/env_infos/final/reward_energy Mean           -0.0459109
evaluation/env_infos/final/reward_energy Std             0.0397628
evaluation/env_infos/final/reward_energy Max            -0.00133665
evaluation/env_infos/final/reward_energy Min            -0.190074
evaluation/env_infos/initial/reward_energy Mean         -0.237035
evaluation/env_infos/initial/reward_energy Std           0.241399
evaluation/env_infos/initial/reward_energy Max          -0.026897
evaluation/env_infos/initial/reward_energy Min          -1.16848
evaluation/env_infos/reward_energy Mean                 -0.0834716
evaluation/env_infos/reward_energy Std                   0.103839
evaluation/env_infos/reward_energy Max                  -0.000993661
evaluation/env_infos/reward_energy Min                  -1.16848
evaluation/env_infos/final/end_effector_loc Mean        -0.0598802
evaluation/env_infos/final/end_effector_loc Std          0.348671
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00128217
evaluation/env_infos/initial/end_effector_loc Std        0.0118924
evaluation/env_infos/initial/end_effector_loc Max        0.0399269
evaluation/env_infos/initial/end_effector_loc Min       -0.0426522
evaluation/env_infos/end_effector_loc Mean              -0.0355559
evaluation/env_infos/end_effector_loc Std                0.232211
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.103816
evaluation/env_infos/final/reward_dist Std               0.197902
evaluation/env_infos/final/reward_dist Max               0.719746
evaluation/env_infos/final/reward_dist Min               8.28179e-143
evaluation/env_infos/initial/reward_dist Mean            0.0107451
evaluation/env_infos/initial/reward_dist Std             0.0205674
evaluation/env_infos/initial/reward_dist Max             0.118442
evaluation/env_infos/initial/reward_dist Min             1.32286e-06
evaluation/env_infos/reward_dist Mean                    0.105625
evaluation/env_infos/reward_dist Std                     0.201513
evaluation/env_infos/reward_dist Max                     0.991066
evaluation/env_infos/reward_dist Min                     8.28179e-143
time/data storing (s)                                   27.5788
time/evaluation sampling (s)                             0.82055
time/exploration sampling (s)                            0.0886173
time/logging (s)                                         0.0147069
time/saving (s)                                          0.567935
time/training (s)                                       36.5267
time/epoch (s)                                          65.5973
time/total (s)                                        3210.22
Epoch                                                   60
---------------------------------------------------  ----------------
2021-05-29 00:50:30.807421 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 61 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00242064
trainer/QF2 Loss                                         0.00154022
trainer/Policy Loss                                      3.04834
trainer/Q1 Predictions Mean                             -0.990276
trainer/Q1 Predictions Std                               0.881513
trainer/Q1 Predictions Max                               0.773078
trainer/Q1 Predictions Min                              -3.48612
trainer/Q2 Predictions Mean                             -0.991811
trainer/Q2 Predictions Std                               0.879931
trainer/Q2 Predictions Max                               0.790976
trainer/Q2 Predictions Min                              -3.4484
trainer/Q Targets Mean                                  -0.991935
trainer/Q Targets Std                                    0.870912
trainer/Q Targets Max                                    0.757002
trainer/Q Targets Min                                   -3.39279
trainer/Log Pis Mean                                     2.06143
trainer/Log Pis Std                                      1.45295
trainer/Log Pis Max                                      6.92364
trainer/Log Pis Min                                     -2.84279
trainer/Policy mu Mean                                  -0.0101534
trainer/Policy mu Std                                    0.426546
trainer/Policy mu Max                                    2.53932
trainer/Policy mu Min                                   -2.95375
trainer/Policy log std Mean                             -2.29598
trainer/Policy log std Std                               0.655821
trainer/Policy log std Max                               0.671031
trainer/Policy log std Min                              -3.24885
trainer/Alpha                                            0.0208088
trainer/Alpha Loss                                       0.23776
exploration/num steps total                           7200
exploration/num paths total                            360
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.117373
exploration/Rewards Std                                  0.0996522
exploration/Rewards Max                                  0.0375853
exploration/Rewards Min                                 -0.439399
exploration/Returns Mean                                -2.34746
exploration/Returns Std                                  1.70123
exploration/Returns Max                                 -0.67365
exploration/Returns Min                                 -4.9469
exploration/Actions Mean                                 0.00938823
exploration/Actions Std                                  0.101619
exploration/Actions Max                                  0.205109
exploration/Actions Min                                 -0.791094
exploration/Num Paths                                    5
exploration/Average Returns                             -2.34746
exploration/env_infos/final/reward_energy Mean          -0.12821
exploration/env_infos/final/reward_energy Std            0.0582123
exploration/env_infos/final/reward_energy Max           -0.0474942
exploration/env_infos/final/reward_energy Min           -0.226702
exploration/env_infos/initial/reward_energy Mean        -0.249323
exploration/env_infos/initial/reward_energy Std          0.281649
exploration/env_infos/initial/reward_energy Max         -0.0100881
exploration/env_infos/initial/reward_energy Min         -0.802051
exploration/env_infos/reward_energy Mean                -0.115346
exploration/env_infos/reward_energy Std                  0.0867433
exploration/env_infos/reward_energy Max                 -0.000833012
exploration/env_infos/reward_energy Min                 -0.802051
exploration/env_infos/final/end_effector_loc Mean        0.0820886
exploration/env_infos/final/end_effector_loc Std         0.245505
exploration/env_infos/final/end_effector_loc Max         0.389556
exploration/env_infos/final/end_effector_loc Min        -0.372393
exploration/env_infos/initial/end_effector_loc Mean     -0.00311049
exploration/env_infos/initial/end_effector_loc Std       0.01293
exploration/env_infos/initial/end_effector_loc Max       0.00729423
exploration/env_infos/initial/end_effector_loc Min      -0.0395547
exploration/env_infos/end_effector_loc Mean              0.0179491
exploration/env_infos/end_effector_loc Std               0.16471
exploration/env_infos/end_effector_loc Max               0.389556
exploration/env_infos/end_effector_loc Min              -0.372393
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0444613
exploration/env_infos/final/reward_dist Std              0.0588593
exploration/env_infos/final/reward_dist Max              0.146566
exploration/env_infos/final/reward_dist Min              4.76746e-28
exploration/env_infos/initial/reward_dist Mean           0.000454353
exploration/env_infos/initial/reward_dist Std            0.000255713
exploration/env_infos/initial/reward_dist Max            0.000773812
exploration/env_infos/initial/reward_dist Min            9.73704e-05
exploration/env_infos/reward_dist Mean                   0.0692223
exploration/env_infos/reward_dist Std                    0.141522
exploration/env_infos/reward_dist Max                    0.634884
exploration/env_infos/reward_dist Min                    4.76746e-28
evaluation/num steps total                           62000
evaluation/num paths total                            3100
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0718181
evaluation/Rewards Std                                   0.0892877
evaluation/Rewards Max                                   0.143614
evaluation/Rewards Min                                  -0.453514
evaluation/Returns Mean                                 -1.43636
evaluation/Returns Std                                   1.48761
evaluation/Returns Max                                   1.07383
evaluation/Returns Min                                  -4.92872
evaluation/Actions Mean                                  0.00519684
evaluation/Actions Std                                   0.0947812
evaluation/Actions Max                                   0.821654
evaluation/Actions Min                                  -0.695396
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.43636
evaluation/env_infos/final/reward_energy Mean           -0.0530737
evaluation/env_infos/final/reward_energy Std             0.0867157
evaluation/env_infos/final/reward_energy Max            -0.00546745
evaluation/env_infos/final/reward_energy Min            -0.537583
evaluation/env_infos/initial/reward_energy Mean         -0.228424
evaluation/env_infos/initial/reward_energy Std           0.226992
evaluation/env_infos/initial/reward_energy Max          -0.00332766
evaluation/env_infos/initial/reward_energy Min          -1.07642
evaluation/env_infos/reward_energy Mean                 -0.0842788
evaluation/env_infos/reward_energy Std                   0.10449
evaluation/env_infos/reward_energy Max                  -0.00132674
evaluation/env_infos/reward_energy Min                  -1.07642
evaluation/env_infos/final/end_effector_loc Mean         0.0461933
evaluation/env_infos/final/end_effector_loc Std          0.379533
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00206693
evaluation/env_infos/initial/end_effector_loc Std        0.0111963
evaluation/env_infos/initial/end_effector_loc Max        0.0410827
evaluation/env_infos/initial/end_effector_loc Min       -0.0347698
evaluation/env_infos/end_effector_loc Mean               0.0254014
evaluation/env_infos/end_effector_loc Std                0.244621
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.113542
evaluation/env_infos/final/reward_dist Std               0.241683
evaluation/env_infos/final/reward_dist Max               0.798115
evaluation/env_infos/final/reward_dist Min               1.55835e-130
evaluation/env_infos/initial/reward_dist Mean            0.00614969
evaluation/env_infos/initial/reward_dist Std             0.0122207
evaluation/env_infos/initial/reward_dist Max             0.0593305
evaluation/env_infos/initial/reward_dist Min             1.57493e-06
evaluation/env_infos/reward_dist Mean                    0.121428
evaluation/env_infos/reward_dist Std                     0.225455
evaluation/env_infos/reward_dist Max                     0.99981
evaluation/env_infos/reward_dist Min                     1.55835e-130
time/data storing (s)                                   28.3287
time/evaluation sampling (s)                             0.650731
time/exploration sampling (s)                            0.0866243
time/logging (s)                                         0.0155099
time/saving (s)                                          0.593626
time/training (s)                                       37.4707
time/epoch (s)                                          67.1459
time/total (s)                                        3278.05
Epoch                                                   61
---------------------------------------------------  ----------------
2021-05-29 00:51:36.848654 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 62 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00106223
trainer/QF2 Loss                                         0.00156949
trainer/Policy Loss                                      2.84263
trainer/Q1 Predictions Mean                             -0.92545
trainer/Q1 Predictions Std                               0.837685
trainer/Q1 Predictions Max                               0.615032
trainer/Q1 Predictions Min                              -3.0249
trainer/Q2 Predictions Mean                             -0.911876
trainer/Q2 Predictions Std                               0.82849
trainer/Q2 Predictions Max                               0.582455
trainer/Q2 Predictions Min                              -2.98842
trainer/Q Targets Mean                                  -0.914302
trainer/Q Targets Std                                    0.838227
trainer/Q Targets Max                                    0.61987
trainer/Q Targets Min                                   -3.01593
trainer/Log Pis Mean                                     1.91238
trainer/Log Pis Std                                      1.36899
trainer/Log Pis Max                                      4.47646
trainer/Log Pis Min                                     -3.29585
trainer/Policy mu Mean                                  -0.00848327
trainer/Policy mu Std                                    0.242886
trainer/Policy mu Max                                    2.13578
trainer/Policy mu Min                                   -2.38882
trainer/Policy log std Mean                             -2.36494
trainer/Policy log std Std                               0.524505
trainer/Policy log std Max                               0.201899
trainer/Policy log std Min                              -3.23365
trainer/Alpha                                            0.0220238
trainer/Alpha Loss                                      -0.334152
exploration/num steps total                           7300
exploration/num paths total                            365
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0653535
exploration/Rewards Std                                  0.0889768
exploration/Rewards Max                                  0.150058
exploration/Rewards Min                                 -0.289253
exploration/Returns Mean                                -1.30707
exploration/Returns Std                                  1.38258
exploration/Returns Max                                  0.0931817
exploration/Returns Min                                 -3.92809
exploration/Actions Mean                                 0.0109536
exploration/Actions Std                                  0.180413
exploration/Actions Max                                  0.642013
exploration/Actions Min                                 -0.626536
exploration/Num Paths                                    5
exploration/Average Returns                             -1.30707
exploration/env_infos/final/reward_energy Mean          -0.19203
exploration/env_infos/final/reward_energy Std            0.125479
exploration/env_infos/final/reward_energy Max           -0.0490712
exploration/env_infos/final/reward_energy Min           -0.423633
exploration/env_infos/initial/reward_energy Mean        -0.298147
exploration/env_infos/initial/reward_energy Std          0.0930412
exploration/env_infos/initial/reward_energy Max         -0.20576
exploration/env_infos/initial/reward_energy Min         -0.477064
exploration/env_infos/reward_energy Mean                -0.209279
exploration/env_infos/reward_energy Std                  0.146765
exploration/env_infos/reward_energy Max                 -0.0131945
exploration/env_infos/reward_energy Min                 -0.748729
exploration/env_infos/final/end_effector_loc Mean        0.0239717
exploration/env_infos/final/end_effector_loc Std         0.219686
exploration/env_infos/final/end_effector_loc Max         0.377562
exploration/env_infos/final/end_effector_loc Min        -0.520304
exploration/env_infos/initial/end_effector_loc Mean     -0.00196421
exploration/env_infos/initial/end_effector_loc Std       0.0108663
exploration/env_infos/initial/end_effector_loc Max       0.0186125
exploration/env_infos/initial/end_effector_loc Min      -0.0149181
exploration/env_infos/end_effector_loc Mean             -0.0197643
exploration/env_infos/end_effector_loc Std               0.15664
exploration/env_infos/end_effector_loc Max               0.377562
exploration/env_infos/end_effector_loc Min              -0.520304
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0168233
exploration/env_infos/final/reward_dist Std              0.0214393
exploration/env_infos/final/reward_dist Max              0.0544773
exploration/env_infos/final/reward_dist Min              5.82755e-08
exploration/env_infos/initial/reward_dist Mean           0.0105866
exploration/env_infos/initial/reward_dist Std            0.0188973
exploration/env_infos/initial/reward_dist Max            0.048293
exploration/env_infos/initial/reward_dist Min            0.000249474
exploration/env_infos/reward_dist Mean                   0.138025
exploration/env_infos/reward_dist Std                    0.208813
exploration/env_infos/reward_dist Max                    0.968203
exploration/env_infos/reward_dist Min                    5.82755e-08
evaluation/num steps total                           63000
evaluation/num paths total                            3150
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0772243
evaluation/Rewards Std                                   0.102161
evaluation/Rewards Max                                   0.153039
evaluation/Rewards Min                                  -0.611406
evaluation/Returns Mean                                 -1.54449
evaluation/Returns Std                                   1.61852
evaluation/Returns Max                                   1.90477
evaluation/Returns Min                                  -5.84243
evaluation/Actions Mean                                  0.00253545
evaluation/Actions Std                                   0.0781384
evaluation/Actions Max                                   0.606361
evaluation/Actions Min                                  -0.436444
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.54449
evaluation/env_infos/final/reward_energy Mean           -0.0604143
evaluation/env_infos/final/reward_energy Std             0.0939653
evaluation/env_infos/final/reward_energy Max            -0.00375265
evaluation/env_infos/final/reward_energy Min            -0.600476
evaluation/env_infos/initial/reward_energy Mean         -0.17018
evaluation/env_infos/initial/reward_energy Std           0.155775
evaluation/env_infos/initial/reward_energy Max          -0.008942
evaluation/env_infos/initial/reward_energy Min          -0.641749
evaluation/env_infos/reward_energy Mean                 -0.0692808
evaluation/env_infos/reward_energy Std                   0.086164
evaluation/env_infos/reward_energy Max                  -0.000919324
evaluation/env_infos/reward_energy Min                  -0.641749
evaluation/env_infos/final/end_effector_loc Mean         0.0129614
evaluation/env_infos/final/end_effector_loc Std          0.397772
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.0012074
evaluation/env_infos/initial/end_effector_loc Std        0.00806697
evaluation/env_infos/initial/end_effector_loc Max        0.0303181
evaluation/env_infos/initial/end_effector_loc Min       -0.0217289
evaluation/env_infos/end_effector_loc Mean               0.0114312
evaluation/env_infos/end_effector_loc Std                0.24603
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0696244
evaluation/env_infos/final/reward_dist Std               0.145857
evaluation/env_infos/final/reward_dist Max               0.649286
evaluation/env_infos/final/reward_dist Min               3.6971e-123
evaluation/env_infos/initial/reward_dist Mean            0.00421903
evaluation/env_infos/initial/reward_dist Std             0.00742734
evaluation/env_infos/initial/reward_dist Max             0.0299186
evaluation/env_infos/initial/reward_dist Min             1.49174e-06
evaluation/env_infos/reward_dist Mean                    0.134264
evaluation/env_infos/reward_dist Std                     0.230796
evaluation/env_infos/reward_dist Max                     0.994162
evaluation/env_infos/reward_dist Min                     3.6971e-123
time/data storing (s)                                   27.7618
time/evaluation sampling (s)                             0.646038
time/exploration sampling (s)                            0.0884534
time/logging (s)                                         0.0140729
time/saving (s)                                          0.582351
time/training (s)                                       36.2502
time/epoch (s)                                          65.3429
time/total (s)                                        3344.08
Epoch                                                   62
---------------------------------------------------  ---------------
2021-05-29 00:52:43.514778 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 63 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00171638
trainer/QF2 Loss                                         0.00179241
trainer/Policy Loss                                      2.86293
trainer/Q1 Predictions Mean                             -0.901847
trainer/Q1 Predictions Std                               0.742936
trainer/Q1 Predictions Max                               0.675789
trainer/Q1 Predictions Min                              -2.85258
trainer/Q2 Predictions Mean                             -0.895575
trainer/Q2 Predictions Std                               0.741174
trainer/Q2 Predictions Max                               0.703051
trainer/Q2 Predictions Min                              -2.89836
trainer/Q Targets Mean                                  -0.896162
trainer/Q Targets Std                                    0.747399
trainer/Q Targets Max                                    0.6934
trainer/Q Targets Min                                   -2.90051
trainer/Log Pis Mean                                     1.98502
trainer/Log Pis Std                                      1.47188
trainer/Log Pis Max                                      4.82444
trainer/Log Pis Min                                     -4.3501
trainer/Policy mu Mean                                   0.0233792
trainer/Policy mu Std                                    0.364247
trainer/Policy mu Max                                    1.81956
trainer/Policy mu Min                                   -2.27364
trainer/Policy log std Mean                             -2.32139
trainer/Policy log std Std                               0.679707
trainer/Policy log std Max                              -0.36602
trainer/Policy log std Min                              -3.43484
trainer/Alpha                                            0.0194683
trainer/Alpha Loss                                      -0.0590025
exploration/num steps total                           7400
exploration/num paths total                            370
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.107328
exploration/Rewards Std                                  0.0763105
exploration/Rewards Max                                  0.0463133
exploration/Rewards Min                                 -0.384149
exploration/Returns Mean                                -2.14656
exploration/Returns Std                                  1.0085
exploration/Returns Max                                 -0.957816
exploration/Returns Min                                 -3.8391
exploration/Actions Mean                                 0.0182437
exploration/Actions Std                                  0.100186
exploration/Actions Max                                  0.473462
exploration/Actions Min                                 -0.298068
exploration/Num Paths                                    5
exploration/Average Returns                             -2.14656
exploration/env_infos/final/reward_energy Mean          -0.143575
exploration/env_infos/final/reward_energy Std            0.0541104
exploration/env_infos/final/reward_energy Max           -0.0813354
exploration/env_infos/final/reward_energy Min           -0.225304
exploration/env_infos/initial/reward_energy Mean        -0.175342
exploration/env_infos/initial/reward_energy Std          0.206303
exploration/env_infos/initial/reward_energy Max         -0.0679082
exploration/env_infos/initial/reward_energy Min         -0.587893
exploration/env_infos/reward_energy Mean                -0.110901
exploration/env_infos/reward_energy Std                  0.0918758
exploration/env_infos/reward_energy Max                 -0.00862439
exploration/env_infos/reward_energy Min                 -0.587893
exploration/env_infos/final/end_effector_loc Mean        0.281705
exploration/env_infos/final/end_effector_loc Std         0.372501
exploration/env_infos/final/end_effector_loc Max         0.898362
exploration/env_infos/final/end_effector_loc Min        -0.245886
exploration/env_infos/initial/end_effector_loc Mean      0.00384995
exploration/env_infos/initial/end_effector_loc Std       0.00876413
exploration/env_infos/initial/end_effector_loc Max       0.0236731
exploration/env_infos/initial/end_effector_loc Min      -0.00349463
exploration/env_infos/end_effector_loc Mean              0.133426
exploration/env_infos/end_effector_loc Std               0.224858
exploration/env_infos/end_effector_loc Max               0.898362
exploration/env_infos/end_effector_loc Min              -0.245886
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.170171
exploration/env_infos/final/reward_dist Std              0.340308
exploration/env_infos/final/reward_dist Max              0.850788
exploration/env_infos/final/reward_dist Min              1.76352e-53
exploration/env_infos/initial/reward_dist Mean           0.0154914
exploration/env_infos/initial/reward_dist Std            0.030226
exploration/env_infos/initial/reward_dist Max            0.0759364
exploration/env_infos/initial/reward_dist Min            1.19675e-06
exploration/env_infos/reward_dist Mean                   0.0669417
exploration/env_infos/reward_dist Std                    0.183452
exploration/env_infos/reward_dist Max                    0.960961
exploration/env_infos/reward_dist Min                    1.76352e-53
evaluation/num steps total                           64000
evaluation/num paths total                            3200
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0849046
evaluation/Rewards Std                                   0.0879435
evaluation/Rewards Max                                   0.118341
evaluation/Rewards Min                                  -0.495926
evaluation/Returns Mean                                 -1.69809
evaluation/Returns Std                                   1.41892
evaluation/Returns Max                                   1.44995
evaluation/Returns Min                                  -5.08857
evaluation/Actions Mean                                  0.0052961
evaluation/Actions Std                                   0.0891783
evaluation/Actions Max                                   0.601413
evaluation/Actions Min                                  -0.809539
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.69809
evaluation/env_infos/final/reward_energy Mean           -0.0667749
evaluation/env_infos/final/reward_energy Std             0.0800974
evaluation/env_infos/final/reward_energy Max            -0.00452089
evaluation/env_infos/final/reward_energy Min            -0.498327
evaluation/env_infos/initial/reward_energy Mean         -0.188407
evaluation/env_infos/initial/reward_energy Std           0.158924
evaluation/env_infos/initial/reward_energy Max          -0.00832616
evaluation/env_infos/initial/reward_energy Min          -0.732624
evaluation/env_infos/reward_energy Mean                 -0.0784658
evaluation/env_infos/reward_energy Std                   0.099019
evaluation/env_infos/reward_energy Max                  -0.00165277
evaluation/env_infos/reward_energy Min                  -0.859113
evaluation/env_infos/final/end_effector_loc Mean         0.0566222
evaluation/env_infos/final/end_effector_loc Std          0.362204
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00156039
evaluation/env_infos/initial/end_effector_loc Std        0.00857367
evaluation/env_infos/initial/end_effector_loc Max        0.0300706
evaluation/env_infos/initial/end_effector_loc Min       -0.020919
evaluation/env_infos/end_effector_loc Mean               0.0263736
evaluation/env_infos/end_effector_loc Std                0.23683
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.108435
evaluation/env_infos/final/reward_dist Std               0.222292
evaluation/env_infos/final/reward_dist Max               0.949812
evaluation/env_infos/final/reward_dist Min               2.94622e-126
evaluation/env_infos/initial/reward_dist Mean            0.00379905
evaluation/env_infos/initial/reward_dist Std             0.00575935
evaluation/env_infos/initial/reward_dist Max             0.0264847
evaluation/env_infos/initial/reward_dist Min             1.00064e-06
evaluation/env_infos/reward_dist Mean                    0.104169
evaluation/env_infos/reward_dist Std                     0.204539
evaluation/env_infos/reward_dist Max                     0.96152
evaluation/env_infos/reward_dist Min                     2.94622e-126
time/data storing (s)                                   28.1434
time/evaluation sampling (s)                             0.646618
time/exploration sampling (s)                            0.0881327
time/logging (s)                                         0.0155508
time/saving (s)                                          0.582847
time/training (s)                                       36.4958
time/epoch (s)                                          65.9723
time/total (s)                                        3410.75
Epoch                                                   63
---------------------------------------------------  ----------------
2021-05-29 00:53:50.678049 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 64 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00297433
trainer/QF2 Loss                                         0.00173894
trainer/Policy Loss                                      2.90383
trainer/Q1 Predictions Mean                             -0.944514
trainer/Q1 Predictions Std                               0.788196
trainer/Q1 Predictions Max                               0.930403
trainer/Q1 Predictions Min                              -3.38144
trainer/Q2 Predictions Mean                             -0.952325
trainer/Q2 Predictions Std                               0.788901
trainer/Q2 Predictions Max                               0.877085
trainer/Q2 Predictions Min                              -3.34014
trainer/Q Targets Mean                                  -0.951119
trainer/Q Targets Std                                    0.792548
trainer/Q Targets Max                                    0.842982
trainer/Q Targets Min                                   -3.36376
trainer/Log Pis Mean                                     1.95164
trainer/Log Pis Std                                      1.36654
trainer/Log Pis Max                                      4.62173
trainer/Log Pis Min                                     -3.20708
trainer/Policy mu Mean                                   0.00288656
trainer/Policy mu Std                                    0.275544
trainer/Policy mu Max                                    1.03108
trainer/Policy mu Min                                   -2.48331
trainer/Policy log std Mean                             -2.31062
trainer/Policy log std Std                               0.577604
trainer/Policy log std Max                               0.275428
trainer/Policy log std Min                              -3.46719
trainer/Alpha                                            0.0206802
trainer/Alpha Loss                                      -0.187512
exploration/num steps total                           7500
exploration/num paths total                            375
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.14274
exploration/Rewards Std                                  0.0564428
exploration/Rewards Max                                 -0.0443124
exploration/Rewards Min                                 -0.367144
exploration/Returns Mean                                -2.8548
exploration/Returns Std                                  0.470687
exploration/Returns Max                                 -2.09625
exploration/Returns Min                                 -3.57348
exploration/Actions Mean                                -0.00399754
exploration/Actions Std                                  0.190134
exploration/Actions Max                                  0.825319
exploration/Actions Min                                 -0.904963
exploration/Num Paths                                    5
exploration/Average Returns                             -2.8548
exploration/env_infos/final/reward_energy Mean          -0.114388
exploration/env_infos/final/reward_energy Std            0.0498054
exploration/env_infos/final/reward_energy Max           -0.019568
exploration/env_infos/final/reward_energy Min           -0.162657
exploration/env_infos/initial/reward_energy Mean        -0.419946
exploration/env_infos/initial/reward_energy Std          0.413712
exploration/env_infos/initial/reward_energy Max         -0.105074
exploration/env_infos/initial/reward_energy Min         -1.22479
exploration/env_infos/reward_energy Mean                -0.20737
exploration/env_infos/reward_energy Std                  0.171265
exploration/env_infos/reward_energy Max                 -0.019568
exploration/env_infos/reward_energy Min                 -1.22479
exploration/env_infos/final/end_effector_loc Mean       -0.0241118
exploration/env_infos/final/end_effector_loc Std         0.290102
exploration/env_infos/final/end_effector_loc Max         0.397682
exploration/env_infos/final/end_effector_loc Min        -0.651057
exploration/env_infos/initial/end_effector_loc Mean     -0.000274876
exploration/env_infos/initial/end_effector_loc Std       0.0208402
exploration/env_infos/initial/end_effector_loc Max       0.0412659
exploration/env_infos/initial/end_effector_loc Min      -0.0452481
exploration/env_infos/end_effector_loc Mean             -0.00628742
exploration/env_infos/end_effector_loc Std               0.187667
exploration/env_infos/end_effector_loc Max               0.397682
exploration/env_infos/end_effector_loc Min              -0.651057
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.16762
exploration/env_infos/final/reward_dist Std              0.334915
exploration/env_infos/final/reward_dist Max              0.837449
exploration/env_infos/final/reward_dist Min              1.003e-24
exploration/env_infos/initial/reward_dist Mean           0.00176965
exploration/env_infos/initial/reward_dist Std            0.00325468
exploration/env_infos/initial/reward_dist Max            0.00827166
exploration/env_infos/initial/reward_dist Min            2.57482e-06
exploration/env_infos/reward_dist Mean                   0.0935397
exploration/env_infos/reward_dist Std                    0.230388
exploration/env_infos/reward_dist Max                    0.929219
exploration/env_infos/reward_dist Min                    1.003e-24
evaluation/num steps total                           65000
evaluation/num paths total                            3250
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0946013
evaluation/Rewards Std                                   0.106244
evaluation/Rewards Max                                   0.141437
evaluation/Rewards Min                                  -0.829266
evaluation/Returns Mean                                 -1.89203
evaluation/Returns Std                                   1.79821
evaluation/Returns Max                                   0.912422
evaluation/Returns Min                                 -10.0404
evaluation/Actions Mean                                  0.0119503
evaluation/Actions Std                                   0.100892
evaluation/Actions Max                                   0.558855
evaluation/Actions Min                                  -0.658238
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.89203
evaluation/env_infos/final/reward_energy Mean           -0.0972883
evaluation/env_infos/final/reward_energy Std             0.137672
evaluation/env_infos/final/reward_energy Max            -0.00465929
evaluation/env_infos/final/reward_energy Min            -0.654974
evaluation/env_infos/initial/reward_energy Mean         -0.197917
evaluation/env_infos/initial/reward_energy Std           0.159005
evaluation/env_infos/initial/reward_energy Max          -0.0183317
evaluation/env_infos/initial/reward_energy Min          -0.681563
evaluation/env_infos/reward_energy Mean                 -0.0913614
evaluation/env_infos/reward_energy Std                   0.110893
evaluation/env_infos/reward_energy Max                  -0.000839244
evaluation/env_infos/reward_energy Min                  -0.777485
evaluation/env_infos/final/end_effector_loc Mean         0.0987387
evaluation/env_infos/final/end_effector_loc Std          0.380669
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00176643
evaluation/env_infos/initial/end_effector_loc Std        0.0088004
evaluation/env_infos/initial/end_effector_loc Max        0.0235072
evaluation/env_infos/initial/end_effector_loc Min       -0.0246725
evaluation/env_infos/end_effector_loc Mean               0.0403096
evaluation/env_infos/end_effector_loc Std                0.265298
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0683959
evaluation/env_infos/final/reward_dist Std               0.214504
evaluation/env_infos/final/reward_dist Max               0.965077
evaluation/env_infos/final/reward_dist Min               1.3469e-153
evaluation/env_infos/initial/reward_dist Mean            0.0041713
evaluation/env_infos/initial/reward_dist Std             0.00670296
evaluation/env_infos/initial/reward_dist Max             0.0285746
evaluation/env_infos/initial/reward_dist Min             3.51657e-07
evaluation/env_infos/reward_dist Mean                    0.0876404
evaluation/env_infos/reward_dist Std                     0.184611
evaluation/env_infos/reward_dist Max                     0.965077
evaluation/env_infos/reward_dist Min                     1.3469e-153
time/data storing (s)                                   28.931
time/evaluation sampling (s)                             0.634343
time/exploration sampling (s)                            0.091331
time/logging (s)                                         0.0171842
time/saving (s)                                          0.603171
time/training (s)                                       36.1544
time/epoch (s)                                          66.4314
time/total (s)                                        3477.91
Epoch                                                   64
---------------------------------------------------  ---------------
2021-05-29 00:54:58.421426 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 65 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00253785
trainer/QF2 Loss                                         0.00203563
trainer/Policy Loss                                      2.76973
trainer/Q1 Predictions Mean                             -0.930739
trainer/Q1 Predictions Std                               0.80151
trainer/Q1 Predictions Max                               0.91081
trainer/Q1 Predictions Min                              -3.00375
trainer/Q2 Predictions Mean                             -0.922233
trainer/Q2 Predictions Std                               0.804111
trainer/Q2 Predictions Max                               0.939425
trainer/Q2 Predictions Min                              -3.03884
trainer/Q Targets Mean                                  -0.922152
trainer/Q Targets Std                                    0.807926
trainer/Q Targets Max                                    0.947596
trainer/Q Targets Min                                   -3.05668
trainer/Log Pis Mean                                     1.83559
trainer/Log Pis Std                                      1.47863
trainer/Log Pis Max                                     10.8199
trainer/Log Pis Min                                     -4.24613
trainer/Policy mu Mean                                   0.0207662
trainer/Policy mu Std                                    0.433288
trainer/Policy mu Max                                    3.05478
trainer/Policy mu Min                                   -3.6766
trainer/Policy log std Mean                             -2.21285
trainer/Policy log std Std                               0.573545
trainer/Policy log std Max                               1.33424
trainer/Policy log std Min                              -3.17755
trainer/Alpha                                            0.0194504
trainer/Alpha Loss                                      -0.647512
exploration/num steps total                           7600
exploration/num paths total                            380
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.091241
exploration/Rewards Std                                  0.0753938
exploration/Rewards Max                                  0.0731691
exploration/Rewards Min                                 -0.28386
exploration/Returns Mean                                -1.82482
exploration/Returns Std                                  1.22059
exploration/Returns Max                                 -0.170021
exploration/Returns Min                                 -3.59599
exploration/Actions Mean                                 0.0266153
exploration/Actions Std                                  0.167548
exploration/Actions Max                                  0.580503
exploration/Actions Min                                 -0.675482
exploration/Num Paths                                    5
exploration/Average Returns                             -1.82482
exploration/env_infos/final/reward_energy Mean          -0.331257
exploration/env_infos/final/reward_energy Std            0.261439
exploration/env_infos/final/reward_energy Max           -0.0933278
exploration/env_infos/final/reward_energy Min           -0.705541
exploration/env_infos/initial/reward_energy Mean        -0.275781
exploration/env_infos/initial/reward_energy Std          0.180025
exploration/env_infos/initial/reward_energy Max         -0.0687667
exploration/env_infos/initial/reward_energy Min         -0.517227
exploration/env_infos/reward_energy Mean                -0.186323
exploration/env_infos/reward_energy Std                  0.151147
exploration/env_infos/reward_energy Max                 -0.0121797
exploration/env_infos/reward_energy Min                 -0.705541
exploration/env_infos/final/end_effector_loc Mean        0.255909
exploration/env_infos/final/end_effector_loc Std         0.411574
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.162739
exploration/env_infos/initial/end_effector_loc Mean      0.00411716
exploration/env_infos/initial/end_effector_loc Std       0.0108917
exploration/env_infos/initial/end_effector_loc Max       0.0215659
exploration/env_infos/initial/end_effector_loc Min      -0.0142731
exploration/env_infos/end_effector_loc Mean              0.134806
exploration/env_infos/end_effector_loc Std               0.314741
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.279818
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0797745
exploration/env_infos/final/reward_dist Std              0.143043
exploration/env_infos/final/reward_dist Max              0.364638
exploration/env_infos/final/reward_dist Min              4.13178e-85
exploration/env_infos/initial/reward_dist Mean           0.00226021
exploration/env_infos/initial/reward_dist Std            0.00197754
exploration/env_infos/initial/reward_dist Max            0.00532886
exploration/env_infos/initial/reward_dist Min            4.65086e-05
exploration/env_infos/reward_dist Mean                   0.0999819
exploration/env_infos/reward_dist Std                    0.210034
exploration/env_infos/reward_dist Max                    0.971556
exploration/env_infos/reward_dist Min                    4.13178e-85
evaluation/num steps total                           66000
evaluation/num paths total                            3300
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0855481
evaluation/Rewards Std                                   0.0833796
evaluation/Rewards Max                                   0.085907
evaluation/Rewards Min                                  -0.627553
evaluation/Returns Mean                                 -1.71096
evaluation/Returns Std                                   1.20761
evaluation/Returns Max                                   0.918395
evaluation/Returns Min                                  -5.20013
evaluation/Actions Mean                                  0.0139219
evaluation/Actions Std                                   0.118049
evaluation/Actions Max                                   0.823151
evaluation/Actions Min                                  -0.981139
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.71096
evaluation/env_infos/final/reward_energy Mean           -0.0679004
evaluation/env_infos/final/reward_energy Std             0.0351784
evaluation/env_infos/final/reward_energy Max            -0.00626979
evaluation/env_infos/final/reward_energy Min            -0.204356
evaluation/env_infos/initial/reward_energy Mean         -0.296737
evaluation/env_infos/initial/reward_energy Std           0.246721
evaluation/env_infos/initial/reward_energy Max          -0.0275425
evaluation/env_infos/initial/reward_energy Min          -0.950205
evaluation/env_infos/reward_energy Mean                 -0.108139
evaluation/env_infos/reward_energy Std                   0.128704
evaluation/env_infos/reward_energy Max                  -0.00161364
evaluation/env_infos/reward_energy Min                  -1.17909
evaluation/env_infos/final/end_effector_loc Mean         0.105712
evaluation/env_infos/final/end_effector_loc Std          0.341741
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       4.60832e-05
evaluation/env_infos/initial/end_effector_loc Std        0.0136438
evaluation/env_infos/initial/end_effector_loc Max        0.0375598
evaluation/env_infos/initial/end_effector_loc Min       -0.039695
evaluation/env_infos/end_effector_loc Mean               0.0305769
evaluation/env_infos/end_effector_loc Std                0.23113
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.045504
evaluation/env_infos/final/reward_dist Std               0.123191
evaluation/env_infos/final/reward_dist Max               0.545998
evaluation/env_infos/final/reward_dist Min               9.49832e-121
evaluation/env_infos/initial/reward_dist Mean            0.00968537
evaluation/env_infos/initial/reward_dist Std             0.0219118
evaluation/env_infos/initial/reward_dist Max             0.113933
evaluation/env_infos/initial/reward_dist Min             2.90746e-07
evaluation/env_infos/reward_dist Mean                    0.0866917
evaluation/env_infos/reward_dist Std                     0.192004
evaluation/env_infos/reward_dist Max                     0.995832
evaluation/env_infos/reward_dist Min                     9.49832e-121
time/data storing (s)                                   29.0328
time/evaluation sampling (s)                             0.769775
time/exploration sampling (s)                            0.0889833
time/logging (s)                                         0.015375
time/saving (s)                                          0.605209
time/training (s)                                       36.4285
time/epoch (s)                                          66.9406
time/total (s)                                        3545.65
Epoch                                                   65
---------------------------------------------------  ----------------
2021-05-29 00:56:06.125274 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 66 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00104731
trainer/QF2 Loss                                         0.00153328
trainer/Policy Loss                                      2.99951
trainer/Q1 Predictions Mean                             -0.93742
trainer/Q1 Predictions Std                               0.787209
trainer/Q1 Predictions Max                               0.829105
trainer/Q1 Predictions Min                              -3.03273
trainer/Q2 Predictions Mean                             -0.928295
trainer/Q2 Predictions Std                               0.780965
trainer/Q2 Predictions Max                               0.829584
trainer/Q2 Predictions Min                              -2.97625
trainer/Q Targets Mean                                  -0.942765
trainer/Q Targets Std                                    0.787203
trainer/Q Targets Max                                    0.817558
trainer/Q Targets Min                                   -3.00882
trainer/Log Pis Mean                                     2.07635
trainer/Log Pis Std                                      1.33742
trainer/Log Pis Max                                      4.56186
trainer/Log Pis Min                                     -6.65261
trainer/Policy mu Mean                                  -0.00418602
trainer/Policy mu Std                                    0.362012
trainer/Policy mu Max                                    2.01083
trainer/Policy mu Min                                   -2.95921
trainer/Policy log std Mean                             -2.34223
trainer/Policy log std Std                               0.55733
trainer/Policy log std Max                              -0.310518
trainer/Policy log std Min                              -3.39357
trainer/Alpha                                            0.0177008
trainer/Alpha Loss                                       0.308114
exploration/num steps total                           7700
exploration/num paths total                            385
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.117427
exploration/Rewards Std                                  0.134923
exploration/Rewards Max                                  0.113608
exploration/Rewards Min                                 -0.473321
exploration/Returns Mean                                -2.34853
exploration/Returns Std                                  2.20897
exploration/Returns Max                                  0.213883
exploration/Returns Min                                 -5.47153
exploration/Actions Mean                                 0.00420547
exploration/Actions Std                                  0.160341
exploration/Actions Max                                  0.626787
exploration/Actions Min                                 -0.407853
exploration/Num Paths                                    5
exploration/Average Returns                             -2.34853
exploration/env_infos/final/reward_energy Mean          -0.123319
exploration/env_infos/final/reward_energy Std            0.0731241
exploration/env_infos/final/reward_energy Max           -0.0250509
exploration/env_infos/final/reward_energy Min           -0.25123
exploration/env_infos/initial/reward_energy Mean        -0.30906
exploration/env_infos/initial/reward_energy Std          0.0858502
exploration/env_infos/initial/reward_energy Max         -0.187197
exploration/env_infos/initial/reward_energy Min         -0.439518
exploration/env_infos/reward_energy Mean                -0.191571
exploration/env_infos/reward_energy Std                  0.121467
exploration/env_infos/reward_energy Max                 -0.0174245
exploration/env_infos/reward_energy Min                 -0.656029
exploration/env_infos/final/end_effector_loc Mean        0.116926
exploration/env_infos/final/end_effector_loc Std         0.363555
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.388107
exploration/env_infos/initial/end_effector_loc Mean      0.00118316
exploration/env_infos/initial/end_effector_loc Std       0.0112788
exploration/env_infos/initial/end_effector_loc Max       0.0206559
exploration/env_infos/initial/end_effector_loc Min      -0.0130171
exploration/env_infos/end_effector_loc Mean              0.0708816
exploration/env_infos/end_effector_loc Std               0.267339
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.407756
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.144562
exploration/env_infos/final/reward_dist Std              0.286566
exploration/env_infos/final/reward_dist Max              0.71768
exploration/env_infos/final/reward_dist Min              1.20794e-49
exploration/env_infos/initial/reward_dist Mean           0.00124947
exploration/env_infos/initial/reward_dist Std            0.00223904
exploration/env_infos/initial/reward_dist Max            0.0057209
exploration/env_infos/initial/reward_dist Min            1.55682e-06
exploration/env_infos/reward_dist Mean                   0.17564
exploration/env_infos/reward_dist Std                    0.245991
exploration/env_infos/reward_dist Max                    0.756449
exploration/env_infos/reward_dist Min                    4.47189e-52
evaluation/num steps total                           67000
evaluation/num paths total                            3350
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0600958
evaluation/Rewards Std                                   0.0827346
evaluation/Rewards Max                                   0.174465
evaluation/Rewards Min                                  -0.444116
evaluation/Returns Mean                                 -1.20192
evaluation/Returns Std                                   1.3689
evaluation/Returns Max                                   2.50697
evaluation/Returns Min                                  -4.33461
evaluation/Actions Mean                                  0.0100995
evaluation/Actions Std                                   0.0739642
evaluation/Actions Max                                   0.70687
evaluation/Actions Min                                  -0.833106
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.20192
evaluation/env_infos/final/reward_energy Mean           -0.0714199
evaluation/env_infos/final/reward_energy Std             0.0578969
evaluation/env_infos/final/reward_energy Max            -0.0171543
evaluation/env_infos/final/reward_energy Min            -0.360035
evaluation/env_infos/initial/reward_energy Mean         -0.186476
evaluation/env_infos/initial/reward_energy Std           0.229298
evaluation/env_infos/initial/reward_energy Max          -0.00385017
evaluation/env_infos/initial/reward_energy Min          -1.09258
evaluation/env_infos/reward_energy Mean                 -0.0681845
evaluation/env_infos/reward_energy Std                   0.0805994
evaluation/env_infos/reward_energy Max                  -0.00228373
evaluation/env_infos/reward_energy Min                  -1.09258
evaluation/env_infos/final/end_effector_loc Mean         0.0497845
evaluation/env_infos/final/end_effector_loc Std          0.295676
evaluation/env_infos/final/end_effector_loc Max          0.727822
evaluation/env_infos/final/end_effector_loc Min         -0.80294
evaluation/env_infos/initial/end_effector_loc Mean      -4.10895e-06
evaluation/env_infos/initial/end_effector_loc Std        0.0104493
evaluation/env_infos/initial/end_effector_loc Max        0.0353435
evaluation/env_infos/initial/end_effector_loc Min       -0.0416553
evaluation/env_infos/end_effector_loc Mean               0.0115172
evaluation/env_infos/end_effector_loc Std                0.176517
evaluation/env_infos/end_effector_loc Max                0.727822
evaluation/env_infos/end_effector_loc Min               -0.80294
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0955987
evaluation/env_infos/final/reward_dist Std               0.178548
evaluation/env_infos/final/reward_dist Max               0.809654
evaluation/env_infos/final/reward_dist Min               1.09797e-57
evaluation/env_infos/initial/reward_dist Mean            0.00507274
evaluation/env_infos/initial/reward_dist Std             0.0124602
evaluation/env_infos/initial/reward_dist Max             0.0762457
evaluation/env_infos/initial/reward_dist Min             1.31696e-06
evaluation/env_infos/reward_dist Mean                    0.14725
evaluation/env_infos/reward_dist Std                     0.258784
evaluation/env_infos/reward_dist Max                     0.999425
evaluation/env_infos/reward_dist Min                     1.09797e-57
time/data storing (s)                                   29.3226
time/evaluation sampling (s)                             0.642151
time/exploration sampling (s)                            0.0897611
time/logging (s)                                         0.0177746
time/saving (s)                                          0.653217
time/training (s)                                       36.2338
time/epoch (s)                                          66.9593
time/total (s)                                        3613.35
Epoch                                                   66
---------------------------------------------------  ---------------
2021-05-29 00:57:14.069396 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 67 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00154841
trainer/QF2 Loss                                         0.0015516
trainer/Policy Loss                                      2.81427
trainer/Q1 Predictions Mean                             -0.739743
trainer/Q1 Predictions Std                               0.791184
trainer/Q1 Predictions Max                               0.926598
trainer/Q1 Predictions Min                              -2.91262
trainer/Q2 Predictions Mean                             -0.740817
trainer/Q2 Predictions Std                               0.795313
trainer/Q2 Predictions Max                               0.971518
trainer/Q2 Predictions Min                              -2.93144
trainer/Q Targets Mean                                  -0.732781
trainer/Q Targets Std                                    0.800893
trainer/Q Targets Max                                    0.970355
trainer/Q Targets Min                                   -2.96216
trainer/Log Pis Mean                                     2.07611
trainer/Log Pis Std                                      1.12501
trainer/Log Pis Max                                      4.72725
trainer/Log Pis Min                                     -1.08292
trainer/Policy mu Mean                                   0.0508411
trainer/Policy mu Std                                    0.360948
trainer/Policy mu Max                                    2.34416
trainer/Policy mu Min                                   -2.23055
trainer/Policy log std Mean                             -2.26859
trainer/Policy log std Std                               0.569063
trainer/Policy log std Max                              -0.230645
trainer/Policy log std Min                              -3.3478
trainer/Alpha                                            0.0196575
trainer/Alpha Loss                                       0.299237
exploration/num steps total                           7800
exploration/num paths total                            390
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0566295
exploration/Rewards Std                                  0.0784884
exploration/Rewards Max                                  0.11107
exploration/Rewards Min                                 -0.229922
exploration/Returns Mean                                -1.13259
exploration/Returns Std                                  1.18467
exploration/Returns Max                                  0.392652
exploration/Returns Min                                 -2.69177
exploration/Actions Mean                                 0.00905936
exploration/Actions Std                                  0.216871
exploration/Actions Max                                  0.905449
exploration/Actions Min                                 -0.992652
exploration/Num Paths                                    5
exploration/Average Returns                             -1.13259
exploration/env_infos/final/reward_energy Mean          -0.132475
exploration/env_infos/final/reward_energy Std            0.0639964
exploration/env_infos/final/reward_energy Max           -0.0451561
exploration/env_infos/final/reward_energy Min           -0.234667
exploration/env_infos/initial/reward_energy Mean        -0.254906
exploration/env_infos/initial/reward_energy Std          0.331649
exploration/env_infos/initial/reward_energy Max         -0.0385496
exploration/env_infos/initial/reward_energy Min         -0.906919
exploration/env_infos/reward_energy Mean                -0.214957
exploration/env_infos/reward_energy Std                  0.219143
exploration/env_infos/reward_energy Max                 -0.0320283
exploration/env_infos/reward_energy Min                 -1.23336
exploration/env_infos/final/end_effector_loc Mean        0.142077
exploration/env_infos/final/end_effector_loc Std         0.145914
exploration/env_infos/final/end_effector_loc Max         0.292162
exploration/env_infos/final/end_effector_loc Min        -0.178327
exploration/env_infos/initial/end_effector_loc Mean      0.00369031
exploration/env_infos/initial/end_effector_loc Std       0.014321
exploration/env_infos/initial/end_effector_loc Max       0.0452725
exploration/env_infos/initial/end_effector_loc Min      -0.0078979
exploration/env_infos/end_effector_loc Mean              0.0769703
exploration/env_infos/end_effector_loc Std               0.127963
exploration/env_infos/end_effector_loc Max               0.367999
exploration/env_infos/end_effector_loc Min              -0.180981
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.143154
exploration/env_infos/final/reward_dist Std              0.257281
exploration/env_infos/final/reward_dist Max              0.656422
exploration/env_infos/final/reward_dist Min              2.91621e-11
exploration/env_infos/initial/reward_dist Mean           0.00646889
exploration/env_infos/initial/reward_dist Std            0.0121479
exploration/env_infos/initial/reward_dist Max            0.0307565
exploration/env_infos/initial/reward_dist Min            1.87389e-05
exploration/env_infos/reward_dist Mean                   0.133278
exploration/env_infos/reward_dist Std                    0.231228
exploration/env_infos/reward_dist Max                    0.903565
exploration/env_infos/reward_dist Min                    2.91621e-11
evaluation/num steps total                           68000
evaluation/num paths total                            3400
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0563539
evaluation/Rewards Std                                   0.0755072
evaluation/Rewards Max                                   0.120013
evaluation/Rewards Min                                  -0.45518
evaluation/Returns Mean                                 -1.12708
evaluation/Returns Std                                   1.14369
evaluation/Returns Max                                   0.661307
evaluation/Returns Min                                  -4.40409
evaluation/Actions Mean                                  0.00208136
evaluation/Actions Std                                   0.104619
evaluation/Actions Max                                   0.952762
evaluation/Actions Min                                  -0.618853
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.12708
evaluation/env_infos/final/reward_energy Mean           -0.0690274
evaluation/env_infos/final/reward_energy Std             0.0881722
evaluation/env_infos/final/reward_energy Max            -0.00374652
evaluation/env_infos/final/reward_energy Min            -0.620754
evaluation/env_infos/initial/reward_energy Mean         -0.273786
evaluation/env_infos/initial/reward_energy Std           0.260092
evaluation/env_infos/initial/reward_energy Max          -0.0134554
evaluation/env_infos/initial/reward_energy Min          -1.10952
evaluation/env_infos/reward_energy Mean                 -0.0888535
evaluation/env_infos/reward_energy Std                   0.118339
evaluation/env_infos/reward_energy Max                  -0.00165983
evaluation/env_infos/reward_energy Min                  -1.10952
evaluation/env_infos/final/end_effector_loc Mean        -0.00887319
evaluation/env_infos/final/end_effector_loc Std          0.264198
evaluation/env_infos/final/end_effector_loc Max          0.962404
evaluation/env_infos/final/end_effector_loc Min         -0.910162
evaluation/env_infos/initial/end_effector_loc Mean      -2.18665e-05
evaluation/env_infos/initial/end_effector_loc Std        0.0133513
evaluation/env_infos/initial/end_effector_loc Max        0.0476381
evaluation/env_infos/initial/end_effector_loc Min       -0.0309426
evaluation/env_infos/end_effector_loc Mean              -0.0100418
evaluation/env_infos/end_effector_loc Std                0.177851
evaluation/env_infos/end_effector_loc Max                0.962404
evaluation/env_infos/end_effector_loc Min               -0.9403
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.139084
evaluation/env_infos/final/reward_dist Std               0.26656
evaluation/env_infos/final/reward_dist Max               0.963734
evaluation/env_infos/final/reward_dist Min               3.12456e-99
evaluation/env_infos/initial/reward_dist Mean            0.00734828
evaluation/env_infos/initial/reward_dist Std             0.0123639
evaluation/env_infos/initial/reward_dist Max             0.0643801
evaluation/env_infos/initial/reward_dist Min             1.52951e-06
evaluation/env_infos/reward_dist Mean                    0.13709
evaluation/env_infos/reward_dist Std                     0.237859
evaluation/env_infos/reward_dist Max                     0.995863
evaluation/env_infos/reward_dist Min                     3.12456e-99
time/data storing (s)                                   29.7649
time/evaluation sampling (s)                             0.663289
time/exploration sampling (s)                            0.0966361
time/logging (s)                                         0.0147209
time/saving (s)                                          0.62299
time/training (s)                                       35.9979
time/epoch (s)                                          67.1605
time/total (s)                                        3681.29
Epoch                                                   67
---------------------------------------------------  ---------------
2021-05-29 00:58:22.313620 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 68 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00286059
trainer/QF2 Loss                                         0.00159079
trainer/Policy Loss                                      2.58235
trainer/Q1 Predictions Mean                             -0.802948
trainer/Q1 Predictions Std                               0.786652
trainer/Q1 Predictions Max                               0.969985
trainer/Q1 Predictions Min                              -3.15789
trainer/Q2 Predictions Mean                             -0.792207
trainer/Q2 Predictions Std                               0.78291
trainer/Q2 Predictions Max                               0.925369
trainer/Q2 Predictions Min                              -3.1309
trainer/Q Targets Mean                                  -0.79425
trainer/Q Targets Std                                    0.777481
trainer/Q Targets Max                                    0.92465
trainer/Q Targets Min                                   -3.12716
trainer/Log Pis Mean                                     1.787
trainer/Log Pis Std                                      1.29328
trainer/Log Pis Max                                      5.55091
trainer/Log Pis Min                                     -2.6005
trainer/Policy mu Mean                                   0.0485857
trainer/Policy mu Std                                    0.393346
trainer/Policy mu Max                                    2.67787
trainer/Policy mu Min                                   -1.89876
trainer/Policy log std Mean                             -2.15279
trainer/Policy log std Std                               0.540046
trainer/Policy log std Max                              -0.118769
trainer/Policy log std Min                              -3.21719
trainer/Alpha                                            0.0182972
trainer/Alpha Loss                                      -0.851912
exploration/num steps total                           7900
exploration/num paths total                            395
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0717719
exploration/Rewards Std                                  0.117091
exploration/Rewards Max                                  0.17669
exploration/Rewards Min                                 -0.31764
exploration/Returns Mean                                -1.43544
exploration/Returns Std                                  2.18917
exploration/Returns Max                                  2.89798
exploration/Returns Min                                 -3.0618
exploration/Actions Mean                                -0.000857716
exploration/Actions Std                                  0.159244
exploration/Actions Max                                  0.747884
exploration/Actions Min                                 -0.672386
exploration/Num Paths                                    5
exploration/Average Returns                             -1.43544
exploration/env_infos/final/reward_energy Mean          -0.123654
exploration/env_infos/final/reward_energy Std            0.0513537
exploration/env_infos/final/reward_energy Max           -0.0546814
exploration/env_infos/final/reward_energy Min           -0.183781
exploration/env_infos/initial/reward_energy Mean        -0.319875
exploration/env_infos/initial/reward_energy Std          0.331549
exploration/env_infos/initial/reward_energy Max         -0.0598549
exploration/env_infos/initial/reward_energy Min         -0.963898
exploration/env_infos/reward_energy Mean                -0.158051
exploration/env_infos/reward_energy Std                  0.160434
exploration/env_infos/reward_energy Max                 -0.0038069
exploration/env_infos/reward_energy Min                 -0.963898
exploration/env_infos/final/end_effector_loc Mean       -0.0199998
exploration/env_infos/final/end_effector_loc Std         0.180057
exploration/env_infos/final/end_effector_loc Max         0.204844
exploration/env_infos/final/end_effector_loc Min        -0.447892
exploration/env_infos/initial/end_effector_loc Mean      0.00614561
exploration/env_infos/initial/end_effector_loc Std       0.0150843
exploration/env_infos/initial/end_effector_loc Max       0.0373942
exploration/env_infos/initial/end_effector_loc Min      -0.00799218
exploration/env_infos/end_effector_loc Mean              0.00192689
exploration/env_infos/end_effector_loc Std               0.117705
exploration/env_infos/end_effector_loc Max               0.204844
exploration/env_infos/end_effector_loc Min              -0.447892
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.155166
exploration/env_infos/final/reward_dist Std              0.276726
exploration/env_infos/final/reward_dist Max              0.705992
exploration/env_infos/final/reward_dist Min              5.07408e-09
exploration/env_infos/initial/reward_dist Mean           0.0410402
exploration/env_infos/initial/reward_dist Std            0.0600455
exploration/env_infos/initial/reward_dist Max            0.158841
exploration/env_infos/initial/reward_dist Min            4.61794e-05
exploration/env_infos/reward_dist Mean                   0.197868
exploration/env_infos/reward_dist Std                    0.308029
exploration/env_infos/reward_dist Max                    0.99428
exploration/env_infos/reward_dist Min                    5.07408e-09
evaluation/num steps total                           69000
evaluation/num paths total                            3450
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0907297
evaluation/Rewards Std                                   0.122358
evaluation/Rewards Max                                   0.140448
evaluation/Rewards Min                                  -0.702684
evaluation/Returns Mean                                 -1.81459
evaluation/Returns Std                                   1.91191
evaluation/Returns Max                                   1.84557
evaluation/Returns Min                                  -7.79492
evaluation/Actions Mean                                 -0.00719299
evaluation/Actions Std                                   0.167232
evaluation/Actions Max                                   0.973806
evaluation/Actions Min                                  -0.961217
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.81459
evaluation/env_infos/final/reward_energy Mean           -0.0948875
evaluation/env_infos/final/reward_energy Std             0.135735
evaluation/env_infos/final/reward_energy Max            -0.00785703
evaluation/env_infos/final/reward_energy Min            -0.744586
evaluation/env_infos/initial/reward_energy Mean         -0.408047
evaluation/env_infos/initial/reward_energy Std           0.370227
evaluation/env_infos/initial/reward_energy Max          -0.00509737
evaluation/env_infos/initial/reward_energy Min          -1.21093
evaluation/env_infos/reward_energy Mean                 -0.135545
evaluation/env_infos/reward_energy Std                   0.194073
evaluation/env_infos/reward_energy Max                  -0.00248851
evaluation/env_infos/reward_energy Min                  -1.21575
evaluation/env_infos/final/end_effector_loc Mean        -0.032898
evaluation/env_infos/final/end_effector_loc Std          0.413675
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00141207
evaluation/env_infos/initial/end_effector_loc Std        0.0194285
evaluation/env_infos/initial/end_effector_loc Max        0.0486903
evaluation/env_infos/initial/end_effector_loc Min       -0.0480609
evaluation/env_infos/end_effector_loc Mean              -0.0314817
evaluation/env_infos/end_effector_loc Std                0.280761
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0870048
evaluation/env_infos/final/reward_dist Std               0.190578
evaluation/env_infos/final/reward_dist Max               0.952424
evaluation/env_infos/final/reward_dist Min               1.48508e-132
evaluation/env_infos/initial/reward_dist Mean            0.0152426
evaluation/env_infos/initial/reward_dist Std             0.0258127
evaluation/env_infos/initial/reward_dist Max             0.114658
evaluation/env_infos/initial/reward_dist Min             1.73695e-06
evaluation/env_infos/reward_dist Mean                    0.122615
evaluation/env_infos/reward_dist Std                     0.226885
evaluation/env_infos/reward_dist Max                     0.999072
evaluation/env_infos/reward_dist Min                     1.48508e-132
time/data storing (s)                                   29.8468
time/evaluation sampling (s)                             0.642819
time/exploration sampling (s)                            0.0871162
time/logging (s)                                         0.0142527
time/saving (s)                                          0.610331
time/training (s)                                       36.2662
time/epoch (s)                                          67.4674
time/total (s)                                        3749.53
Epoch                                                   68
---------------------------------------------------  ----------------
2021-05-29 00:59:31.849679 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 69 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00165987
trainer/QF2 Loss                                         0.00225268
trainer/Policy Loss                                      2.64309
trainer/Q1 Predictions Mean                             -0.721643
trainer/Q1 Predictions Std                               0.757263
trainer/Q1 Predictions Max                               0.757848
trainer/Q1 Predictions Min                              -2.74531
trainer/Q2 Predictions Mean                             -0.714533
trainer/Q2 Predictions Std                               0.764361
trainer/Q2 Predictions Max                               0.813463
trainer/Q2 Predictions Min                              -2.74899
trainer/Q Targets Mean                                  -0.711483
trainer/Q Targets Std                                    0.762997
trainer/Q Targets Max                                    0.822573
trainer/Q Targets Min                                   -2.76815
trainer/Log Pis Mean                                     1.93059
trainer/Log Pis Std                                      1.48475
trainer/Log Pis Max                                      4.66271
trainer/Log Pis Min                                     -7.35466
trainer/Policy mu Mean                                   0.041825
trainer/Policy mu Std                                    0.418226
trainer/Policy mu Max                                    2.17282
trainer/Policy mu Min                                   -2.49466
trainer/Policy log std Mean                             -2.25117
trainer/Policy log std Std                               0.61303
trainer/Policy log std Max                              -0.376217
trainer/Policy log std Min                              -3.30485
trainer/Alpha                                            0.0182749
trainer/Alpha Loss                                      -0.27776
exploration/num steps total                           8000
exploration/num paths total                            400
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0979246
exploration/Rewards Std                                  0.0761548
exploration/Rewards Max                                  0.053735
exploration/Rewards Min                                 -0.404459
exploration/Returns Mean                                -1.95849
exploration/Returns Std                                  1.08215
exploration/Returns Max                                 -0.614343
exploration/Returns Min                                 -3.40419
exploration/Actions Mean                                 0.0126491
exploration/Actions Std                                  0.152061
exploration/Actions Max                                  0.538213
exploration/Actions Min                                 -0.470713
exploration/Num Paths                                    5
exploration/Average Returns                             -1.95849
exploration/env_infos/final/reward_energy Mean          -0.120568
exploration/env_infos/final/reward_energy Std            0.087257
exploration/env_infos/final/reward_energy Max           -0.0140757
exploration/env_infos/final/reward_energy Min           -0.234932
exploration/env_infos/initial/reward_energy Mean        -0.335529
exploration/env_infos/initial/reward_energy Std          0.266774
exploration/env_infos/initial/reward_energy Max         -0.0447836
exploration/env_infos/initial/reward_energy Min         -0.6866
exploration/env_infos/reward_energy Mean                -0.171357
exploration/env_infos/reward_energy Std                  0.131155
exploration/env_infos/reward_energy Max                 -0.00985211
exploration/env_infos/reward_energy Min                 -0.6866
exploration/env_infos/final/end_effector_loc Mean        0.0760128
exploration/env_infos/final/end_effector_loc Std         0.395204
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -0.492796
exploration/env_infos/initial/end_effector_loc Mean      0.00530834
exploration/env_infos/initial/end_effector_loc Std       0.0141953
exploration/env_infos/initial/end_effector_loc Max       0.0243607
exploration/env_infos/initial/end_effector_loc Min      -0.0235356
exploration/env_infos/end_effector_loc Mean              0.0562258
exploration/env_infos/end_effector_loc Std               0.285277
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -0.492796
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0646033
exploration/env_infos/final/reward_dist Std              0.128136
exploration/env_infos/final/reward_dist Max              0.320869
exploration/env_infos/final/reward_dist Min              3.03003e-50
exploration/env_infos/initial/reward_dist Mean           0.0132763
exploration/env_infos/initial/reward_dist Std            0.0221135
exploration/env_infos/initial/reward_dist Max            0.0573112
exploration/env_infos/initial/reward_dist Min            9.95966e-07
exploration/env_infos/reward_dist Mean                   0.0776968
exploration/env_infos/reward_dist Std                    0.161212
exploration/env_infos/reward_dist Max                    0.894709
exploration/env_infos/reward_dist Min                    2.56099e-55
evaluation/num steps total                           70000
evaluation/num paths total                            3500
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0569236
evaluation/Rewards Std                                   0.0964202
evaluation/Rewards Max                                   0.149295
evaluation/Rewards Min                                  -0.840122
evaluation/Returns Mean                                 -1.13847
evaluation/Returns Std                                   1.5862
evaluation/Returns Max                                   1.72126
evaluation/Returns Min                                  -5.79386
evaluation/Actions Mean                                  0.0035969
evaluation/Actions Std                                   0.101933
evaluation/Actions Max                                   0.912811
evaluation/Actions Min                                  -0.733006
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.13847
evaluation/env_infos/final/reward_energy Mean           -0.0581042
evaluation/env_infos/final/reward_energy Std             0.0690349
evaluation/env_infos/final/reward_energy Max            -0.00677173
evaluation/env_infos/final/reward_energy Min            -0.482115
evaluation/env_infos/initial/reward_energy Mean         -0.304509
evaluation/env_infos/initial/reward_energy Std           0.305768
evaluation/env_infos/initial/reward_energy Max          -0.0155588
evaluation/env_infos/initial/reward_energy Min          -1.13741
evaluation/env_infos/reward_energy Mean                 -0.0806309
evaluation/env_infos/reward_energy Std                   0.119605
evaluation/env_infos/reward_energy Max                  -0.00231399
evaluation/env_infos/reward_energy Min                  -1.13741
evaluation/env_infos/final/end_effector_loc Mean         0.0543016
evaluation/env_infos/final/end_effector_loc Std          0.330516
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00218762
evaluation/env_infos/initial/end_effector_loc Std        0.0150993
evaluation/env_infos/initial/end_effector_loc Max        0.0456406
evaluation/env_infos/initial/end_effector_loc Min       -0.0366503
evaluation/env_infos/end_effector_loc Mean               0.0198089
evaluation/env_infos/end_effector_loc Std                0.210033
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0768069
evaluation/env_infos/final/reward_dist Std               0.160155
evaluation/env_infos/final/reward_dist Max               0.747768
evaluation/env_infos/final/reward_dist Min               6.87292e-103
evaluation/env_infos/initial/reward_dist Mean            0.0120459
evaluation/env_infos/initial/reward_dist Std             0.0266668
evaluation/env_infos/initial/reward_dist Max             0.161638
evaluation/env_infos/initial/reward_dist Min             1.28858e-06
evaluation/env_infos/reward_dist Mean                    0.120844
evaluation/env_infos/reward_dist Std                     0.207557
evaluation/env_infos/reward_dist Max                     0.990395
evaluation/env_infos/reward_dist Min                     6.87292e-103
time/data storing (s)                                   30.8283
time/evaluation sampling (s)                             0.729952
time/exploration sampling (s)                            0.089935
time/logging (s)                                         0.0142441
time/saving (s)                                          0.64007
time/training (s)                                       36.4646
time/epoch (s)                                          68.7671
time/total (s)                                        3819.06
Epoch                                                   69
---------------------------------------------------  ----------------
2021-05-29 01:00:41.231475 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 70 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00215785
trainer/QF2 Loss                                         0.00083968
trainer/Policy Loss                                      2.68433
trainer/Q1 Predictions Mean                             -0.74437
trainer/Q1 Predictions Std                               0.765159
trainer/Q1 Predictions Max                               0.752524
trainer/Q1 Predictions Min                              -2.99629
trainer/Q2 Predictions Mean                             -0.74901
trainer/Q2 Predictions Std                               0.764107
trainer/Q2 Predictions Max                               0.733864
trainer/Q2 Predictions Min                              -2.98309
trainer/Q Targets Mean                                  -0.753257
trainer/Q Targets Std                                    0.763497
trainer/Q Targets Max                                    0.749086
trainer/Q Targets Min                                   -3.0624
trainer/Log Pis Mean                                     1.94245
trainer/Log Pis Std                                      1.34574
trainer/Log Pis Max                                      4.43838
trainer/Log Pis Min                                     -3.52637
trainer/Policy mu Mean                                   0.0502926
trainer/Policy mu Std                                    0.312867
trainer/Policy mu Max                                    1.53053
trainer/Policy mu Min                                   -1.97581
trainer/Policy log std Mean                             -2.31905
trainer/Policy log std Std                               0.54623
trainer/Policy log std Max                              -0.405999
trainer/Policy log std Min                              -3.29051
trainer/Alpha                                            0.0180759
trainer/Alpha Loss                                      -0.230851
exploration/num steps total                           8100
exploration/num paths total                            405
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0917263
exploration/Rewards Std                                  0.103813
exploration/Rewards Max                                  0.122432
exploration/Rewards Min                                 -0.395094
exploration/Returns Mean                                -1.83453
exploration/Returns Std                                  1.49008
exploration/Returns Max                                  0.307444
exploration/Returns Min                                 -3.73651
exploration/Actions Mean                                 0.0102079
exploration/Actions Std                                  0.196421
exploration/Actions Max                                  0.911967
exploration/Actions Min                                 -0.732586
exploration/Num Paths                                    5
exploration/Average Returns                             -1.83453
exploration/env_infos/final/reward_energy Mean          -0.139458
exploration/env_infos/final/reward_energy Std            0.0538532
exploration/env_infos/final/reward_energy Max           -0.0406848
exploration/env_infos/final/reward_energy Min           -0.186454
exploration/env_infos/initial/reward_energy Mean        -0.464551
exploration/env_infos/initial/reward_energy Std          0.309502
exploration/env_infos/initial/reward_energy Max         -0.110039
exploration/env_infos/initial/reward_energy Min         -1.0012
exploration/env_infos/reward_energy Mean                -0.206838
exploration/env_infos/reward_energy Std                  0.185981
exploration/env_infos/reward_energy Max                 -0.010406
exploration/env_infos/reward_energy Min                 -1.0012
exploration/env_infos/final/end_effector_loc Mean        0.0156484
exploration/env_infos/final/end_effector_loc Std         0.493825
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -1
exploration/env_infos/initial/end_effector_loc Mean      0.000982349
exploration/env_infos/initial/end_effector_loc Std       0.0197113
exploration/env_infos/initial/end_effector_loc Max       0.0455984
exploration/env_infos/initial/end_effector_loc Min      -0.0221793
exploration/env_infos/end_effector_loc Mean              0.00894717
exploration/env_infos/end_effector_loc Std               0.306297
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -1
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.140347
exploration/env_infos/final/reward_dist Std              0.128609
exploration/env_infos/final/reward_dist Max              0.333383
exploration/env_infos/final/reward_dist Min              9.4523e-54
exploration/env_infos/initial/reward_dist Mean           0.000546482
exploration/env_infos/initial/reward_dist Std            0.000851561
exploration/env_infos/initial/reward_dist Max            0.00222354
exploration/env_infos/initial/reward_dist Min            1.14753e-05
exploration/env_infos/reward_dist Mean                   0.166026
exploration/env_infos/reward_dist Std                    0.248923
exploration/env_infos/reward_dist Max                    0.999296
exploration/env_infos/reward_dist Min                    8.67864e-54
evaluation/num steps total                           71000
evaluation/num paths total                            3550
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.05993
evaluation/Rewards Std                                   0.0826754
evaluation/Rewards Max                                   0.12359
evaluation/Rewards Min                                  -0.754593
evaluation/Returns Mean                                 -1.1986
evaluation/Returns Std                                   1.29544
evaluation/Returns Max                                   1.71439
evaluation/Returns Min                                  -4.49674
evaluation/Actions Mean                                  0.00810412
evaluation/Actions Std                                   0.0801167
evaluation/Actions Max                                   0.828656
evaluation/Actions Min                                  -0.849641
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.1986
evaluation/env_infos/final/reward_energy Mean           -0.0461015
evaluation/env_infos/final/reward_energy Std             0.0301931
evaluation/env_infos/final/reward_energy Max            -0.00234832
evaluation/env_infos/final/reward_energy Min            -0.138226
evaluation/env_infos/initial/reward_energy Mean         -0.235406
evaluation/env_infos/initial/reward_energy Std           0.252208
evaluation/env_infos/initial/reward_energy Max          -0.00632138
evaluation/env_infos/initial/reward_energy Min          -1.09624
evaluation/env_infos/reward_energy Mean                 -0.068594
evaluation/env_infos/reward_energy Std                   0.0909043
evaluation/env_infos/reward_energy Max                  -0.000696128
evaluation/env_infos/reward_energy Min                  -1.09624
evaluation/env_infos/final/end_effector_loc Mean         0.108803
evaluation/env_infos/final/end_effector_loc Std          0.327321
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.000946211
evaluation/env_infos/initial/end_effector_loc Std        0.0121608
evaluation/env_infos/initial/end_effector_loc Max        0.0414328
evaluation/env_infos/initial/end_effector_loc Min       -0.0424821
evaluation/env_infos/end_effector_loc Mean               0.0474945
evaluation/env_infos/end_effector_loc Std                0.212623
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.108981
evaluation/env_infos/final/reward_dist Std               0.180578
evaluation/env_infos/final/reward_dist Max               0.600261
evaluation/env_infos/final/reward_dist Min               9.13153e-72
evaluation/env_infos/initial/reward_dist Mean            0.00658581
evaluation/env_infos/initial/reward_dist Std             0.017993
evaluation/env_infos/initial/reward_dist Max             0.109376
evaluation/env_infos/initial/reward_dist Min             1.30011e-06
evaluation/env_infos/reward_dist Mean                    0.137898
evaluation/env_infos/reward_dist Std                     0.236221
evaluation/env_infos/reward_dist Max                     0.998882
evaluation/env_infos/reward_dist Min                     9.13153e-72
time/data storing (s)                                   30.89
time/evaluation sampling (s)                             0.623632
time/exploration sampling (s)                            0.0928621
time/logging (s)                                         0.0148794
time/saving (s)                                          0.736057
time/training (s)                                       36.2616
time/epoch (s)                                          68.619
time/total (s)                                        3888.44
Epoch                                                   70
---------------------------------------------------  ---------------
2021-05-29 01:01:50.656047 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 71 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00123381
trainer/QF2 Loss                                         0.000971822
trainer/Policy Loss                                      2.95032
trainer/Q1 Predictions Mean                             -0.818621
trainer/Q1 Predictions Std                               0.916195
trainer/Q1 Predictions Max                               0.961189
trainer/Q1 Predictions Min                              -3.10026
trainer/Q2 Predictions Mean                             -0.825372
trainer/Q2 Predictions Std                               0.914978
trainer/Q2 Predictions Max                               0.952475
trainer/Q2 Predictions Min                              -3.15908
trainer/Q Targets Mean                                  -0.832381
trainer/Q Targets Std                                    0.912924
trainer/Q Targets Max                                    0.932679
trainer/Q Targets Min                                   -3.14557
trainer/Log Pis Mean                                     2.13534
trainer/Log Pis Std                                      1.23072
trainer/Log Pis Max                                      5.5792
trainer/Log Pis Min                                     -2.44991
trainer/Policy mu Mean                                   0.0148356
trainer/Policy mu Std                                    0.41852
trainer/Policy mu Max                                    1.58279
trainer/Policy mu Min                                   -2.58803
trainer/Policy log std Mean                             -2.31905
trainer/Policy log std Std                               0.595228
trainer/Policy log std Max                              -0.137487
trainer/Policy log std Min                              -3.30324
trainer/Alpha                                            0.0170596
trainer/Alpha Loss                                       0.551181
exploration/num steps total                           8200
exploration/num paths total                            410
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.127678
exploration/Rewards Std                                  0.0698403
exploration/Rewards Max                                 -0.0337718
exploration/Rewards Min                                 -0.381227
exploration/Returns Mean                                -2.55356
exploration/Returns Std                                  0.671876
exploration/Returns Max                                 -1.85366
exploration/Returns Min                                 -3.48254
exploration/Actions Mean                                 0.012494
exploration/Actions Std                                  0.243837
exploration/Actions Max                                  0.969201
exploration/Actions Min                                 -0.89602
exploration/Num Paths                                    5
exploration/Average Returns                             -2.55356
exploration/env_infos/final/reward_energy Mean          -0.114604
exploration/env_infos/final/reward_energy Std            0.0837333
exploration/env_infos/final/reward_energy Max           -0.020089
exploration/env_infos/final/reward_energy Min           -0.247439
exploration/env_infos/initial/reward_energy Mean        -0.382164
exploration/env_infos/initial/reward_energy Std          0.299111
exploration/env_infos/initial/reward_energy Max         -0.0638724
exploration/env_infos/initial/reward_energy Min         -0.865543
exploration/env_infos/reward_energy Mean                -0.214658
exploration/env_infos/reward_energy Std                  0.270457
exploration/env_infos/reward_energy Max                 -0.0125731
exploration/env_infos/reward_energy Min                 -1.10811
exploration/env_infos/final/end_effector_loc Mean        0.143792
exploration/env_infos/final/end_effector_loc Std         0.403117
exploration/env_infos/final/end_effector_loc Max         0.898882
exploration/env_infos/final/end_effector_loc Min        -0.488004
exploration/env_infos/initial/end_effector_loc Mean      0.00197622
exploration/env_infos/initial/end_effector_loc Std       0.0170438
exploration/env_infos/initial/end_effector_loc Max       0.0324422
exploration/env_infos/initial/end_effector_loc Min      -0.0286428
exploration/env_infos/end_effector_loc Mean              0.0537499
exploration/env_infos/end_effector_loc Std               0.294777
exploration/env_infos/end_effector_loc Max               0.898882
exploration/env_infos/end_effector_loc Min              -0.737608
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.14026
exploration/env_infos/final/reward_dist Std              0.276334
exploration/env_infos/final/reward_dist Max              0.69289
exploration/env_infos/final/reward_dist Min              9.05449e-54
exploration/env_infos/initial/reward_dist Mean           0.00510239
exploration/env_infos/initial/reward_dist Std            0.0046706
exploration/env_infos/initial/reward_dist Max            0.0115244
exploration/env_infos/initial/reward_dist Min            2.31266e-06
exploration/env_infos/reward_dist Mean                   0.0628235
exploration/env_infos/reward_dist Std                    0.155273
exploration/env_infos/reward_dist Max                    0.77277
exploration/env_infos/reward_dist Min                    9.05449e-54
evaluation/num steps total                           72000
evaluation/num paths total                            3600
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.053322
evaluation/Rewards Std                                   0.0782973
evaluation/Rewards Max                                   0.164001
evaluation/Rewards Min                                  -0.446628
evaluation/Returns Mean                                 -1.06644
evaluation/Returns Std                                   1.22806
evaluation/Returns Max                                   1.56094
evaluation/Returns Min                                  -4.45179
evaluation/Actions Mean                                  0.00408579
evaluation/Actions Std                                   0.0869725
evaluation/Actions Max                                   0.641824
evaluation/Actions Min                                  -0.772278
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.06644
evaluation/env_infos/final/reward_energy Mean           -0.0453213
evaluation/env_infos/final/reward_energy Std             0.0229768
evaluation/env_infos/final/reward_energy Max            -0.00768802
evaluation/env_infos/final/reward_energy Min            -0.110443
evaluation/env_infos/initial/reward_energy Mean         -0.272873
evaluation/env_infos/initial/reward_energy Std           0.261854
evaluation/env_infos/initial/reward_energy Max          -0.017139
evaluation/env_infos/initial/reward_energy Min          -1.08137
evaluation/env_infos/reward_energy Mean                 -0.0720482
evaluation/env_infos/reward_energy Std                   0.0998542
evaluation/env_infos/reward_energy Max                  -0.000931343
evaluation/env_infos/reward_energy Min                  -1.08137
evaluation/env_infos/final/end_effector_loc Mean         0.0420672
evaluation/env_infos/final/end_effector_loc Std          0.323053
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.000603904
evaluation/env_infos/initial/end_effector_loc Std        0.0133574
evaluation/env_infos/initial/end_effector_loc Max        0.0320912
evaluation/env_infos/initial/end_effector_loc Min       -0.0386139
evaluation/env_infos/end_effector_loc Mean               0.0170448
evaluation/env_infos/end_effector_loc Std                0.202274
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0918767
evaluation/env_infos/final/reward_dist Std               0.20345
evaluation/env_infos/final/reward_dist Max               0.955714
evaluation/env_infos/final/reward_dist Min               2.48517e-71
evaluation/env_infos/initial/reward_dist Mean            0.00547695
evaluation/env_infos/initial/reward_dist Std             0.0108744
evaluation/env_infos/initial/reward_dist Max             0.0464584
evaluation/env_infos/initial/reward_dist Min             1.09147e-06
evaluation/env_infos/reward_dist Mean                    0.147333
evaluation/env_infos/reward_dist Std                     0.251413
evaluation/env_infos/reward_dist Max                     0.99841
evaluation/env_infos/reward_dist Min                     2.48517e-71
time/data storing (s)                                   31.2896
time/evaluation sampling (s)                             0.647623
time/exploration sampling (s)                            0.0898911
time/logging (s)                                         0.0148295
time/saving (s)                                          0.657574
time/training (s)                                       35.9355
time/epoch (s)                                          68.635
time/total (s)                                        3957.86
Epoch                                                   71
---------------------------------------------------  ---------------
2021-05-29 01:03:00.782233 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 72 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.000977878
trainer/QF2 Loss                                         0.000841284
trainer/Policy Loss                                      2.969
trainer/Q1 Predictions Mean                             -0.805763
trainer/Q1 Predictions Std                               0.82316
trainer/Q1 Predictions Max                               1.07271
trainer/Q1 Predictions Min                              -2.94229
trainer/Q2 Predictions Mean                             -0.803506
trainer/Q2 Predictions Std                               0.825298
trainer/Q2 Predictions Max                               1.05765
trainer/Q2 Predictions Min                              -3.01413
trainer/Q Targets Mean                                  -0.807286
trainer/Q Targets Std                                    0.824923
trainer/Q Targets Max                                    1.07343
trainer/Q Targets Min                                   -2.95396
trainer/Log Pis Mean                                     2.17826
trainer/Log Pis Std                                      1.3013
trainer/Log Pis Max                                      4.73122
trainer/Log Pis Min                                     -2.40042
trainer/Policy mu Mean                                  -0.0193664
trainer/Policy mu Std                                    0.3153
trainer/Policy mu Max                                    0.993888
trainer/Policy mu Min                                   -2.55635
trainer/Policy log std Mean                             -2.3656
trainer/Policy log std Std                               0.546481
trainer/Policy log std Max                              -0.504236
trainer/Policy log std Min                              -3.42603
trainer/Alpha                                            0.0169105
trainer/Alpha Loss                                       0.727444
exploration/num steps total                           8300
exploration/num paths total                            415
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.158815
exploration/Rewards Std                                  0.0917836
exploration/Rewards Max                                 -0.08186
exploration/Rewards Min                                 -0.604629
exploration/Returns Mean                                -3.1763
exploration/Returns Std                                  1.06089
exploration/Returns Max                                 -2.43922
exploration/Returns Min                                 -5.27704
exploration/Actions Mean                                -0.0232968
exploration/Actions Std                                  0.153968
exploration/Actions Max                                  0.760411
exploration/Actions Min                                 -0.675546
exploration/Num Paths                                    5
exploration/Average Returns                             -3.1763
exploration/env_infos/final/reward_energy Mean          -0.139356
exploration/env_infos/final/reward_energy Std            0.0846804
exploration/env_infos/final/reward_energy Max           -0.0452243
exploration/env_infos/final/reward_energy Min           -0.280747
exploration/env_infos/initial/reward_energy Mean        -0.28372
exploration/env_infos/initial/reward_energy Std          0.366984
exploration/env_infos/initial/reward_energy Max         -0.0855887
exploration/env_infos/initial/reward_energy Min         -1.01715
exploration/env_infos/reward_energy Mean                -0.150639
exploration/env_infos/reward_energy Std                  0.160641
exploration/env_infos/reward_energy Max                 -0.0102744
exploration/env_infos/reward_energy Min                 -1.01715
exploration/env_infos/final/end_effector_loc Mean       -0.308122
exploration/env_infos/final/end_effector_loc Std         0.363517
exploration/env_infos/final/end_effector_loc Max         0.176182
exploration/env_infos/final/end_effector_loc Min        -0.964966
exploration/env_infos/initial/end_effector_loc Mean     -0.00180312
exploration/env_infos/initial/end_effector_loc Std       0.0163008
exploration/env_infos/initial/end_effector_loc Max       0.0380205
exploration/env_infos/initial/end_effector_loc Min      -0.0337773
exploration/env_infos/end_effector_loc Mean             -0.119268
exploration/env_infos/end_effector_loc Std               0.209965
exploration/env_infos/end_effector_loc Max               0.214316
exploration/env_infos/end_effector_loc Min              -0.964966
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             9.8537e-06
exploration/env_infos/final/reward_dist Std              1.9217e-05
exploration/env_infos/final/reward_dist Max              4.828e-05
exploration/env_infos/final/reward_dist Min              4.71901e-104
exploration/env_infos/initial/reward_dist Mean           0.00538712
exploration/env_infos/initial/reward_dist Std            0.0104341
exploration/env_infos/initial/reward_dist Max            0.0262532
exploration/env_infos/initial/reward_dist Min            1.86144e-06
exploration/env_infos/reward_dist Mean                   0.0124461
exploration/env_infos/reward_dist Std                    0.0329318
exploration/env_infos/reward_dist Max                    0.176102
exploration/env_infos/reward_dist Min                    4.71901e-104
evaluation/num steps total                           73000
evaluation/num paths total                            3650
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0649395
evaluation/Rewards Std                                   0.0834448
evaluation/Rewards Max                                   0.155163
evaluation/Rewards Min                                  -0.538352
evaluation/Returns Mean                                 -1.29879
evaluation/Returns Std                                   1.40501
evaluation/Returns Max                                   2.07044
evaluation/Returns Min                                  -5.61626
evaluation/Actions Mean                                 -0.0059881
evaluation/Actions Std                                   0.0630085
evaluation/Actions Max                                   0.848483
evaluation/Actions Min                                  -0.501702
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.29879
evaluation/env_infos/final/reward_energy Mean           -0.0468769
evaluation/env_infos/final/reward_energy Std             0.0391791
evaluation/env_infos/final/reward_energy Max            -0.00643307
evaluation/env_infos/final/reward_energy Min            -0.208465
evaluation/env_infos/initial/reward_energy Mean         -0.170582
evaluation/env_infos/initial/reward_energy Std           0.183856
evaluation/env_infos/initial/reward_energy Max          -0.0115616
evaluation/env_infos/initial/reward_energy Min          -0.853608
evaluation/env_infos/reward_energy Mean                 -0.0595843
evaluation/env_infos/reward_energy Std                   0.0667949
evaluation/env_infos/reward_energy Max                  -0.0012287
evaluation/env_infos/reward_energy Min                  -0.853608
evaluation/env_infos/final/end_effector_loc Mean        -0.059019
evaluation/env_infos/final/end_effector_loc Std          0.33979
evaluation/env_infos/final/end_effector_loc Max          0.9688
evaluation/env_infos/final/end_effector_loc Min         -0.969365
evaluation/env_infos/initial/end_effector_loc Mean       0.000390479
evaluation/env_infos/initial/end_effector_loc Std        0.00885856
evaluation/env_infos/initial/end_effector_loc Max        0.0424241
evaluation/env_infos/initial/end_effector_loc Min       -0.0250851
evaluation/env_infos/end_effector_loc Mean              -0.0207598
evaluation/env_infos/end_effector_loc Std                0.196094
evaluation/env_infos/end_effector_loc Max                0.9688
evaluation/env_infos/end_effector_loc Min               -0.969365
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.116265
evaluation/env_infos/final/reward_dist Std               0.259812
evaluation/env_infos/final/reward_dist Max               0.912307
evaluation/env_infos/final/reward_dist Min               8.95263e-141
evaluation/env_infos/initial/reward_dist Mean            0.00625586
evaluation/env_infos/initial/reward_dist Std             0.00961587
evaluation/env_infos/initial/reward_dist Max             0.0344001
evaluation/env_infos/initial/reward_dist Min             1.66321e-06
evaluation/env_infos/reward_dist Mean                    0.112895
evaluation/env_infos/reward_dist Std                     0.218101
evaluation/env_infos/reward_dist Max                     0.98938
evaluation/env_infos/reward_dist Min                     8.95263e-141
time/data storing (s)                                   31.5592
time/evaluation sampling (s)                             0.643659
time/exploration sampling (s)                            0.0959128
time/logging (s)                                         0.017166
time/saving (s)                                          0.689195
time/training (s)                                       36.3329
time/epoch (s)                                          69.338
time/total (s)                                        4027.98
Epoch                                                   72
---------------------------------------------------  ----------------
2021-05-29 01:04:12.146295 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 73 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00138776
trainer/QF2 Loss                                         0.00272812
trainer/Policy Loss                                      2.44272
trainer/Q1 Predictions Mean                             -0.673493
trainer/Q1 Predictions Std                               0.866127
trainer/Q1 Predictions Max                               1.27688
trainer/Q1 Predictions Min                              -3.09871
trainer/Q2 Predictions Mean                             -0.670833
trainer/Q2 Predictions Std                               0.860334
trainer/Q2 Predictions Max                               1.27685
trainer/Q2 Predictions Min                              -3.10842
trainer/Q Targets Mean                                  -0.681357
trainer/Q Targets Std                                    0.864893
trainer/Q Targets Max                                    1.28692
trainer/Q Targets Min                                   -3.16032
trainer/Log Pis Mean                                     1.77073
trainer/Log Pis Std                                      1.23599
trainer/Log Pis Max                                      4.29763
trainer/Log Pis Min                                     -3.24955
trainer/Policy mu Mean                                   0.00814208
trainer/Policy mu Std                                    0.288853
trainer/Policy mu Max                                    1.00498
trainer/Policy mu Min                                   -2.13965
trainer/Policy log std Mean                             -2.23304
trainer/Policy log std Std                               0.501634
trainer/Policy log std Max                              -0.503099
trainer/Policy log std Min                              -3.22832
trainer/Alpha                                            0.0189878
trainer/Alpha Loss                                      -0.908672
exploration/num steps total                           8400
exploration/num paths total                            420
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0490538
exploration/Rewards Std                                  0.0668693
exploration/Rewards Max                                  0.0672227
exploration/Rewards Min                                 -0.177766
exploration/Returns Mean                                -0.981075
exploration/Returns Std                                  1.02683
exploration/Returns Max                                  0.118136
exploration/Returns Min                                 -2.77927
exploration/Actions Mean                                 0.00332
exploration/Actions Std                                  0.170273
exploration/Actions Max                                  0.710669
exploration/Actions Min                                 -0.597399
exploration/Num Paths                                    5
exploration/Average Returns                             -0.981075
exploration/env_infos/final/reward_energy Mean          -0.144302
exploration/env_infos/final/reward_energy Std            0.116836
exploration/env_infos/final/reward_energy Max           -0.0369169
exploration/env_infos/final/reward_energy Min           -0.370697
exploration/env_infos/initial/reward_energy Mean        -0.41498
exploration/env_infos/initial/reward_energy Std          0.288223
exploration/env_infos/initial/reward_energy Max         -0.044619
exploration/env_infos/initial/reward_energy Min         -0.73167
exploration/env_infos/reward_energy Mean                -0.187897
exploration/env_infos/reward_energy Std                  0.150673
exploration/env_infos/reward_energy Max                 -0.0161734
exploration/env_infos/reward_energy Min                 -0.73167
exploration/env_infos/final/end_effector_loc Mean        0.0501345
exploration/env_infos/final/end_effector_loc Std         0.146526
exploration/env_infos/final/end_effector_loc Max         0.301882
exploration/env_infos/final/end_effector_loc Min        -0.20996
exploration/env_infos/initial/end_effector_loc Mean     -0.0010957
exploration/env_infos/initial/end_effector_loc Std       0.0178298
exploration/env_infos/initial/end_effector_loc Max       0.0355334
exploration/env_infos/initial/end_effector_loc Min      -0.0298699
exploration/env_infos/end_effector_loc Mean              0.0191456
exploration/env_infos/end_effector_loc Std               0.147226
exploration/env_infos/end_effector_loc Max               0.301882
exploration/env_infos/end_effector_loc Min              -0.314345
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0656914
exploration/env_infos/final/reward_dist Std              0.0518039
exploration/env_infos/final/reward_dist Max              0.142325
exploration/env_infos/final/reward_dist Min              3.74725e-05
exploration/env_infos/initial/reward_dist Mean           0.00524233
exploration/env_infos/initial/reward_dist Std            0.00594514
exploration/env_infos/initial/reward_dist Max            0.0155822
exploration/env_infos/initial/reward_dist Min            5.09772e-05
exploration/env_infos/reward_dist Mean                   0.185693
exploration/env_infos/reward_dist Std                    0.222742
exploration/env_infos/reward_dist Max                    0.955019
exploration/env_infos/reward_dist Min                    3.74725e-05
evaluation/num steps total                           74000
evaluation/num paths total                            3700
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0619646
evaluation/Rewards Std                                   0.0697668
evaluation/Rewards Max                                   0.168132
evaluation/Rewards Min                                  -0.406961
evaluation/Returns Mean                                 -1.23929
evaluation/Returns Std                                   1.02039
evaluation/Returns Max                                   1.59397
evaluation/Returns Min                                  -2.98384
evaluation/Actions Mean                                  0.00139744
evaluation/Actions Std                                   0.106609
evaluation/Actions Max                                   0.809296
evaluation/Actions Min                                  -0.892703
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.23929
evaluation/env_infos/final/reward_energy Mean           -0.0474235
evaluation/env_infos/final/reward_energy Std             0.0405123
evaluation/env_infos/final/reward_energy Max            -0.00747654
evaluation/env_infos/final/reward_energy Min            -0.176027
evaluation/env_infos/initial/reward_energy Mean         -0.269746
evaluation/env_infos/initial/reward_energy Std           0.269523
evaluation/env_infos/initial/reward_energy Max          -0.0113772
evaluation/env_infos/initial/reward_energy Min          -1.04557
evaluation/env_infos/reward_energy Mean                 -0.0816353
evaluation/env_infos/reward_energy Std                   0.126769
evaluation/env_infos/reward_energy Max                  -0.00295686
evaluation/env_infos/reward_energy Min                  -1.21407
evaluation/env_infos/final/end_effector_loc Mean         0.0275562
evaluation/env_infos/final/end_effector_loc Std          0.296648
evaluation/env_infos/final/end_effector_loc Max          0.833689
evaluation/env_infos/final/end_effector_loc Min         -0.628736
evaluation/env_infos/initial/end_effector_loc Mean       0.00173994
evaluation/env_infos/initial/end_effector_loc Std        0.013369
evaluation/env_infos/initial/end_effector_loc Max        0.0404648
evaluation/env_infos/initial/end_effector_loc Min       -0.0421142
evaluation/env_infos/end_effector_loc Mean               0.0176093
evaluation/env_infos/end_effector_loc Std                0.188601
evaluation/env_infos/end_effector_loc Max                0.833689
evaluation/env_infos/end_effector_loc Min               -0.628736
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0384092
evaluation/env_infos/final/reward_dist Std               0.0741858
evaluation/env_infos/final/reward_dist Max               0.282435
evaluation/env_infos/final/reward_dist Min               1.17138e-41
evaluation/env_infos/initial/reward_dist Mean            0.0033986
evaluation/env_infos/initial/reward_dist Std             0.00607473
evaluation/env_infos/initial/reward_dist Max             0.023732
evaluation/env_infos/initial/reward_dist Min             2.1232e-06
evaluation/env_infos/reward_dist Mean                    0.113179
evaluation/env_infos/reward_dist Std                     0.223895
evaluation/env_infos/reward_dist Max                     0.994932
evaluation/env_infos/reward_dist Min                     1.17138e-41
time/data storing (s)                                   32.4069
time/evaluation sampling (s)                             0.570186
time/exploration sampling (s)                            0.0877762
time/logging (s)                                         0.0185395
time/saving (s)                                          0.690922
time/training (s)                                       36.7719
time/epoch (s)                                          70.5462
time/total (s)                                        4099.35
Epoch                                                   73
---------------------------------------------------  ---------------
2021-05-29 01:05:23.154618 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 74 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00135496
trainer/QF2 Loss                                         0.000971058
trainer/Policy Loss                                      2.75503
trainer/Q1 Predictions Mean                             -0.685925
trainer/Q1 Predictions Std                               0.791529
trainer/Q1 Predictions Max                               1.41088
trainer/Q1 Predictions Min                              -3.39628
trainer/Q2 Predictions Mean                             -0.68238
trainer/Q2 Predictions Std                               0.786785
trainer/Q2 Predictions Max                               1.4426
trainer/Q2 Predictions Min                              -3.32937
trainer/Q Targets Mean                                  -0.68358
trainer/Q Targets Std                                    0.78871
trainer/Q Targets Max                                    1.41528
trainer/Q Targets Min                                   -3.37532
trainer/Log Pis Mean                                     2.07944
trainer/Log Pis Std                                      1.35168
trainer/Log Pis Max                                      4.75133
trainer/Log Pis Min                                     -1.9729
trainer/Policy mu Mean                                   0.0134382
trainer/Policy mu Std                                    0.315956
trainer/Policy mu Max                                    1.55735
trainer/Policy mu Min                                   -2.47671
trainer/Policy log std Mean                             -2.36247
trainer/Policy log std Std                               0.579438
trainer/Policy log std Max                              -0.534305
trainer/Policy log std Min                              -3.43139
trainer/Alpha                                            0.0169822
trainer/Alpha Loss                                       0.323788
exploration/num steps total                           8500
exploration/num paths total                            425
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0515824
exploration/Rewards Std                                  0.0655628
exploration/Rewards Max                                  0.0949905
exploration/Rewards Min                                 -0.225816
exploration/Returns Mean                                -1.03165
exploration/Returns Std                                  0.66398
exploration/Returns Max                                 -0.35126
exploration/Returns Min                                 -2.27075
exploration/Actions Mean                                 0.00610798
exploration/Actions Std                                  0.148951
exploration/Actions Max                                  0.491865
exploration/Actions Min                                 -0.680695
exploration/Num Paths                                    5
exploration/Average Returns                             -1.03165
exploration/env_infos/final/reward_energy Mean          -0.114795
exploration/env_infos/final/reward_energy Std            0.0418395
exploration/env_infos/final/reward_energy Max           -0.0616237
exploration/env_infos/final/reward_energy Min           -0.189499
exploration/env_infos/initial/reward_energy Mean        -0.330495
exploration/env_infos/initial/reward_energy Std          0.269143
exploration/env_infos/initial/reward_energy Max         -0.0138432
exploration/env_infos/initial/reward_energy Min         -0.700304
exploration/env_infos/reward_energy Mean                -0.16671
exploration/env_infos/reward_energy Std                  0.129055
exploration/env_infos/reward_energy Max                 -0.0138432
exploration/env_infos/reward_energy Min                 -0.700304
exploration/env_infos/final/end_effector_loc Mean       -0.0462097
exploration/env_infos/final/end_effector_loc Std         0.176328
exploration/env_infos/final/end_effector_loc Max         0.248622
exploration/env_infos/final/end_effector_loc Min        -0.292491
exploration/env_infos/initial/end_effector_loc Mean     -0.00451832
exploration/env_infos/initial/end_effector_loc Std       0.0143759
exploration/env_infos/initial/end_effector_loc Max       0.0230955
exploration/env_infos/initial/end_effector_loc Min      -0.0340347
exploration/env_infos/end_effector_loc Mean             -0.0606715
exploration/env_infos/end_effector_loc Std               0.125015
exploration/env_infos/end_effector_loc Max               0.260775
exploration/env_infos/end_effector_loc Min              -0.292491
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.113638
exploration/env_infos/final/reward_dist Std              0.215091
exploration/env_infos/final/reward_dist Max              0.54344
exploration/env_infos/final/reward_dist Min              9.25976e-14
exploration/env_infos/initial/reward_dist Mean           0.0365571
exploration/env_infos/initial/reward_dist Std            0.0428192
exploration/env_infos/initial/reward_dist Max            0.11439
exploration/env_infos/initial/reward_dist Min            0.00184398
exploration/env_infos/reward_dist Mean                   0.221677
exploration/env_infos/reward_dist Std                    0.281922
exploration/env_infos/reward_dist Max                    0.941354
exploration/env_infos/reward_dist Min                    5.3233e-14
evaluation/num steps total                           75000
evaluation/num paths total                            3750
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0575124
evaluation/Rewards Std                                   0.0828634
evaluation/Rewards Max                                   0.146958
evaluation/Rewards Min                                  -0.499436
evaluation/Returns Mean                                 -1.15025
evaluation/Returns Std                                   1.26282
evaluation/Returns Max                                   1.1979
evaluation/Returns Min                                  -5.12533
evaluation/Actions Mean                                  0.00284064
evaluation/Actions Std                                   0.0833852
evaluation/Actions Max                                   0.629043
evaluation/Actions Min                                  -0.785038
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.15025
evaluation/env_infos/final/reward_energy Mean           -0.0434437
evaluation/env_infos/final/reward_energy Std             0.0671758
evaluation/env_infos/final/reward_energy Max            -0.00143866
evaluation/env_infos/final/reward_energy Min            -0.455897
evaluation/env_infos/initial/reward_energy Mean         -0.231313
evaluation/env_infos/initial/reward_energy Std           0.251886
evaluation/env_infos/initial/reward_energy Max          -0.0143177
evaluation/env_infos/initial/reward_energy Min          -1.05395
evaluation/env_infos/reward_energy Mean                 -0.0661619
evaluation/env_infos/reward_energy Std                   0.0976981
evaluation/env_infos/reward_energy Max                  -0.000226528
evaluation/env_infos/reward_energy Min                  -1.05395
evaluation/env_infos/final/end_effector_loc Mean         0.0681396
evaluation/env_infos/final/end_effector_loc Std          0.292326
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00227715
evaluation/env_infos/initial/end_effector_loc Std        0.0118745
evaluation/env_infos/initial/end_effector_loc Max        0.0314521
evaluation/env_infos/initial/end_effector_loc Min       -0.0392519
evaluation/env_infos/end_effector_loc Mean               0.0402278
evaluation/env_infos/end_effector_loc Std                0.189768
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.100231
evaluation/env_infos/final/reward_dist Std               0.200722
evaluation/env_infos/final/reward_dist Max               0.857871
evaluation/env_infos/final/reward_dist Min               1.0906e-90
evaluation/env_infos/initial/reward_dist Mean            0.00586611
evaluation/env_infos/initial/reward_dist Std             0.0123172
evaluation/env_infos/initial/reward_dist Max             0.0744498
evaluation/env_infos/initial/reward_dist Min             4.8601e-06
evaluation/env_infos/reward_dist Mean                    0.110074
evaluation/env_infos/reward_dist Std                     0.222303
evaluation/env_infos/reward_dist Max                     0.998601
evaluation/env_infos/reward_dist Min                     1.0906e-90
time/data storing (s)                                   32.5582
time/evaluation sampling (s)                             0.638821
time/exploration sampling (s)                            0.0883818
time/logging (s)                                         0.0142771
time/saving (s)                                          0.688539
time/training (s)                                       36.1723
time/epoch (s)                                          70.1605
time/total (s)                                        4170.35
Epoch                                                   74
---------------------------------------------------  ---------------
2021-05-29 01:06:34.205540 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 75 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00097561
trainer/QF2 Loss                                         0.000841184
trainer/Policy Loss                                      2.42661
trainer/Q1 Predictions Mean                             -0.647397
trainer/Q1 Predictions Std                               0.86593
trainer/Q1 Predictions Max                               1.57581
trainer/Q1 Predictions Min                              -2.86822
trainer/Q2 Predictions Mean                             -0.637177
trainer/Q2 Predictions Std                               0.865931
trainer/Q2 Predictions Max                               1.59159
trainer/Q2 Predictions Min                              -2.83795
trainer/Q Targets Mean                                  -0.640055
trainer/Q Targets Std                                    0.872138
trainer/Q Targets Max                                    1.55511
trainer/Q Targets Min                                   -2.89294
trainer/Log Pis Mean                                     1.78351
trainer/Log Pis Std                                      1.31347
trainer/Log Pis Max                                      4.4328
trainer/Log Pis Min                                     -3.4135
trainer/Policy mu Mean                                   0.00114021
trainer/Policy mu Std                                    0.253593
trainer/Policy mu Max                                    1.41966
trainer/Policy mu Min                                   -1.75766
trainer/Policy log std Mean                             -2.28164
trainer/Policy log std Std                               0.515129
trainer/Policy log std Max                              -0.23225
trainer/Policy log std Min                              -3.37341
trainer/Alpha                                            0.0171583
trainer/Alpha Loss                                      -0.879315
exploration/num steps total                           8600
exploration/num paths total                            430
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.101583
exploration/Rewards Std                                  0.0904117
exploration/Rewards Max                                  0.0584191
exploration/Rewards Min                                 -0.289325
exploration/Returns Mean                                -2.03166
exploration/Returns Std                                  1.6202
exploration/Returns Max                                  0.234339
exploration/Returns Min                                 -3.73877
exploration/Actions Mean                                 0.00853523
exploration/Actions Std                                  0.15066
exploration/Actions Max                                  0.970117
exploration/Actions Min                                 -0.467023
exploration/Num Paths                                    5
exploration/Average Returns                             -2.03166
exploration/env_infos/final/reward_energy Mean          -0.150457
exploration/env_infos/final/reward_energy Std            0.0887345
exploration/env_infos/final/reward_energy Max           -0.02562
exploration/env_infos/final/reward_energy Min           -0.249212
exploration/env_infos/initial/reward_energy Mean        -0.410143
exploration/env_infos/initial/reward_energy Std          0.314698
exploration/env_infos/initial/reward_energy Max         -0.155618
exploration/env_infos/initial/reward_energy Min         -0.995181
exploration/env_infos/reward_energy Mean                -0.169788
exploration/env_infos/reward_energy Std                  0.129285
exploration/env_infos/reward_energy Max                 -0.0199113
exploration/env_infos/reward_energy Min                 -0.995181
exploration/env_infos/final/end_effector_loc Mean        0.0929549
exploration/env_infos/final/end_effector_loc Std         0.276001
exploration/env_infos/final/end_effector_loc Max         0.667143
exploration/env_infos/final/end_effector_loc Min        -0.233128
exploration/env_infos/initial/end_effector_loc Mean      0.00319465
exploration/env_infos/initial/end_effector_loc Std       0.0179961
exploration/env_infos/initial/end_effector_loc Max       0.0485058
exploration/env_infos/initial/end_effector_loc Min      -0.019802
exploration/env_infos/end_effector_loc Mean              0.0509372
exploration/env_infos/end_effector_loc Std               0.177363
exploration/env_infos/end_effector_loc Max               0.667143
exploration/env_infos/end_effector_loc Min              -0.233128
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0626184
exploration/env_infos/final/reward_dist Std              0.0784861
exploration/env_infos/final/reward_dist Max              0.186812
exploration/env_infos/final/reward_dist Min              7.34771e-24
exploration/env_infos/initial/reward_dist Mean           0.00133971
exploration/env_infos/initial/reward_dist Std            0.000833435
exploration/env_infos/initial/reward_dist Max            0.00219592
exploration/env_infos/initial/reward_dist Min            1.03772e-06
exploration/env_infos/reward_dist Mean                   0.18284
exploration/env_infos/reward_dist Std                    0.250776
exploration/env_infos/reward_dist Max                    0.874013
exploration/env_infos/reward_dist Min                    7.34771e-24
evaluation/num steps total                           76000
evaluation/num paths total                            3800
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0500601
evaluation/Rewards Std                                   0.0775813
evaluation/Rewards Max                                   0.151045
evaluation/Rewards Min                                  -0.470027
evaluation/Returns Mean                                 -1.0012
evaluation/Returns Std                                   1.22066
evaluation/Returns Max                                   1.6959
evaluation/Returns Min                                  -2.91197
evaluation/Actions Mean                                  0.000317072
evaluation/Actions Std                                   0.0714525
evaluation/Actions Max                                   0.769857
evaluation/Actions Min                                  -0.761538
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.0012
evaluation/env_infos/final/reward_energy Mean           -0.0408238
evaluation/env_infos/final/reward_energy Std             0.0301957
evaluation/env_infos/final/reward_energy Max            -0.0043813
evaluation/env_infos/final/reward_energy Min            -0.134448
evaluation/env_infos/initial/reward_energy Mean         -0.224972
evaluation/env_infos/initial/reward_energy Std           0.231979
evaluation/env_infos/initial/reward_energy Max          -0.0135548
evaluation/env_infos/initial/reward_energy Min          -1.03841
evaluation/env_infos/reward_energy Mean                 -0.0608533
evaluation/env_infos/reward_energy Std                   0.0806721
evaluation/env_infos/reward_energy Max                  -0.00078808
evaluation/env_infos/reward_energy Min                  -1.03841
evaluation/env_infos/final/end_effector_loc Mean         0.0154165
evaluation/env_infos/final/end_effector_loc Std          0.306262
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.752699
evaluation/env_infos/initial/end_effector_loc Mean       0.00183955
evaluation/env_infos/initial/end_effector_loc Std        0.011276
evaluation/env_infos/initial/end_effector_loc Max        0.0384929
evaluation/env_infos/initial/end_effector_loc Min       -0.0380769
evaluation/env_infos/end_effector_loc Mean               0.014009
evaluation/env_infos/end_effector_loc Std                0.192617
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.752699
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.118957
evaluation/env_infos/final/reward_dist Std               0.227797
evaluation/env_infos/final/reward_dist Max               0.982428
evaluation/env_infos/final/reward_dist Min               1.53251e-67
evaluation/env_infos/initial/reward_dist Mean            0.00665004
evaluation/env_infos/initial/reward_dist Std             0.0142354
evaluation/env_infos/initial/reward_dist Max             0.0901281
evaluation/env_infos/initial/reward_dist Min             2.42852e-06
evaluation/env_infos/reward_dist Mean                    0.149767
evaluation/env_infos/reward_dist Std                     0.239845
evaluation/env_infos/reward_dist Max                     0.996967
evaluation/env_infos/reward_dist Min                     8.90487e-68
time/data storing (s)                                   32.7482
time/evaluation sampling (s)                             0.68338
time/exploration sampling (s)                            0.0859948
time/logging (s)                                         0.0150235
time/saving (s)                                          0.761556
time/training (s)                                       35.9089
time/epoch (s)                                          70.203
time/total (s)                                        4241.39
Epoch                                                   75
---------------------------------------------------  ---------------
2021-05-29 01:07:45.804480 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 76 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.001005
trainer/QF2 Loss                                         0.000745379
trainer/Policy Loss                                      2.90019
trainer/Q1 Predictions Mean                             -0.743649
trainer/Q1 Predictions Std                               0.821115
trainer/Q1 Predictions Max                               1.04111
trainer/Q1 Predictions Min                              -2.93292
trainer/Q2 Predictions Mean                             -0.746834
trainer/Q2 Predictions Std                               0.83004
trainer/Q2 Predictions Max                               1.04007
trainer/Q2 Predictions Min                              -2.95223
trainer/Q Targets Mean                                  -0.74386
trainer/Q Targets Std                                    0.823562
trainer/Q Targets Max                                    1.07457
trainer/Q Targets Min                                   -2.93094
trainer/Log Pis Mean                                     2.15927
trainer/Log Pis Std                                      1.25938
trainer/Log Pis Max                                      4.7002
trainer/Log Pis Min                                     -2.82941
trainer/Policy mu Mean                                   0.00375532
trainer/Policy mu Std                                    0.263663
trainer/Policy mu Max                                    1.71617
trainer/Policy mu Min                                   -1.95919
trainer/Policy log std Mean                             -2.40256
trainer/Policy log std Std                               0.515752
trainer/Policy log std Max                              -0.457074
trainer/Policy log std Min                              -3.42964
trainer/Alpha                                            0.0164379
trainer/Alpha Loss                                       0.6544
exploration/num steps total                           8700
exploration/num paths total                            435
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.145418
exploration/Rewards Std                                  0.0990309
exploration/Rewards Max                                  0.00122362
exploration/Rewards Min                                 -0.57777
exploration/Returns Mean                                -2.90837
exploration/Returns Std                                  0.961506
exploration/Returns Max                                 -1.97248
exploration/Returns Min                                 -4.7281
exploration/Actions Mean                                 0.00110631
exploration/Actions Std                                  0.125347
exploration/Actions Max                                  0.415453
exploration/Actions Min                                 -0.608973
exploration/Num Paths                                    5
exploration/Average Returns                             -2.90837
exploration/env_infos/final/reward_energy Mean          -0.230806
exploration/env_infos/final/reward_energy Std            0.196397
exploration/env_infos/final/reward_energy Max           -0.0971444
exploration/env_infos/final/reward_energy Min           -0.610071
exploration/env_infos/initial/reward_energy Mean        -0.178798
exploration/env_infos/initial/reward_energy Std          0.121756
exploration/env_infos/initial/reward_energy Max         -0.0198914
exploration/env_infos/initial/reward_energy Min         -0.366527
exploration/env_infos/reward_energy Mean                -0.14072
exploration/env_infos/reward_energy Std                  0.107816
exploration/env_infos/reward_energy Max                 -0.0188566
exploration/env_infos/reward_energy Min                 -0.610071
exploration/env_infos/final/end_effector_loc Mean       -0.00238647
exploration/env_infos/final/end_effector_loc Std         0.305692
exploration/env_infos/final/end_effector_loc Max         0.501922
exploration/env_infos/final/end_effector_loc Min        -0.515388
exploration/env_infos/initial/end_effector_loc Mean     -0.000353077
exploration/env_infos/initial/end_effector_loc Std       0.00763981
exploration/env_infos/initial/end_effector_loc Max       0.0143618
exploration/env_infos/initial/end_effector_loc Min      -0.0128978
exploration/env_infos/end_effector_loc Mean             -0.0129742
exploration/env_infos/end_effector_loc Std               0.203724
exploration/env_infos/end_effector_loc Max               0.501922
exploration/env_infos/end_effector_loc Min              -0.515388
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.000298991
exploration/env_infos/final/reward_dist Std              0.000581712
exploration/env_infos/final/reward_dist Max              0.00146222
exploration/env_infos/final/reward_dist Min              8.413e-41
exploration/env_infos/initial/reward_dist Mean           0.0132123
exploration/env_infos/initial/reward_dist Std            0.0159609
exploration/env_infos/initial/reward_dist Max            0.0366031
exploration/env_infos/initial/reward_dist Min            7.40307e-06
exploration/env_infos/reward_dist Mean                   0.0440149
exploration/env_infos/reward_dist Std                    0.133418
exploration/env_infos/reward_dist Max                    0.700449
exploration/env_infos/reward_dist Min                    8.413e-41
evaluation/num steps total                           77000
evaluation/num paths total                            3850
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0582114
evaluation/Rewards Std                                   0.0792196
evaluation/Rewards Max                                   0.148957
evaluation/Rewards Min                                  -0.374328
evaluation/Returns Mean                                 -1.16423
evaluation/Returns Std                                   1.11388
evaluation/Returns Max                                   1.62951
evaluation/Returns Min                                  -3.25658
evaluation/Actions Mean                                  0.00610611
evaluation/Actions Std                                   0.0905038
evaluation/Actions Max                                   0.892247
evaluation/Actions Min                                  -0.668955
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.16423
evaluation/env_infos/final/reward_energy Mean           -0.0526482
evaluation/env_infos/final/reward_energy Std             0.0645298
evaluation/env_infos/final/reward_energy Max            -0.00264788
evaluation/env_infos/final/reward_energy Min            -0.369062
evaluation/env_infos/initial/reward_energy Mean         -0.280386
evaluation/env_infos/initial/reward_energy Std           0.255088
evaluation/env_infos/initial/reward_energy Max          -0.015902
evaluation/env_infos/initial/reward_energy Min          -1.06158
evaluation/env_infos/reward_energy Mean                 -0.0776202
evaluation/env_infos/reward_energy Std                   0.102135
evaluation/env_infos/reward_energy Max                  -0.00115503
evaluation/env_infos/reward_energy Min                  -1.06158
evaluation/env_infos/final/end_effector_loc Mean         0.0923741
evaluation/env_infos/final/end_effector_loc Std          0.310411
evaluation/env_infos/final/end_effector_loc Max          0.946854
evaluation/env_infos/final/end_effector_loc Min         -0.627116
evaluation/env_infos/initial/end_effector_loc Mean       0.00254551
evaluation/env_infos/initial/end_effector_loc Std        0.0131578
evaluation/env_infos/initial/end_effector_loc Max        0.0446124
evaluation/env_infos/initial/end_effector_loc Min       -0.0334478
evaluation/env_infos/end_effector_loc Mean               0.0457313
evaluation/env_infos/end_effector_loc Std                0.200058
evaluation/env_infos/end_effector_loc Max                0.946854
evaluation/env_infos/end_effector_loc Min               -0.627116
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.140499
evaluation/env_infos/final/reward_dist Std               0.247676
evaluation/env_infos/final/reward_dist Max               0.970231
evaluation/env_infos/final/reward_dist Min               3.67937e-82
evaluation/env_infos/initial/reward_dist Mean            0.00859822
evaluation/env_infos/initial/reward_dist Std             0.0136628
evaluation/env_infos/initial/reward_dist Max             0.0657815
evaluation/env_infos/initial/reward_dist Min             1.88297e-06
evaluation/env_infos/reward_dist Mean                    0.171769
evaluation/env_infos/reward_dist Std                     0.27431
evaluation/env_infos/reward_dist Max                     0.99559
evaluation/env_infos/reward_dist Min                     3.67937e-82
time/data storing (s)                                   32.9198
time/evaluation sampling (s)                             0.636945
time/exploration sampling (s)                            0.0856504
time/logging (s)                                         0.0148821
time/saving (s)                                          0.691187
time/training (s)                                       36.4454
time/epoch (s)                                          70.7939
time/total (s)                                        4312.99
Epoch                                                   76
---------------------------------------------------  ---------------
2021-05-29 01:08:58.071143 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 77 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.0010476
trainer/QF2 Loss                                         0.00103679
trainer/Policy Loss                                      2.64997
trainer/Q1 Predictions Mean                             -0.662189
trainer/Q1 Predictions Std                               0.730167
trainer/Q1 Predictions Max                               0.767648
trainer/Q1 Predictions Min                              -2.70177
trainer/Q2 Predictions Mean                             -0.671724
trainer/Q2 Predictions Std                               0.730811
trainer/Q2 Predictions Max                               0.778984
trainer/Q2 Predictions Min                              -2.69642
trainer/Q Targets Mean                                  -0.664695
trainer/Q Targets Std                                    0.73498
trainer/Q Targets Max                                    0.788892
trainer/Q Targets Min                                   -2.73058
trainer/Log Pis Mean                                     1.98926
trainer/Log Pis Std                                      1.18393
trainer/Log Pis Max                                      4.47635
trainer/Log Pis Min                                     -2.54035
trainer/Policy mu Mean                                   0.00294622
trainer/Policy mu Std                                    0.239823
trainer/Policy mu Max                                    1.52298
trainer/Policy mu Min                                   -1.80831
trainer/Policy log std Mean                             -2.34462
trainer/Policy log std Std                               0.498238
trainer/Policy log std Max                              -0.683204
trainer/Policy log std Min                              -3.31109
trainer/Alpha                                            0.0161387
trainer/Alpha Loss                                      -0.0442983
exploration/num steps total                           8800
exploration/num paths total                            440
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.062909
exploration/Rewards Std                                  0.0840232
exploration/Rewards Max                                  0.126264
exploration/Rewards Min                                 -0.361772
exploration/Returns Mean                                -1.25818
exploration/Returns Std                                  1.19005
exploration/Returns Max                                  0.455128
exploration/Returns Min                                 -3.13757
exploration/Actions Mean                                 0.00393022
exploration/Actions Std                                  0.0894544
exploration/Actions Max                                  0.312066
exploration/Actions Min                                 -0.314888
exploration/Num Paths                                    5
exploration/Average Returns                             -1.25818
exploration/env_infos/final/reward_energy Mean          -0.0803929
exploration/env_infos/final/reward_energy Std            0.0543133
exploration/env_infos/final/reward_energy Max           -0.0262506
exploration/env_infos/final/reward_energy Min           -0.158715
exploration/env_infos/initial/reward_energy Mean        -0.181718
exploration/env_infos/initial/reward_energy Std          0.154675
exploration/env_infos/initial/reward_energy Max         -0.0422455
exploration/env_infos/initial/reward_energy Min         -0.397692
exploration/env_infos/reward_energy Mean                -0.100747
exploration/env_infos/reward_energy Std                  0.076715
exploration/env_infos/reward_energy Max                 -0.0110412
exploration/env_infos/reward_energy Min                 -0.397692
exploration/env_infos/final/end_effector_loc Mean        0.013836
exploration/env_infos/final/end_effector_loc Std         0.296425
exploration/env_infos/final/end_effector_loc Max         0.486724
exploration/env_infos/final/end_effector_loc Min        -0.625182
exploration/env_infos/initial/end_effector_loc Mean     -0.000423194
exploration/env_infos/initial/end_effector_loc Std       0.00842634
exploration/env_infos/initial/end_effector_loc Max       0.0123679
exploration/env_infos/initial/end_effector_loc Min      -0.0157444
exploration/env_infos/end_effector_loc Mean              0.00611607
exploration/env_infos/end_effector_loc Std               0.174874
exploration/env_infos/end_effector_loc Max               0.486724
exploration/env_infos/end_effector_loc Min              -0.625182
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.191592
exploration/env_infos/final/reward_dist Std              0.336346
exploration/env_infos/final/reward_dist Max              0.859991
exploration/env_infos/final/reward_dist Min              7.07e-38
exploration/env_infos/initial/reward_dist Mean           0.00528066
exploration/env_infos/initial/reward_dist Std            0.00431947
exploration/env_infos/initial/reward_dist Max            0.0118054
exploration/env_infos/initial/reward_dist Min            1.42035e-06
exploration/env_infos/reward_dist Mean                   0.108791
exploration/env_infos/reward_dist Std                    0.20917
exploration/env_infos/reward_dist Max                    0.968602
exploration/env_infos/reward_dist Min                    7.07e-38
evaluation/num steps total                           78000
evaluation/num paths total                            3900
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0633364
evaluation/Rewards Std                                   0.0654929
evaluation/Rewards Max                                   0.18093
evaluation/Rewards Min                                  -0.33747
evaluation/Returns Mean                                 -1.26673
evaluation/Returns Std                                   1.00551
evaluation/Returns Max                                   1.00971
evaluation/Returns Min                                  -3.30755
evaluation/Actions Mean                                  0.00202898
evaluation/Actions Std                                   0.0921751
evaluation/Actions Max                                   0.902436
evaluation/Actions Min                                  -0.771427
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.26673
evaluation/env_infos/final/reward_energy Mean           -0.0468416
evaluation/env_infos/final/reward_energy Std             0.0361236
evaluation/env_infos/final/reward_energy Max            -0.0043838
evaluation/env_infos/final/reward_energy Min            -0.174436
evaluation/env_infos/initial/reward_energy Mean         -0.284936
evaluation/env_infos/initial/reward_energy Std           0.279696
evaluation/env_infos/initial/reward_energy Max          -0.0142959
evaluation/env_infos/initial/reward_energy Min          -1.08207
evaluation/env_infos/reward_energy Mean                 -0.0792809
evaluation/env_infos/reward_energy Std                   0.103515
evaluation/env_infos/reward_energy Max                  -0.000960978
evaluation/env_infos/reward_energy Min                  -1.08207
evaluation/env_infos/final/end_effector_loc Mean        -0.0114322
evaluation/env_infos/final/end_effector_loc Std          0.309893
evaluation/env_infos/final/end_effector_loc Max          0.934119
evaluation/env_infos/final/end_effector_loc Min         -0.612034
evaluation/env_infos/initial/end_effector_loc Mean      -0.000872507
evaluation/env_infos/initial/end_effector_loc Std        0.0140894
evaluation/env_infos/initial/end_effector_loc Max        0.0451218
evaluation/env_infos/initial/end_effector_loc Min       -0.0385713
evaluation/env_infos/end_effector_loc Mean              -0.0133366
evaluation/env_infos/end_effector_loc Std                0.200419
evaluation/env_infos/end_effector_loc Max                0.934119
evaluation/env_infos/end_effector_loc Min               -0.612034
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.100506
evaluation/env_infos/final/reward_dist Std               0.210762
evaluation/env_infos/final/reward_dist Max               0.917629
evaluation/env_infos/final/reward_dist Min               4.17468e-57
evaluation/env_infos/initial/reward_dist Mean            0.00295702
evaluation/env_infos/initial/reward_dist Std             0.00802408
evaluation/env_infos/initial/reward_dist Max             0.0553523
evaluation/env_infos/initial/reward_dist Min             2.81886e-06
evaluation/env_infos/reward_dist Mean                    0.129106
evaluation/env_infos/reward_dist Std                     0.228173
evaluation/env_infos/reward_dist Max                     0.999806
evaluation/env_infos/reward_dist Min                     4.17468e-57
time/data storing (s)                                   33.6077
time/evaluation sampling (s)                             0.649263
time/exploration sampling (s)                            0.0880143
time/logging (s)                                         0.014887
time/saving (s)                                          0.701217
time/training (s)                                       36.3688
time/epoch (s)                                          71.4298
time/total (s)                                        4385.25
Epoch                                                   77
---------------------------------------------------  ---------------
2021-05-29 01:10:10.230828 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 78 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00143014
trainer/QF2 Loss                                         0.00147713
trainer/Policy Loss                                      2.72444
trainer/Q1 Predictions Mean                             -0.762098
trainer/Q1 Predictions Std                               0.801018
trainer/Q1 Predictions Max                               1.84137
trainer/Q1 Predictions Min                              -3.3236
trainer/Q2 Predictions Mean                             -0.759473
trainer/Q2 Predictions Std                               0.802816
trainer/Q2 Predictions Max                               1.8178
trainer/Q2 Predictions Min                              -3.43814
trainer/Q Targets Mean                                  -0.765011
trainer/Q Targets Std                                    0.806883
trainer/Q Targets Max                                    1.83424
trainer/Q Targets Min                                   -3.41691
trainer/Log Pis Mean                                     1.9657
trainer/Log Pis Std                                      1.39756
trainer/Log Pis Max                                      4.64151
trainer/Log Pis Min                                     -3.26681
trainer/Policy mu Mean                                   0.00117408
trainer/Policy mu Std                                    0.214279
trainer/Policy mu Max                                    1.97571
trainer/Policy mu Min                                   -1.80265
trainer/Policy log std Mean                             -2.33784
trainer/Policy log std Std                               0.507993
trainer/Policy log std Max                              -0.435548
trainer/Policy log std Min                              -3.33212
trainer/Alpha                                            0.0156037
trainer/Alpha Loss                                      -0.142677
exploration/num steps total                           8900
exploration/num paths total                            445
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0937383
exploration/Rewards Std                                  0.0685495
exploration/Rewards Max                                  0.094613
exploration/Rewards Min                                 -0.391431
exploration/Returns Mean                                -1.87477
exploration/Returns Std                                  0.809875
exploration/Returns Max                                 -0.422659
exploration/Returns Min                                 -2.60648
exploration/Actions Mean                                 0.00110918
exploration/Actions Std                                  0.123472
exploration/Actions Max                                  0.534851
exploration/Actions Min                                 -0.49111
exploration/Num Paths                                    5
exploration/Average Returns                             -1.87477
exploration/env_infos/final/reward_energy Mean          -0.118165
exploration/env_infos/final/reward_energy Std            0.0620914
exploration/env_infos/final/reward_energy Max           -0.0332113
exploration/env_infos/final/reward_energy Min           -0.20324
exploration/env_infos/initial/reward_energy Mean        -0.329084
exploration/env_infos/initial/reward_energy Std          0.206094
exploration/env_infos/initial/reward_energy Max         -0.0466078
exploration/env_infos/initial/reward_energy Min         -0.558133
exploration/env_infos/reward_energy Mean                -0.131933
exploration/env_infos/reward_energy Std                  0.114397
exploration/env_infos/reward_energy Max                 -0.011526
exploration/env_infos/reward_energy Min                 -0.569504
exploration/env_infos/final/end_effector_loc Mean       -0.112387
exploration/env_infos/final/end_effector_loc Std         0.275923
exploration/env_infos/final/end_effector_loc Max         0.263152
exploration/env_infos/final/end_effector_loc Min        -0.669671
exploration/env_infos/initial/end_effector_loc Mean     -0.00422218
exploration/env_infos/initial/end_effector_loc Std       0.0130628
exploration/env_infos/initial/end_effector_loc Max       0.0188165
exploration/env_infos/initial/end_effector_loc Min      -0.0245555
exploration/env_infos/end_effector_loc Mean             -0.0780488
exploration/env_infos/end_effector_loc Std               0.183106
exploration/env_infos/end_effector_loc Max               0.263152
exploration/env_infos/end_effector_loc Min              -0.669671
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.100324
exploration/env_infos/final/reward_dist Std              0.127104
exploration/env_infos/final/reward_dist Max              0.342152
exploration/env_infos/final/reward_dist Min              4.83091e-15
exploration/env_infos/initial/reward_dist Mean           0.00240302
exploration/env_infos/initial/reward_dist Std            0.00475726
exploration/env_infos/initial/reward_dist Max            0.0119175
exploration/env_infos/initial/reward_dist Min            8.43546e-06
exploration/env_infos/reward_dist Mean                   0.104947
exploration/env_infos/reward_dist Std                    0.142404
exploration/env_infos/reward_dist Max                    0.647724
exploration/env_infos/reward_dist Min                    4.83091e-15
evaluation/num steps total                           79000
evaluation/num paths total                            3950
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0438685
evaluation/Rewards Std                                   0.0701665
evaluation/Rewards Max                                   0.150892
evaluation/Rewards Min                                  -0.380177
evaluation/Returns Mean                                 -0.877369
evaluation/Returns Std                                   1.0738
evaluation/Returns Max                                   1.81641
evaluation/Returns Min                                  -2.81153
evaluation/Actions Mean                                  0.00271866
evaluation/Actions Std                                   0.0938112
evaluation/Actions Max                                   0.785666
evaluation/Actions Min                                  -0.737362
evaluation/Num Paths                                    50
evaluation/Average Returns                              -0.877369
evaluation/env_infos/final/reward_energy Mean           -0.0561194
evaluation/env_infos/final/reward_energy Std             0.0586996
evaluation/env_infos/final/reward_energy Max            -0.010029
evaluation/env_infos/final/reward_energy Min            -0.397071
evaluation/env_infos/initial/reward_energy Mean         -0.281874
evaluation/env_infos/initial/reward_energy Std           0.277565
evaluation/env_infos/initial/reward_energy Max          -0.0213266
evaluation/env_infos/initial/reward_energy Min          -1.03605
evaluation/env_infos/reward_energy Mean                 -0.0809261
evaluation/env_infos/reward_energy Std                   0.105199
evaluation/env_infos/reward_energy Max                  -0.000910975
evaluation/env_infos/reward_energy Min                  -1.03605
evaluation/env_infos/final/end_effector_loc Mean         0.003339
evaluation/env_infos/final/end_effector_loc Std          0.304947
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.000622222
evaluation/env_infos/initial/end_effector_loc Std        0.0139725
evaluation/env_infos/initial/end_effector_loc Max        0.0392833
evaluation/env_infos/initial/end_effector_loc Min       -0.0368681
evaluation/env_infos/end_effector_loc Mean              -0.00058954
evaluation/env_infos/end_effector_loc Std                0.203004
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.119247
evaluation/env_infos/final/reward_dist Std               0.234633
evaluation/env_infos/final/reward_dist Max               0.994293
evaluation/env_infos/final/reward_dist Min               3.69266e-88
evaluation/env_infos/initial/reward_dist Mean            0.00728898
evaluation/env_infos/initial/reward_dist Std             0.011505
evaluation/env_infos/initial/reward_dist Max             0.0490987
evaluation/env_infos/initial/reward_dist Min             2.29487e-06
evaluation/env_infos/reward_dist Mean                    0.160211
evaluation/env_infos/reward_dist Std                     0.25873
evaluation/env_infos/reward_dist Max                     0.999422
evaluation/env_infos/reward_dist Min                     3.69266e-88
time/data storing (s)                                   33.618
time/evaluation sampling (s)                             0.64327
time/exploration sampling (s)                            0.0861216
time/logging (s)                                         0.0149497
time/saving (s)                                          0.711377
time/training (s)                                       36.2034
time/epoch (s)                                          71.2771
time/total (s)                                        4457.41
Epoch                                                   78
---------------------------------------------------  ---------------
2021-05-29 01:11:23.066894 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 79 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00085006
trainer/QF2 Loss                                         0.00301023
trainer/Policy Loss                                      2.72869
trainer/Q1 Predictions Mean                             -0.817209
trainer/Q1 Predictions Std                               0.748872
trainer/Q1 Predictions Max                               0.638347
trainer/Q1 Predictions Min                              -3.18331
trainer/Q2 Predictions Mean                             -0.806021
trainer/Q2 Predictions Std                               0.750228
trainer/Q2 Predictions Max                               0.68038
trainer/Q2 Predictions Min                              -3.19954
trainer/Q Targets Mean                                  -0.809679
trainer/Q Targets Std                                    0.744812
trainer/Q Targets Max                                    0.688569
trainer/Q Targets Min                                   -3.16056
trainer/Log Pis Mean                                     1.91605
trainer/Log Pis Std                                      1.30562
trainer/Log Pis Max                                      4.2427
trainer/Log Pis Min                                     -3.04253
trainer/Policy mu Mean                                   0.0297549
trainer/Policy mu Std                                    0.302838
trainer/Policy mu Max                                    2.10847
trainer/Policy mu Min                                   -1.09647
trainer/Policy log std Mean                             -2.28694
trainer/Policy log std Std                               0.551881
trainer/Policy log std Max                               0.311102
trainer/Policy log std Min                              -3.37741
trainer/Alpha                                            0.0159703
trainer/Alpha Loss                                      -0.347219
exploration/num steps total                           9000
exploration/num paths total                            450
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0633436
exploration/Rewards Std                                  0.0763857
exploration/Rewards Max                                  0.0882812
exploration/Rewards Min                                 -0.204972
exploration/Returns Mean                                -1.26687
exploration/Returns Std                                  1.23267
exploration/Returns Max                                  0.65889
exploration/Returns Min                                 -3.22067
exploration/Actions Mean                                 0.00740137
exploration/Actions Std                                  0.167028
exploration/Actions Max                                  0.788585
exploration/Actions Min                                 -0.639728
exploration/Num Paths                                    5
exploration/Average Returns                             -1.26687
exploration/env_infos/final/reward_energy Mean          -0.10385
exploration/env_infos/final/reward_energy Std            0.057109
exploration/env_infos/final/reward_energy Max           -0.050458
exploration/env_infos/final/reward_energy Min           -0.213187
exploration/env_infos/initial/reward_energy Mean        -0.474211
exploration/env_infos/initial/reward_energy Std          0.362708
exploration/env_infos/initial/reward_energy Max         -0.0386226
exploration/env_infos/initial/reward_energy Min         -0.988274
exploration/env_infos/reward_energy Mean                -0.176792
exploration/env_infos/reward_energy Std                  0.157005
exploration/env_infos/reward_energy Max                 -0.00259383
exploration/env_infos/reward_energy Min                 -0.988274
exploration/env_infos/final/end_effector_loc Mean       -0.125622
exploration/env_infos/final/end_effector_loc Std         0.196902
exploration/env_infos/final/end_effector_loc Max         0.078077
exploration/env_infos/final/end_effector_loc Min        -0.592957
exploration/env_infos/initial/end_effector_loc Mean     -0.00773234
exploration/env_infos/initial/end_effector_loc Std       0.0196406
exploration/env_infos/initial/end_effector_loc Max       0.0394292
exploration/env_infos/initial/end_effector_loc Min      -0.0310861
exploration/env_infos/end_effector_loc Mean             -0.110282
exploration/env_infos/end_effector_loc Std               0.165036
exploration/env_infos/end_effector_loc Max               0.234858
exploration/env_infos/end_effector_loc Min              -0.592957
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.161925
exploration/env_infos/final/reward_dist Std              0.249742
exploration/env_infos/final/reward_dist Max              0.64686
exploration/env_infos/final/reward_dist Min              1.21535e-07
exploration/env_infos/initial/reward_dist Mean           0.00419578
exploration/env_infos/initial/reward_dist Std            0.00785545
exploration/env_infos/initial/reward_dist Max            0.0198888
exploration/env_infos/initial/reward_dist Min            1.16088e-06
exploration/env_infos/reward_dist Mean                   0.108776
exploration/env_infos/reward_dist Std                    0.211711
exploration/env_infos/reward_dist Max                    0.844923
exploration/env_infos/reward_dist Min                    1.21535e-07
evaluation/num steps total                           80000
evaluation/num paths total                            4000
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0574312
evaluation/Rewards Std                                   0.0694114
evaluation/Rewards Max                                   0.135596
evaluation/Rewards Min                                  -0.293676
evaluation/Returns Mean                                 -1.14862
evaluation/Returns Std                                   1.09385
evaluation/Returns Max                                   1.14204
evaluation/Returns Min                                  -3.55403
evaluation/Actions Mean                                  0.00238091
evaluation/Actions Std                                   0.0774505
evaluation/Actions Max                                   0.776663
evaluation/Actions Min                                  -0.608892
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.14862
evaluation/env_infos/final/reward_energy Mean           -0.0653769
evaluation/env_infos/final/reward_energy Std             0.0565076
evaluation/env_infos/final/reward_energy Max            -0.00510461
evaluation/env_infos/final/reward_energy Min            -0.348788
evaluation/env_infos/initial/reward_energy Mean         -0.1973
evaluation/env_infos/initial/reward_energy Std           0.209539
evaluation/env_infos/initial/reward_energy Max          -0.0119007
evaluation/env_infos/initial/reward_energy Min          -1.03938
evaluation/env_infos/reward_energy Mean                 -0.0715498
evaluation/env_infos/reward_energy Std                   0.0830007
evaluation/env_infos/reward_energy Max                  -0.00116856
evaluation/env_infos/reward_energy Min                  -1.03938
evaluation/env_infos/final/end_effector_loc Mean         0.0179948
evaluation/env_infos/final/end_effector_loc Std          0.273465
evaluation/env_infos/final/end_effector_loc Max          0.763247
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00150931
evaluation/env_infos/initial/end_effector_loc Std        0.010063
evaluation/env_infos/initial/end_effector_loc Max        0.0388331
evaluation/env_infos/initial/end_effector_loc Min       -0.0304446
evaluation/env_infos/end_effector_loc Mean               0.0109072
evaluation/env_infos/end_effector_loc Std                0.174119
evaluation/env_infos/end_effector_loc Max                0.763247
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.12347
evaluation/env_infos/final/reward_dist Std               0.216263
evaluation/env_infos/final/reward_dist Max               0.930409
evaluation/env_infos/final/reward_dist Min               9.34746e-65
evaluation/env_infos/initial/reward_dist Mean            0.00777667
evaluation/env_infos/initial/reward_dist Std             0.0148152
evaluation/env_infos/initial/reward_dist Max             0.0681545
evaluation/env_infos/initial/reward_dist Min             1.25527e-06
evaluation/env_infos/reward_dist Mean                    0.150768
evaluation/env_infos/reward_dist Std                     0.249167
evaluation/env_infos/reward_dist Max                     0.999035
evaluation/env_infos/reward_dist Min                     9.34746e-65
time/data storing (s)                                   34.4284
time/evaluation sampling (s)                             0.642231
time/exploration sampling (s)                            0.0904471
time/logging (s)                                         0.0153496
time/saving (s)                                          0.729295
time/training (s)                                       36.0519
time/epoch (s)                                          71.9577
time/total (s)                                        4530.24
Epoch                                                   79
---------------------------------------------------  ---------------
2021-05-29 01:12:36.143077 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 80 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00129202
trainer/QF2 Loss                                         0.00125967
trainer/Policy Loss                                      2.54404
trainer/Q1 Predictions Mean                             -0.675244
trainer/Q1 Predictions Std                               0.708479
trainer/Q1 Predictions Max                               0.772456
trainer/Q1 Predictions Min                              -3.51275
trainer/Q2 Predictions Mean                             -0.670006
trainer/Q2 Predictions Std                               0.711888
trainer/Q2 Predictions Max                               0.755748
trainer/Q2 Predictions Min                              -3.52642
trainer/Q Targets Mean                                  -0.671469
trainer/Q Targets Std                                    0.714023
trainer/Q Targets Max                                    0.761583
trainer/Q Targets Min                                   -3.52385
trainer/Log Pis Mean                                     1.87998
trainer/Log Pis Std                                      1.2832
trainer/Log Pis Max                                      4.59396
trainer/Log Pis Min                                     -1.78677
trainer/Policy mu Mean                                   0.0426618
trainer/Policy mu Std                                    0.339679
trainer/Policy mu Max                                    2.45519
trainer/Policy mu Min                                   -2.44838
trainer/Policy log std Mean                             -2.27108
trainer/Policy log std Std                               0.575823
trainer/Policy log std Max                               0.186016
trainer/Policy log std Min                              -3.39826
trainer/Alpha                                            0.015277
trainer/Alpha Loss                                      -0.5018
exploration/num steps total                           9100
exploration/num paths total                            455
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0659873
exploration/Rewards Std                                  0.0904867
exploration/Rewards Max                                  0.155201
exploration/Rewards Min                                 -0.3296
exploration/Returns Mean                                -1.31975
exploration/Returns Std                                  1.40412
exploration/Returns Max                                  0.421202
exploration/Returns Min                                 -3.17307
exploration/Actions Mean                                -0.000359817
exploration/Actions Std                                  0.151814
exploration/Actions Max                                  0.499722
exploration/Actions Min                                 -0.500581
exploration/Num Paths                                    5
exploration/Average Returns                             -1.31975
exploration/env_infos/final/reward_energy Mean          -0.166077
exploration/env_infos/final/reward_energy Std            0.114905
exploration/env_infos/final/reward_energy Max           -0.046771
exploration/env_infos/final/reward_energy Min           -0.347972
exploration/env_infos/initial/reward_energy Mean        -0.352364
exploration/env_infos/initial/reward_energy Std          0.216834
exploration/env_infos/initial/reward_energy Max         -0.108065
exploration/env_infos/initial/reward_energy Min         -0.633306
exploration/env_infos/reward_energy Mean                -0.1728
exploration/env_infos/reward_energy Std                  0.127419
exploration/env_infos/reward_energy Max                 -0.0171343
exploration/env_infos/reward_energy Min                 -0.633306
exploration/env_infos/final/end_effector_loc Mean        0.0396497
exploration/env_infos/final/end_effector_loc Std         0.222638
exploration/env_infos/final/end_effector_loc Max         0.430107
exploration/env_infos/final/end_effector_loc Min        -0.251518
exploration/env_infos/initial/end_effector_loc Mean     -0.000820836
exploration/env_infos/initial/end_effector_loc Std       0.0146047
exploration/env_infos/initial/end_effector_loc Max       0.0249861
exploration/env_infos/initial/end_effector_loc Min      -0.0239896
exploration/env_infos/end_effector_loc Mean              0.025119
exploration/env_infos/end_effector_loc Std               0.142795
exploration/env_infos/end_effector_loc Max               0.430107
exploration/env_infos/end_effector_loc Min              -0.251518
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.289122
exploration/env_infos/final/reward_dist Std              0.261183
exploration/env_infos/final/reward_dist Max              0.682684
exploration/env_infos/final/reward_dist Min              2.63703e-14
exploration/env_infos/initial/reward_dist Mean           0.0220296
exploration/env_infos/initial/reward_dist Std            0.0349868
exploration/env_infos/initial/reward_dist Max            0.0917492
exploration/env_infos/initial/reward_dist Min            3.86051e-06
exploration/env_infos/reward_dist Mean                   0.205629
exploration/env_infos/reward_dist Std                    0.276501
exploration/env_infos/reward_dist Max                    0.929661
exploration/env_infos/reward_dist Min                    2.63703e-14
evaluation/num steps total                           81000
evaluation/num paths total                            4050
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0651027
evaluation/Rewards Std                                   0.0859392
evaluation/Rewards Max                                   0.130175
evaluation/Rewards Min                                  -0.446214
evaluation/Returns Mean                                 -1.30205
evaluation/Returns Std                                   1.33749
evaluation/Returns Max                                   1.17636
evaluation/Returns Min                                  -4.05196
evaluation/Actions Mean                                 -0.0031893
evaluation/Actions Std                                   0.0831478
evaluation/Actions Max                                   0.777052
evaluation/Actions Min                                  -0.710703
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.30205
evaluation/env_infos/final/reward_energy Mean           -0.0811191
evaluation/env_infos/final/reward_energy Std             0.0618591
evaluation/env_infos/final/reward_energy Max            -0.00609077
evaluation/env_infos/final/reward_energy Min            -0.228174
evaluation/env_infos/initial/reward_energy Mean         -0.247419
evaluation/env_infos/initial/reward_energy Std           0.213987
evaluation/env_infos/initial/reward_energy Max          -0.00583778
evaluation/env_infos/initial/reward_energy Min          -0.877393
evaluation/env_infos/reward_energy Mean                 -0.0808663
evaluation/env_infos/reward_energy Std                   0.0854873
evaluation/env_infos/reward_energy Max                  -0.00121684
evaluation/env_infos/reward_energy Min                  -0.877393
evaluation/env_infos/final/end_effector_loc Mean        -0.01933
evaluation/env_infos/final/end_effector_loc Std          0.269437
evaluation/env_infos/final/end_effector_loc Max          0.646588
evaluation/env_infos/final/end_effector_loc Min         -0.699888
evaluation/env_infos/initial/end_effector_loc Mean       0.00204858
evaluation/env_infos/initial/end_effector_loc Std        0.0113825
evaluation/env_infos/initial/end_effector_loc Max        0.0388526
evaluation/env_infos/initial/end_effector_loc Min       -0.0355352
evaluation/env_infos/end_effector_loc Mean              -0.00212098
evaluation/env_infos/end_effector_loc Std                0.172305
evaluation/env_infos/end_effector_loc Max                0.646588
evaluation/env_infos/end_effector_loc Min               -0.699888
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.1621
evaluation/env_infos/final/reward_dist Std               0.270211
evaluation/env_infos/final/reward_dist Max               0.971687
evaluation/env_infos/final/reward_dist Min               1.99748e-42
evaluation/env_infos/initial/reward_dist Mean            0.00996637
evaluation/env_infos/initial/reward_dist Std             0.0185949
evaluation/env_infos/initial/reward_dist Max             0.0813148
evaluation/env_infos/initial/reward_dist Min             1.81086e-06
evaluation/env_infos/reward_dist Mean                    0.190441
evaluation/env_infos/reward_dist Std                     0.277501
evaluation/env_infos/reward_dist Max                     0.994462
evaluation/env_infos/reward_dist Min                     1.99748e-42
time/data storing (s)                                   34.4924
time/evaluation sampling (s)                             0.650211
time/exploration sampling (s)                            0.0869226
time/logging (s)                                         0.0154372
time/saving (s)                                          0.727796
time/training (s)                                       36.1805
time/epoch (s)                                          72.1533
time/total (s)                                        4603.31
Epoch                                                   80
---------------------------------------------------  ---------------
2021-05-29 01:13:50.362946 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 81 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00116795
trainer/QF2 Loss                                         0.00087288
trainer/Policy Loss                                      2.73949
trainer/Q1 Predictions Mean                             -0.75418
trainer/Q1 Predictions Std                               0.75334
trainer/Q1 Predictions Max                               0.644568
trainer/Q1 Predictions Min                              -3.53374
trainer/Q2 Predictions Mean                             -0.75366
trainer/Q2 Predictions Std                               0.754999
trainer/Q2 Predictions Max                               0.593094
trainer/Q2 Predictions Min                              -3.62816
trainer/Q Targets Mean                                  -0.749968
trainer/Q Targets Std                                    0.758502
trainer/Q Targets Max                                    0.615031
trainer/Q Targets Min                                   -3.54086
trainer/Log Pis Mean                                     2.00179
trainer/Log Pis Std                                      1.37179
trainer/Log Pis Max                                      4.73854
trainer/Log Pis Min                                     -3.97311
trainer/Policy mu Mean                                   0.0187034
trainer/Policy mu Std                                    0.353973
trainer/Policy mu Max                                    1.95652
trainer/Policy mu Min                                   -2.08269
trainer/Policy log std Mean                             -2.31145
trainer/Policy log std Std                               0.584695
trainer/Policy log std Max                              -0.0969368
trainer/Policy log std Min                              -3.42751
trainer/Alpha                                            0.0140738
trainer/Alpha Loss                                       0.0076248
exploration/num steps total                           9200
exploration/num paths total                            460
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.110788
exploration/Rewards Std                                  0.0796969
exploration/Rewards Max                                  0.0114043
exploration/Rewards Min                                 -0.361403
exploration/Returns Mean                                -2.21575
exploration/Returns Std                                  1.17456
exploration/Returns Max                                 -0.994525
exploration/Returns Min                                 -4.37395
exploration/Actions Mean                                 0.0132859
exploration/Actions Std                                  0.103555
exploration/Actions Max                                  0.475204
exploration/Actions Min                                 -0.262832
exploration/Num Paths                                    5
exploration/Average Returns                             -2.21575
exploration/env_infos/final/reward_energy Mean          -0.124555
exploration/env_infos/final/reward_energy Std            0.0511973
exploration/env_infos/final/reward_energy Max           -0.0531326
exploration/env_infos/final/reward_energy Min           -0.212509
exploration/env_infos/initial/reward_energy Mean        -0.216763
exploration/env_infos/initial/reward_energy Std          0.210822
exploration/env_infos/initial/reward_energy Max         -0.0291482
exploration/env_infos/initial/reward_energy Min         -0.627378
exploration/env_infos/reward_energy Mean                -0.112852
exploration/env_infos/reward_energy Std                  0.0952074
exploration/env_infos/reward_energy Max                 -0.00862265
exploration/env_infos/reward_energy Min                 -0.627378
exploration/env_infos/final/end_effector_loc Mean        0.226865
exploration/env_infos/final/end_effector_loc Std         0.265168
exploration/env_infos/final/end_effector_loc Max         0.572859
exploration/env_infos/final/end_effector_loc Min        -0.166003
exploration/env_infos/initial/end_effector_loc Mean      0.00552211
exploration/env_infos/initial/end_effector_loc Std       0.00915405
exploration/env_infos/initial/end_effector_loc Max       0.0237602
exploration/env_infos/initial/end_effector_loc Min      -0.00592106
exploration/env_infos/end_effector_loc Mean              0.124413
exploration/env_infos/end_effector_loc Std               0.178614
exploration/env_infos/end_effector_loc Max               0.572859
exploration/env_infos/end_effector_loc Min              -0.166003
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.044984
exploration/env_infos/final/reward_dist Std              0.0899353
exploration/env_infos/final/reward_dist Max              0.224855
exploration/env_infos/final/reward_dist Min              2.09901e-25
exploration/env_infos/initial/reward_dist Mean           0.0185967
exploration/env_infos/initial/reward_dist Std            0.0298821
exploration/env_infos/initial/reward_dist Max            0.0775155
exploration/env_infos/initial/reward_dist Min            1.65715e-05
exploration/env_infos/reward_dist Mean                   0.0854217
exploration/env_infos/reward_dist Std                    0.154493
exploration/env_infos/reward_dist Max                    0.852214
exploration/env_infos/reward_dist Min                    2.09901e-25
evaluation/num steps total                           82000
evaluation/num paths total                            4100
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0401398
evaluation/Rewards Std                                   0.0751583
evaluation/Rewards Max                                   0.169276
evaluation/Rewards Min                                  -0.311653
evaluation/Returns Mean                                 -0.802797
evaluation/Returns Std                                   1.24609
evaluation/Returns Max                                   2.17919
evaluation/Returns Min                                  -3.40565
evaluation/Actions Mean                                 -0.00219459
evaluation/Actions Std                                   0.076756
evaluation/Actions Max                                   0.560863
evaluation/Actions Min                                  -0.710973
evaluation/Num Paths                                    50
evaluation/Average Returns                              -0.802797
evaluation/env_infos/final/reward_energy Mean           -0.0643654
evaluation/env_infos/final/reward_energy Std             0.0543749
evaluation/env_infos/final/reward_energy Max            -0.00882762
evaluation/env_infos/final/reward_energy Min            -0.330995
evaluation/env_infos/initial/reward_energy Mean         -0.225478
evaluation/env_infos/initial/reward_energy Std           0.212386
evaluation/env_infos/initial/reward_energy Max          -0.0118841
evaluation/env_infos/initial/reward_energy Min          -0.927761
evaluation/env_infos/reward_energy Mean                 -0.0696867
evaluation/env_infos/reward_energy Std                   0.0832848
evaluation/env_infos/reward_energy Max                  -0.00153853
evaluation/env_infos/reward_energy Min                  -0.927761
evaluation/env_infos/final/end_effector_loc Mean        -0.0403188
evaluation/env_infos/final/end_effector_loc Std          0.282122
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00163221
evaluation/env_infos/initial/end_effector_loc Std        0.0108292
evaluation/env_infos/initial/end_effector_loc Max        0.0280432
evaluation/env_infos/initial/end_effector_loc Min       -0.0355486
evaluation/env_infos/end_effector_loc Mean              -0.0221449
evaluation/env_infos/end_effector_loc Std                0.172263
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.116315
evaluation/env_infos/final/reward_dist Std               0.201283
evaluation/env_infos/final/reward_dist Max               0.88904
evaluation/env_infos/final/reward_dist Min               7.64118e-60
evaluation/env_infos/initial/reward_dist Mean            0.00537389
evaluation/env_infos/initial/reward_dist Std             0.010462
evaluation/env_infos/initial/reward_dist Max             0.0588705
evaluation/env_infos/initial/reward_dist Min             1.33529e-06
evaluation/env_infos/reward_dist Mean                    0.169088
evaluation/env_infos/reward_dist Std                     0.260052
evaluation/env_infos/reward_dist Max                     0.99874
evaluation/env_infos/reward_dist Min                     7.64118e-60
time/data storing (s)                                   35.0329
time/evaluation sampling (s)                             0.652339
time/exploration sampling (s)                            0.0954097
time/logging (s)                                         0.0172229
time/saving (s)                                          0.759858
time/training (s)                                       36.6406
time/epoch (s)                                          73.1983
time/total (s)                                        4677.53
Epoch                                                   81
---------------------------------------------------  ---------------
2021-05-29 01:15:06.652306 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 82 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00128951
trainer/QF2 Loss                                         0.0017642
trainer/Policy Loss                                      2.66546
trainer/Q1 Predictions Mean                             -0.753843
trainer/Q1 Predictions Std                               0.722489
trainer/Q1 Predictions Max                               0.544744
trainer/Q1 Predictions Min                              -2.89366
trainer/Q2 Predictions Mean                             -0.745239
trainer/Q2 Predictions Std                               0.716693
trainer/Q2 Predictions Max                               0.566331
trainer/Q2 Predictions Min                              -2.8713
trainer/Q Targets Mean                                  -0.760898
trainer/Q Targets Std                                    0.722717
trainer/Q Targets Max                                    0.543761
trainer/Q Targets Min                                   -2.85675
trainer/Log Pis Mean                                     1.9204
trainer/Log Pis Std                                      1.40778
trainer/Log Pis Max                                      4.91847
trainer/Log Pis Min                                     -4.49688
trainer/Policy mu Mean                                   0.0182233
trainer/Policy mu Std                                    0.350199
trainer/Policy mu Max                                    1.99267
trainer/Policy mu Min                                   -2.15994
trainer/Policy log std Mean                             -2.27226
trainer/Policy log std Std                               0.591874
trainer/Policy log std Max                              -0.398397
trainer/Policy log std Min                              -3.43749
trainer/Alpha                                            0.0154109
trainer/Alpha Loss                                      -0.332069
exploration/num steps total                           9300
exploration/num paths total                            465
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0964986
exploration/Rewards Std                                  0.0936942
exploration/Rewards Max                                  0.0770119
exploration/Rewards Min                                 -0.449828
exploration/Returns Mean                                -1.92997
exploration/Returns Std                                  1.5682
exploration/Returns Max                                  0.194446
exploration/Returns Min                                 -4.68944
exploration/Actions Mean                                -0.00158631
exploration/Actions Std                                  0.0873085
exploration/Actions Max                                  0.457874
exploration/Actions Min                                 -0.335809
exploration/Num Paths                                    5
exploration/Average Returns                             -1.92997
exploration/env_infos/final/reward_energy Mean          -0.0877472
exploration/env_infos/final/reward_energy Std            0.0517489
exploration/env_infos/final/reward_energy Max           -0.0500798
exploration/env_infos/final/reward_energy Min           -0.18732
exploration/env_infos/initial/reward_energy Mean        -0.17546
exploration/env_infos/initial/reward_energy Std          0.163163
exploration/env_infos/initial/reward_energy Max         -0.0042553
exploration/env_infos/initial/reward_energy Min         -0.479283
exploration/env_infos/reward_energy Mean                -0.0873238
exploration/env_infos/reward_energy Std                  0.087322
exploration/env_infos/reward_energy Max                 -0.0042553
exploration/env_infos/reward_energy Min                 -0.52922
exploration/env_infos/final/end_effector_loc Mean        0.0189565
exploration/env_infos/final/end_effector_loc Std         0.197527
exploration/env_infos/final/end_effector_loc Max         0.461302
exploration/env_infos/final/end_effector_loc Min        -0.241901
exploration/env_infos/initial/end_effector_loc Mean      0.000293448
exploration/env_infos/initial/end_effector_loc Std       0.00846607
exploration/env_infos/initial/end_effector_loc Max       0.0228937
exploration/env_infos/initial/end_effector_loc Min      -0.00933326
exploration/env_infos/end_effector_loc Mean              0.00912117
exploration/env_infos/end_effector_loc Std               0.131283
exploration/env_infos/end_effector_loc Max               0.461302
exploration/env_infos/end_effector_loc Min              -0.241901
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.211533
exploration/env_infos/final/reward_dist Std              0.292398
exploration/env_infos/final/reward_dist Max              0.746399
exploration/env_infos/final/reward_dist Min              1.10495e-11
exploration/env_infos/initial/reward_dist Mean           0.0037012
exploration/env_infos/initial/reward_dist Std            0.00722066
exploration/env_infos/initial/reward_dist Max            0.0181414
exploration/env_infos/initial/reward_dist Min            1.67823e-05
exploration/env_infos/reward_dist Mean                   0.0997972
exploration/env_infos/reward_dist Std                    0.191206
exploration/env_infos/reward_dist Max                    0.746399
exploration/env_infos/reward_dist Min                    1.10495e-11
evaluation/num steps total                           83000
evaluation/num paths total                            4150
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0603891
evaluation/Rewards Std                                   0.0888872
evaluation/Rewards Max                                   0.124155
evaluation/Rewards Min                                  -0.561816
evaluation/Returns Mean                                 -1.20778
evaluation/Returns Std                                   1.40447
evaluation/Returns Max                                   1.42509
evaluation/Returns Min                                  -4.00443
evaluation/Actions Mean                                  0.00360364
evaluation/Actions Std                                   0.0945229
evaluation/Actions Max                                   0.899271
evaluation/Actions Min                                  -0.700238
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.20778
evaluation/env_infos/final/reward_energy Mean           -0.0597165
evaluation/env_infos/final/reward_energy Std             0.041159
evaluation/env_infos/final/reward_energy Max            -0.000961032
evaluation/env_infos/final/reward_energy Min            -0.177827
evaluation/env_infos/initial/reward_energy Mean         -0.307635
evaluation/env_infos/initial/reward_energy Std           0.271203
evaluation/env_infos/initial/reward_energy Max          -0.0212766
evaluation/env_infos/initial/reward_energy Min          -0.930172
evaluation/env_infos/reward_energy Mean                 -0.084682
evaluation/env_infos/reward_energy Std                   0.103557
evaluation/env_infos/reward_energy Max                  -0.000961032
evaluation/env_infos/reward_energy Min                  -0.930172
evaluation/env_infos/final/end_effector_loc Mean         0.0165517
evaluation/env_infos/final/end_effector_loc Std          0.294011
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.751391
evaluation/env_infos/initial/end_effector_loc Mean       0.000220441
evaluation/env_infos/initial/end_effector_loc Std        0.0144979
evaluation/env_infos/initial/end_effector_loc Max        0.0449636
evaluation/env_infos/initial/end_effector_loc Min       -0.0350119
evaluation/env_infos/end_effector_loc Mean               0.00468279
evaluation/env_infos/end_effector_loc Std                0.197802
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.751391
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.120417
evaluation/env_infos/final/reward_dist Std               0.224265
evaluation/env_infos/final/reward_dist Max               0.98188
evaluation/env_infos/final/reward_dist Min               3.18296e-66
evaluation/env_infos/initial/reward_dist Mean            0.00822229
evaluation/env_infos/initial/reward_dist Std             0.0192474
evaluation/env_infos/initial/reward_dist Max             0.0998807
evaluation/env_infos/initial/reward_dist Min             2.099e-06
evaluation/env_infos/reward_dist Mean                    0.169696
evaluation/env_infos/reward_dist Std                     0.25786
evaluation/env_infos/reward_dist Max                     0.999239
evaluation/env_infos/reward_dist Min                     3.18296e-66
time/data storing (s)                                   36.1201
time/evaluation sampling (s)                             0.690585
time/exploration sampling (s)                            0.0906434
time/logging (s)                                         0.0171942
time/saving (s)                                          0.808539
time/training (s)                                       37.6084
time/epoch (s)                                          75.3355
time/total (s)                                        4753.82
Epoch                                                   82
---------------------------------------------------  ---------------
2021-05-29 01:16:25.181139 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 83 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.001418
trainer/QF2 Loss                                         0.000797373
trainer/Policy Loss                                      2.81738
trainer/Q1 Predictions Mean                             -0.702348
trainer/Q1 Predictions Std                               0.732456
trainer/Q1 Predictions Max                               0.669141
trainer/Q1 Predictions Min                              -3.12321
trainer/Q2 Predictions Mean                             -0.692655
trainer/Q2 Predictions Std                               0.725321
trainer/Q2 Predictions Max                               0.661944
trainer/Q2 Predictions Min                              -3.09248
trainer/Q Targets Mean                                  -0.695114
trainer/Q Targets Std                                    0.721638
trainer/Q Targets Max                                    0.644953
trainer/Q Targets Min                                   -3.07782
trainer/Log Pis Mean                                     2.11146
trainer/Log Pis Std                                      1.4535
trainer/Log Pis Max                                      4.8636
trainer/Log Pis Min                                     -2.94954
trainer/Policy mu Mean                                   0.0319936
trainer/Policy mu Std                                    0.309868
trainer/Policy mu Max                                    2.16521
trainer/Policy mu Min                                   -1.767
trainer/Policy log std Mean                             -2.36058
trainer/Policy log std Std                               0.609026
trainer/Policy log std Max                              -0.166856
trainer/Policy log std Min                              -3.47492
trainer/Alpha                                            0.0165241
trainer/Alpha Loss                                       0.457361
exploration/num steps total                           9400
exploration/num paths total                            470
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0507564
exploration/Rewards Std                                  0.0832075
exploration/Rewards Max                                  0.14956
exploration/Rewards Min                                 -0.276766
exploration/Returns Mean                                -1.01513
exploration/Returns Std                                  1.33515
exploration/Returns Max                                  1.17765
exploration/Returns Min                                 -3.00215
exploration/Actions Mean                                -0.00256404
exploration/Actions Std                                  0.143014
exploration/Actions Max                                  0.500466
exploration/Actions Min                                 -0.493073
exploration/Num Paths                                    5
exploration/Average Returns                             -1.01513
exploration/env_infos/final/reward_energy Mean          -0.0953646
exploration/env_infos/final/reward_energy Std            0.0726519
exploration/env_infos/final/reward_energy Max           -0.0208354
exploration/env_infos/final/reward_energy Min           -0.198942
exploration/env_infos/initial/reward_energy Mean        -0.328448
exploration/env_infos/initial/reward_energy Std          0.216625
exploration/env_infos/initial/reward_energy Max         -0.0856638
exploration/env_infos/initial/reward_energy Min         -0.585529
exploration/env_infos/reward_energy Mean                -0.159676
exploration/env_infos/reward_energy Std                  0.124189
exploration/env_infos/reward_energy Max                 -0.0201384
exploration/env_infos/reward_energy Min                 -0.585529
exploration/env_infos/final/end_effector_loc Mean        0.0126949
exploration/env_infos/final/end_effector_loc Std         0.148117
exploration/env_infos/final/end_effector_loc Max         0.270611
exploration/env_infos/final/end_effector_loc Min        -0.16448
exploration/env_infos/initial/end_effector_loc Mean     -0.000959713
exploration/env_infos/initial/end_effector_loc Std       0.0138775
exploration/env_infos/initial/end_effector_loc Max       0.0250233
exploration/env_infos/initial/end_effector_loc Min      -0.0246536
exploration/env_infos/end_effector_loc Mean              0.00700593
exploration/env_infos/end_effector_loc Std               0.142991
exploration/env_infos/end_effector_loc Max               0.343937
exploration/env_infos/end_effector_loc Min              -0.308137
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.328279
exploration/env_infos/final/reward_dist Std              0.314527
exploration/env_infos/final/reward_dist Max              0.809956
exploration/env_infos/final/reward_dist Min              0.000106418
exploration/env_infos/initial/reward_dist Mean           0.0053745
exploration/env_infos/initial/reward_dist Std            0.00860744
exploration/env_infos/initial/reward_dist Max            0.0223209
exploration/env_infos/initial/reward_dist Min            1.36937e-05
exploration/env_infos/reward_dist Mean                   0.255742
exploration/env_infos/reward_dist Std                    0.309792
exploration/env_infos/reward_dist Max                    0.99714
exploration/env_infos/reward_dist Min                    8.51524e-12
evaluation/num steps total                           84000
evaluation/num paths total                            4200
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0691476
evaluation/Rewards Std                                   0.0863501
evaluation/Rewards Max                                   0.108459
evaluation/Rewards Min                                  -0.689971
evaluation/Returns Mean                                 -1.38295
evaluation/Returns Std                                   1.35201
evaluation/Returns Max                                   1.3555
evaluation/Returns Min                                  -4.9928
evaluation/Actions Mean                                  0.00648143
evaluation/Actions Std                                   0.0942752
evaluation/Actions Max                                   0.985646
evaluation/Actions Min                                  -0.498781
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.38295
evaluation/env_infos/final/reward_energy Mean           -0.0815368
evaluation/env_infos/final/reward_energy Std             0.0675463
evaluation/env_infos/final/reward_energy Max            -0.0195316
evaluation/env_infos/final/reward_energy Min            -0.383752
evaluation/env_infos/initial/reward_energy Mean         -0.298043
evaluation/env_infos/initial/reward_energy Std           0.281283
evaluation/env_infos/initial/reward_energy Max          -0.00327903
evaluation/env_infos/initial/reward_energy Min          -0.985672
evaluation/env_infos/reward_energy Mean                 -0.0807269
evaluation/env_infos/reward_energy Std                   0.106503
evaluation/env_infos/reward_energy Max                  -0.00181482
evaluation/env_infos/reward_energy Min                  -0.985672
evaluation/env_infos/final/end_effector_loc Mean         0.101577
evaluation/env_infos/final/end_effector_loc Std          0.320675
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.500119
evaluation/env_infos/initial/end_effector_loc Mean       0.00421234
evaluation/env_infos/initial/end_effector_loc Std        0.0138634
evaluation/env_infos/initial/end_effector_loc Max        0.0492823
evaluation/env_infos/initial/end_effector_loc Min       -0.0249391
evaluation/env_infos/end_effector_loc Mean               0.0577834
evaluation/env_infos/end_effector_loc Std                0.208187
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.583867
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.145826
evaluation/env_infos/final/reward_dist Std               0.234511
evaluation/env_infos/final/reward_dist Max               0.811499
evaluation/env_infos/final/reward_dist Min               2.37305e-109
evaluation/env_infos/initial/reward_dist Mean            0.00703343
evaluation/env_infos/initial/reward_dist Std             0.0112544
evaluation/env_infos/initial/reward_dist Max             0.0474282
evaluation/env_infos/initial/reward_dist Min             1.27013e-06
evaluation/env_infos/reward_dist Mean                    0.142524
evaluation/env_infos/reward_dist Std                     0.231153
evaluation/env_infos/reward_dist Max                     0.999467
evaluation/env_infos/reward_dist Min                     2.37305e-109
time/data storing (s)                                   37.5573
time/evaluation sampling (s)                             0.72607
time/exploration sampling (s)                            0.092616
time/logging (s)                                         0.0187462
time/saving (s)                                          0.802043
time/training (s)                                       38.3853
time/epoch (s)                                          77.5821
time/total (s)                                        4832.34
Epoch                                                   83
---------------------------------------------------  ----------------
2021-05-29 01:17:55.042989 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 84 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00107694
trainer/QF2 Loss                                         0.00147635
trainer/Policy Loss                                      2.78294
trainer/Q1 Predictions Mean                             -0.73469
trainer/Q1 Predictions Std                               0.740529
trainer/Q1 Predictions Max                               0.935788
trainer/Q1 Predictions Min                              -2.75815
trainer/Q2 Predictions Mean                             -0.730067
trainer/Q2 Predictions Std                               0.736443
trainer/Q2 Predictions Max                               0.909454
trainer/Q2 Predictions Min                              -2.73124
trainer/Q Targets Mean                                  -0.746237
trainer/Q Targets Std                                    0.735674
trainer/Q Targets Max                                    0.911611
trainer/Q Targets Min                                   -2.70269
trainer/Log Pis Mean                                     2.05823
trainer/Log Pis Std                                      1.42454
trainer/Log Pis Max                                      5.25795
trainer/Log Pis Min                                     -3.48453
trainer/Policy mu Mean                                   0.0116257
trainer/Policy mu Std                                    0.3841
trainer/Policy mu Max                                    2.9262
trainer/Policy mu Min                                   -2.08817
trainer/Policy log std Mean                             -2.31304
trainer/Policy log std Std                               0.635485
trainer/Policy log std Max                              -0.146112
trainer/Policy log std Min                              -3.39932
trainer/Alpha                                            0.0169722
trainer/Alpha Loss                                       0.237344
exploration/num steps total                           9500
exploration/num paths total                            475
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0450007
exploration/Rewards Std                                  0.0596963
exploration/Rewards Max                                  0.0564616
exploration/Rewards Min                                 -0.249727
exploration/Returns Mean                                -0.900013
exploration/Returns Std                                  0.721165
exploration/Returns Max                                 -0.14086
exploration/Returns Min                                 -2.00912
exploration/Actions Mean                                -0.00200151
exploration/Actions Std                                  0.171018
exploration/Actions Max                                  0.490594
exploration/Actions Min                                 -0.96965
exploration/Num Paths                                    5
exploration/Average Returns                             -0.900013
exploration/env_infos/final/reward_energy Mean          -0.141858
exploration/env_infos/final/reward_energy Std            0.0949822
exploration/env_infos/final/reward_energy Max           -0.0248971
exploration/env_infos/final/reward_energy Min           -0.275382
exploration/env_infos/initial/reward_energy Mean        -0.483801
exploration/env_infos/initial/reward_energy Std          0.396202
exploration/env_infos/initial/reward_energy Max         -0.101783
exploration/env_infos/initial/reward_energy Min         -1.20239
exploration/env_infos/reward_energy Mean                -0.185513
exploration/env_infos/reward_energy Std                  0.155201
exploration/env_infos/reward_energy Max                 -0.0166805
exploration/env_infos/reward_energy Min                 -1.20239
exploration/env_infos/final/end_effector_loc Mean       -0.0706275
exploration/env_infos/final/end_effector_loc Std         0.201528
exploration/env_infos/final/end_effector_loc Max         0.297182
exploration/env_infos/final/end_effector_loc Min        -0.389531
exploration/env_infos/initial/end_effector_loc Mean     -0.0133873
exploration/env_infos/initial/end_effector_loc Std       0.0175948
exploration/env_infos/initial/end_effector_loc Max       0.0112688
exploration/env_infos/initial/end_effector_loc Min      -0.0484825
exploration/env_infos/end_effector_loc Mean             -0.0656998
exploration/env_infos/end_effector_loc Std               0.155099
exploration/env_infos/end_effector_loc Max               0.297182
exploration/env_infos/end_effector_loc Min              -0.389531
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.159192
exploration/env_infos/final/reward_dist Std              0.171265
exploration/env_infos/final/reward_dist Max              0.369559
exploration/env_infos/final/reward_dist Min              3.13641e-09
exploration/env_infos/initial/reward_dist Mean           0.00869219
exploration/env_infos/initial/reward_dist Std            0.0138972
exploration/env_infos/initial/reward_dist Max            0.0360235
exploration/env_infos/initial/reward_dist Min            8.85388e-05
exploration/env_infos/reward_dist Mean                   0.234773
exploration/env_infos/reward_dist Std                    0.287631
exploration/env_infos/reward_dist Max                    0.984886
exploration/env_infos/reward_dist Min                    3.13641e-09
evaluation/num steps total                           85000
evaluation/num paths total                            4250
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0585946
evaluation/Rewards Std                                   0.0883434
evaluation/Rewards Max                                   0.125886
evaluation/Rewards Min                                  -0.618929
evaluation/Returns Mean                                 -1.17189
evaluation/Returns Std                                   1.38514
evaluation/Returns Max                                   1.4502
evaluation/Returns Min                                  -6.78321
evaluation/Actions Mean                                  0.00632804
evaluation/Actions Std                                   0.101776
evaluation/Actions Max                                   0.968691
evaluation/Actions Min                                  -0.788318
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.17189
evaluation/env_infos/final/reward_energy Mean           -0.0720573
evaluation/env_infos/final/reward_energy Std             0.053322
evaluation/env_infos/final/reward_energy Max            -0.00429085
evaluation/env_infos/final/reward_energy Min            -0.256814
evaluation/env_infos/initial/reward_energy Mean         -0.226903
evaluation/env_infos/initial/reward_energy Std           0.263793
evaluation/env_infos/initial/reward_energy Max          -0.00293667
evaluation/env_infos/initial/reward_energy Min          -0.953214
evaluation/env_infos/reward_energy Mean                 -0.0810337
evaluation/env_infos/reward_energy Std                   0.119291
evaluation/env_infos/reward_energy Max                  -0.000952176
evaluation/env_infos/reward_energy Min                  -0.971728
evaluation/env_infos/final/end_effector_loc Mean         0.109667
evaluation/env_infos/final/end_effector_loc Std          0.310934
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.368909
evaluation/env_infos/initial/end_effector_loc Mean       0.00317761
evaluation/env_infos/initial/end_effector_loc Std        0.0118845
evaluation/env_infos/initial/end_effector_loc Max        0.0466503
evaluation/env_infos/initial/end_effector_loc Min       -0.0254331
evaluation/env_infos/end_effector_loc Mean               0.0637357
evaluation/env_infos/end_effector_loc Std                0.221671
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.368909
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.181743
evaluation/env_infos/final/reward_dist Std               0.285284
evaluation/env_infos/final/reward_dist Max               0.974416
evaluation/env_infos/final/reward_dist Min               1.88057e-97
evaluation/env_infos/initial/reward_dist Mean            0.00796673
evaluation/env_infos/initial/reward_dist Std             0.0237922
evaluation/env_infos/initial/reward_dist Max             0.146686
evaluation/env_infos/initial/reward_dist Min             8.91677e-07
evaluation/env_infos/reward_dist Mean                    0.129431
evaluation/env_infos/reward_dist Std                     0.227103
evaluation/env_infos/reward_dist Max                     0.974416
evaluation/env_infos/reward_dist Min                     1.88057e-97
time/data storing (s)                                   43.2176
time/evaluation sampling (s)                             0.734924
time/exploration sampling (s)                            0.10566
time/logging (s)                                         0.0172821
time/saving (s)                                          0.759975
time/training (s)                                       43.9639
time/epoch (s)                                          88.7993
time/total (s)                                        4922.2
Epoch                                                   84
---------------------------------------------------  ---------------
2021-05-29 01:19:16.530586 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 85 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00223989
trainer/QF2 Loss                                         0.00143008
trainer/Policy Loss                                      2.78841
trainer/Q1 Predictions Mean                             -0.676395
trainer/Q1 Predictions Std                               0.770743
trainer/Q1 Predictions Max                               1.00986
trainer/Q1 Predictions Min                              -3.21006
trainer/Q2 Predictions Mean                             -0.675311
trainer/Q2 Predictions Std                               0.76607
trainer/Q2 Predictions Max                               1.04453
trainer/Q2 Predictions Min                              -3.18547
trainer/Q Targets Mean                                  -0.674692
trainer/Q Targets Std                                    0.773068
trainer/Q Targets Max                                    1.09076
trainer/Q Targets Min                                   -3.23457
trainer/Log Pis Mean                                     2.11438
trainer/Log Pis Std                                      1.32707
trainer/Log Pis Max                                      4.69677
trainer/Log Pis Min                                     -3.67242
trainer/Policy mu Mean                                  -0.0075859
trainer/Policy mu Std                                    0.361061
trainer/Policy mu Max                                    2.49929
trainer/Policy mu Min                                   -2.11248
trainer/Policy log std Mean                             -2.30712
trainer/Policy log std Std                               0.638701
trainer/Policy log std Max                              -0.0805484
trainer/Policy log std Min                              -3.50158
trainer/Alpha                                            0.0174235
trainer/Alpha Loss                                       0.463374
exploration/num steps total                           9600
exploration/num paths total                            480
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0791013
exploration/Rewards Std                                  0.0831378
exploration/Rewards Max                                  0.106565
exploration/Rewards Min                                 -0.343071
exploration/Returns Mean                                -1.58203
exploration/Returns Std                                  1.10259
exploration/Returns Max                                 -0.0400108
exploration/Returns Min                                 -3.05854
exploration/Actions Mean                                -0.00989691
exploration/Actions Std                                  0.242945
exploration/Actions Max                                  0.722687
exploration/Actions Min                                 -0.923835
exploration/Num Paths                                    5
exploration/Average Returns                             -1.58203
exploration/env_infos/final/reward_energy Mean          -0.227198
exploration/env_infos/final/reward_energy Std            0.0687978
exploration/env_infos/final/reward_energy Max           -0.131788
exploration/env_infos/final/reward_energy Min           -0.331778
exploration/env_infos/initial/reward_energy Mean        -0.49956
exploration/env_infos/initial/reward_energy Std          0.123804
exploration/env_infos/initial/reward_energy Max         -0.353837
exploration/env_infos/initial/reward_energy Min         -0.660971
exploration/env_infos/reward_energy Mean                -0.259859
exploration/env_infos/reward_energy Std                  0.225196
exploration/env_infos/reward_energy Max                 -0.0344293
exploration/env_infos/reward_energy Min                 -1.14674
exploration/env_infos/final/end_effector_loc Mean       -0.11784
exploration/env_infos/final/end_effector_loc Std         0.224071
exploration/env_infos/final/end_effector_loc Max         0.334228
exploration/env_infos/final/end_effector_loc Min        -0.481532
exploration/env_infos/initial/end_effector_loc Mean     -0.00191242
exploration/env_infos/initial/end_effector_loc Std       0.0180956
exploration/env_infos/initial/end_effector_loc Max       0.0271437
exploration/env_infos/initial/end_effector_loc Min      -0.0265024
exploration/env_infos/end_effector_loc Mean             -0.0539306
exploration/env_infos/end_effector_loc Std               0.195713
exploration/env_infos/end_effector_loc Max               0.53869
exploration/env_infos/end_effector_loc Min              -0.481532
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0189492
exploration/env_infos/final/reward_dist Std              0.0236089
exploration/env_infos/final/reward_dist Max              0.0629738
exploration/env_infos/final/reward_dist Min              7.2379e-18
exploration/env_infos/initial/reward_dist Mean           0.0171212
exploration/env_infos/initial/reward_dist Std            0.0186494
exploration/env_infos/initial/reward_dist Max            0.049753
exploration/env_infos/initial/reward_dist Min            1.70918e-05
exploration/env_infos/reward_dist Mean                   0.201779
exploration/env_infos/reward_dist Std                    0.289524
exploration/env_infos/reward_dist Max                    0.946461
exploration/env_infos/reward_dist Min                    7.2379e-18
evaluation/num steps total                           86000
evaluation/num paths total                            4300
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0558873
evaluation/Rewards Std                                   0.0827116
evaluation/Rewards Max                                   0.169172
evaluation/Rewards Min                                  -0.460677
evaluation/Returns Mean                                 -1.11775
evaluation/Returns Std                                   1.40968
evaluation/Returns Max                                   1.97709
evaluation/Returns Min                                  -3.78999
evaluation/Actions Mean                                  0.00738306
evaluation/Actions Std                                   0.0925809
evaluation/Actions Max                                   0.952272
evaluation/Actions Min                                  -0.809649
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.11775
evaluation/env_infos/final/reward_energy Mean           -0.0861256
evaluation/env_infos/final/reward_energy Std             0.0680862
evaluation/env_infos/final/reward_energy Max            -0.00614314
evaluation/env_infos/final/reward_energy Min            -0.345922
evaluation/env_infos/initial/reward_energy Mean         -0.243739
evaluation/env_infos/initial/reward_energy Std           0.307981
evaluation/env_infos/initial/reward_energy Max          -0.00447382
evaluation/env_infos/initial/reward_energy Min          -1.22242
evaluation/env_infos/reward_energy Mean                 -0.0787919
evaluation/env_infos/reward_energy Std                   0.105087
evaluation/env_infos/reward_energy Max                  -0.0010769
evaluation/env_infos/reward_energy Min                  -1.22242
evaluation/env_infos/final/end_effector_loc Mean         0.113191
evaluation/env_infos/final/end_effector_loc Std          0.244351
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.356902
evaluation/env_infos/initial/end_effector_loc Mean       0.00320098
evaluation/env_infos/initial/end_effector_loc Std        0.0135122
evaluation/env_infos/initial/end_effector_loc Max        0.0476136
evaluation/env_infos/initial/end_effector_loc Min       -0.0404824
evaluation/env_infos/end_effector_loc Mean               0.0552423
evaluation/env_infos/end_effector_loc Std                0.16596
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.366104
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.137011
evaluation/env_infos/final/reward_dist Std               0.238289
evaluation/env_infos/final/reward_dist Max               0.944962
evaluation/env_infos/final/reward_dist Min               4.12523e-123
evaluation/env_infos/initial/reward_dist Mean            0.0104355
evaluation/env_infos/initial/reward_dist Std             0.0255809
evaluation/env_infos/initial/reward_dist Max             0.134011
evaluation/env_infos/initial/reward_dist Min             8.07983e-07
evaluation/env_infos/reward_dist Mean                    0.133548
evaluation/env_infos/reward_dist Std                     0.236626
evaluation/env_infos/reward_dist Max                     0.996335
evaluation/env_infos/reward_dist Min                     4.12523e-123
time/data storing (s)                                   40.1706
time/evaluation sampling (s)                             0.665235
time/exploration sampling (s)                            0.0908196
time/logging (s)                                         0.0147035
time/saving (s)                                          0.767447
time/training (s)                                       38.7948
time/epoch (s)                                          80.5036
time/total (s)                                        5003.68
Epoch                                                   85
---------------------------------------------------  ----------------
2021-05-29 01:20:35.102319 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 86 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00229746
trainer/QF2 Loss                                         0.00180673
trainer/Policy Loss                                      2.65918
trainer/Q1 Predictions Mean                             -0.710372
trainer/Q1 Predictions Std                               0.746092
trainer/Q1 Predictions Max                               1.02501
trainer/Q1 Predictions Min                              -2.7382
trainer/Q2 Predictions Mean                             -0.73222
trainer/Q2 Predictions Std                               0.759348
trainer/Q2 Predictions Max                               1.10456
trainer/Q2 Predictions Min                              -2.84406
trainer/Q Targets Mean                                  -0.724375
trainer/Q Targets Std                                    0.750778
trainer/Q Targets Max                                    1.03131
trainer/Q Targets Min                                   -2.82483
trainer/Log Pis Mean                                     1.93027
trainer/Log Pis Std                                      1.3859
trainer/Log Pis Max                                      4.87235
trainer/Log Pis Min                                     -3.08362
trainer/Policy mu Mean                                  -0.016403
trainer/Policy mu Std                                    0.395038
trainer/Policy mu Max                                    2.68197
trainer/Policy mu Min                                   -2.00937
trainer/Policy log std Mean                             -2.26103
trainer/Policy log std Std                               0.614929
trainer/Policy log std Max                               0.172005
trainer/Policy log std Min                              -3.38602
trainer/Alpha                                            0.0176128
trainer/Alpha Loss                                      -0.281797
exploration/num steps total                           9700
exploration/num paths total                            485
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0618915
exploration/Rewards Std                                  0.0885718
exploration/Rewards Max                                  0.160211
exploration/Rewards Min                                 -0.299327
exploration/Returns Mean                                -1.23783
exploration/Returns Std                                  1.2006
exploration/Returns Max                                  1.11425
exploration/Returns Min                                 -2.16078
exploration/Actions Mean                                 0.00612154
exploration/Actions Std                                  0.110957
exploration/Actions Max                                  0.37434
exploration/Actions Min                                 -0.33524
exploration/Num Paths                                    5
exploration/Average Returns                             -1.23783
exploration/env_infos/final/reward_energy Mean          -0.236995
exploration/env_infos/final/reward_energy Std            0.0965583
exploration/env_infos/final/reward_energy Max           -0.0837125
exploration/env_infos/final/reward_energy Min           -0.349571
exploration/env_infos/initial/reward_energy Mean        -0.180583
exploration/env_infos/initial/reward_energy Std          0.14334
exploration/env_infos/initial/reward_energy Max         -0.0868722
exploration/env_infos/initial/reward_energy Min         -0.462983
exploration/env_infos/reward_energy Mean                -0.130197
exploration/env_infos/reward_energy Std                  0.0880158
exploration/env_infos/reward_energy Max                 -0.0129373
exploration/env_infos/reward_energy Min                 -0.462983
exploration/env_infos/final/end_effector_loc Mean        0.113237
exploration/env_infos/final/end_effector_loc Std         0.236627
exploration/env_infos/final/end_effector_loc Max         0.521986
exploration/env_infos/final/end_effector_loc Min        -0.189354
exploration/env_infos/initial/end_effector_loc Mean      0.00111151
exploration/env_infos/initial/end_effector_loc Std       0.00807526
exploration/env_infos/initial/end_effector_loc Max       0.0159662
exploration/env_infos/initial/end_effector_loc Min      -0.016762
exploration/env_infos/end_effector_loc Mean              0.0621296
exploration/env_infos/end_effector_loc Std               0.158513
exploration/env_infos/end_effector_loc Max               0.521986
exploration/env_infos/end_effector_loc Min              -0.237949
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.213146
exploration/env_infos/final/reward_dist Std              0.327571
exploration/env_infos/final/reward_dist Max              0.845785
exploration/env_infos/final/reward_dist Min              2.14033e-13
exploration/env_infos/initial/reward_dist Mean           0.0065951
exploration/env_infos/initial/reward_dist Std            0.00873066
exploration/env_infos/initial/reward_dist Max            0.0238443
exploration/env_infos/initial/reward_dist Min            0.000275792
exploration/env_infos/reward_dist Mean                   0.208864
exploration/env_infos/reward_dist Std                    0.311387
exploration/env_infos/reward_dist Max                    0.974952
exploration/env_infos/reward_dist Min                    2.14033e-13
evaluation/num steps total                           87000
evaluation/num paths total                            4350
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.065165
evaluation/Rewards Std                                   0.0938744
evaluation/Rewards Max                                   0.131244
evaluation/Rewards Min                                  -0.579256
evaluation/Returns Mean                                 -1.3033
evaluation/Returns Std                                   1.65116
evaluation/Returns Max                                   1.23283
evaluation/Returns Min                                  -7.31573
evaluation/Actions Mean                                  0.00381781
evaluation/Actions Std                                   0.0828577
evaluation/Actions Max                                   0.770412
evaluation/Actions Min                                  -0.722301
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.3033
evaluation/env_infos/final/reward_energy Mean           -0.0916177
evaluation/env_infos/final/reward_energy Std             0.0764615
evaluation/env_infos/final/reward_energy Max            -0.0160744
evaluation/env_infos/final/reward_energy Min            -0.372348
evaluation/env_infos/initial/reward_energy Mean         -0.216894
evaluation/env_infos/initial/reward_energy Std           0.237052
evaluation/env_infos/initial/reward_energy Max          -0.0138669
evaluation/env_infos/initial/reward_energy Min          -1.05166
evaluation/env_infos/reward_energy Mean                 -0.078079
evaluation/env_infos/reward_energy Std                   0.087542
evaluation/env_infos/reward_energy Max                  -0.00313533
evaluation/env_infos/reward_energy Min                  -1.05166
evaluation/env_infos/final/end_effector_loc Mean         0.0644579
evaluation/env_infos/final/end_effector_loc Std          0.272756
evaluation/env_infos/final/end_effector_loc Max          0.925371
evaluation/env_infos/final/end_effector_loc Min         -0.564951
evaluation/env_infos/initial/end_effector_loc Mean       0.0020926
evaluation/env_infos/initial/end_effector_loc Std        0.0111654
evaluation/env_infos/initial/end_effector_loc Max        0.0385206
evaluation/env_infos/initial/end_effector_loc Min       -0.036115
evaluation/env_infos/end_effector_loc Mean               0.0335651
evaluation/env_infos/end_effector_loc Std                0.169322
evaluation/env_infos/end_effector_loc Max                0.925371
evaluation/env_infos/end_effector_loc Min               -0.564951
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.157449
evaluation/env_infos/final/reward_dist Std               0.264714
evaluation/env_infos/final/reward_dist Max               0.979654
evaluation/env_infos/final/reward_dist Min               3.98841e-118
evaluation/env_infos/initial/reward_dist Mean            0.00803268
evaluation/env_infos/initial/reward_dist Std             0.0147592
evaluation/env_infos/initial/reward_dist Max             0.0831763
evaluation/env_infos/initial/reward_dist Min             8.91827e-07
evaluation/env_infos/reward_dist Mean                    0.128066
evaluation/env_infos/reward_dist Std                     0.21145
evaluation/env_infos/reward_dist Max                     0.997027
evaluation/env_infos/reward_dist Min                     3.98841e-118
time/data storing (s)                                   38.8582
time/evaluation sampling (s)                             0.638231
time/exploration sampling (s)                            0.0914613
time/logging (s)                                         0.0156728
time/saving (s)                                          0.831408
time/training (s)                                       37.1981
time/epoch (s)                                          77.6331
time/total (s)                                        5082.25
Epoch                                                   86
---------------------------------------------------  ----------------
2021-05-29 01:21:50.422706 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 87 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00109157
trainer/QF2 Loss                                         0.00120422
trainer/Policy Loss                                      2.63974
trainer/Q1 Predictions Mean                             -0.613787
trainer/Q1 Predictions Std                               0.693803
trainer/Q1 Predictions Max                               0.845164
trainer/Q1 Predictions Min                              -2.32688
trainer/Q2 Predictions Mean                             -0.609057
trainer/Q2 Predictions Std                               0.690622
trainer/Q2 Predictions Max                               0.845464
trainer/Q2 Predictions Min                              -2.2827
trainer/Q Targets Mean                                  -0.607814
trainer/Q Targets Std                                    0.696209
trainer/Q Targets Max                                    0.862129
trainer/Q Targets Min                                   -2.28237
trainer/Log Pis Mean                                     2.03361
trainer/Log Pis Std                                      1.14506
trainer/Log Pis Max                                      4.6913
trainer/Log Pis Min                                     -1.78381
trainer/Policy mu Mean                                   0.0423229
trainer/Policy mu Std                                    0.356856
trainer/Policy mu Max                                    1.94623
trainer/Policy mu Min                                   -1.83259
trainer/Policy log std Mean                             -2.25825
trainer/Policy log std Std                               0.552236
trainer/Policy log std Max                              -0.397236
trainer/Policy log std Min                              -3.36991
trainer/Alpha                                            0.0184243
trainer/Alpha Loss                                       0.134297
exploration/num steps total                           9800
exploration/num paths total                            490
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0719974
exploration/Rewards Std                                  0.0871593
exploration/Rewards Max                                  0.0928939
exploration/Rewards Min                                 -0.296842
exploration/Returns Mean                                -1.43995
exploration/Returns Std                                  1.54488
exploration/Returns Max                                  1.00724
exploration/Returns Min                                 -2.96934
exploration/Actions Mean                                -0.00533436
exploration/Actions Std                                  0.197057
exploration/Actions Max                                  0.929639
exploration/Actions Min                                 -0.627178
exploration/Num Paths                                    5
exploration/Average Returns                             -1.43995
exploration/env_infos/final/reward_energy Mean          -0.193885
exploration/env_infos/final/reward_energy Std            0.103107
exploration/env_infos/final/reward_energy Max           -0.0502321
exploration/env_infos/final/reward_energy Min           -0.31738
exploration/env_infos/initial/reward_energy Mean        -0.492705
exploration/env_infos/initial/reward_energy Std          0.388941
exploration/env_infos/initial/reward_energy Max         -0.0527418
exploration/env_infos/initial/reward_energy Min         -0.970982
exploration/env_infos/reward_energy Mean                -0.202399
exploration/env_infos/reward_energy Std                  0.191715
exploration/env_infos/reward_energy Max                 -0.0111912
exploration/env_infos/reward_energy Min                 -0.970982
exploration/env_infos/final/end_effector_loc Mean       -0.013636
exploration/env_infos/final/end_effector_loc Std         0.145884
exploration/env_infos/final/end_effector_loc Max         0.21117
exploration/env_infos/final/end_effector_loc Min        -0.226182
exploration/env_infos/initial/end_effector_loc Mean      0.00553462
exploration/env_infos/initial/end_effector_loc Std       0.0214921
exploration/env_infos/initial/end_effector_loc Max       0.0464819
exploration/env_infos/initial/end_effector_loc Min      -0.0262513
exploration/env_infos/end_effector_loc Mean              0.00888505
exploration/env_infos/end_effector_loc Std               0.118077
exploration/env_infos/end_effector_loc Max               0.276234
exploration/env_infos/end_effector_loc Min              -0.229253
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.308467
exploration/env_infos/final/reward_dist Std              0.391755
exploration/env_infos/final/reward_dist Max              0.990415
exploration/env_infos/final/reward_dist Min              0.000111482
exploration/env_infos/initial/reward_dist Mean           0.0122176
exploration/env_infos/initial/reward_dist Std            0.0216859
exploration/env_infos/initial/reward_dist Max            0.0555188
exploration/env_infos/initial/reward_dist Min            0.000306765
exploration/env_infos/reward_dist Mean                   0.19547
exploration/env_infos/reward_dist Std                    0.321365
exploration/env_infos/reward_dist Max                    0.990415
exploration/env_infos/reward_dist Min                    0.000111482
evaluation/num steps total                           88000
evaluation/num paths total                            4400
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0560329
evaluation/Rewards Std                                   0.0964008
evaluation/Rewards Max                                   0.129011
evaluation/Rewards Min                                  -0.88135
evaluation/Returns Mean                                 -1.12066
evaluation/Returns Std                                   1.56215
evaluation/Returns Max                                   0.929159
evaluation/Returns Min                                  -9.62559
evaluation/Actions Mean                                  0.00638291
evaluation/Actions Std                                   0.0935924
evaluation/Actions Max                                   0.949813
evaluation/Actions Min                                  -0.819486
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.12066
evaluation/env_infos/final/reward_energy Mean           -0.06334
evaluation/env_infos/final/reward_energy Std             0.049033
evaluation/env_infos/final/reward_energy Max            -0.00952227
evaluation/env_infos/final/reward_energy Min            -0.276707
evaluation/env_infos/initial/reward_energy Mean         -0.218404
evaluation/env_infos/initial/reward_energy Std           0.268435
evaluation/env_infos/initial/reward_energy Max          -0.00676367
evaluation/env_infos/initial/reward_energy Min          -0.981681
evaluation/env_infos/reward_energy Mean                 -0.072994
evaluation/env_infos/reward_energy Std                   0.110781
evaluation/env_infos/reward_energy Max                  -0.00054236
evaluation/env_infos/reward_energy Min                  -0.981681
evaluation/env_infos/final/end_effector_loc Mean         0.0712126
evaluation/env_infos/final/end_effector_loc Std          0.261835
evaluation/env_infos/final/end_effector_loc Max          0.941251
evaluation/env_infos/final/end_effector_loc Min         -0.421853
evaluation/env_infos/initial/end_effector_loc Mean       0.000571244
evaluation/env_infos/initial/end_effector_loc Std        0.0122217
evaluation/env_infos/initial/end_effector_loc Max        0.0474907
evaluation/env_infos/initial/end_effector_loc Min       -0.0409743
evaluation/env_infos/end_effector_loc Mean               0.0273288
evaluation/env_infos/end_effector_loc Std                0.165093
evaluation/env_infos/end_effector_loc Max                0.941251
evaluation/env_infos/end_effector_loc Min               -0.525682
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.176446
evaluation/env_infos/final/reward_dist Std               0.299233
evaluation/env_infos/final/reward_dist Max               0.991647
evaluation/env_infos/final/reward_dist Min               5.40241e-76
evaluation/env_infos/initial/reward_dist Mean            0.0113621
evaluation/env_infos/initial/reward_dist Std             0.028316
evaluation/env_infos/initial/reward_dist Max             0.174163
evaluation/env_infos/initial/reward_dist Min             1.39591e-06
evaluation/env_infos/reward_dist Mean                    0.147562
evaluation/env_infos/reward_dist Std                     0.255229
evaluation/env_infos/reward_dist Max                     0.991647
evaluation/env_infos/reward_dist Min                     5.40241e-76
time/data storing (s)                                   37.0294
time/evaluation sampling (s)                             0.643189
time/exploration sampling (s)                            0.0843462
time/logging (s)                                         0.0143501
time/saving (s)                                          0.766732
time/training (s)                                       35.7141
time/epoch (s)                                          74.2521
time/total (s)                                        5157.56
Epoch                                                   87
---------------------------------------------------  ---------------
2021-05-29 01:23:06.357252 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 88 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.000925753
trainer/QF2 Loss                                         0.00138845
trainer/Policy Loss                                      2.62366
trainer/Q1 Predictions Mean                             -0.624327
trainer/Q1 Predictions Std                               0.763484
trainer/Q1 Predictions Max                               1.12512
trainer/Q1 Predictions Min                              -2.88189
trainer/Q2 Predictions Mean                             -0.624888
trainer/Q2 Predictions Std                               0.761219
trainer/Q2 Predictions Max                               1.13669
trainer/Q2 Predictions Min                              -2.91325
trainer/Q Targets Mean                                  -0.624962
trainer/Q Targets Std                                    0.769573
trainer/Q Targets Max                                    1.14589
trainer/Q Targets Min                                   -2.93763
trainer/Log Pis Mean                                     2.00667
trainer/Log Pis Std                                      1.43016
trainer/Log Pis Max                                      4.8534
trainer/Log Pis Min                                     -3.91963
trainer/Policy mu Mean                                   0.0509886
trainer/Policy mu Std                                    0.369152
trainer/Policy mu Max                                    2.29034
trainer/Policy mu Min                                   -1.50482
trainer/Policy log std Mean                             -2.32346
trainer/Policy log std Std                               0.594328
trainer/Policy log std Max                              -0.514176
trainer/Policy log std Min                              -3.51757
trainer/Alpha                                            0.0171563
trainer/Alpha Loss                                       0.0271189
exploration/num steps total                           9900
exploration/num paths total                            495
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.057843
exploration/Rewards Std                                  0.0643678
exploration/Rewards Max                                  0.0991651
exploration/Rewards Min                                 -0.178611
exploration/Returns Mean                                -1.15686
exploration/Returns Std                                  1.02191
exploration/Returns Max                                  0.0724776
exploration/Returns Min                                 -2.33219
exploration/Actions Mean                                -0.00759592
exploration/Actions Std                                  0.13395
exploration/Actions Max                                  0.605319
exploration/Actions Min                                 -0.511358
exploration/Num Paths                                    5
exploration/Average Returns                             -1.15686
exploration/env_infos/final/reward_energy Mean          -0.164221
exploration/env_infos/final/reward_energy Std            0.0676328
exploration/env_infos/final/reward_energy Max           -0.0744115
exploration/env_infos/final/reward_energy Min           -0.2641
exploration/env_infos/initial/reward_energy Mean        -0.310173
exploration/env_infos/initial/reward_energy Std          0.247212
exploration/env_infos/initial/reward_energy Max         -0.119556
exploration/env_infos/initial/reward_energy Min         -0.7924
exploration/env_infos/reward_energy Mean                -0.151147
exploration/env_infos/reward_energy Std                  0.114697
exploration/env_infos/reward_energy Max                 -0.0142819
exploration/env_infos/reward_energy Min                 -0.7924
exploration/env_infos/final/end_effector_loc Mean       -0.0435974
exploration/env_infos/final/end_effector_loc Std         0.210901
exploration/env_infos/final/end_effector_loc Max         0.418047
exploration/env_infos/final/end_effector_loc Min        -0.296735
exploration/env_infos/initial/end_effector_loc Mean     -0.000970373
exploration/env_infos/initial/end_effector_loc Std       0.0139896
exploration/env_infos/initial/end_effector_loc Max       0.0302659
exploration/env_infos/initial/end_effector_loc Min      -0.0255679
exploration/env_infos/end_effector_loc Mean             -0.0195915
exploration/env_infos/end_effector_loc Std               0.138883
exploration/env_infos/end_effector_loc Max               0.418047
exploration/env_infos/end_effector_loc Min              -0.296735
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.125914
exploration/env_infos/final/reward_dist Std              0.167793
exploration/env_infos/final/reward_dist Max              0.440607
exploration/env_infos/final/reward_dist Min              0.000736679
exploration/env_infos/initial/reward_dist Mean           0.0114963
exploration/env_infos/initial/reward_dist Std            0.0140678
exploration/env_infos/initial/reward_dist Max            0.0360477
exploration/env_infos/initial/reward_dist Min            5.38667e-06
exploration/env_infos/reward_dist Mean                   0.202585
exploration/env_infos/reward_dist Std                    0.233433
exploration/env_infos/reward_dist Max                    0.992845
exploration/env_infos/reward_dist Min                    5.38667e-06
evaluation/num steps total                           89000
evaluation/num paths total                            4450
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0445589
evaluation/Rewards Std                                   0.0810956
evaluation/Rewards Max                                   0.144305
evaluation/Rewards Min                                  -0.417826
evaluation/Returns Mean                                 -0.891179
evaluation/Returns Std                                   1.37917
evaluation/Returns Max                                   1.66759
evaluation/Returns Min                                  -5.25824
evaluation/Actions Mean                                  0.000520331
evaluation/Actions Std                                   0.0900453
evaluation/Actions Max                                   0.980784
evaluation/Actions Min                                  -0.709909
evaluation/Num Paths                                    50
evaluation/Average Returns                              -0.891179
evaluation/env_infos/final/reward_energy Mean           -0.0554343
evaluation/env_infos/final/reward_energy Std             0.0443366
evaluation/env_infos/final/reward_energy Max            -0.00456318
evaluation/env_infos/final/reward_energy Min            -0.203787
evaluation/env_infos/initial/reward_energy Mean         -0.18565
evaluation/env_infos/initial/reward_energy Std           0.238902
evaluation/env_infos/initial/reward_energy Max          -0.00205478
evaluation/env_infos/initial/reward_energy Min          -1.0485
evaluation/env_infos/reward_energy Mean                 -0.0652285
evaluation/env_infos/reward_energy Std                   0.109371
evaluation/env_infos/reward_energy Max                  -0.00111866
evaluation/env_infos/reward_energy Min                  -1.0485
evaluation/env_infos/final/end_effector_loc Mean         0.0199447
evaluation/env_infos/final/end_effector_loc Std          0.195084
evaluation/env_infos/final/end_effector_loc Max          0.413653
evaluation/env_infos/final/end_effector_loc Min         -0.372568
evaluation/env_infos/initial/end_effector_loc Mean       0.000126275
evaluation/env_infos/initial/end_effector_loc Std        0.0106962
evaluation/env_infos/initial/end_effector_loc Max        0.0490392
evaluation/env_infos/initial/end_effector_loc Min       -0.0354954
evaluation/env_infos/end_effector_loc Mean               0.00946092
evaluation/env_infos/end_effector_loc Std                0.134668
evaluation/env_infos/end_effector_loc Max                0.510974
evaluation/env_infos/end_effector_loc Min               -0.372568
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.233689
evaluation/env_infos/final/reward_dist Std               0.271674
evaluation/env_infos/final/reward_dist Max               0.888239
evaluation/env_infos/final/reward_dist Min               1.0655e-13
evaluation/env_infos/initial/reward_dist Mean            0.00928671
evaluation/env_infos/initial/reward_dist Std             0.0195554
evaluation/env_infos/initial/reward_dist Max             0.127778
evaluation/env_infos/initial/reward_dist Min             1.23627e-06
evaluation/env_infos/reward_dist Mean                    0.178365
evaluation/env_infos/reward_dist Std                     0.257503
evaluation/env_infos/reward_dist Max                     0.993876
evaluation/env_infos/reward_dist Min                     1.0655e-13
time/data storing (s)                                   37.6528
time/evaluation sampling (s)                             0.621007
time/exploration sampling (s)                            0.0946722
time/logging (s)                                         0.0138441
time/saving (s)                                          0.776394
time/training (s)                                       35.8002
time/epoch (s)                                          74.9589
time/total (s)                                        5233.49
Epoch                                                   88
---------------------------------------------------  ---------------
2021-05-29 01:24:25.343201 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 89 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00118127
trainer/QF2 Loss                                         0.00146603
trainer/Policy Loss                                      2.68343
trainer/Q1 Predictions Mean                             -0.648873
trainer/Q1 Predictions Std                               0.803845
trainer/Q1 Predictions Max                               1.1825
trainer/Q1 Predictions Min                              -2.90097
trainer/Q2 Predictions Mean                             -0.647966
trainer/Q2 Predictions Std                               0.800408
trainer/Q2 Predictions Max                               1.1763
trainer/Q2 Predictions Min                              -2.9816
trainer/Q Targets Mean                                  -0.647738
trainer/Q Targets Std                                    0.80936
trainer/Q Targets Max                                    1.1821
trainer/Q Targets Min                                   -2.96961
trainer/Log Pis Mean                                     2.04128
trainer/Log Pis Std                                      1.43807
trainer/Log Pis Max                                      7.61048
trainer/Log Pis Min                                     -3.92862
trainer/Policy mu Mean                                   0.00622778
trainer/Policy mu Std                                    0.365369
trainer/Policy mu Max                                    2.21614
trainer/Policy mu Min                                   -2.79675
trainer/Policy log std Mean                             -2.32472
trainer/Policy log std Std                               0.649551
trainer/Policy log std Max                              -0.0486298
trainer/Policy log std Min                              -3.54194
trainer/Alpha                                            0.0161995
trainer/Alpha Loss                                       0.170188
exploration/num steps total                          10000
exploration/num paths total                            500
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.168686
exploration/Rewards Std                                  0.134421
exploration/Rewards Max                                 -0.0221615
exploration/Rewards Min                                 -0.850272
exploration/Returns Mean                                -3.37371
exploration/Returns Std                                  2.08711
exploration/Returns Max                                 -1.11936
exploration/Returns Min                                 -7.33061
exploration/Actions Mean                                 0.00247133
exploration/Actions Std                                  0.226515
exploration/Actions Max                                  0.97448
exploration/Actions Min                                 -0.88578
exploration/Num Paths                                    5
exploration/Average Returns                             -3.37371
exploration/env_infos/final/reward_energy Mean          -0.288696
exploration/env_infos/final/reward_energy Std            0.380398
exploration/env_infos/final/reward_energy Max           -0.0547914
exploration/env_infos/final/reward_energy Min           -1.04664
exploration/env_infos/initial/reward_energy Mean        -0.474259
exploration/env_infos/initial/reward_energy Std          0.432351
exploration/env_infos/initial/reward_energy Max         -0.0206559
exploration/env_infos/initial/reward_energy Min         -1.03253
exploration/env_infos/reward_energy Mean                -0.21492
exploration/env_infos/reward_energy Std                  0.23757
exploration/env_infos/reward_energy Max                 -0.00539709
exploration/env_infos/reward_energy Min                 -1.04664
exploration/env_infos/final/end_effector_loc Mean        0.0755543
exploration/env_infos/final/end_effector_loc Std         0.530049
exploration/env_infos/final/end_effector_loc Max         1
exploration/env_infos/final/end_effector_loc Min        -1
exploration/env_infos/initial/end_effector_loc Mean      0.0014278
exploration/env_infos/initial/end_effector_loc Std       0.0226445
exploration/env_infos/initial/end_effector_loc Max       0.048724
exploration/env_infos/initial/end_effector_loc Min      -0.044289
exploration/env_infos/end_effector_loc Mean              0.0458423
exploration/env_infos/end_effector_loc Std               0.284783
exploration/env_infos/end_effector_loc Max               1
exploration/env_infos/end_effector_loc Min              -1
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0782571
exploration/env_infos/final/reward_dist Std              0.156446
exploration/env_infos/final/reward_dist Max              0.391148
exploration/env_infos/final/reward_dist Min              2.32275e-101
exploration/env_infos/initial/reward_dist Mean           0.00623951
exploration/env_infos/initial/reward_dist Std            0.00544964
exploration/env_infos/initial/reward_dist Max            0.0140669
exploration/env_infos/initial/reward_dist Min            1.53351e-05
exploration/env_infos/reward_dist Mean                   0.036171
exploration/env_infos/reward_dist Std                    0.120798
exploration/env_infos/reward_dist Max                    0.980937
exploration/env_infos/reward_dist Min                    2.32275e-101
evaluation/num steps total                           90000
evaluation/num paths total                            4500
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0383405
evaluation/Rewards Std                                   0.0779172
evaluation/Rewards Max                                   0.177887
evaluation/Rewards Min                                  -0.302629
evaluation/Returns Mean                                 -0.766809
evaluation/Returns Std                                   1.28961
evaluation/Returns Max                                   2.18874
evaluation/Returns Min                                  -3.18742
evaluation/Actions Mean                                 -0.000502245
evaluation/Actions Std                                   0.0749714
evaluation/Actions Max                                   0.691469
evaluation/Actions Min                                  -0.699993
evaluation/Num Paths                                    50
evaluation/Average Returns                              -0.766809
evaluation/env_infos/final/reward_energy Mean           -0.0580733
evaluation/env_infos/final/reward_energy Std             0.0456765
evaluation/env_infos/final/reward_energy Max            -0.00443257
evaluation/env_infos/final/reward_energy Min            -0.190822
evaluation/env_infos/initial/reward_energy Mean         -0.227239
evaluation/env_infos/initial/reward_energy Std           0.232181
evaluation/env_infos/initial/reward_energy Max          -0.0119196
evaluation/env_infos/initial/reward_energy Min          -0.71726
evaluation/env_infos/reward_energy Mean                 -0.0671067
evaluation/env_infos/reward_energy Std                   0.0820891
evaluation/env_infos/reward_energy Max                  -0.000125772
evaluation/env_infos/reward_energy Min                  -0.71726
evaluation/env_infos/final/end_effector_loc Mean         0.00727139
evaluation/env_infos/final/end_effector_loc Std          0.225091
evaluation/env_infos/final/end_effector_loc Max          0.978247
evaluation/env_infos/final/end_effector_loc Min         -0.3748
evaluation/env_infos/initial/end_effector_loc Mean      -0.000231781
evaluation/env_infos/initial/end_effector_loc Std        0.0114838
evaluation/env_infos/initial/end_effector_loc Max        0.0345734
evaluation/env_infos/initial/end_effector_loc Min       -0.0349996
evaluation/env_infos/end_effector_loc Mean               0.0046216
evaluation/env_infos/end_effector_loc Std                0.140912
evaluation/env_infos/end_effector_loc Max                0.978247
evaluation/env_infos/end_effector_loc Min               -0.3748
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.176696
evaluation/env_infos/final/reward_dist Std               0.26898
evaluation/env_infos/final/reward_dist Max               0.900763
evaluation/env_infos/final/reward_dist Min               3.37265e-106
evaluation/env_infos/initial/reward_dist Mean            0.00791612
evaluation/env_infos/initial/reward_dist Std             0.0146902
evaluation/env_infos/initial/reward_dist Max             0.064526
evaluation/env_infos/initial/reward_dist Min             1.12301e-06
evaluation/env_infos/reward_dist Mean                    0.194531
evaluation/env_infos/reward_dist Std                     0.280009
evaluation/env_infos/reward_dist Max                     0.999569
evaluation/env_infos/reward_dist Min                     3.37265e-106
time/data storing (s)                                   39.0303
time/evaluation sampling (s)                             0.623057
time/exploration sampling (s)                            0.101274
time/logging (s)                                         0.0180793
time/saving (s)                                          0.939993
time/training (s)                                       37.3404
time/epoch (s)                                          78.0532
time/total (s)                                        5312.48
Epoch                                                   89
---------------------------------------------------  ----------------
2021-05-29 01:26:00.241898 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 90 finished
---------------------------------------------------  ----------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00101109
trainer/QF2 Loss                                         0.00223016
trainer/Policy Loss                                      2.34173
trainer/Q1 Predictions Mean                             -0.565382
trainer/Q1 Predictions Std                               0.749557
trainer/Q1 Predictions Max                               1.22991
trainer/Q1 Predictions Min                              -2.79296
trainer/Q2 Predictions Mean                             -0.560166
trainer/Q2 Predictions Std                               0.761584
trainer/Q2 Predictions Max                               1.25345
trainer/Q2 Predictions Min                              -2.8113
trainer/Q Targets Mean                                  -0.567975
trainer/Q Targets Std                                    0.753379
trainer/Q Targets Max                                    1.27156
trainer/Q Targets Min                                   -2.77875
trainer/Log Pis Mean                                     1.77932
trainer/Log Pis Std                                      1.35759
trainer/Log Pis Max                                      4.69964
trainer/Log Pis Min                                     -4.68218
trainer/Policy mu Mean                                   0.0156793
trainer/Policy mu Std                                    0.304478
trainer/Policy mu Max                                    1.84287
trainer/Policy mu Min                                   -2.39438
trainer/Policy log std Mean                             -2.2423
trainer/Policy log std Std                               0.569822
trainer/Policy log std Max                              -0.336921
trainer/Policy log std Min                              -3.49501
trainer/Alpha                                            0.01681
trainer/Alpha Loss                                      -0.901615
exploration/num steps total                          10100
exploration/num paths total                            505
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0773699
exploration/Rewards Std                                  0.0866689
exploration/Rewards Max                                  0.0601662
exploration/Rewards Min                                 -0.275997
exploration/Returns Mean                                -1.5474
exploration/Returns Std                                  1.03258
exploration/Returns Max                                 -0.135795
exploration/Returns Min                                 -3.00231
exploration/Actions Mean                                -0.00461837
exploration/Actions Std                                  0.180738
exploration/Actions Max                                  0.790922
exploration/Actions Min                                 -0.61928
exploration/Num Paths                                    5
exploration/Average Returns                             -1.5474
exploration/env_infos/final/reward_energy Mean          -0.169246
exploration/env_infos/final/reward_energy Std            0.041777
exploration/env_infos/final/reward_energy Max           -0.094782
exploration/env_infos/final/reward_energy Min           -0.217805
exploration/env_infos/initial/reward_energy Mean        -0.461109
exploration/env_infos/initial/reward_energy Std          0.13529
exploration/env_infos/initial/reward_energy Max         -0.266272
exploration/env_infos/initial/reward_energy Min         -0.670955
exploration/env_infos/reward_energy Mean                -0.205816
exploration/env_infos/reward_energy Std                  0.151705
exploration/env_infos/reward_energy Max                 -0.0232813
exploration/env_infos/reward_energy Min                 -0.814105
exploration/env_infos/final/end_effector_loc Mean        0.00931301
exploration/env_infos/final/end_effector_loc Std         0.234533
exploration/env_infos/final/end_effector_loc Max         0.380372
exploration/env_infos/final/end_effector_loc Min        -0.368268
exploration/env_infos/initial/end_effector_loc Mean     -0.002287
exploration/env_infos/initial/end_effector_loc Std       0.0168353
exploration/env_infos/initial/end_effector_loc Max       0.0237151
exploration/env_infos/initial/end_effector_loc Min      -0.0250629
exploration/env_infos/end_effector_loc Mean             -0.00735598
exploration/env_infos/end_effector_loc Std               0.202149
exploration/env_infos/end_effector_loc Max               0.408157
exploration/env_infos/end_effector_loc Min              -0.381572
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0516302
exploration/env_infos/final/reward_dist Std              0.0664545
exploration/env_infos/final/reward_dist Max              0.16597
exploration/env_infos/final/reward_dist Min              4.85617e-07
exploration/env_infos/initial/reward_dist Mean           0.0252915
exploration/env_infos/initial/reward_dist Std            0.0388293
exploration/env_infos/initial/reward_dist Max            0.101672
exploration/env_infos/initial/reward_dist Min            1.64042e-05
exploration/env_infos/reward_dist Mean                   0.175083
exploration/env_infos/reward_dist Std                    0.241635
exploration/env_infos/reward_dist Max                    0.980322
exploration/env_infos/reward_dist Min                    4.85617e-07
evaluation/num steps total                           91000
evaluation/num paths total                            4550
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0666448
evaluation/Rewards Std                                   0.0666073
evaluation/Rewards Max                                   0.0934315
evaluation/Rewards Min                                  -0.320658
evaluation/Returns Mean                                 -1.3329
evaluation/Returns Std                                   1.02668
evaluation/Returns Max                                   0.934648
evaluation/Returns Min                                  -3.88523
evaluation/Actions Mean                                  0.00197101
evaluation/Actions Std                                   0.0976814
evaluation/Actions Max                                   0.924691
evaluation/Actions Min                                  -0.726707
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.3329
evaluation/env_infos/final/reward_energy Mean           -0.0545152
evaluation/env_infos/final/reward_energy Std             0.0412883
evaluation/env_infos/final/reward_energy Max            -0.00907942
evaluation/env_infos/final/reward_energy Min            -0.214991
evaluation/env_infos/initial/reward_energy Mean         -0.276314
evaluation/env_infos/initial/reward_energy Std           0.310519
evaluation/env_infos/initial/reward_energy Max          -0.00886632
evaluation/env_infos/initial/reward_energy Min          -1.13772
evaluation/env_infos/reward_energy Mean                 -0.0766267
evaluation/env_infos/reward_energy Std                   0.114976
evaluation/env_infos/reward_energy Max                  -0.000380065
evaluation/env_infos/reward_energy Min                  -1.13772
evaluation/env_infos/final/end_effector_loc Mean         0.0500208
evaluation/env_infos/final/end_effector_loc Std          0.247211
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.507474
evaluation/env_infos/initial/end_effector_loc Mean       0.00103642
evaluation/env_infos/initial/end_effector_loc Std        0.0146591
evaluation/env_infos/initial/end_effector_loc Max        0.0462346
evaluation/env_infos/initial/end_effector_loc Min       -0.0363353
evaluation/env_infos/end_effector_loc Mean               0.0252524
evaluation/env_infos/end_effector_loc Std                0.163877
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.507474
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.107841
evaluation/env_infos/final/reward_dist Std               0.162484
evaluation/env_infos/final/reward_dist Max               0.553186
evaluation/env_infos/final/reward_dist Min               3.79582e-115
evaluation/env_infos/initial/reward_dist Mean            0.00348272
evaluation/env_infos/initial/reward_dist Std             0.00610468
evaluation/env_infos/initial/reward_dist Max             0.022879
evaluation/env_infos/initial/reward_dist Min             8.79514e-07
evaluation/env_infos/reward_dist Mean                    0.129364
evaluation/env_infos/reward_dist Std                     0.219563
evaluation/env_infos/reward_dist Max                     0.998809
evaluation/env_infos/reward_dist Min                     3.79582e-115
time/data storing (s)                                   43.3094
time/evaluation sampling (s)                             0.99624
time/exploration sampling (s)                            0.124955
time/logging (s)                                         0.0210134
time/saving (s)                                          0.865631
time/training (s)                                       48.4392
time/epoch (s)                                          93.7564
time/total (s)                                        5407.37
Epoch                                                   90
---------------------------------------------------  ----------------
2021-05-29 01:27:27.708375 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 91 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00133724
trainer/QF2 Loss                                         0.00129137
trainer/Policy Loss                                      2.73709
trainer/Q1 Predictions Mean                             -0.684945
trainer/Q1 Predictions Std                               0.713597
trainer/Q1 Predictions Max                               1.30042
trainer/Q1 Predictions Min                              -2.40717
trainer/Q2 Predictions Mean                             -0.669687
trainer/Q2 Predictions Std                               0.707102
trainer/Q2 Predictions Max                               1.34217
trainer/Q2 Predictions Min                              -2.39825
trainer/Q Targets Mean                                  -0.66635
trainer/Q Targets Std                                    0.713617
trainer/Q Targets Max                                    1.38405
trainer/Q Targets Min                                   -2.42629
trainer/Log Pis Mean                                     2.05834
trainer/Log Pis Std                                      1.51267
trainer/Log Pis Max                                      4.71323
trainer/Log Pis Min                                     -5.70923
trainer/Policy mu Mean                                  -0.0168481
trainer/Policy mu Std                                    0.316489
trainer/Policy mu Max                                    1.84457
trainer/Policy mu Min                                   -2.17542
trainer/Policy log std Mean                             -2.35998
trainer/Policy log std Std                               0.566801
trainer/Policy log std Max                              -0.347216
trainer/Policy log std Min                              -3.51271
trainer/Alpha                                            0.0173321
trainer/Alpha Loss                                       0.236536
exploration/num steps total                          10200
exploration/num paths total                            510
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.148934
exploration/Rewards Std                                  0.0997887
exploration/Rewards Max                                  0.0867652
exploration/Rewards Min                                 -0.47099
exploration/Returns Mean                                -2.97868
exploration/Returns Std                                  0.872033
exploration/Returns Max                                 -1.97741
exploration/Returns Min                                 -4.45141
exploration/Actions Mean                                -0.00333048
exploration/Actions Std                                  0.0926909
exploration/Actions Max                                  0.331682
exploration/Actions Min                                 -0.301178
exploration/Num Paths                                    5
exploration/Average Returns                             -2.97868
exploration/env_infos/final/reward_energy Mean          -0.160726
exploration/env_infos/final/reward_energy Std            0.0981281
exploration/env_infos/final/reward_energy Max           -0.0386809
exploration/env_infos/final/reward_energy Min           -0.315649
exploration/env_infos/initial/reward_energy Mean        -0.0866735
exploration/env_infos/initial/reward_energy Std          0.0376722
exploration/env_infos/initial/reward_energy Max         -0.0149815
exploration/env_infos/initial/reward_energy Min         -0.121383
exploration/env_infos/reward_energy Mean                -0.109508
exploration/env_infos/reward_energy Std                  0.072204
exploration/env_infos/reward_energy Max                 -0.0118464
exploration/env_infos/reward_energy Min                 -0.337345
exploration/env_infos/final/end_effector_loc Mean       -0.0801049
exploration/env_infos/final/end_effector_loc Std         0.313053
exploration/env_infos/final/end_effector_loc Max         0.277612
exploration/env_infos/final/end_effector_loc Min        -0.771482
exploration/env_infos/initial/end_effector_loc Mean     -0.00020867
exploration/env_infos/initial/end_effector_loc Std       0.00333479
exploration/env_infos/initial/end_effector_loc Max       0.00539862
exploration/env_infos/initial/end_effector_loc Min      -0.00461862
exploration/env_infos/end_effector_loc Mean             -0.0382041
exploration/env_infos/end_effector_loc Std               0.164747
exploration/env_infos/end_effector_loc Max               0.277612
exploration/env_infos/end_effector_loc Min              -0.771482
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.00232099
exploration/env_infos/final/reward_dist Std              0.00460742
exploration/env_infos/final/reward_dist Max              0.0115357
exploration/env_infos/final/reward_dist Min              2.09078e-31
exploration/env_infos/initial/reward_dist Mean           0.00531286
exploration/env_infos/initial/reward_dist Std            0.0100813
exploration/env_infos/initial/reward_dist Max            0.025468
exploration/env_infos/initial/reward_dist Min            2.2373e-05
exploration/env_infos/reward_dist Mean                   0.0198761
exploration/env_infos/reward_dist Std                    0.0699144
exploration/env_infos/reward_dist Max                    0.387533
exploration/env_infos/reward_dist Min                    2.09078e-31
evaluation/num steps total                           92000
evaluation/num paths total                            4600
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0613051
evaluation/Rewards Std                                   0.0858784
evaluation/Rewards Max                                   0.123933
evaluation/Rewards Min                                  -0.70921
evaluation/Returns Mean                                 -1.2261
evaluation/Returns Std                                   1.26399
evaluation/Returns Max                                   1.08118
evaluation/Returns Min                                  -5.77078
evaluation/Actions Mean                                  0.00375898
evaluation/Actions Std                                   0.0865616
evaluation/Actions Max                                   0.807265
evaluation/Actions Min                                  -0.848352
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.2261
evaluation/env_infos/final/reward_energy Mean           -0.08401
evaluation/env_infos/final/reward_energy Std             0.0574878
evaluation/env_infos/final/reward_energy Max            -0.00504384
evaluation/env_infos/final/reward_energy Min            -0.306974
evaluation/env_infos/initial/reward_energy Mean         -0.260769
evaluation/env_infos/initial/reward_energy Std           0.257277
evaluation/env_infos/initial/reward_energy Max          -0.00626718
evaluation/env_infos/initial/reward_energy Min          -0.969779
evaluation/env_infos/reward_energy Mean                 -0.0772117
evaluation/env_infos/reward_energy Std                   0.0951444
evaluation/env_infos/reward_energy Max                  -0.000902577
evaluation/env_infos/reward_energy Min                  -0.969779
evaluation/env_infos/final/end_effector_loc Mean         0.0953959
evaluation/env_infos/final/end_effector_loc Std          0.356379
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean       0.00372962
evaluation/env_infos/initial/end_effector_loc Std        0.0124028
evaluation/env_infos/initial/end_effector_loc Max        0.0403633
evaluation/env_infos/initial/end_effector_loc Min       -0.0424176
evaluation/env_infos/end_effector_loc Mean               0.0576979
evaluation/env_infos/end_effector_loc Std                0.228813
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.129547
evaluation/env_infos/final/reward_dist Std               0.224362
evaluation/env_infos/final/reward_dist Max               0.894092
evaluation/env_infos/final/reward_dist Min               5.9389e-78
evaluation/env_infos/initial/reward_dist Mean            0.0102348
evaluation/env_infos/initial/reward_dist Std             0.0220887
evaluation/env_infos/initial/reward_dist Max             0.1315
evaluation/env_infos/initial/reward_dist Min             1.04353e-06
evaluation/env_infos/reward_dist Mean                    0.141353
evaluation/env_infos/reward_dist Std                     0.239588
evaluation/env_infos/reward_dist Max                     0.981266
evaluation/env_infos/reward_dist Min                     5.9389e-78
time/data storing (s)                                   43.2255
time/evaluation sampling (s)                             0.802217
time/exploration sampling (s)                            0.111382
time/logging (s)                                         0.0186501
time/saving (s)                                          0.857749
time/training (s)                                       41.3938
time/epoch (s)                                          86.4093
time/total (s)                                        5494.83
Epoch                                                   91
---------------------------------------------------  ---------------
2021-05-29 01:28:59.470989 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 92 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00121551
trainer/QF2 Loss                                         0.000756179
trainer/Policy Loss                                      2.64187
trainer/Q1 Predictions Mean                             -0.601699
trainer/Q1 Predictions Std                               0.660976
trainer/Q1 Predictions Max                               0.965953
trainer/Q1 Predictions Min                              -2.57705
trainer/Q2 Predictions Mean                             -0.596165
trainer/Q2 Predictions Std                               0.659152
trainer/Q2 Predictions Max                               0.931056
trainer/Q2 Predictions Min                              -2.53358
trainer/Q Targets Mean                                  -0.597056
trainer/Q Targets Std                                    0.655917
trainer/Q Targets Max                                    0.92135
trainer/Q Targets Min                                   -2.54725
trainer/Log Pis Mean                                     2.04506
trainer/Log Pis Std                                      1.31365
trainer/Log Pis Max                                      4.93452
trainer/Log Pis Min                                     -3.54012
trainer/Policy mu Mean                                  -0.0126197
trainer/Policy mu Std                                    0.214704
trainer/Policy mu Max                                    1.00633
trainer/Policy mu Min                                   -2.12073
trainer/Policy log std Mean                             -2.36236
trainer/Policy log std Std                               0.518504
trainer/Policy log std Max                              -0.670401
trainer/Policy log std Min                              -3.48207
trainer/Alpha                                            0.0177861
trainer/Alpha Loss                                       0.181588
exploration/num steps total                          10300
exploration/num paths total                            515
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.105657
exploration/Rewards Std                                  0.0782625
exploration/Rewards Max                                  0.0857416
exploration/Rewards Min                                 -0.356423
exploration/Returns Mean                                -2.11314
exploration/Returns Std                                  1.02627
exploration/Returns Max                                 -0.27481
exploration/Returns Min                                 -3.35415
exploration/Actions Mean                                -0.000243618
exploration/Actions Std                                  0.0965885
exploration/Actions Max                                  0.457832
exploration/Actions Min                                 -0.31847
exploration/Num Paths                                    5
exploration/Average Returns                             -2.11314
exploration/env_infos/final/reward_energy Mean          -0.164106
exploration/env_infos/final/reward_energy Std            0.106707
exploration/env_infos/final/reward_energy Max           -0.0585506
exploration/env_infos/final/reward_energy Min           -0.307694
exploration/env_infos/initial/reward_energy Mean        -0.225407
exploration/env_infos/initial/reward_energy Std          0.161108
exploration/env_infos/initial/reward_energy Max         -0.051979
exploration/env_infos/initial/reward_energy Min         -0.462698
exploration/env_infos/reward_energy Mean                -0.112912
exploration/env_infos/reward_energy Std                  0.0768739
exploration/env_infos/reward_energy Max                 -0.0024679
exploration/env_infos/reward_energy Min                 -0.462698
exploration/env_infos/final/end_effector_loc Mean       -0.0326067
exploration/env_infos/final/end_effector_loc Std         0.325924
exploration/env_infos/final/end_effector_loc Max         0.79496
exploration/env_infos/final/end_effector_loc Min        -0.364324
exploration/env_infos/initial/end_effector_loc Mean      0.000254309
exploration/env_infos/initial/end_effector_loc Std       0.00979236
exploration/env_infos/initial/end_effector_loc Max       0.0228916
exploration/env_infos/initial/end_effector_loc Min      -0.0159235
exploration/env_infos/end_effector_loc Mean             -0.0131888
exploration/env_infos/end_effector_loc Std               0.200955
exploration/env_infos/end_effector_loc Max               0.79496
exploration/env_infos/end_effector_loc Min              -0.364324
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.076272
exploration/env_infos/final/reward_dist Std              0.152493
exploration/env_infos/final/reward_dist Max              0.381258
exploration/env_infos/final/reward_dist Min              6.24784e-31
exploration/env_infos/initial/reward_dist Mean           0.00662417
exploration/env_infos/initial/reward_dist Std            0.00869848
exploration/env_infos/initial/reward_dist Max            0.0218604
exploration/env_infos/initial/reward_dist Min            2.39216e-06
exploration/env_infos/reward_dist Mean                   0.0823517
exploration/env_infos/reward_dist Std                    0.176042
exploration/env_infos/reward_dist Max                    0.772902
exploration/env_infos/reward_dist Min                    6.24784e-31
evaluation/num steps total                           93000
evaluation/num paths total                            4650
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.063337
evaluation/Rewards Std                                   0.0902873
evaluation/Rewards Max                                   0.147477
evaluation/Rewards Min                                  -0.674382
evaluation/Returns Mean                                 -1.26674
evaluation/Returns Std                                   1.41056
evaluation/Returns Max                                   1.7425
evaluation/Returns Min                                  -5.94682
evaluation/Actions Mean                                 -0.00458899
evaluation/Actions Std                                   0.0933921
evaluation/Actions Max                                   0.776678
evaluation/Actions Min                                  -0.863122
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.26674
evaluation/env_infos/final/reward_energy Mean           -0.0568894
evaluation/env_infos/final/reward_energy Std             0.0462779
evaluation/env_infos/final/reward_energy Max            -0.00545617
evaluation/env_infos/final/reward_energy Min            -0.241451
evaluation/env_infos/initial/reward_energy Mean         -0.302601
evaluation/env_infos/initial/reward_energy Std           0.29265
evaluation/env_infos/initial/reward_energy Max          -0.00290529
evaluation/env_infos/initial/reward_energy Min          -0.958256
evaluation/env_infos/reward_energy Mean                 -0.077467
evaluation/env_infos/reward_energy Std                   0.107169
evaluation/env_infos/reward_energy Max                  -0.000735595
evaluation/env_infos/reward_energy Min                  -0.958256
evaluation/env_infos/final/end_effector_loc Mean        -0.0547144
evaluation/env_infos/final/end_effector_loc Std          0.294949
evaluation/env_infos/final/end_effector_loc Max          0.768161
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00152726
evaluation/env_infos/initial/end_effector_loc Std        0.0148048
evaluation/env_infos/initial/end_effector_loc Max        0.0388339
evaluation/env_infos/initial/end_effector_loc Min       -0.0431561
evaluation/env_infos/end_effector_loc Mean              -0.0265098
evaluation/env_infos/end_effector_loc Std                0.191781
evaluation/env_infos/end_effector_loc Max                0.768161
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.162287
evaluation/env_infos/final/reward_dist Std               0.272574
evaluation/env_infos/final/reward_dist Max               0.956901
evaluation/env_infos/final/reward_dist Min               7.68799e-61
evaluation/env_infos/initial/reward_dist Mean            0.0101849
evaluation/env_infos/initial/reward_dist Std             0.0232676
evaluation/env_infos/initial/reward_dist Max             0.115108
evaluation/env_infos/initial/reward_dist Min             8.5471e-07
evaluation/env_infos/reward_dist Mean                    0.140748
evaluation/env_infos/reward_dist Std                     0.227806
evaluation/env_infos/reward_dist Max                     0.996663
evaluation/env_infos/reward_dist Min                     7.68799e-61
time/data storing (s)                                   43.7433
time/evaluation sampling (s)                             0.802581
time/exploration sampling (s)                            0.106054
time/logging (s)                                         0.0215607
time/saving (s)                                          0.917013
time/training (s)                                       45.0857
time/epoch (s)                                          90.6762
time/total (s)                                        5586.59
Epoch                                                   92
---------------------------------------------------  ---------------
2021-05-29 01:30:27.937584 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 93 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00225286
trainer/QF2 Loss                                         0.00120255
trainer/Policy Loss                                      2.61648
trainer/Q1 Predictions Mean                             -0.603143
trainer/Q1 Predictions Std                               0.763266
trainer/Q1 Predictions Max                               1.12398
trainer/Q1 Predictions Min                              -2.60357
trainer/Q2 Predictions Mean                             -0.606157
trainer/Q2 Predictions Std                               0.766269
trainer/Q2 Predictions Max                               1.13213
trainer/Q2 Predictions Min                              -2.58992
trainer/Q Targets Mean                                  -0.609094
trainer/Q Targets Std                                    0.772513
trainer/Q Targets Max                                    1.15668
trainer/Q Targets Min                                   -2.62493
trainer/Log Pis Mean                                     2.00906
trainer/Log Pis Std                                      1.33177
trainer/Log Pis Max                                      4.72259
trainer/Log Pis Min                                     -3.25827
trainer/Policy mu Mean                                  -0.0129933
trainer/Policy mu Std                                    0.221059
trainer/Policy mu Max                                    1.30073
trainer/Policy mu Min                                   -1.6976
trainer/Policy log std Mean                             -2.33521
trainer/Policy log std Std                               0.528657
trainer/Policy log std Max                              -0.547593
trainer/Policy log std Min                              -3.54887
trainer/Alpha                                            0.0172261
trainer/Alpha Loss                                       0.0368226
exploration/num steps total                          10400
exploration/num paths total                            520
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0893198
exploration/Rewards Std                                  0.0652553
exploration/Rewards Max                                  0.045805
exploration/Rewards Min                                 -0.264046
exploration/Returns Mean                                -1.7864
exploration/Returns Std                                  0.920861
exploration/Returns Max                                 -0.473616
exploration/Returns Min                                 -2.96021
exploration/Actions Mean                                 0.00255396
exploration/Actions Std                                  0.151305
exploration/Actions Max                                  0.83099
exploration/Actions Min                                 -0.677114
exploration/Num Paths                                    5
exploration/Average Returns                             -1.7864
exploration/env_infos/final/reward_energy Mean          -0.113889
exploration/env_infos/final/reward_energy Std            0.065751
exploration/env_infos/final/reward_energy Max           -0.0455797
exploration/env_infos/final/reward_energy Min           -0.222935
exploration/env_infos/initial/reward_energy Mean        -0.222017
exploration/env_infos/initial/reward_energy Std          0.245049
exploration/env_infos/initial/reward_energy Max         -0.0140133
exploration/env_infos/initial/reward_energy Min         -0.67556
exploration/env_infos/reward_energy Mean                -0.13649
exploration/env_infos/reward_energy Std                  0.164832
exploration/env_infos/reward_energy Max                 -0.00571826
exploration/env_infos/reward_energy Min                 -0.85298
exploration/env_infos/final/end_effector_loc Mean       -0.00388397
exploration/env_infos/final/end_effector_loc Std         0.298246
exploration/env_infos/final/end_effector_loc Max         0.342268
exploration/env_infos/final/end_effector_loc Min        -0.7264
exploration/env_infos/initial/end_effector_loc Mean     -0.00287766
exploration/env_infos/initial/end_effector_loc Std       0.0113311
exploration/env_infos/initial/end_effector_loc Max       0.0130718
exploration/env_infos/initial/end_effector_loc Min      -0.0325152
exploration/env_infos/end_effector_loc Mean             -0.0113665
exploration/env_infos/end_effector_loc Std               0.187478
exploration/env_infos/end_effector_loc Max               0.342268
exploration/env_infos/end_effector_loc Min              -0.7264
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.087481
exploration/env_infos/final/reward_dist Std              0.123614
exploration/env_infos/final/reward_dist Max              0.327146
exploration/env_infos/final/reward_dist Min              9.6468e-17
exploration/env_infos/initial/reward_dist Mean           0.00237228
exploration/env_infos/initial/reward_dist Std            0.00332913
exploration/env_infos/initial/reward_dist Max            0.0086999
exploration/env_infos/initial/reward_dist Min            7.34206e-06
exploration/env_infos/reward_dist Mean                   0.147123
exploration/env_infos/reward_dist Std                    0.259557
exploration/env_infos/reward_dist Max                    0.968058
exploration/env_infos/reward_dist Min                    9.6468e-17
evaluation/num steps total                           94000
evaluation/num paths total                            4700
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0486899
evaluation/Rewards Std                                   0.0748365
evaluation/Rewards Max                                   0.155596
evaluation/Rewards Min                                  -0.358118
evaluation/Returns Mean                                 -0.973798
evaluation/Returns Std                                   1.24049
evaluation/Returns Max                                   1.82954
evaluation/Returns Min                                  -3.12911
evaluation/Actions Mean                                  0.00210141
evaluation/Actions Std                                   0.0846233
evaluation/Actions Max                                   0.737522
evaluation/Actions Min                                  -0.866597
evaluation/Num Paths                                    50
evaluation/Average Returns                              -0.973798
evaluation/env_infos/final/reward_energy Mean           -0.0580862
evaluation/env_infos/final/reward_energy Std             0.0359045
evaluation/env_infos/final/reward_energy Max            -0.0147609
evaluation/env_infos/final/reward_energy Min            -0.156731
evaluation/env_infos/initial/reward_energy Mean         -0.263427
evaluation/env_infos/initial/reward_energy Std           0.253735
evaluation/env_infos/initial/reward_energy Max          -0.0100807
evaluation/env_infos/initial/reward_energy Min          -1.08963
evaluation/env_infos/reward_energy Mean                 -0.0741541
evaluation/env_infos/reward_energy Std                   0.0939799
evaluation/env_infos/reward_energy Max                  -0.000280486
evaluation/env_infos/reward_energy Min                  -1.08963
evaluation/env_infos/final/end_effector_loc Mean         0.0407412
evaluation/env_infos/final/end_effector_loc Std          0.280112
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.629974
evaluation/env_infos/initial/end_effector_loc Mean      -7.9603e-05
evaluation/env_infos/initial/end_effector_loc Std        0.0129311
evaluation/env_infos/initial/end_effector_loc Max        0.0368761
evaluation/env_infos/initial/end_effector_loc Min       -0.0433298
evaluation/env_infos/end_effector_loc Mean               0.0158972
evaluation/env_infos/end_effector_loc Std                0.181281
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.629974
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.20028
evaluation/env_infos/final/reward_dist Std               0.288153
evaluation/env_infos/final/reward_dist Max               0.96014
evaluation/env_infos/final/reward_dist Min               5.79746e-66
evaluation/env_infos/initial/reward_dist Mean            0.00967236
evaluation/env_infos/initial/reward_dist Std             0.0170796
evaluation/env_infos/initial/reward_dist Max             0.0824216
evaluation/env_infos/initial/reward_dist Min             1.8928e-06
evaluation/env_infos/reward_dist Mean                    0.179232
evaluation/env_infos/reward_dist Std                     0.274525
evaluation/env_infos/reward_dist Max                     0.997301
evaluation/env_infos/reward_dist Min                     5.79746e-66
time/data storing (s)                                   41.8273
time/evaluation sampling (s)                             1.03568
time/exploration sampling (s)                            0.116601
time/logging (s)                                         0.0211101
time/saving (s)                                          0.820906
time/training (s)                                       42.9975
time/epoch (s)                                          86.8191
time/total (s)                                        5675.06
Epoch                                                   93
---------------------------------------------------  ---------------
2021-05-29 01:31:53.283861 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 94 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00291957
trainer/QF2 Loss                                         0.00259509
trainer/Policy Loss                                      2.69535
trainer/Q1 Predictions Mean                             -0.710191
trainer/Q1 Predictions Std                               0.717377
trainer/Q1 Predictions Max                               0.938863
trainer/Q1 Predictions Min                              -2.72856
trainer/Q2 Predictions Mean                             -0.720064
trainer/Q2 Predictions Std                               0.721371
trainer/Q2 Predictions Max                               0.914557
trainer/Q2 Predictions Min                              -2.74159
trainer/Q Targets Mean                                  -0.72014
trainer/Q Targets Std                                    0.713725
trainer/Q Targets Max                                    0.941141
trainer/Q Targets Min                                   -2.75523
trainer/Log Pis Mean                                     1.98094
trainer/Log Pis Std                                      1.44115
trainer/Log Pis Max                                      4.9159
trainer/Log Pis Min                                     -3.37727
trainer/Policy mu Mean                                   0.0270442
trainer/Policy mu Std                                    0.295908
trainer/Policy mu Max                                    1.70266
trainer/Policy mu Min                                   -2.13587
trainer/Policy log std Mean                             -2.34207
trainer/Policy log std Std                               0.626776
trainer/Policy log std Max                              -0.436695
trainer/Policy log std Min                              -3.52297
trainer/Alpha                                            0.0173638
trainer/Alpha Loss                                      -0.0772737
exploration/num steps total                          10500
exploration/num paths total                            525
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.075721
exploration/Rewards Std                                  0.0998787
exploration/Rewards Max                                  0.176888
exploration/Rewards Min                                 -0.221992
exploration/Returns Mean                                -1.51442
exploration/Returns Std                                  1.83888
exploration/Returns Max                                  1.75387
exploration/Returns Min                                 -3.23365
exploration/Actions Mean                                 0.00140514
exploration/Actions Std                                  0.119761
exploration/Actions Max                                  0.961643
exploration/Actions Min                                 -0.477781
exploration/Num Paths                                    5
exploration/Average Returns                             -1.51442
exploration/env_infos/final/reward_energy Mean          -0.0831665
exploration/env_infos/final/reward_energy Std            0.0466773
exploration/env_infos/final/reward_energy Max           -0.00717921
exploration/env_infos/final/reward_energy Min           -0.138516
exploration/env_infos/initial/reward_energy Mean        -0.263977
exploration/env_infos/initial/reward_energy Std          0.378589
exploration/env_infos/initial/reward_energy Max         -0.0396309
exploration/env_infos/initial/reward_energy Min         -1.01979
exploration/env_infos/reward_energy Mean                -0.108962
exploration/env_infos/reward_energy Std                  0.129679
exploration/env_infos/reward_energy Max                 -0.00717921
exploration/env_infos/reward_energy Min                 -1.01979
exploration/env_infos/final/end_effector_loc Mean        0.0664708
exploration/env_infos/final/end_effector_loc Std         0.154876
exploration/env_infos/final/end_effector_loc Max         0.313367
exploration/env_infos/final/end_effector_loc Min        -0.182757
exploration/env_infos/initial/end_effector_loc Mean      0.0036592
exploration/env_infos/initial/end_effector_loc Std       0.0159021
exploration/env_infos/initial/end_effector_loc Max       0.0480822
exploration/env_infos/initial/end_effector_loc Min      -0.0169721
exploration/env_infos/end_effector_loc Mean              0.0369333
exploration/env_infos/end_effector_loc Std               0.129074
exploration/env_infos/end_effector_loc Max               0.350756
exploration/env_infos/end_effector_loc Min              -0.269814
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.218811
exploration/env_infos/final/reward_dist Std              0.296314
exploration/env_infos/final/reward_dist Max              0.752287
exploration/env_infos/final/reward_dist Min              9.81749e-12
exploration/env_infos/initial/reward_dist Mean           3.90881e-05
exploration/env_infos/initial/reward_dist Std            3.71151e-05
exploration/env_infos/initial/reward_dist Max            0.000101653
exploration/env_infos/initial/reward_dist Min            1.45638e-06
exploration/env_infos/reward_dist Mean                   0.101363
exploration/env_infos/reward_dist Std                    0.217172
exploration/env_infos/reward_dist Max                    0.971286
exploration/env_infos/reward_dist Min                    9.81749e-12
evaluation/num steps total                           95000
evaluation/num paths total                            4750
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0671288
evaluation/Rewards Std                                   0.0872732
evaluation/Rewards Max                                   0.149729
evaluation/Rewards Min                                  -0.634323
evaluation/Returns Mean                                 -1.34258
evaluation/Returns Std                                   1.28013
evaluation/Returns Max                                   1.36758
evaluation/Returns Min                                  -5.33973
evaluation/Actions Mean                                  0.00813749
evaluation/Actions Std                                   0.0914938
evaluation/Actions Max                                   0.730485
evaluation/Actions Min                                  -0.815817
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.34258
evaluation/env_infos/final/reward_energy Mean           -0.060632
evaluation/env_infos/final/reward_energy Std             0.0502053
evaluation/env_infos/final/reward_energy Max            -0.00566608
evaluation/env_infos/final/reward_energy Min            -0.252676
evaluation/env_infos/initial/reward_energy Mean         -0.27926
evaluation/env_infos/initial/reward_energy Std           0.279109
evaluation/env_infos/initial/reward_energy Max          -0.00834549
evaluation/env_infos/initial/reward_energy Min          -1.03918
evaluation/env_infos/reward_energy Mean                 -0.0741252
evaluation/env_infos/reward_energy Std                   0.106678
evaluation/env_infos/reward_energy Max                  -0.000648022
evaluation/env_infos/reward_energy Min                  -1.03918
evaluation/env_infos/final/end_effector_loc Mean         0.15604
evaluation/env_infos/final/end_effector_loc Std          0.30664
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -0.347722
evaluation/env_infos/initial/end_effector_loc Mean       0.00219736
evaluation/env_infos/initial/end_effector_loc Std        0.0137852
evaluation/env_infos/initial/end_effector_loc Max        0.0365243
evaluation/env_infos/initial/end_effector_loc Min       -0.0407908
evaluation/env_infos/end_effector_loc Mean               0.0746337
evaluation/env_infos/end_effector_loc Std                0.20024
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -0.347722
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.0909588
evaluation/env_infos/final/reward_dist Std               0.180443
evaluation/env_infos/final/reward_dist Max               0.984195
evaluation/env_infos/final/reward_dist Min               2.75558e-79
evaluation/env_infos/initial/reward_dist Mean            0.00508495
evaluation/env_infos/initial/reward_dist Std             0.0105326
evaluation/env_infos/initial/reward_dist Max             0.0579036
evaluation/env_infos/initial/reward_dist Min             2.2492e-06
evaluation/env_infos/reward_dist Mean                    0.113597
evaluation/env_infos/reward_dist Std                     0.215586
evaluation/env_infos/reward_dist Max                     0.988521
evaluation/env_infos/reward_dist Min                     2.75558e-79
time/data storing (s)                                   40.5442
time/evaluation sampling (s)                             0.664145
time/exploration sampling (s)                            0.09666
time/logging (s)                                         0.0179306
time/saving (s)                                          0.851544
time/training (s)                                       42.098
time/epoch (s)                                          84.2725
time/total (s)                                        5760.39
Epoch                                                   94
---------------------------------------------------  ---------------
2021-05-29 01:33:16.618012 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 95 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00086694
trainer/QF2 Loss                                         0.00261364
trainer/Policy Loss                                      2.7414
trainer/Q1 Predictions Mean                             -0.781331
trainer/Q1 Predictions Std                               0.72224
trainer/Q1 Predictions Max                               0.875969
trainer/Q1 Predictions Min                              -2.59062
trainer/Q2 Predictions Mean                             -0.772541
trainer/Q2 Predictions Std                               0.724867
trainer/Q2 Predictions Max                               0.86509
trainer/Q2 Predictions Min                              -2.53724
trainer/Q Targets Mean                                  -0.781622
trainer/Q Targets Std                                    0.721136
trainer/Q Targets Max                                    0.889462
trainer/Q Targets Min                                   -2.54712
trainer/Log Pis Mean                                     1.95733
trainer/Log Pis Std                                      1.42599
trainer/Log Pis Max                                      4.92921
trainer/Log Pis Min                                     -3.63964
trainer/Policy mu Mean                                   0.0184392
trainer/Policy mu Std                                    0.284011
trainer/Policy mu Max                                    1.1163
trainer/Policy mu Min                                   -2.0341
trainer/Policy log std Mean                             -2.30964
trainer/Policy log std Std                               0.613358
trainer/Policy log std Max                              -0.11662
trainer/Policy log std Min                              -3.42105
trainer/Alpha                                            0.0191277
trainer/Alpha Loss                                      -0.168821
exploration/num steps total                          10600
exploration/num paths total                            530
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.108549
exploration/Rewards Std                                  0.070832
exploration/Rewards Max                                  0.0215986
exploration/Rewards Min                                 -0.381941
exploration/Returns Mean                                -2.17099
exploration/Returns Std                                  0.811518
exploration/Returns Max                                 -1.33089
exploration/Returns Min                                 -3.60303
exploration/Actions Mean                                 0.00382446
exploration/Actions Std                                  0.121381
exploration/Actions Max                                  0.453501
exploration/Actions Min                                 -0.791552
exploration/Num Paths                                    5
exploration/Average Returns                             -2.17099
exploration/env_infos/final/reward_energy Mean          -0.0989677
exploration/env_infos/final/reward_energy Std            0.0527326
exploration/env_infos/final/reward_energy Max           -0.0283724
exploration/env_infos/final/reward_energy Min           -0.187428
exploration/env_infos/initial/reward_energy Mean        -0.365556
exploration/env_infos/initial/reward_energy Std          0.354054
exploration/env_infos/initial/reward_energy Max         -0.056699
exploration/env_infos/initial/reward_energy Min         -1.00528
exploration/env_infos/reward_energy Mean                -0.119489
exploration/env_infos/reward_energy Std                  0.123364
exploration/env_infos/reward_energy Max                 -0.00450633
exploration/env_infos/reward_energy Min                 -1.00528
exploration/env_infos/final/end_effector_loc Mean        0.068041
exploration/env_infos/final/end_effector_loc Std         0.276939
exploration/env_infos/final/end_effector_loc Max         0.513668
exploration/env_infos/final/end_effector_loc Min        -0.218784
exploration/env_infos/initial/end_effector_loc Mean     -0.00271089
exploration/env_infos/initial/end_effector_loc Std       0.0177871
exploration/env_infos/initial/end_effector_loc Max       0.022675
exploration/env_infos/initial/end_effector_loc Min      -0.0395776
exploration/env_infos/end_effector_loc Mean              0.0256671
exploration/env_infos/end_effector_loc Std               0.183312
exploration/env_infos/end_effector_loc Max               0.513668
exploration/env_infos/end_effector_loc Min              -0.305544
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0300922
exploration/env_infos/final/reward_dist Std              0.0601539
exploration/env_infos/final/reward_dist Max              0.1504
exploration/env_infos/final/reward_dist Min              1.87778e-08
exploration/env_infos/initial/reward_dist Mean           0.0026418
exploration/env_infos/initial/reward_dist Std            0.00393986
exploration/env_infos/initial/reward_dist Max            0.0103057
exploration/env_infos/initial/reward_dist Min            2.07676e-05
exploration/env_infos/reward_dist Mean                   0.152116
exploration/env_infos/reward_dist Std                    0.266138
exploration/env_infos/reward_dist Max                    0.990811
exploration/env_infos/reward_dist Min                    1.87778e-08
evaluation/num steps total                           96000
evaluation/num paths total                            4800
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0512662
evaluation/Rewards Std                                   0.0675929
evaluation/Rewards Max                                   0.142128
evaluation/Rewards Min                                  -0.418641
evaluation/Returns Mean                                 -1.02532
evaluation/Returns Std                                   1.08457
evaluation/Returns Max                                   1.45053
evaluation/Returns Min                                  -3.78557
evaluation/Actions Mean                                  0.00167714
evaluation/Actions Std                                   0.0617832
evaluation/Actions Max                                   0.748281
evaluation/Actions Min                                  -0.664205
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.02532
evaluation/env_infos/final/reward_energy Mean           -0.0406321
evaluation/env_infos/final/reward_energy Std             0.0324654
evaluation/env_infos/final/reward_energy Max            -0.00421721
evaluation/env_infos/final/reward_energy Min            -0.20462
evaluation/env_infos/initial/reward_energy Mean         -0.18387
evaluation/env_infos/initial/reward_energy Std           0.206424
evaluation/env_infos/initial/reward_energy Max          -0.00503569
evaluation/env_infos/initial/reward_energy Min          -0.867239
evaluation/env_infos/reward_energy Mean                 -0.0516033
evaluation/env_infos/reward_energy Std                   0.0705482
evaluation/env_infos/reward_energy Max                  -0.000836794
evaluation/env_infos/reward_energy Min                  -0.867239
evaluation/env_infos/final/end_effector_loc Mean         0.0587922
evaluation/env_infos/final/end_effector_loc Std          0.196997
evaluation/env_infos/final/end_effector_loc Max          0.567482
evaluation/env_infos/final/end_effector_loc Min         -0.451987
evaluation/env_infos/initial/end_effector_loc Mean       0.0020448
evaluation/env_infos/initial/end_effector_loc Std        0.00955733
evaluation/env_infos/initial/end_effector_loc Max        0.037414
evaluation/env_infos/initial/end_effector_loc Min       -0.0332103
evaluation/env_infos/end_effector_loc Mean               0.0305641
evaluation/env_infos/end_effector_loc Std                0.128711
evaluation/env_infos/end_effector_loc Max                0.567482
evaluation/env_infos/end_effector_loc Min               -0.451987
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.18088
evaluation/env_infos/final/reward_dist Std               0.242141
evaluation/env_infos/final/reward_dist Max               0.83353
evaluation/env_infos/final/reward_dist Min               8.35412e-17
evaluation/env_infos/initial/reward_dist Mean            0.00863148
evaluation/env_infos/initial/reward_dist Std             0.0176398
evaluation/env_infos/initial/reward_dist Max             0.0857411
evaluation/env_infos/initial/reward_dist Min             1.38446e-06
evaluation/env_infos/reward_dist Mean                    0.183761
evaluation/env_infos/reward_dist Std                     0.274317
evaluation/env_infos/reward_dist Max                     0.991145
evaluation/env_infos/reward_dist Min                     8.35412e-17
time/data storing (s)                                   41.1122
time/evaluation sampling (s)                             0.75276
time/exploration sampling (s)                            0.0950404
time/logging (s)                                         0.0149888
time/saving (s)                                          0.825992
time/training (s)                                       39.4094
time/epoch (s)                                          82.2104
time/total (s)                                        5843.72
Epoch                                                   95
---------------------------------------------------  ---------------
2021-05-29 01:34:41.277296 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 96 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00109483
trainer/QF2 Loss                                         0.00138228
trainer/Policy Loss                                      2.63546
trainer/Q1 Predictions Mean                             -0.77868
trainer/Q1 Predictions Std                               0.798051
trainer/Q1 Predictions Max                               0.70582
trainer/Q1 Predictions Min                              -3.25318
trainer/Q2 Predictions Mean                             -0.77972
trainer/Q2 Predictions Std                               0.803263
trainer/Q2 Predictions Max                               0.708368
trainer/Q2 Predictions Min                              -3.23467
trainer/Q Targets Mean                                  -0.773444
trainer/Q Targets Std                                    0.800632
trainer/Q Targets Max                                    0.709528
trainer/Q Targets Min                                   -3.24912
trainer/Log Pis Mean                                     1.85466
trainer/Log Pis Std                                      1.44494
trainer/Log Pis Max                                      4.73317
trainer/Log Pis Min                                     -5.09443
trainer/Policy mu Mean                                   0.0283975
trainer/Policy mu Std                                    0.316013
trainer/Policy mu Max                                    1.56232
trainer/Policy mu Min                                   -1.85597
trainer/Policy log std Mean                             -2.22195
trainer/Policy log std Std                               0.636684
trainer/Policy log std Max                              -0.284801
trainer/Policy log std Min                              -3.42973
trainer/Alpha                                            0.0186006
trainer/Alpha Loss                                      -0.579205
exploration/num steps total                          10700
exploration/num paths total                            535
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0988904
exploration/Rewards Std                                  0.0648767
exploration/Rewards Max                                  0.0673976
exploration/Rewards Min                                 -0.407352
exploration/Returns Mean                                -1.97781
exploration/Returns Std                                  0.826691
exploration/Returns Max                                 -0.524634
exploration/Returns Min                                 -2.80228
exploration/Actions Mean                                 0.00897617
exploration/Actions Std                                  0.163364
exploration/Actions Max                                  0.729425
exploration/Actions Min                                 -0.757849
exploration/Num Paths                                    5
exploration/Average Returns                             -1.97781
exploration/env_infos/final/reward_energy Mean          -0.10384
exploration/env_infos/final/reward_energy Std            0.0337982
exploration/env_infos/final/reward_energy Max           -0.0714872
exploration/env_infos/final/reward_energy Min           -0.167868
exploration/env_infos/initial/reward_energy Mean        -0.548211
exploration/env_infos/initial/reward_energy Std          0.321177
exploration/env_infos/initial/reward_energy Max         -0.143703
exploration/env_infos/initial/reward_energy Min         -0.845506
exploration/env_infos/reward_energy Mean                -0.173841
exploration/env_infos/reward_energy Std                  0.152695
exploration/env_infos/reward_energy Max                 -0.0138337
exploration/env_infos/reward_energy Min                 -0.845506
exploration/env_infos/final/end_effector_loc Mean        0.128348
exploration/env_infos/final/end_effector_loc Std         0.2237
exploration/env_infos/final/end_effector_loc Max         0.545142
exploration/env_infos/final/end_effector_loc Min        -0.241665
exploration/env_infos/initial/end_effector_loc Mean     -0.00384053
exploration/env_infos/initial/end_effector_loc Std       0.0221329
exploration/env_infos/initial/end_effector_loc Max       0.0364713
exploration/env_infos/initial/end_effector_loc Min      -0.0378925
exploration/env_infos/end_effector_loc Mean              0.0391038
exploration/env_infos/end_effector_loc Std               0.187378
exploration/env_infos/end_effector_loc Max               0.545142
exploration/env_infos/end_effector_loc Min              -0.323613
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.233457
exploration/env_infos/final/reward_dist Std              0.346494
exploration/env_infos/final/reward_dist Max              0.906348
exploration/env_infos/final/reward_dist Min              8.84154e-27
exploration/env_infos/initial/reward_dist Mean           0.00769644
exploration/env_infos/initial/reward_dist Std            0.0124248
exploration/env_infos/initial/reward_dist Max            0.032139
exploration/env_infos/initial/reward_dist Min            5.05599e-05
exploration/env_infos/reward_dist Mean                   0.180795
exploration/env_infos/reward_dist Std                    0.31276
exploration/env_infos/reward_dist Max                    0.995599
exploration/env_infos/reward_dist Min                    8.84154e-27
evaluation/num steps total                           97000
evaluation/num paths total                            4850
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0611624
evaluation/Rewards Std                                   0.0906165
evaluation/Rewards Max                                   0.193177
evaluation/Rewards Min                                  -0.574259
evaluation/Returns Mean                                 -1.22325
evaluation/Returns Std                                   1.46998
evaluation/Returns Max                                   2.52004
evaluation/Returns Min                                  -6.21051
evaluation/Actions Mean                                  0.00381318
evaluation/Actions Std                                   0.0903372
evaluation/Actions Max                                   0.919565
evaluation/Actions Min                                  -0.860768
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.22325
evaluation/env_infos/final/reward_energy Mean           -0.0529458
evaluation/env_infos/final/reward_energy Std             0.0497026
evaluation/env_infos/final/reward_energy Max            -0.00613961
evaluation/env_infos/final/reward_energy Min            -0.265727
evaluation/env_infos/initial/reward_energy Mean         -0.252785
evaluation/env_infos/initial/reward_energy Std           0.282169
evaluation/env_infos/initial/reward_energy Max          -0.00255128
evaluation/env_infos/initial/reward_energy Min          -1.11228
evaluation/env_infos/reward_energy Mean                 -0.0678412
evaluation/env_infos/reward_energy Std                   0.108389
evaluation/env_infos/reward_energy Max                  -0.000566601
evaluation/env_infos/reward_energy Min                  -1.11228
evaluation/env_infos/final/end_effector_loc Mean         0.0835703
evaluation/env_infos/final/end_effector_loc Std          0.277953
evaluation/env_infos/final/end_effector_loc Max          1
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00159224
evaluation/env_infos/initial/end_effector_loc Std        0.013299
evaluation/env_infos/initial/end_effector_loc Max        0.0459783
evaluation/env_infos/initial/end_effector_loc Min       -0.0430384
evaluation/env_infos/end_effector_loc Mean               0.0326907
evaluation/env_infos/end_effector_loc Std                0.189194
evaluation/env_infos/end_effector_loc Max                1
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.242754
evaluation/env_infos/final/reward_dist Std               0.348974
evaluation/env_infos/final/reward_dist Max               0.988007
evaluation/env_infos/final/reward_dist Min               4.37419e-97
evaluation/env_infos/initial/reward_dist Mean            0.00770538
evaluation/env_infos/initial/reward_dist Std             0.0178615
evaluation/env_infos/initial/reward_dist Max             0.0878881
evaluation/env_infos/initial/reward_dist Min             1.86888e-06
evaluation/env_infos/reward_dist Mean                    0.148759
evaluation/env_infos/reward_dist Std                     0.260592
evaluation/env_infos/reward_dist Max                     0.999191
evaluation/env_infos/reward_dist Min                     4.37419e-97
time/data storing (s)                                   40.9551
time/evaluation sampling (s)                             0.747763
time/exploration sampling (s)                            0.0984627
time/logging (s)                                         0.0179821
time/saving (s)                                          0.81514
time/training (s)                                       40.9219
time/epoch (s)                                          83.5564
time/total (s)                                        5928.38
Epoch                                                   96
---------------------------------------------------  ---------------
2021-05-29 01:36:03.929750 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 97 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00191681
trainer/QF2 Loss                                         0.00204826
trainer/Policy Loss                                      2.63495
trainer/Q1 Predictions Mean                             -0.729836
trainer/Q1 Predictions Std                               0.790878
trainer/Q1 Predictions Max                               0.775979
trainer/Q1 Predictions Min                              -3.30948
trainer/Q2 Predictions Mean                             -0.723622
trainer/Q2 Predictions Std                               0.790199
trainer/Q2 Predictions Max                               0.838662
trainer/Q2 Predictions Min                              -3.32335
trainer/Q Targets Mean                                  -0.724472
trainer/Q Targets Std                                    0.797434
trainer/Q Targets Max                                    0.797319
trainer/Q Targets Min                                   -3.32452
trainer/Log Pis Mean                                     1.91558
trainer/Log Pis Std                                      1.38663
trainer/Log Pis Max                                      6.48831
trainer/Log Pis Min                                     -3.89429
trainer/Policy mu Mean                                  -0.0160856
trainer/Policy mu Std                                    0.533777
trainer/Policy mu Max                                    2.09641
trainer/Policy mu Min                                   -2.67706
trainer/Policy log std Mean                             -2.1447
trainer/Policy log std Std                               0.670688
trainer/Policy log std Max                              -0.065406
trainer/Policy log std Min                              -3.33539
trainer/Alpha                                            0.0171627
trainer/Alpha Loss                                      -0.343111
exploration/num steps total                          10800
exploration/num paths total                            540
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.10148
exploration/Rewards Std                                  0.100132
exploration/Rewards Max                                  0.118679
exploration/Rewards Min                                 -0.291895
exploration/Returns Mean                                -2.02959
exploration/Returns Std                                  1.6141
exploration/Returns Max                                  0.684264
exploration/Returns Min                                 -3.95271
exploration/Actions Mean                                 0.0163646
exploration/Actions Std                                  0.156671
exploration/Actions Max                                  0.540641
exploration/Actions Min                                 -0.705344
exploration/Num Paths                                    5
exploration/Average Returns                             -2.02959
exploration/env_infos/final/reward_energy Mean          -0.0905778
exploration/env_infos/final/reward_energy Std            0.0524315
exploration/env_infos/final/reward_energy Max           -0.0305956
exploration/env_infos/final/reward_energy Min           -0.168231
exploration/env_infos/initial/reward_energy Mean        -0.310581
exploration/env_infos/initial/reward_energy Std          0.147575
exploration/env_infos/initial/reward_energy Max         -0.130968
exploration/env_infos/initial/reward_energy Min         -0.555363
exploration/env_infos/reward_energy Mean                -0.167893
exploration/env_infos/reward_energy Std                  0.146422
exploration/env_infos/reward_energy Max                 -0.00257694
exploration/env_infos/reward_energy Min                 -0.714794
exploration/env_infos/final/end_effector_loc Mean        0.104338
exploration/env_infos/final/end_effector_loc Std         0.198538
exploration/env_infos/final/end_effector_loc Max         0.376886
exploration/env_infos/final/end_effector_loc Min        -0.285561
exploration/env_infos/initial/end_effector_loc Mean      0.00101755
exploration/env_infos/initial/end_effector_loc Std       0.0121146
exploration/env_infos/initial/end_effector_loc Max       0.027032
exploration/env_infos/initial/end_effector_loc Min      -0.0173706
exploration/env_infos/end_effector_loc Mean              0.0091038
exploration/env_infos/end_effector_loc Std               0.177933
exploration/env_infos/end_effector_loc Max               0.376886
exploration/env_infos/end_effector_loc Min              -0.462376
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.0639194
exploration/env_infos/final/reward_dist Std              0.118868
exploration/env_infos/final/reward_dist Max              0.301234
exploration/env_infos/final/reward_dist Min              6.65031e-15
exploration/env_infos/initial/reward_dist Mean           0.00532706
exploration/env_infos/initial/reward_dist Std            0.00980987
exploration/env_infos/initial/reward_dist Max            0.0249328
exploration/env_infos/initial/reward_dist Min            5.89994e-05
exploration/env_infos/reward_dist Mean                   0.120643
exploration/env_infos/reward_dist Std                    0.228722
exploration/env_infos/reward_dist Max                    0.996787
exploration/env_infos/reward_dist Min                    6.65031e-15
evaluation/num steps total                           98000
evaluation/num paths total                            4900
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0702309
evaluation/Rewards Std                                   0.0883529
evaluation/Rewards Max                                   0.159016
evaluation/Rewards Min                                  -0.681037
evaluation/Returns Mean                                 -1.40462
evaluation/Returns Std                                   1.34028
evaluation/Returns Max                                   1.35993
evaluation/Returns Min                                  -5.17023
evaluation/Actions Mean                                  0.00268241
evaluation/Actions Std                                   0.125865
evaluation/Actions Max                                   0.747791
evaluation/Actions Min                                  -0.952333
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.40462
evaluation/env_infos/final/reward_energy Mean           -0.0741645
evaluation/env_infos/final/reward_energy Std             0.0980827
evaluation/env_infos/final/reward_energy Max            -0.00498993
evaluation/env_infos/final/reward_energy Min            -0.602331
evaluation/env_infos/initial/reward_energy Mean         -0.322384
evaluation/env_infos/initial/reward_energy Std           0.314757
evaluation/env_infos/initial/reward_energy Max          -0.00374242
evaluation/env_infos/initial/reward_energy Min          -1.33803
evaluation/env_infos/reward_energy Mean                 -0.100695
evaluation/env_infos/reward_energy Std                   0.146829
evaluation/env_infos/reward_energy Max                  -0.000914354
evaluation/env_infos/reward_energy Min                  -1.33803
evaluation/env_infos/final/end_effector_loc Mean         0.0243662
evaluation/env_infos/final/end_effector_loc Std          0.265134
evaluation/env_infos/final/end_effector_loc Max          0.833786
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.00229514
evaluation/env_infos/initial/end_effector_loc Std        0.0157635
evaluation/env_infos/initial/end_effector_loc Max        0.0308956
evaluation/env_infos/initial/end_effector_loc Min       -0.0476167
evaluation/env_infos/end_effector_loc Mean              -0.00514792
evaluation/env_infos/end_effector_loc Std                0.197088
evaluation/env_infos/end_effector_loc Max                0.833786
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.14951
evaluation/env_infos/final/reward_dist Std               0.254495
evaluation/env_infos/final/reward_dist Max               0.969786
evaluation/env_infos/final/reward_dist Min               4.8033e-55
evaluation/env_infos/initial/reward_dist Mean            0.0138403
evaluation/env_infos/initial/reward_dist Std             0.0380895
evaluation/env_infos/initial/reward_dist Max             0.190199
evaluation/env_infos/initial/reward_dist Min             1.52209e-06
evaluation/env_infos/reward_dist Mean                    0.133324
evaluation/env_infos/reward_dist Std                     0.244519
evaluation/env_infos/reward_dist Max                     0.99678
evaluation/env_infos/reward_dist Min                     4.8033e-55
time/data storing (s)                                   39.346
time/evaluation sampling (s)                             0.665146
time/exploration sampling (s)                            0.0946519
time/logging (s)                                         0.0176871
time/saving (s)                                          0.839132
time/training (s)                                       40.5757
time/epoch (s)                                          81.5384
time/total (s)                                        6011.02
Epoch                                                   97
---------------------------------------------------  ---------------
2021-05-29 01:37:28.647216 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 98 finished
---------------------------------------------------  ---------------
replay_buffer/size                                    2000
trainer/QF1 Loss                                         0.00123433
trainer/QF2 Loss                                         0.00162892
trainer/Policy Loss                                      2.77621
trainer/Q1 Predictions Mean                             -0.913155
trainer/Q1 Predictions Std                               0.826456
trainer/Q1 Predictions Max                               0.980689
trainer/Q1 Predictions Min                              -2.89561
trainer/Q2 Predictions Mean                             -0.916693
trainer/Q2 Predictions Std                               0.822982
trainer/Q2 Predictions Max                               0.955377
trainer/Q2 Predictions Min                              -2.89264
trainer/Q Targets Mean                                  -0.910536
trainer/Q Targets Std                                    0.822972
trainer/Q Targets Max                                    1.00159
trainer/Q Targets Min                                   -2.86976
trainer/Log Pis Mean                                     1.85762
trainer/Log Pis Std                                      1.34667
trainer/Log Pis Max                                      4.30114
trainer/Log Pis Min                                     -4.64859
trainer/Policy mu Mean                                  -0.0256635
trainer/Policy mu Std                                    0.354656
trainer/Policy mu Max                                    1.53876
trainer/Policy mu Min                                   -2.26438
trainer/Policy log std Mean                             -2.26758
trainer/Policy log std Std                               0.590982
trainer/Policy log std Max                              -0.465934
trainer/Policy log std Min                              -3.31998
trainer/Alpha                                            0.0179957
trainer/Alpha Loss                                      -0.571925
exploration/num steps total                          10900
exploration/num paths total                            545
exploration/path length Mean                            20
exploration/path length Std                              0
exploration/path length Max                             20
exploration/path length Min                             20
exploration/Rewards Mean                                -0.0848683
exploration/Rewards Std                                  0.0951368
exploration/Rewards Max                                  0.104909
exploration/Rewards Min                                 -0.283546
exploration/Returns Mean                                -1.69737
exploration/Returns Std                                  1.65865
exploration/Returns Max                                  0.758029
exploration/Returns Min                                 -4.1554
exploration/Actions Mean                                 0.00541072
exploration/Actions Std                                  0.112253
exploration/Actions Max                                  0.36948
exploration/Actions Min                                 -0.366113
exploration/Num Paths                                    5
exploration/Average Returns                             -1.69737
exploration/env_infos/final/reward_energy Mean          -0.142631
exploration/env_infos/final/reward_energy Std            0.109364
exploration/env_infos/final/reward_energy Max           -0.0419676
exploration/env_infos/final/reward_energy Min           -0.31444
exploration/env_infos/initial/reward_energy Mean        -0.196285
exploration/env_infos/initial/reward_energy Std          0.130492
exploration/env_infos/initial/reward_energy Max         -0.0487313
exploration/env_infos/initial/reward_energy Min         -0.41626
exploration/env_infos/reward_energy Mean                -0.126216
exploration/env_infos/reward_energy Std                  0.0965904
exploration/env_infos/reward_energy Max                 -0.00820222
exploration/env_infos/reward_energy Min                 -0.418063
exploration/env_infos/final/end_effector_loc Mean        0.110658
exploration/env_infos/final/end_effector_loc Std         0.173133
exploration/env_infos/final/end_effector_loc Max         0.353923
exploration/env_infos/final/end_effector_loc Min        -0.17495
exploration/env_infos/initial/end_effector_loc Mean     -0.00150701
exploration/env_infos/initial/end_effector_loc Std       0.00819598
exploration/env_infos/initial/end_effector_loc Max       0.0115376
exploration/env_infos/initial/end_effector_loc Min      -0.0183056
exploration/env_infos/end_effector_loc Mean              0.0290912
exploration/env_infos/end_effector_loc Std               0.132585
exploration/env_infos/end_effector_loc Max               0.353923
exploration/env_infos/end_effector_loc Min              -0.287611
exploration/env_infos/final/reward_safety Mean           0
exploration/env_infos/final/reward_safety Std            0
exploration/env_infos/final/reward_safety Max            0
exploration/env_infos/final/reward_safety Min            0
exploration/env_infos/initial/reward_safety Mean         0
exploration/env_infos/initial/reward_safety Std          0
exploration/env_infos/initial/reward_safety Max          0
exploration/env_infos/initial/reward_safety Min          0
exploration/env_infos/reward_safety Mean                 0
exploration/env_infos/reward_safety Std                  0
exploration/env_infos/reward_safety Max                  0
exploration/env_infos/reward_safety Min                  0
exploration/env_infos/final/reward_dist Mean             0.202377
exploration/env_infos/final/reward_dist Std              0.370193
exploration/env_infos/final/reward_dist Max              0.942136
exploration/env_infos/final/reward_dist Min              3.84886e-07
exploration/env_infos/initial/reward_dist Mean           0.0110684
exploration/env_infos/initial/reward_dist Std            0.0144817
exploration/env_infos/initial/reward_dist Max            0.0391896
exploration/env_infos/initial/reward_dist Min            0.000115646
exploration/env_infos/reward_dist Mean                   0.239951
exploration/env_infos/reward_dist Std                    0.32656
exploration/env_infos/reward_dist Max                    0.995495
exploration/env_infos/reward_dist Min                    3.84886e-07
evaluation/num steps total                           99000
evaluation/num paths total                            4950
evaluation/path length Mean                             20
evaluation/path length Std                               0
evaluation/path length Max                              20
evaluation/path length Min                              20
evaluation/Rewards Mean                                 -0.0936156
evaluation/Rewards Std                                   0.103524
evaluation/Rewards Max                                   0.0954964
evaluation/Rewards Min                                  -0.697753
evaluation/Returns Mean                                 -1.87231
evaluation/Returns Std                                   1.74102
evaluation/Returns Max                                   0.583569
evaluation/Returns Min                                  -6.67259
evaluation/Actions Mean                                  0.00245356
evaluation/Actions Std                                   0.133
evaluation/Actions Max                                   0.768863
evaluation/Actions Min                                  -0.92386
evaluation/Num Paths                                    50
evaluation/Average Returns                              -1.87231
evaluation/env_infos/final/reward_energy Mean           -0.0883163
evaluation/env_infos/final/reward_energy Std             0.138976
evaluation/env_infos/final/reward_energy Max            -0.00553598
evaluation/env_infos/final/reward_energy Min            -0.781035
evaluation/env_infos/initial/reward_energy Mean         -0.308822
evaluation/env_infos/initial/reward_energy Std           0.325195
evaluation/env_infos/initial/reward_energy Max          -0.0136392
evaluation/env_infos/initial/reward_energy Min          -1.00878
evaluation/env_infos/reward_energy Mean                 -0.105205
evaluation/env_infos/reward_energy Std                   0.155955
evaluation/env_infos/reward_energy Max                  -0.000858555
evaluation/env_infos/reward_energy Min                  -1.00878
evaluation/env_infos/final/end_effector_loc Mean         0.052333
evaluation/env_infos/final/end_effector_loc Std          0.328929
evaluation/env_infos/final/end_effector_loc Max          0.916988
evaluation/env_infos/final/end_effector_loc Min         -1
evaluation/env_infos/initial/end_effector_loc Mean      -0.000583783
evaluation/env_infos/initial/end_effector_loc Std        0.015845
evaluation/env_infos/initial/end_effector_loc Max        0.0384432
evaluation/env_infos/initial/end_effector_loc Min       -0.046193
evaluation/env_infos/end_effector_loc Mean               0.0139004
evaluation/env_infos/end_effector_loc Std                0.234666
evaluation/env_infos/end_effector_loc Max                0.916988
evaluation/env_infos/end_effector_loc Min               -1
evaluation/env_infos/final/reward_safety Mean            0
evaluation/env_infos/final/reward_safety Std             0
evaluation/env_infos/final/reward_safety Max             0
evaluation/env_infos/final/reward_safety Min             0
evaluation/env_infos/initial/reward_safety Mean          0
evaluation/env_infos/initial/reward_safety Std           0
evaluation/env_infos/initial/reward_safety Max           0
evaluation/env_infos/initial/reward_safety Min           0
evaluation/env_infos/reward_safety Mean                  0
evaluation/env_infos/reward_safety Std                   0
evaluation/env_infos/reward_safety Max                   0
evaluation/env_infos/reward_safety Min                   0
evaluation/env_infos/final/reward_dist Mean              0.144397
evaluation/env_infos/final/reward_dist Std               0.296573
evaluation/env_infos/final/reward_dist Max               0.971839
evaluation/env_infos/final/reward_dist Min               1.70818e-67
evaluation/env_infos/initial/reward_dist Mean            0.00825332
evaluation/env_infos/initial/reward_dist Std             0.0159274
evaluation/env_infos/initial/reward_dist Max             0.0779254
evaluation/env_infos/initial/reward_dist Min             5.43017e-06
evaluation/env_infos/reward_dist Mean                    0.128537
evaluation/env_infos/reward_dist Std                     0.253949
evaluation/env_infos/reward_dist Max                     0.994915
evaluation/env_infos/reward_dist Min                     1.5604e-72
time/data storing (s)                                   40.9089
time/evaluation sampling (s)                             1.48857
time/exploration sampling (s)                            0.099065
time/logging (s)                                         0.0160772
time/saving (s)                                          0.807813
time/training (s)                                       40.0981
time/epoch (s)                                          83.4185
time/total (s)                                        6095.74
Epoch                                                   98
---------------------------------------------------  ---------------
2021-05-29 01:38:53.662254 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 99 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00243188
trainer/QF2 Loss                                          0.00321737
trainer/Policy Loss                                       2.88507
trainer/Q1 Predictions Mean                              -0.817725
trainer/Q1 Predictions Std                                0.811713
trainer/Q1 Predictions Max                                0.932533
trainer/Q1 Predictions Min                               -3.36645
trainer/Q2 Predictions Mean                              -0.823368
trainer/Q2 Predictions Std                                0.807186
trainer/Q2 Predictions Max                                0.944362
trainer/Q2 Predictions Min                               -3.3446
trainer/Q Targets Mean                                   -0.827685
trainer/Q Targets Std                                     0.808242
trainer/Q Targets Max                                     0.949717
trainer/Q Targets Min                                    -3.31186
trainer/Log Pis Mean                                      2.05633
trainer/Log Pis Std                                       1.30885
trainer/Log Pis Max                                       4.71016
trainer/Log Pis Min                                      -2.8348
trainer/Policy mu Mean                                   -0.0257543
trainer/Policy mu Std                                     0.357189
trainer/Policy mu Max                                     1.88035
trainer/Policy mu Min                                    -2.44091
trainer/Policy log std Mean                              -2.3124
trainer/Policy log std Std                                0.579314
trainer/Policy log std Max                               -0.0266311
trainer/Policy log std Min                               -3.33656
trainer/Alpha                                             0.0196887
trainer/Alpha Loss                                        0.221268
exploration/num steps total                           11000
exploration/num paths total                             550
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.116996
exploration/Rewards Std                                   0.116263
exploration/Rewards Max                                   0.0540153
exploration/Rewards Min                                  -0.536837
exploration/Returns Mean                                 -2.33993
exploration/Returns Std                                   1.55803
exploration/Returns Max                                   0.02081
exploration/Returns Min                                  -4.26908
exploration/Actions Mean                                 -0.00261925
exploration/Actions Std                                   0.150712
exploration/Actions Max                                   0.518067
exploration/Actions Min                                  -0.837618
exploration/Num Paths                                     5
exploration/Average Returns                              -2.33993
exploration/env_infos/final/reward_energy Mean           -0.154979
exploration/env_infos/final/reward_energy Std             0.140635
exploration/env_infos/final/reward_energy Max            -0.0139828
exploration/env_infos/final/reward_energy Min            -0.378011
exploration/env_infos/initial/reward_energy Mean         -0.468291
exploration/env_infos/initial/reward_energy Std           0.300574
exploration/env_infos/initial/reward_energy Max          -0.0949382
exploration/env_infos/initial/reward_energy Min          -0.880907
exploration/env_infos/reward_energy Mean                 -0.164519
exploration/env_infos/reward_energy Std                   0.135556
exploration/env_infos/reward_energy Max                  -0.00500502
exploration/env_infos/reward_energy Min                  -0.880907
exploration/env_infos/final/end_effector_loc Mean         0.0378349
exploration/env_infos/final/end_effector_loc Std          0.299909
exploration/env_infos/final/end_effector_loc Max          0.506375
exploration/env_infos/final/end_effector_loc Min         -0.55528
exploration/env_infos/initial/end_effector_loc Mean      -0.00468947
exploration/env_infos/initial/end_effector_loc Std        0.0191065
exploration/env_infos/initial/end_effector_loc Max        0.0259033
exploration/env_infos/initial/end_effector_loc Min       -0.0418809
exploration/env_infos/end_effector_loc Mean               0.00977019
exploration/env_infos/end_effector_loc Std                0.192408
exploration/env_infos/end_effector_loc Max                0.506375
exploration/env_infos/end_effector_loc Min               -0.55528
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0016959
exploration/env_infos/final/reward_dist Std               0.00337631
exploration/env_infos/final/reward_dist Max               0.00844849
exploration/env_infos/final/reward_dist Min               1.61434e-25
exploration/env_infos/initial/reward_dist Mean            8.86258e-05
exploration/env_infos/initial/reward_dist Std             0.000112282
exploration/env_infos/initial/reward_dist Max             0.000304703
exploration/env_infos/initial/reward_dist Min             2.21714e-06
exploration/env_infos/reward_dist Mean                    0.0486817
exploration/env_infos/reward_dist Std                     0.112512
exploration/env_infos/reward_dist Max                     0.625498
exploration/env_infos/reward_dist Min                     1.61434e-25
evaluation/num steps total                           100000
evaluation/num paths total                             5000
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0615823
evaluation/Rewards Std                                    0.0761526
evaluation/Rewards Max                                    0.170123
evaluation/Rewards Min                                   -0.257524
evaluation/Returns Mean                                  -1.23165
evaluation/Returns Std                                    1.28648
evaluation/Returns Max                                    1.48638
evaluation/Returns Min                                   -3.77305
evaluation/Actions Mean                                   0.000445382
evaluation/Actions Std                                    0.0801235
evaluation/Actions Max                                    0.461154
evaluation/Actions Min                                   -0.775527
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.23165
evaluation/env_infos/final/reward_energy Mean            -0.0569613
evaluation/env_infos/final/reward_energy Std              0.0388472
evaluation/env_infos/final/reward_energy Max             -0.00670907
evaluation/env_infos/final/reward_energy Min             -0.173582
evaluation/env_infos/initial/reward_energy Mean          -0.190028
evaluation/env_infos/initial/reward_energy Std            0.202585
evaluation/env_infos/initial/reward_energy Max           -0.0141269
evaluation/env_infos/initial/reward_energy Min           -0.884268
evaluation/env_infos/reward_energy Mean                  -0.0708414
evaluation/env_infos/reward_energy Std                    0.0884389
evaluation/env_infos/reward_energy Max                   -0.000955971
evaluation/env_infos/reward_energy Min                   -0.884268
evaluation/env_infos/final/end_effector_loc Mean          0.0156348
evaluation/env_infos/final/end_effector_loc Std           0.210495
evaluation/env_infos/final/end_effector_loc Max           0.604333
evaluation/env_infos/final/end_effector_loc Min          -0.442075
evaluation/env_infos/initial/end_effector_loc Mean       -0.00127347
evaluation/env_infos/initial/end_effector_loc Std         0.00973741
evaluation/env_infos/initial/end_effector_loc Max         0.0197601
evaluation/env_infos/initial/end_effector_loc Min        -0.0387763
evaluation/env_infos/end_effector_loc Mean                0.00116332
evaluation/env_infos/end_effector_loc Std                 0.148761
evaluation/env_infos/end_effector_loc Max                 0.604333
evaluation/env_infos/end_effector_loc Min                -0.488936
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.152448
evaluation/env_infos/final/reward_dist Std                0.29271
evaluation/env_infos/final/reward_dist Max                0.996673
evaluation/env_infos/final/reward_dist Min                4.46222e-30
evaluation/env_infos/initial/reward_dist Mean             0.00594422
evaluation/env_infos/initial/reward_dist Std              0.0124758
evaluation/env_infos/initial/reward_dist Max              0.0569719
evaluation/env_infos/initial/reward_dist Min              1.10105e-06
evaluation/env_infos/reward_dist Mean                     0.147238
evaluation/env_infos/reward_dist Std                      0.253295
evaluation/env_infos/reward_dist Max                      0.996673
evaluation/env_infos/reward_dist Min                      4.46222e-30
time/data storing (s)                                    41.0726
time/evaluation sampling (s)                              0.686639
time/exploration sampling (s)                             0.104285
time/logging (s)                                          0.015463
time/saving (s)                                           0.798766
time/training (s)                                        41.0456
time/epoch (s)                                           83.7234
time/total (s)                                         6180.75
Epoch                                                    99
---------------------------------------------------  ----------------
2021-05-29 01:40:12.714616 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 100 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0012214
trainer/QF2 Loss                                          0.00167089
trainer/Policy Loss                                       2.6627
trainer/Q1 Predictions Mean                              -0.721963
trainer/Q1 Predictions Std                                0.818829
trainer/Q1 Predictions Max                                1.07112
trainer/Q1 Predictions Min                               -3.2582
trainer/Q2 Predictions Mean                              -0.729708
trainer/Q2 Predictions Std                                0.821811
trainer/Q2 Predictions Max                                1.04269
trainer/Q2 Predictions Min                               -3.27851
trainer/Q Targets Mean                                   -0.732509
trainer/Q Targets Std                                     0.823771
trainer/Q Targets Max                                     1.04357
trainer/Q Targets Min                                    -3.30288
trainer/Log Pis Mean                                      1.93239
trainer/Log Pis Std                                       1.51574
trainer/Log Pis Max                                       4.70118
trainer/Log Pis Min                                      -4.52211
trainer/Policy mu Mean                                   -0.0232841
trainer/Policy mu Std                                     0.306977
trainer/Policy mu Max                                     1.80129
trainer/Policy mu Min                                    -2.2185
trainer/Policy log std Mean                              -2.33426
trainer/Policy log std Std                                0.598475
trainer/Policy log std Max                                0.280281
trainer/Policy log std Min                               -3.33112
trainer/Alpha                                             0.0195397
trainer/Alpha Loss                                       -0.266015
exploration/num steps total                           11100
exploration/num paths total                             555
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.091344
exploration/Rewards Std                                   0.0492043
exploration/Rewards Max                                   0.00243989
exploration/Rewards Min                                  -0.25915
exploration/Returns Mean                                 -1.82688
exploration/Returns Std                                   0.630353
exploration/Returns Max                                  -1.01096
exploration/Returns Min                                  -2.88308
exploration/Actions Mean                                 -0.00440411
exploration/Actions Std                                   0.105455
exploration/Actions Max                                   0.297785
exploration/Actions Min                                  -0.426648
exploration/Num Paths                                     5
exploration/Average Returns                              -1.82688
exploration/env_infos/final/reward_energy Mean           -0.149165
exploration/env_infos/final/reward_energy Std             0.0852313
exploration/env_infos/final/reward_energy Max            -0.0357487
exploration/env_infos/final/reward_energy Min            -0.272056
exploration/env_infos/initial/reward_energy Mean         -0.154994
exploration/env_infos/initial/reward_energy Std           0.124863
exploration/env_infos/initial/reward_energy Max          -0.0276798
exploration/env_infos/initial/reward_energy Min          -0.316316
exploration/env_infos/reward_energy Mean                 -0.120398
exploration/env_infos/reward_energy Std                   0.0882308
exploration/env_infos/reward_energy Max                  -0.0170453
exploration/env_infos/reward_energy Min                  -0.44703
exploration/env_infos/final/end_effector_loc Mean        -0.105109
exploration/env_infos/final/end_effector_loc Std          0.156561
exploration/env_infos/final/end_effector_loc Max          0.182454
exploration/env_infos/final/end_effector_loc Min         -0.301861
exploration/env_infos/initial/end_effector_loc Mean      -0.000461687
exploration/env_infos/initial/end_effector_loc Std        0.00702171
exploration/env_infos/initial/end_effector_loc Max        0.0148893
exploration/env_infos/initial/end_effector_loc Min       -0.0143707
exploration/env_infos/end_effector_loc Mean              -0.0524115
exploration/env_infos/end_effector_loc Std                0.116213
exploration/env_infos/end_effector_loc Max                0.223366
exploration/env_infos/end_effector_loc Min               -0.301861
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.1381
exploration/env_infos/final/reward_dist Std               0.275334
exploration/env_infos/final/reward_dist Max               0.688766
exploration/env_infos/final/reward_dist Min               2.36849e-07
exploration/env_infos/initial/reward_dist Mean            0.00487964
exploration/env_infos/initial/reward_dist Std             0.00585348
exploration/env_infos/initial/reward_dist Max             0.016072
exploration/env_infos/initial/reward_dist Min             6.13667e-06
exploration/env_infos/reward_dist Mean                    0.0897811
exploration/env_infos/reward_dist Std                     0.212141
exploration/env_infos/reward_dist Max                     0.977195
exploration/env_infos/reward_dist Min                     2.36849e-07
evaluation/num steps total                           101000
evaluation/num paths total                             5050
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0455663
evaluation/Rewards Std                                    0.0710469
evaluation/Rewards Max                                    0.164872
evaluation/Rewards Min                                   -0.31208
evaluation/Returns Mean                                  -0.911325
evaluation/Returns Std                                    1.1515
evaluation/Returns Max                                    2.55352
evaluation/Returns Min                                   -3.83905
evaluation/Actions Mean                                   0.00171218
evaluation/Actions Std                                    0.0753359
evaluation/Actions Max                                    0.866969
evaluation/Actions Min                                   -0.725313
evaluation/Num Paths                                     50
evaluation/Average Returns                               -0.911325
evaluation/env_infos/final/reward_energy Mean            -0.0539744
evaluation/env_infos/final/reward_energy Std              0.0486473
evaluation/env_infos/final/reward_energy Max             -0.00702771
evaluation/env_infos/final/reward_energy Min             -0.253038
evaluation/env_infos/initial/reward_energy Mean          -0.186566
evaluation/env_infos/initial/reward_energy Std            0.214548
evaluation/env_infos/initial/reward_energy Max           -0.00268595
evaluation/env_infos/initial/reward_energy Min           -0.879411
evaluation/env_infos/reward_energy Mean                  -0.0635635
evaluation/env_infos/reward_energy Std                    0.0855368
evaluation/env_infos/reward_energy Max                   -0.000253183
evaluation/env_infos/reward_energy Min                   -0.879411
evaluation/env_infos/final/end_effector_loc Mean          0.0298166
evaluation/env_infos/final/end_effector_loc Std           0.219636
evaluation/env_infos/final/end_effector_loc Max           0.850786
evaluation/env_infos/final/end_effector_loc Min          -0.627513
evaluation/env_infos/initial/end_effector_loc Mean        0.000434749
evaluation/env_infos/initial/end_effector_loc Std         0.0100428
evaluation/env_infos/initial/end_effector_loc Max         0.0433484
evaluation/env_infos/initial/end_effector_loc Min        -0.0362657
evaluation/env_infos/end_effector_loc Mean                0.0125728
evaluation/env_infos/end_effector_loc Std                 0.147357
evaluation/env_infos/end_effector_loc Max                 0.850786
evaluation/env_infos/end_effector_loc Min                -0.627513
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.137656
evaluation/env_infos/final/reward_dist Std                0.236098
evaluation/env_infos/final/reward_dist Max                0.853348
evaluation/env_infos/final/reward_dist Min                7.71124e-47
evaluation/env_infos/initial/reward_dist Mean             0.00676683
evaluation/env_infos/initial/reward_dist Std              0.0152487
evaluation/env_infos/initial/reward_dist Max              0.0780484
evaluation/env_infos/initial/reward_dist Min              1.08712e-06
evaluation/env_infos/reward_dist Mean                     0.15795
evaluation/env_infos/reward_dist Std                      0.255048
evaluation/env_infos/reward_dist Max                      0.991506
evaluation/env_infos/reward_dist Min                      7.71124e-47
time/data storing (s)                                    38.2183
time/evaluation sampling (s)                              0.643638
time/exploration sampling (s)                             0.0953694
time/logging (s)                                          0.0161578
time/saving (s)                                           1.57884
time/training (s)                                        37.3914
time/epoch (s)                                           77.9438
time/total (s)                                         6259.79
Epoch                                                   100
---------------------------------------------------  ----------------
2021-05-29 01:41:29.437936 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 101 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0016728
trainer/QF2 Loss                                          0.00159468
trainer/Policy Loss                                       2.83082
trainer/Q1 Predictions Mean                              -0.8221
trainer/Q1 Predictions Std                                0.828921
trainer/Q1 Predictions Max                                1.10861
trainer/Q1 Predictions Min                               -3.3677
trainer/Q2 Predictions Mean                              -0.832931
trainer/Q2 Predictions Std                                0.828028
trainer/Q2 Predictions Max                                1.10395
trainer/Q2 Predictions Min                               -3.37551
trainer/Q Targets Mean                                   -0.831774
trainer/Q Targets Std                                     0.834317
trainer/Q Targets Max                                     1.15354
trainer/Q Targets Min                                    -3.36601
trainer/Log Pis Mean                                      2.00556
trainer/Log Pis Std                                       1.43874
trainer/Log Pis Max                                       4.69845
trainer/Log Pis Min                                      -5.34396
trainer/Policy mu Mean                                   -0.0350726
trainer/Policy mu Std                                     0.40963
trainer/Policy mu Max                                     2.16629
trainer/Policy mu Min                                    -2.97627
trainer/Policy log std Mean                              -2.27697
trainer/Policy log std Std                                0.620241
trainer/Policy log std Max                               -0.312656
trainer/Policy log std Min                               -3.33516
trainer/Alpha                                             0.0208702
trainer/Alpha Loss                                        0.0215203
exploration/num steps total                           11200
exploration/num paths total                             560
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.111099
exploration/Rewards Std                                   0.0852781
exploration/Rewards Max                                   0.09164
exploration/Rewards Min                                  -0.308478
exploration/Returns Mean                                 -2.22199
exploration/Returns Std                                   1.38396
exploration/Returns Max                                   0.174127
exploration/Returns Min                                  -3.89954
exploration/Actions Mean                                  0.00874057
exploration/Actions Std                                   0.151774
exploration/Actions Max                                   0.548156
exploration/Actions Min                                  -0.85753
exploration/Num Paths                                     5
exploration/Average Returns                              -2.22199
exploration/env_infos/final/reward_energy Mean           -0.140352
exploration/env_infos/final/reward_energy Std             0.117563
exploration/env_infos/final/reward_energy Max            -0.0513683
exploration/env_infos/final/reward_energy Min            -0.3704
exploration/env_infos/initial/reward_energy Mean         -0.379729
exploration/env_infos/initial/reward_energy Std           0.294297
exploration/env_infos/initial/reward_energy Max          -0.033917
exploration/env_infos/initial/reward_energy Min          -0.887333
exploration/env_infos/reward_energy Mean                 -0.1533
exploration/env_infos/reward_energy Std                   0.15074
exploration/env_infos/reward_energy Max                  -0.0115408
exploration/env_infos/reward_energy Min                  -0.887333
exploration/env_infos/final/end_effector_loc Mean         0.207888
exploration/env_infos/final/end_effector_loc Std          0.169312
exploration/env_infos/final/end_effector_loc Max          0.47196
exploration/env_infos/final/end_effector_loc Min         -0.111292
exploration/env_infos/initial/end_effector_loc Mean       0.00275495
exploration/env_infos/initial/end_effector_loc Std        0.0167606
exploration/env_infos/initial/end_effector_loc Max        0.0208283
exploration/env_infos/initial/end_effector_loc Min       -0.0428765
exploration/env_infos/end_effector_loc Mean               0.112678
exploration/env_infos/end_effector_loc Std                0.159708
exploration/env_infos/end_effector_loc Max                0.495373
exploration/env_infos/end_effector_loc Min               -0.223467
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00524234
exploration/env_infos/final/reward_dist Std               0.0104494
exploration/env_infos/final/reward_dist Max               0.0261411
exploration/env_infos/final/reward_dist Min               4.93295e-26
exploration/env_infos/initial/reward_dist Mean            1.77041e-05
exploration/env_infos/initial/reward_dist Std             1.88016e-05
exploration/env_infos/initial/reward_dist Max             5.10481e-05
exploration/env_infos/initial/reward_dist Min             2.64506e-06
exploration/env_infos/reward_dist Mean                    0.047313
exploration/env_infos/reward_dist Std                     0.131016
exploration/env_infos/reward_dist Max                     0.61907
exploration/env_infos/reward_dist Min                     4.93295e-26
evaluation/num steps total                           102000
evaluation/num paths total                             5100
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0622442
evaluation/Rewards Std                                    0.100818
evaluation/Rewards Max                                    0.142128
evaluation/Rewards Min                                   -0.736392
evaluation/Returns Mean                                  -1.24488
evaluation/Returns Std                                    1.59568
evaluation/Returns Max                                    1.51878
evaluation/Returns Min                                   -6.47444
evaluation/Actions Mean                                   0.000585695
evaluation/Actions Std                                    0.105591
evaluation/Actions Max                                    0.844747
evaluation/Actions Min                                   -0.847139
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.24488
evaluation/env_infos/final/reward_energy Mean            -0.0631801
evaluation/env_infos/final/reward_energy Std              0.0978088
evaluation/env_infos/final/reward_energy Max             -0.00389333
evaluation/env_infos/final/reward_energy Min             -0.589265
evaluation/env_infos/initial/reward_energy Mean          -0.281478
evaluation/env_infos/initial/reward_energy Std            0.278915
evaluation/env_infos/initial/reward_energy Max           -0.00322497
evaluation/env_infos/initial/reward_energy Min           -1.03427
evaluation/env_infos/reward_energy Mean                  -0.0891909
evaluation/env_infos/reward_energy Std                    0.11977
evaluation/env_infos/reward_energy Max                   -0.0014834
evaluation/env_infos/reward_energy Min                   -1.03427
evaluation/env_infos/final/end_effector_loc Mean          0.00085132
evaluation/env_infos/final/end_effector_loc Std           0.271771
evaluation/env_infos/final/end_effector_loc Max           0.782261
evaluation/env_infos/final/end_effector_loc Min          -0.871193
evaluation/env_infos/initial/end_effector_loc Mean       -0.00119891
evaluation/env_infos/initial/end_effector_loc Std         0.0139586
evaluation/env_infos/initial/end_effector_loc Max         0.0422373
evaluation/env_infos/initial/end_effector_loc Min        -0.0373271
evaluation/env_infos/end_effector_loc Mean               -0.00990612
evaluation/env_infos/end_effector_loc Std                 0.187074
evaluation/env_infos/end_effector_loc Max                 0.782261
evaluation/env_infos/end_effector_loc Min                -0.871193
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.149336
evaluation/env_infos/final/reward_dist Std                0.239528
evaluation/env_infos/final/reward_dist Max                0.847907
evaluation/env_infos/final/reward_dist Min                5.59852e-99
evaluation/env_infos/initial/reward_dist Mean             0.00817263
evaluation/env_infos/initial/reward_dist Std              0.0167672
evaluation/env_infos/initial/reward_dist Max              0.0847148
evaluation/env_infos/initial/reward_dist Min              2.35058e-06
evaluation/env_infos/reward_dist Mean                     0.134791
evaluation/env_infos/reward_dist Std                      0.231192
evaluation/env_infos/reward_dist Max                      0.989945
evaluation/env_infos/reward_dist Min                      5.59852e-99
time/data storing (s)                                    37.8848
time/evaluation sampling (s)                              0.465746
time/exploration sampling (s)                             0.083946
time/logging (s)                                          0.0143881
time/saving (s)                                           0.794188
time/training (s)                                        36.3733
time/epoch (s)                                           75.6164
time/total (s)                                         6336.51
Epoch                                                   101
---------------------------------------------------  ----------------
2021-05-29 01:42:53.896906 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 102 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00147765
trainer/QF2 Loss                                          0.00140508
trainer/Policy Loss                                       2.65396
trainer/Q1 Predictions Mean                              -0.721883
trainer/Q1 Predictions Std                                0.789942
trainer/Q1 Predictions Max                                1.19488
trainer/Q1 Predictions Min                               -2.94938
trainer/Q2 Predictions Mean                              -0.717717
trainer/Q2 Predictions Std                                0.789409
trainer/Q2 Predictions Max                                1.18311
trainer/Q2 Predictions Min                               -2.94803
trainer/Q Targets Mean                                   -0.712197
trainer/Q Targets Std                                     0.791819
trainer/Q Targets Max                                     1.19387
trainer/Q Targets Min                                    -2.9152
trainer/Log Pis Mean                                      1.92917
trainer/Log Pis Std                                       1.32349
trainer/Log Pis Max                                       4.47823
trainer/Log Pis Min                                      -4.49943
trainer/Policy mu Mean                                   -0.047348
trainer/Policy mu Std                                     0.410247
trainer/Policy mu Max                                     2.05141
trainer/Policy mu Min                                    -3.03504
trainer/Policy log std Mean                              -2.22357
trainer/Policy log std Std                                0.631412
trainer/Policy log std Max                               -0.0373594
trainer/Policy log std Min                               -3.41074
trainer/Alpha                                             0.0216448
trainer/Alpha Loss                                       -0.271506
exploration/num steps total                           11300
exploration/num paths total                             565
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.100839
exploration/Rewards Std                                   0.138727
exploration/Rewards Max                                   0.138079
exploration/Rewards Min                                  -0.732825
exploration/Returns Mean                                 -2.01678
exploration/Returns Std                                   1.97068
exploration/Returns Max                                   0.675579
exploration/Returns Min                                  -5.28652
exploration/Actions Mean                                 -0.024977
exploration/Actions Std                                   0.244239
exploration/Actions Max                                   0.683453
exploration/Actions Min                                  -0.986523
exploration/Num Paths                                     5
exploration/Average Returns                              -2.01678
exploration/env_infos/final/reward_energy Mean           -0.275529
exploration/env_infos/final/reward_energy Std             0.205007
exploration/env_infos/final/reward_energy Max            -0.0386927
exploration/env_infos/final/reward_energy Min            -0.648792
exploration/env_infos/initial/reward_energy Mean         -0.518362
exploration/env_infos/initial/reward_energy Std           0.358925
exploration/env_infos/initial/reward_energy Max          -0.141282
exploration/env_infos/initial/reward_energy Min          -1.1085
exploration/env_infos/reward_energy Mean                 -0.27152
exploration/env_infos/reward_energy Std                   0.216403
exploration/env_infos/reward_energy Max                  -0.0155426
exploration/env_infos/reward_energy Min                  -1.1085
exploration/env_infos/final/end_effector_loc Mean        -0.142445
exploration/env_infos/final/end_effector_loc Std          0.346878
exploration/env_infos/final/end_effector_loc Max          0.210043
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.013401
exploration/env_infos/initial/end_effector_loc Std        0.0178135
exploration/env_infos/initial/end_effector_loc Max        0.0209219
exploration/env_infos/initial/end_effector_loc Min       -0.0488272
exploration/env_infos/end_effector_loc Mean              -0.145091
exploration/env_infos/end_effector_loc Std                0.27138
exploration/env_infos/end_effector_loc Max                0.210043
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.001007
exploration/env_infos/final/reward_dist Std               0.00171516
exploration/env_infos/final/reward_dist Max               0.00440227
exploration/env_infos/final/reward_dist Min               9.94629e-44
exploration/env_infos/initial/reward_dist Mean            0.0360742
exploration/env_infos/initial/reward_dist Std             0.0616395
exploration/env_infos/initial/reward_dist Max             0.158874
exploration/env_infos/initial/reward_dist Min             4.59393e-06
exploration/env_infos/reward_dist Mean                    0.169248
exploration/env_infos/reward_dist Std                     0.258428
exploration/env_infos/reward_dist Max                     0.887232
exploration/env_infos/reward_dist Min                     4.70584e-44
evaluation/num steps total                           103000
evaluation/num paths total                             5150
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0866125
evaluation/Rewards Std                                    0.114284
evaluation/Rewards Max                                    0.137105
evaluation/Rewards Min                                   -0.824314
evaluation/Returns Mean                                  -1.73225
evaluation/Returns Std                                    1.95287
evaluation/Returns Max                                    1.07088
evaluation/Returns Min                                  -12.8142
evaluation/Actions Mean                                  -0.00281299
evaluation/Actions Std                                    0.106422
evaluation/Actions Max                                    0.808161
evaluation/Actions Min                                   -0.984445
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.73225
evaluation/env_infos/final/reward_energy Mean            -0.0983931
evaluation/env_infos/final/reward_energy Std              0.185048
evaluation/env_infos/final/reward_energy Max             -0.00548033
evaluation/env_infos/final/reward_energy Min             -0.997225
evaluation/env_infos/initial/reward_energy Mean          -0.201939
evaluation/env_infos/initial/reward_energy Std            0.209408
evaluation/env_infos/initial/reward_energy Max           -0.00865359
evaluation/env_infos/initial/reward_energy Min           -1.01397
evaluation/env_infos/reward_energy Mean                  -0.0871548
evaluation/env_infos/reward_energy Std                    0.122764
evaluation/env_infos/reward_energy Max                   -0.00240859
evaluation/env_infos/reward_energy Min                   -1.01397
evaluation/env_infos/final/end_effector_loc Mean          0.000814401
evaluation/env_infos/final/end_effector_loc Std           0.312329
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00113419
evaluation/env_infos/initial/end_effector_loc Std         0.0102226
evaluation/env_infos/initial/end_effector_loc Max         0.0202688
evaluation/env_infos/initial/end_effector_loc Min        -0.0492223
evaluation/env_infos/end_effector_loc Mean               -0.0100863
evaluation/env_infos/end_effector_loc Std                 0.207665
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.147373
evaluation/env_infos/final/reward_dist Std                0.230289
evaluation/env_infos/final/reward_dist Max                0.90078
evaluation/env_infos/final/reward_dist Min                3.70456e-96
evaluation/env_infos/initial/reward_dist Mean             0.00610974
evaluation/env_infos/initial/reward_dist Std              0.0100471
evaluation/env_infos/initial/reward_dist Max              0.0406277
evaluation/env_infos/initial/reward_dist Min              1.04745e-06
evaluation/env_infos/reward_dist Mean                     0.149573
evaluation/env_infos/reward_dist Std                      0.244715
evaluation/env_infos/reward_dist Max                      0.996313
evaluation/env_infos/reward_dist Min                      3.70456e-96
time/data storing (s)                                    40.8817
time/evaluation sampling (s)                              0.642615
time/exploration sampling (s)                             0.0979242
time/logging (s)                                          0.020954
time/saving (s)                                           0.812274
time/training (s)                                        40.882
time/epoch (s)                                           83.3374
time/total (s)                                         6420.97
Epoch                                                   102
---------------------------------------------------  ----------------
2021-05-29 01:44:22.396387 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 103 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00128652
trainer/QF2 Loss                                          0.00116833
trainer/Policy Loss                                       2.70051
trainer/Q1 Predictions Mean                              -0.751103
trainer/Q1 Predictions Std                                0.71698
trainer/Q1 Predictions Max                                1.01157
trainer/Q1 Predictions Min                               -3.01802
trainer/Q2 Predictions Mean                              -0.759454
trainer/Q2 Predictions Std                                0.716503
trainer/Q2 Predictions Max                                1.05636
trainer/Q2 Predictions Min                               -2.99381
trainer/Q Targets Mean                                   -0.756003
trainer/Q Targets Std                                     0.716547
trainer/Q Targets Max                                     0.997412
trainer/Q Targets Min                                    -3.02761
trainer/Log Pis Mean                                      1.93423
trainer/Log Pis Std                                       1.53358
trainer/Log Pis Max                                       4.69066
trainer/Log Pis Min                                      -3.40786
trainer/Policy mu Mean                                   -0.00914423
trainer/Policy mu Std                                     0.252911
trainer/Policy mu Max                                     1.73902
trainer/Policy mu Min                                    -1.31603
trainer/Policy log std Mean                              -2.32914
trainer/Policy log std Std                                0.617078
trainer/Policy log std Max                               -0.394494
trainer/Policy log std Min                               -3.37004
trainer/Alpha                                             0.019593
trainer/Alpha Loss                                       -0.258578
exploration/num steps total                           11400
exploration/num paths total                             570
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.123043
exploration/Rewards Std                                   0.0496745
exploration/Rewards Max                                  -0.0371762
exploration/Rewards Min                                  -0.264657
exploration/Returns Mean                                 -2.46086
exploration/Returns Std                                   0.366031
exploration/Returns Max                                  -1.98897
exploration/Returns Min                                  -2.91904
exploration/Actions Mean                                  0.0093136
exploration/Actions Std                                   0.089631
exploration/Actions Max                                   0.262058
exploration/Actions Min                                  -0.588766
exploration/Num Paths                                     5
exploration/Average Returns                              -2.46086
exploration/env_infos/final/reward_energy Mean           -0.0763964
exploration/env_infos/final/reward_energy Std             0.0309373
exploration/env_infos/final/reward_energy Max            -0.0171616
exploration/env_infos/final/reward_energy Min            -0.10181
exploration/env_infos/initial/reward_energy Mean         -0.184216
exploration/env_infos/initial/reward_energy Std           0.0459167
exploration/env_infos/initial/reward_energy Max          -0.107348
exploration/env_infos/initial/reward_energy Min          -0.243752
exploration/env_infos/reward_energy Mean                 -0.0992972
exploration/env_infos/reward_energy Std                   0.079881
exploration/env_infos/reward_energy Max                  -0.0112743
exploration/env_infos/reward_energy Min                  -0.599475
exploration/env_infos/final/end_effector_loc Mean         0.0829363
exploration/env_infos/final/end_effector_loc Std          0.231674
exploration/env_infos/final/end_effector_loc Max          0.431292
exploration/env_infos/final/end_effector_loc Min         -0.211628
exploration/env_infos/initial/end_effector_loc Mean      -0.00022004
exploration/env_infos/initial/end_effector_loc Std        0.00670867
exploration/env_infos/initial/end_effector_loc Max        0.0103327
exploration/env_infos/initial/end_effector_loc Min       -0.0106083
exploration/env_infos/end_effector_loc Mean               0.0241263
exploration/env_infos/end_effector_loc Std                0.156512
exploration/env_infos/end_effector_loc Max                0.431292
exploration/env_infos/end_effector_loc Min               -0.27911
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.2298
exploration/env_infos/final/reward_dist Std               0.284313
exploration/env_infos/final/reward_dist Max               0.641035
exploration/env_infos/final/reward_dist Min               3.73572e-15
exploration/env_infos/initial/reward_dist Mean            0.000341312
exploration/env_infos/initial/reward_dist Std             0.0004634
exploration/env_infos/initial/reward_dist Max             0.00125994
exploration/env_infos/initial/reward_dist Min             1.38708e-05
exploration/env_infos/reward_dist Mean                    0.0930877
exploration/env_infos/reward_dist Std                     0.189645
exploration/env_infos/reward_dist Max                     0.905109
exploration/env_infos/reward_dist Min                     3.73572e-15
evaluation/num steps total                           104000
evaluation/num paths total                             5200
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0583927
evaluation/Rewards Std                                    0.0753489
evaluation/Rewards Max                                    0.135875
evaluation/Rewards Min                                   -0.55241
evaluation/Returns Mean                                  -1.16785
evaluation/Returns Std                                    1.1495
evaluation/Returns Max                                    1.04089
evaluation/Returns Min                                   -4.0391
evaluation/Actions Mean                                  -0.000295255
evaluation/Actions Std                                    0.0625577
evaluation/Actions Max                                    0.778468
evaluation/Actions Min                                   -0.68388
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.16785
evaluation/env_infos/final/reward_energy Mean            -0.0409534
evaluation/env_infos/final/reward_energy Std              0.0331361
evaluation/env_infos/final/reward_energy Max             -0.000404423
evaluation/env_infos/final/reward_energy Min             -0.158871
evaluation/env_infos/initial/reward_energy Mean          -0.16408
evaluation/env_infos/initial/reward_energy Std            0.189018
evaluation/env_infos/initial/reward_energy Max           -0.0128226
evaluation/env_infos/initial/reward_energy Min           -0.815732
evaluation/env_infos/reward_energy Mean                  -0.0544516
evaluation/env_infos/reward_energy Std                    0.0697291
evaluation/env_infos/reward_energy Max                   -0.000404423
evaluation/env_infos/reward_energy Min                   -0.815732
evaluation/env_infos/final/end_effector_loc Mean         -0.0076651
evaluation/env_infos/final/end_effector_loc Std           0.240898
evaluation/env_infos/final/end_effector_loc Max           0.513185
evaluation/env_infos/final/end_effector_loc Min          -0.897379
evaluation/env_infos/initial/end_effector_loc Mean        0.000278057
evaluation/env_infos/initial/end_effector_loc Std         0.00884506
evaluation/env_infos/initial/end_effector_loc Max         0.0389234
evaluation/env_infos/initial/end_effector_loc Min        -0.034194
evaluation/env_infos/end_effector_loc Mean               -0.00426468
evaluation/env_infos/end_effector_loc Std                 0.155066
evaluation/env_infos/end_effector_loc Max                 0.513185
evaluation/env_infos/end_effector_loc Min                -0.897379
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.13866
evaluation/env_infos/final/reward_dist Std                0.200904
evaluation/env_infos/final/reward_dist Max                0.969125
evaluation/env_infos/final/reward_dist Min                1.83346e-39
evaluation/env_infos/initial/reward_dist Mean             0.00591337
evaluation/env_infos/initial/reward_dist Std              0.0095717
evaluation/env_infos/initial/reward_dist Max              0.0369873
evaluation/env_infos/initial/reward_dist Min              2.00556e-06
evaluation/env_infos/reward_dist Mean                     0.136575
evaluation/env_infos/reward_dist Std                      0.219361
evaluation/env_infos/reward_dist Max                      0.969125
evaluation/env_infos/reward_dist Min                      1.83346e-39
time/data storing (s)                                    43.5644
time/evaluation sampling (s)                              0.93075
time/exploration sampling (s)                             0.109561
time/logging (s)                                          0.0186981
time/saving (s)                                           0.912845
time/training (s)                                        41.8053
time/epoch (s)                                           87.3415
time/total (s)                                         6509.46
Epoch                                                   103
---------------------------------------------------  ----------------
2021-05-29 01:45:46.992378 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 104 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00121097
trainer/QF2 Loss                                          0.00162688
trainer/Policy Loss                                       2.73675
trainer/Q1 Predictions Mean                              -0.787738
trainer/Q1 Predictions Std                                0.82744
trainer/Q1 Predictions Max                                1.42923
trainer/Q1 Predictions Min                               -3.69541
trainer/Q2 Predictions Mean                              -0.784934
trainer/Q2 Predictions Std                                0.825695
trainer/Q2 Predictions Max                                1.46853
trainer/Q2 Predictions Min                               -3.67836
trainer/Q Targets Mean                                   -0.788134
trainer/Q Targets Std                                     0.831645
trainer/Q Targets Max                                     1.45553
trainer/Q Targets Min                                    -3.67233
trainer/Log Pis Mean                                      1.9437
trainer/Log Pis Std                                       1.28522
trainer/Log Pis Max                                       4.48158
trainer/Log Pis Min                                      -2.53164
trainer/Policy mu Mean                                   -0.00151549
trainer/Policy mu Std                                     0.287447
trainer/Policy mu Max                                     1.68671
trainer/Policy mu Min                                    -1.78172
trainer/Policy log std Mean                              -2.31578
trainer/Policy log std Std                                0.570641
trainer/Policy log std Max                               -0.413154
trainer/Policy log std Min                               -3.34401
trainer/Alpha                                             0.0207514
trainer/Alpha Loss                                       -0.218176
exploration/num steps total                           11500
exploration/num paths total                             575
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0835717
exploration/Rewards Std                                   0.0740056
exploration/Rewards Max                                   0.040153
exploration/Rewards Min                                  -0.396602
exploration/Returns Mean                                 -1.67143
exploration/Returns Std                                   1.0006
exploration/Returns Max                                  -0.898769
exploration/Returns Min                                  -3.5172
exploration/Actions Mean                                 -0.000990541
exploration/Actions Std                                   0.0752821
exploration/Actions Max                                   0.224095
exploration/Actions Min                                  -0.362455
exploration/Num Paths                                     5
exploration/Average Returns                              -1.67143
exploration/env_infos/final/reward_energy Mean           -0.196318
exploration/env_infos/final/reward_energy Std             0.118881
exploration/env_infos/final/reward_energy Max            -0.0586911
exploration/env_infos/final/reward_energy Min            -0.36787
exploration/env_infos/initial/reward_energy Mean         -0.0578283
exploration/env_infos/initial/reward_energy Std           0.0262795
exploration/env_infos/initial/reward_energy Max          -0.0296954
exploration/env_infos/initial/reward_energy Min          -0.0966219
exploration/env_infos/reward_energy Mean                 -0.0874975
exploration/env_infos/reward_energy Std                   0.0606707
exploration/env_infos/reward_energy Max                  -0.00115036
exploration/env_infos/reward_energy Min                  -0.36787
exploration/env_infos/final/end_effector_loc Mean         0.0191532
exploration/env_infos/final/end_effector_loc Std          0.205127
exploration/env_infos/final/end_effector_loc Max          0.250496
exploration/env_infos/final/end_effector_loc Min         -0.327385
exploration/env_infos/initial/end_effector_loc Mean      -0.00054961
exploration/env_infos/initial/end_effector_loc Std        0.00217746
exploration/env_infos/initial/end_effector_loc Max        0.00406733
exploration/env_infos/initial/end_effector_loc Min       -0.00411154
exploration/env_infos/end_effector_loc Mean               0.00239245
exploration/env_infos/end_effector_loc Std                0.113052
exploration/env_infos/end_effector_loc Max                0.250496
exploration/env_infos/end_effector_loc Min               -0.327385
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0167309
exploration/env_infos/final/reward_dist Std               0.0327506
exploration/env_infos/final/reward_dist Max               0.0822227
exploration/env_infos/final/reward_dist Min               1.47985e-25
exploration/env_infos/initial/reward_dist Mean            0.00641557
exploration/env_infos/initial/reward_dist Std             0.0053458
exploration/env_infos/initial/reward_dist Max             0.011706
exploration/env_infos/initial/reward_dist Min             2.5694e-06
exploration/env_infos/reward_dist Mean                    0.0929257
exploration/env_infos/reward_dist Std                     0.178439
exploration/env_infos/reward_dist Max                     0.732773
exploration/env_infos/reward_dist Min                     1.47985e-25
evaluation/num steps total                           105000
evaluation/num paths total                             5250
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0570307
evaluation/Rewards Std                                    0.0768906
evaluation/Rewards Max                                    0.147302
evaluation/Rewards Min                                   -0.581153
evaluation/Returns Mean                                  -1.14061
evaluation/Returns Std                                    1.21269
evaluation/Returns Max                                    2.21277
evaluation/Returns Min                                   -4.77341
evaluation/Actions Mean                                   0.00160451
evaluation/Actions Std                                    0.0780606
evaluation/Actions Max                                    0.72724
evaluation/Actions Min                                   -0.775126
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.14061
evaluation/env_infos/final/reward_energy Mean            -0.0411237
evaluation/env_infos/final/reward_energy Std              0.0373429
evaluation/env_infos/final/reward_energy Max             -0.0064312
evaluation/env_infos/final/reward_energy Min             -0.187132
evaluation/env_infos/initial/reward_energy Mean          -0.19638
evaluation/env_infos/initial/reward_energy Std            0.202046
evaluation/env_infos/initial/reward_energy Max           -0.0020068
evaluation/env_infos/initial/reward_energy Min           -0.815579
evaluation/env_infos/reward_energy Mean                  -0.0642298
evaluation/env_infos/reward_energy Std                    0.0898143
evaluation/env_infos/reward_energy Max                   -0.000214856
evaluation/env_infos/reward_energy Min                   -0.998131
evaluation/env_infos/final/end_effector_loc Mean         -0.00178159
evaluation/env_infos/final/end_effector_loc Std           0.249069
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.739869
evaluation/env_infos/initial/end_effector_loc Mean       -0.00204967
evaluation/env_infos/initial/end_effector_loc Std         0.00974849
evaluation/env_infos/initial/end_effector_loc Max         0.036362
evaluation/env_infos/initial/end_effector_loc Min        -0.0387563
evaluation/env_infos/end_effector_loc Mean               -0.00965327
evaluation/env_infos/end_effector_loc Std                 0.165037
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.739869
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.186467
evaluation/env_infos/final/reward_dist Std                0.256641
evaluation/env_infos/final/reward_dist Max                0.856053
evaluation/env_infos/final/reward_dist Min                5.71184e-61
evaluation/env_infos/initial/reward_dist Mean             0.00489055
evaluation/env_infos/initial/reward_dist Std              0.00838925
evaluation/env_infos/initial/reward_dist Max              0.0445848
evaluation/env_infos/initial/reward_dist Min              1.32134e-06
evaluation/env_infos/reward_dist Mean                     0.170162
evaluation/env_infos/reward_dist Std                      0.259354
evaluation/env_infos/reward_dist Max                      0.954656
evaluation/env_infos/reward_dist Min                      5.71184e-61
time/data storing (s)                                    41.4959
time/evaluation sampling (s)                              0.883701
time/exploration sampling (s)                             0.0926936
time/logging (s)                                          0.015756
time/saving (s)                                           0.823977
time/training (s)                                        39.8939
time/epoch (s)                                           83.2059
time/total (s)                                         6594.05
Epoch                                                   104
---------------------------------------------------  ----------------
2021-05-29 01:47:09.648529 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 105 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00115453
trainer/QF2 Loss                                          0.00109112
trainer/Policy Loss                                       2.99543
trainer/Q1 Predictions Mean                              -0.802019
trainer/Q1 Predictions Std                                0.824532
trainer/Q1 Predictions Max                                1.33834
trainer/Q1 Predictions Min                               -3.69223
trainer/Q2 Predictions Mean                              -0.815083
trainer/Q2 Predictions Std                                0.828689
trainer/Q2 Predictions Max                                1.34745
trainer/Q2 Predictions Min                               -3.73441
trainer/Q Targets Mean                                   -0.810825
trainer/Q Targets Std                                     0.825166
trainer/Q Targets Max                                     1.3479
trainer/Q Targets Min                                    -3.72504
trainer/Log Pis Mean                                      2.18682
trainer/Log Pis Std                                       1.31111
trainer/Log Pis Max                                       4.90592
trainer/Log Pis Min                                      -2.01592
trainer/Policy mu Mean                                    0.0113691
trainer/Policy mu Std                                     0.306567
trainer/Policy mu Max                                     2.02589
trainer/Policy mu Min                                    -1.92662
trainer/Policy log std Mean                              -2.37953
trainer/Policy log std Std                                0.579174
trainer/Policy log std Max                                0.0878066
trainer/Policy log std Min                               -3.45879
trainer/Alpha                                             0.0185769
trainer/Alpha Loss                                        0.744981
exploration/num steps total                           11600
exploration/num paths total                             580
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0767166
exploration/Rewards Std                                   0.0770705
exploration/Rewards Max                                   0.0945934
exploration/Rewards Min                                  -0.357862
exploration/Returns Mean                                 -1.53433
exploration/Returns Std                                   0.86732
exploration/Returns Max                                  -0.0378208
exploration/Returns Min                                  -2.57002
exploration/Actions Mean                                  0.00305508
exploration/Actions Std                                   0.190871
exploration/Actions Max                                   0.51074
exploration/Actions Min                                  -0.935903
exploration/Num Paths                                     5
exploration/Average Returns                              -1.53433
exploration/env_infos/final/reward_energy Mean           -0.177464
exploration/env_infos/final/reward_energy Std             0.174345
exploration/env_infos/final/reward_energy Max            -0.0336425
exploration/env_infos/final/reward_energy Min            -0.52055
exploration/env_infos/initial/reward_energy Mean         -0.531498
exploration/env_infos/initial/reward_energy Std           0.393639
exploration/env_infos/initial/reward_energy Max          -0.0620985
exploration/env_infos/initial/reward_energy Min          -1.06578
exploration/env_infos/reward_energy Mean                 -0.194734
exploration/env_infos/reward_energy Std                   0.186979
exploration/env_infos/reward_energy Max                  -0.0137988
exploration/env_infos/reward_energy Min                  -1.06578
exploration/env_infos/final/end_effector_loc Mean        -0.0568269
exploration/env_infos/final/end_effector_loc Std          0.220492
exploration/env_infos/final/end_effector_loc Max          0.215756
exploration/env_infos/final/end_effector_loc Min         -0.453722
exploration/env_infos/initial/end_effector_loc Mean      -0.00894044
exploration/env_infos/initial/end_effector_loc Std        0.0216072
exploration/env_infos/initial/end_effector_loc Max        0.0254933
exploration/env_infos/initial/end_effector_loc Min       -0.0467951
exploration/env_infos/end_effector_loc Mean              -0.0429537
exploration/env_infos/end_effector_loc Std                0.151743
exploration/env_infos/end_effector_loc Max                0.236822
exploration/env_infos/end_effector_loc Min               -0.453722
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.202455
exploration/env_infos/final/reward_dist Std               0.225565
exploration/env_infos/final/reward_dist Max               0.612553
exploration/env_infos/final/reward_dist Min               1.83278e-08
exploration/env_infos/initial/reward_dist Mean            0.00300838
exploration/env_infos/initial/reward_dist Std             0.00396047
exploration/env_infos/initial/reward_dist Max             0.00997932
exploration/env_infos/initial/reward_dist Min             4.20135e-06
exploration/env_infos/reward_dist Mean                    0.256708
exploration/env_infos/reward_dist Std                     0.309223
exploration/env_infos/reward_dist Max                     0.879059
exploration/env_infos/reward_dist Min                     1.83278e-08
evaluation/num steps total                           106000
evaluation/num paths total                             5300
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0616845
evaluation/Rewards Std                                    0.121189
evaluation/Rewards Max                                    0.169927
evaluation/Rewards Min                                   -1.20328
evaluation/Returns Mean                                  -1.23369
evaluation/Returns Std                                    1.90245
evaluation/Returns Max                                    2.57658
evaluation/Returns Min                                  -10.6725
evaluation/Actions Mean                                   0.00448183
evaluation/Actions Std                                    0.0976214
evaluation/Actions Max                                    0.545066
evaluation/Actions Min                                   -0.986873
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.23369
evaluation/env_infos/final/reward_energy Mean            -0.0602489
evaluation/env_infos/final/reward_energy Std              0.147179
evaluation/env_infos/final/reward_energy Max             -0.00587006
evaluation/env_infos/final/reward_energy Min             -0.983834
evaluation/env_infos/initial/reward_energy Mean          -0.24951
evaluation/env_infos/initial/reward_energy Std            0.253192
evaluation/env_infos/initial/reward_energy Max           -0.00215505
evaluation/env_infos/initial/reward_energy Min           -0.92535
evaluation/env_infos/reward_energy Mean                  -0.0750354
evaluation/env_infos/reward_energy Std                    0.116059
evaluation/env_infos/reward_energy Max                   -0.000105489
evaluation/env_infos/reward_energy Min                   -0.995629
evaluation/env_infos/final/end_effector_loc Mean          0.072359
evaluation/env_infos/final/end_effector_loc Std           0.272297
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000396122
evaluation/env_infos/initial/end_effector_loc Std         0.0125616
evaluation/env_infos/initial/end_effector_loc Max         0.0272533
evaluation/env_infos/initial/end_effector_loc Min        -0.0461835
evaluation/env_infos/end_effector_loc Mean                0.0314824
evaluation/env_infos/end_effector_loc Std                 0.178473
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.184687
evaluation/env_infos/final/reward_dist Std                0.257272
evaluation/env_infos/final/reward_dist Max                0.794869
evaluation/env_infos/final/reward_dist Min                1.25032e-163
evaluation/env_infos/initial/reward_dist Mean             0.00664635
evaluation/env_infos/initial/reward_dist Std              0.0103935
evaluation/env_infos/initial/reward_dist Max              0.0414183
evaluation/env_infos/initial/reward_dist Min              9.14871e-07
evaluation/env_infos/reward_dist Mean                     0.185768
evaluation/env_infos/reward_dist Std                      0.288631
evaluation/env_infos/reward_dist Max                      0.999735
evaluation/env_infos/reward_dist Min                      1.25032e-163
time/data storing (s)                                    40.2257
time/evaluation sampling (s)                              0.859778
time/exploration sampling (s)                             0.123185
time/logging (s)                                          0.0150791
time/saving (s)                                           1.14676
time/training (s)                                        39.0375
time/epoch (s)                                           81.408
time/total (s)                                         6676.7
Epoch                                                   105
---------------------------------------------------  -----------------
2021-05-29 01:48:30.012700 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 106 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00116958
trainer/QF2 Loss                                          0.00329899
trainer/Policy Loss                                       2.78517
trainer/Q1 Predictions Mean                              -0.762974
trainer/Q1 Predictions Std                                0.838251
trainer/Q1 Predictions Max                                1.25074
trainer/Q1 Predictions Min                               -3.33068
trainer/Q2 Predictions Mean                              -0.764101
trainer/Q2 Predictions Std                                0.853007
trainer/Q2 Predictions Max                                1.30301
trainer/Q2 Predictions Min                               -3.41098
trainer/Q Targets Mean                                   -0.758706
trainer/Q Targets Std                                     0.843001
trainer/Q Targets Max                                     1.33573
trainer/Q Targets Min                                    -3.32775
trainer/Log Pis Mean                                      2.02104
trainer/Log Pis Std                                       1.44056
trainer/Log Pis Max                                       4.70173
trainer/Log Pis Min                                      -3.83898
trainer/Policy mu Mean                                   -0.018381
trainer/Policy mu Std                                     0.306163
trainer/Policy mu Max                                     1.29696
trainer/Policy mu Min                                    -2.43941
trainer/Policy log std Mean                              -2.32134
trainer/Policy log std Std                                0.57974
trainer/Policy log std Max                               -0.184692
trainer/Policy log std Min                               -3.38168
trainer/Alpha                                             0.0188999
trainer/Alpha Loss                                        0.0835037
exploration/num steps total                           11700
exploration/num paths total                             585
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0812454
exploration/Rewards Std                                   0.0754819
exploration/Rewards Max                                   0.0510287
exploration/Rewards Min                                  -0.31309
exploration/Returns Mean                                 -1.62491
exploration/Returns Std                                   1.11813
exploration/Returns Max                                  -0.0192458
exploration/Returns Min                                  -3.14522
exploration/Actions Mean                                 -0.0106777
exploration/Actions Std                                   0.16524
exploration/Actions Max                                   0.526795
exploration/Actions Min                                  -0.731011
exploration/Num Paths                                     5
exploration/Average Returns                              -1.62491
exploration/env_infos/final/reward_energy Mean           -0.181266
exploration/env_infos/final/reward_energy Std             0.0793371
exploration/env_infos/final/reward_energy Max            -0.0661258
exploration/env_infos/final/reward_energy Min            -0.315066
exploration/env_infos/initial/reward_energy Mean         -0.317523
exploration/env_infos/initial/reward_energy Std           0.237483
exploration/env_infos/initial/reward_energy Max          -0.0301644
exploration/env_infos/initial/reward_energy Min          -0.63765
exploration/env_infos/reward_energy Mean                 -0.174079
exploration/env_infos/reward_energy Std                   0.156629
exploration/env_infos/reward_energy Max                  -0.0107936
exploration/env_infos/reward_energy Min                  -0.886541
exploration/env_infos/final/end_effector_loc Mean        -0.115321
exploration/env_infos/final/end_effector_loc Std          0.172063
exploration/env_infos/final/end_effector_loc Max          0.212197
exploration/env_infos/final/end_effector_loc Min         -0.462008
exploration/env_infos/initial/end_effector_loc Mean      -0.00054455
exploration/env_infos/initial/end_effector_loc Std        0.0140081
exploration/env_infos/initial/end_effector_loc Max        0.0263398
exploration/env_infos/initial/end_effector_loc Min       -0.020476
exploration/env_infos/end_effector_loc Mean              -0.0559233
exploration/env_infos/end_effector_loc Std                0.132411
exploration/env_infos/end_effector_loc Max                0.265305
exploration/env_infos/end_effector_loc Min               -0.462008
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.157116
exploration/env_infos/final/reward_dist Std               0.178589
exploration/env_infos/final/reward_dist Max               0.425691
exploration/env_infos/final/reward_dist Min               8.70518e-07
exploration/env_infos/initial/reward_dist Mean            0.00312806
exploration/env_infos/initial/reward_dist Std             0.00553352
exploration/env_infos/initial/reward_dist Max             0.0141534
exploration/env_infos/initial/reward_dist Min             1.15862e-06
exploration/env_infos/reward_dist Mean                    0.255908
exploration/env_infos/reward_dist Std                     0.299874
exploration/env_infos/reward_dist Max                     0.994445
exploration/env_infos/reward_dist Min                     8.70518e-07
evaluation/num steps total                           107000
evaluation/num paths total                             5350
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0371699
evaluation/Rewards Std                                    0.086087
evaluation/Rewards Max                                    0.156138
evaluation/Rewards Min                                   -0.671322
evaluation/Returns Mean                                  -0.743399
evaluation/Returns Std                                    1.25424
evaluation/Returns Max                                    1.95818
evaluation/Returns Min                                   -3.93389
evaluation/Actions Mean                                  -0.00064562
evaluation/Actions Std                                    0.116309
evaluation/Actions Max                                    0.65345
evaluation/Actions Min                                   -0.841944
evaluation/Num Paths                                     50
evaluation/Average Returns                               -0.743399
evaluation/env_infos/final/reward_energy Mean            -0.0524228
evaluation/env_infos/final/reward_energy Std              0.132573
evaluation/env_infos/final/reward_energy Max             -4.11492e-05
evaluation/env_infos/final/reward_energy Min             -0.956034
evaluation/env_infos/initial/reward_energy Mean          -0.337748
evaluation/env_infos/initial/reward_energy Std            0.329559
evaluation/env_infos/initial/reward_energy Max           -0.00628483
evaluation/env_infos/initial/reward_energy Min           -1.05069
evaluation/env_infos/reward_energy Mean                  -0.0862584
evaluation/env_infos/reward_energy Std                    0.140057
evaluation/env_infos/reward_energy Max                   -4.11492e-05
evaluation/env_infos/reward_energy Min                   -1.05069
evaluation/env_infos/final/end_effector_loc Mean          0.0310539
evaluation/env_infos/final/end_effector_loc Std           0.261976
evaluation/env_infos/final/end_effector_loc Max           0.703796
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00359324
evaluation/env_infos/initial/end_effector_loc Std         0.0162924
evaluation/env_infos/initial/end_effector_loc Max         0.0326725
evaluation/env_infos/initial/end_effector_loc Min        -0.0420972
evaluation/env_infos/end_effector_loc Mean                0.00708246
evaluation/env_infos/end_effector_loc Std                 0.176465
evaluation/env_infos/end_effector_loc Max                 0.703796
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.245579
evaluation/env_infos/final/reward_dist Std                0.292245
evaluation/env_infos/final/reward_dist Max                0.870362
evaluation/env_infos/final/reward_dist Min                6.54975e-74
evaluation/env_infos/initial/reward_dist Mean             0.00852627
evaluation/env_infos/initial/reward_dist Std              0.0201226
evaluation/env_infos/initial/reward_dist Max              0.11689
evaluation/env_infos/initial/reward_dist Min              1.45019e-06
evaluation/env_infos/reward_dist Mean                     0.225031
evaluation/env_infos/reward_dist Std                      0.304838
evaluation/env_infos/reward_dist Max                      0.997299
evaluation/env_infos/reward_dist Min                      6.54975e-74
time/data storing (s)                                    39.4157
time/evaluation sampling (s)                              0.656225
time/exploration sampling (s)                             0.0903421
time/logging (s)                                          0.0178134
time/saving (s)                                           0.975622
time/training (s)                                        38.0399
time/epoch (s)                                           79.1956
time/total (s)                                         6757.07
Epoch                                                   106
---------------------------------------------------  ----------------
2021-05-29 01:49:55.415160 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 107 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00095525
trainer/QF2 Loss                                          0.00131314
trainer/Policy Loss                                       2.87705
trainer/Q1 Predictions Mean                              -0.872131
trainer/Q1 Predictions Std                                0.791577
trainer/Q1 Predictions Max                                1.10739
trainer/Q1 Predictions Min                               -3.48395
trainer/Q2 Predictions Mean                              -0.863708
trainer/Q2 Predictions Std                                0.794949
trainer/Q2 Predictions Max                                1.13207
trainer/Q2 Predictions Min                               -3.50215
trainer/Q Targets Mean                                   -0.869144
trainer/Q Targets Std                                     0.786913
trainer/Q Targets Max                                     1.0591
trainer/Q Targets Min                                    -3.40951
trainer/Log Pis Mean                                      2.0082
trainer/Log Pis Std                                       1.26672
trainer/Log Pis Max                                       4.63591
trainer/Log Pis Min                                      -4.26061
trainer/Policy mu Mean                                    0.00476841
trainer/Policy mu Std                                     0.288923
trainer/Policy mu Max                                     1.67489
trainer/Policy mu Min                                    -1.16686
trainer/Policy log std Mean                              -2.34166
trainer/Policy log std Std                                0.548386
trainer/Policy log std Max                               -0.469597
trainer/Policy log std Min                               -3.37039
trainer/Alpha                                             0.018314
trainer/Alpha Loss                                        0.0328268
exploration/num steps total                           11800
exploration/num paths total                             590
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0954806
exploration/Rewards Std                                   0.0578191
exploration/Rewards Max                                   0.0387752
exploration/Rewards Min                                  -0.260063
exploration/Returns Mean                                 -1.90961
exploration/Returns Std                                   0.822209
exploration/Returns Max                                  -0.568028
exploration/Returns Min                                  -3.01205
exploration/Actions Mean                                 -0.000926356
exploration/Actions Std                                   0.0683519
exploration/Actions Max                                   0.238413
exploration/Actions Min                                  -0.277318
exploration/Num Paths                                     5
exploration/Average Returns                              -1.90961
exploration/env_infos/final/reward_energy Mean           -0.0871109
exploration/env_infos/final/reward_energy Std             0.0346859
exploration/env_infos/final/reward_energy Max            -0.0437346
exploration/env_infos/final/reward_energy Min            -0.130936
exploration/env_infos/initial/reward_energy Mean         -0.12144
exploration/env_infos/initial/reward_energy Std           0.0645383
exploration/env_infos/initial/reward_energy Max          -0.0511385
exploration/env_infos/initial/reward_energy Min          -0.228368
exploration/env_infos/reward_energy Mean                 -0.082643
exploration/env_infos/reward_energy Std                   0.0501579
exploration/env_infos/reward_energy Max                  -0.00490362
exploration/env_infos/reward_energy Min                  -0.282751
exploration/env_infos/final/end_effector_loc Mean         0.070402
exploration/env_infos/final/end_effector_loc Std          0.275276
exploration/env_infos/final/end_effector_loc Max          0.570384
exploration/env_infos/final/end_effector_loc Min         -0.543934
exploration/env_infos/initial/end_effector_loc Mean       0.00334352
exploration/env_infos/initial/end_effector_loc Std        0.00353016
exploration/env_infos/initial/end_effector_loc Max        0.0108048
exploration/env_infos/initial/end_effector_loc Min       -0.00246987
exploration/env_infos/end_effector_loc Mean               0.0429249
exploration/env_infos/end_effector_loc Std                0.157603
exploration/env_infos/end_effector_loc Max                0.570384
exploration/env_infos/end_effector_loc Min               -0.543934
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0482877
exploration/env_infos/final/reward_dist Std               0.0577575
exploration/env_infos/final/reward_dist Max               0.135642
exploration/env_infos/final/reward_dist Min               1.85312e-23
exploration/env_infos/initial/reward_dist Mean            0.0042693
exploration/env_infos/initial/reward_dist Std             0.00396748
exploration/env_infos/initial/reward_dist Max             0.00914525
exploration/env_infos/initial/reward_dist Min             0.000586716
exploration/env_infos/reward_dist Mean                    0.122311
exploration/env_infos/reward_dist Std                     0.223203
exploration/env_infos/reward_dist Max                     0.89475
exploration/env_infos/reward_dist Min                     1.85312e-23
evaluation/num steps total                           108000
evaluation/num paths total                             5400
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0686637
evaluation/Rewards Std                                    0.086478
evaluation/Rewards Max                                    0.119913
evaluation/Rewards Min                                   -0.525126
evaluation/Returns Mean                                  -1.37327
evaluation/Returns Std                                    1.35411
evaluation/Returns Max                                    0.465246
evaluation/Returns Min                                   -6.74762
evaluation/Actions Mean                                  -0.00263556
evaluation/Actions Std                                    0.0897497
evaluation/Actions Max                                    0.768122
evaluation/Actions Min                                   -0.795738
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.37327
evaluation/env_infos/final/reward_energy Mean            -0.0783852
evaluation/env_infos/final/reward_energy Std              0.115087
evaluation/env_infos/final/reward_energy Max             -0.00786393
evaluation/env_infos/final/reward_energy Min             -0.808702
evaluation/env_infos/initial/reward_energy Mean          -0.24769
evaluation/env_infos/initial/reward_energy Std            0.246709
evaluation/env_infos/initial/reward_energy Max           -0.00725571
evaluation/env_infos/initial/reward_energy Min           -0.768163
evaluation/env_infos/reward_energy Mean                  -0.0772588
evaluation/env_infos/reward_energy Std                    0.100772
evaluation/env_infos/reward_energy Max                   -0.000661252
evaluation/env_infos/reward_energy Min                   -0.808702
evaluation/env_infos/final/end_effector_loc Mean          0.035621
evaluation/env_infos/final/end_effector_loc Std           0.27362
evaluation/env_infos/final/end_effector_loc Max           0.478489
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000415572
evaluation/env_infos/initial/end_effector_loc Std         0.012353
evaluation/env_infos/initial/end_effector_loc Max         0.0384061
evaluation/env_infos/initial/end_effector_loc Min        -0.033825
evaluation/env_infos/end_effector_loc Mean                0.0157871
evaluation/env_infos/end_effector_loc Std                 0.176379
evaluation/env_infos/end_effector_loc Max                 0.478489
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.20066
evaluation/env_infos/final/reward_dist Std                0.264408
evaluation/env_infos/final/reward_dist Max                0.894499
evaluation/env_infos/final/reward_dist Min                1.09745e-51
evaluation/env_infos/initial/reward_dist Mean             0.00507027
evaluation/env_infos/initial/reward_dist Std              0.00821029
evaluation/env_infos/initial/reward_dist Max              0.0393808
evaluation/env_infos/initial/reward_dist Min              4.21553e-06
evaluation/env_infos/reward_dist Mean                     0.17452
evaluation/env_infos/reward_dist Std                      0.257454
evaluation/env_infos/reward_dist Max                      0.978817
evaluation/env_infos/reward_dist Min                      2.04761e-63
time/data storing (s)                                    42.2499
time/evaluation sampling (s)                              1.04189
time/exploration sampling (s)                             0.10887
time/logging (s)                                          0.0149519
time/saving (s)                                           0.766334
time/training (s)                                        39.7047
time/epoch (s)                                           83.8866
time/total (s)                                         6842.46
Epoch                                                   107
---------------------------------------------------  ----------------
2021-05-29 01:51:18.580397 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 108 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00188966
trainer/QF2 Loss                                          0.00098215
trainer/Policy Loss                                       2.92397
trainer/Q1 Predictions Mean                              -0.849279
trainer/Q1 Predictions Std                                0.776967
trainer/Q1 Predictions Max                                0.661462
trainer/Q1 Predictions Min                               -3.04095
trainer/Q2 Predictions Mean                              -0.853763
trainer/Q2 Predictions Std                                0.784569
trainer/Q2 Predictions Max                                0.657723
trainer/Q2 Predictions Min                               -3.10695
trainer/Q Targets Mean                                   -0.852343
trainer/Q Targets Std                                     0.782216
trainer/Q Targets Max                                     0.696744
trainer/Q Targets Min                                    -3.08089
trainer/Log Pis Mean                                      2.07148
trainer/Log Pis Std                                       1.25634
trainer/Log Pis Max                                       4.49195
trainer/Log Pis Min                                      -2.59833
trainer/Policy mu Mean                                   -0.00238037
trainer/Policy mu Std                                     0.327516
trainer/Policy mu Max                                     2.17034
trainer/Policy mu Min                                    -2.25554
trainer/Policy log std Mean                              -2.30783
trainer/Policy log std Std                                0.56817
trainer/Policy log std Max                               -0.402092
trainer/Policy log std Min                               -3.36063
trainer/Alpha                                             0.0205048
trainer/Alpha Loss                                        0.277806
exploration/num steps total                           11900
exploration/num paths total                             595
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.142365
exploration/Rewards Std                                   0.130198
exploration/Rewards Max                                   0.0743923
exploration/Rewards Min                                  -0.568757
exploration/Returns Mean                                 -2.84729
exploration/Returns Std                                   1.30015
exploration/Returns Max                                  -1.54049
exploration/Returns Min                                  -4.58645
exploration/Actions Mean                                  0.00198389
exploration/Actions Std                                   0.124297
exploration/Actions Max                                   0.498688
exploration/Actions Min                                  -0.293557
exploration/Num Paths                                     5
exploration/Average Returns                              -2.84729
exploration/env_infos/final/reward_energy Mean           -0.141547
exploration/env_infos/final/reward_energy Std             0.0504157
exploration/env_infos/final/reward_energy Max            -0.0831815
exploration/env_infos/final/reward_energy Min            -0.212319
exploration/env_infos/initial/reward_energy Mean         -0.0780036
exploration/env_infos/initial/reward_energy Std           0.0471692
exploration/env_infos/initial/reward_energy Max          -0.0325147
exploration/env_infos/initial/reward_energy Min          -0.16235
exploration/env_infos/reward_energy Mean                 -0.14811
exploration/env_infos/reward_energy Std                   0.0947131
exploration/env_infos/reward_energy Max                  -0.0124714
exploration/env_infos/reward_energy Min                  -0.53903
exploration/env_infos/final/end_effector_loc Mean         0.116725
exploration/env_infos/final/end_effector_loc Std          0.430997
exploration/env_infos/final/end_effector_loc Max          0.731222
exploration/env_infos/final/end_effector_loc Min         -0.548324
exploration/env_infos/initial/end_effector_loc Mean      -0.000588809
exploration/env_infos/initial/end_effector_loc Std        0.00316863
exploration/env_infos/initial/end_effector_loc Max        0.00454117
exploration/env_infos/initial/end_effector_loc Min       -0.00767578
exploration/env_infos/end_effector_loc Mean               0.0550779
exploration/env_infos/end_effector_loc Std                0.261567
exploration/env_infos/end_effector_loc Max                0.731222
exploration/env_infos/end_effector_loc Min               -0.548324
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000541348
exploration/env_infos/final/reward_dist Std               0.00107937
exploration/env_infos/final/reward_dist Max               0.00270008
exploration/env_infos/final/reward_dist Min               2.0438e-49
exploration/env_infos/initial/reward_dist Mean            0.0184813
exploration/env_infos/initial/reward_dist Std             0.00964074
exploration/env_infos/initial/reward_dist Max             0.0276171
exploration/env_infos/initial/reward_dist Min             2.49366e-05
exploration/env_infos/reward_dist Mean                    0.10833
exploration/env_infos/reward_dist Std                     0.2297
exploration/env_infos/reward_dist Max                     0.957927
exploration/env_infos/reward_dist Min                     2.0438e-49
evaluation/num steps total                           109000
evaluation/num paths total                             5450
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0687587
evaluation/Rewards Std                                    0.0969495
evaluation/Rewards Max                                    0.155179
evaluation/Rewards Min                                   -1.08247
evaluation/Returns Mean                                  -1.37517
evaluation/Returns Std                                    1.58252
evaluation/Returns Max                                    2.05639
evaluation/Returns Min                                   -6.33816
evaluation/Actions Mean                                   0.00167592
evaluation/Actions Std                                    0.10353
evaluation/Actions Max                                    0.744867
evaluation/Actions Min                                   -0.980398
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.37517
evaluation/env_infos/final/reward_energy Mean            -0.0660997
evaluation/env_infos/final/reward_energy Std              0.0931904
evaluation/env_infos/final/reward_energy Max             -0.00400439
evaluation/env_infos/final/reward_energy Min             -0.588033
evaluation/env_infos/initial/reward_energy Mean          -0.265573
evaluation/env_infos/initial/reward_energy Std            0.297088
evaluation/env_infos/initial/reward_energy Max           -0.00740628
evaluation/env_infos/initial/reward_energy Min           -1.23126
evaluation/env_infos/reward_energy Mean                  -0.0865995
evaluation/env_infos/reward_energy Std                    0.118081
evaluation/env_infos/reward_energy Max                   -0.00104392
evaluation/env_infos/reward_energy Min                   -1.23126
evaluation/env_infos/final/end_effector_loc Mean          0.0275114
evaluation/env_infos/final/end_effector_loc Std           0.251556
evaluation/env_infos/final/end_effector_loc Max           0.654619
evaluation/env_infos/final/end_effector_loc Min          -0.671033
evaluation/env_infos/initial/end_effector_loc Mean       -0.00173325
evaluation/env_infos/initial/end_effector_loc Std         0.0139815
evaluation/env_infos/initial/end_effector_loc Max         0.0372433
evaluation/env_infos/initial/end_effector_loc Min        -0.0490199
evaluation/env_infos/end_effector_loc Mean                0.00458851
evaluation/env_infos/end_effector_loc Std                 0.174897
evaluation/env_infos/end_effector_loc Max                 0.654619
evaluation/env_infos/end_effector_loc Min                -0.671033
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.135528
evaluation/env_infos/final/reward_dist Std                0.272098
evaluation/env_infos/final/reward_dist Max                0.947067
evaluation/env_infos/final/reward_dist Min                3.58484e-22
evaluation/env_infos/initial/reward_dist Mean             0.00388407
evaluation/env_infos/initial/reward_dist Std              0.00795954
evaluation/env_infos/initial/reward_dist Max              0.0361192
evaluation/env_infos/initial/reward_dist Min              2.19229e-06
evaluation/env_infos/reward_dist Mean                     0.138447
evaluation/env_infos/reward_dist Std                      0.250237
evaluation/env_infos/reward_dist Max                      0.991724
evaluation/env_infos/reward_dist Min                      4.00478e-38
time/data storing (s)                                    41.1053
time/evaluation sampling (s)                              0.583389
time/exploration sampling (s)                             0.100838
time/logging (s)                                          0.0161164
time/saving (s)                                           0.822534
time/training (s)                                        39.3928
time/epoch (s)                                           82.0209
time/total (s)                                         6925.62
Epoch                                                   108
---------------------------------------------------  ----------------
2021-05-29 01:52:41.061547 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 109 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00193498
trainer/QF2 Loss                                          0.00154087
trainer/Policy Loss                                       2.79403
trainer/Q1 Predictions Mean                              -0.868423
trainer/Q1 Predictions Std                                0.755512
trainer/Q1 Predictions Max                                0.730749
trainer/Q1 Predictions Min                               -3.36598
trainer/Q2 Predictions Mean                              -0.853696
trainer/Q2 Predictions Std                                0.766608
trainer/Q2 Predictions Max                                0.713502
trainer/Q2 Predictions Min                               -3.36383
trainer/Q Targets Mean                                   -0.860172
trainer/Q Targets Std                                     0.764243
trainer/Q Targets Max                                     0.753066
trainer/Q Targets Min                                    -3.34647
trainer/Log Pis Mean                                      1.92652
trainer/Log Pis Std                                       1.34929
trainer/Log Pis Max                                       4.45647
trainer/Log Pis Min                                      -2.5147
trainer/Policy mu Mean                                    0.0467602
trainer/Policy mu Std                                     0.279969
trainer/Policy mu Max                                     1.68682
trainer/Policy mu Min                                    -1.34445
trainer/Policy log std Mean                              -2.30363
trainer/Policy log std Std                                0.566209
trainer/Policy log std Max                               -0.420983
trainer/Policy log std Min                               -3.2781
trainer/Alpha                                             0.0193467
trainer/Alpha Loss                                       -0.289815
exploration/num steps total                           12000
exploration/num paths total                             600
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.117987
exploration/Rewards Std                                   0.0887178
exploration/Rewards Max                                   0.0312013
exploration/Rewards Min                                  -0.3809
exploration/Returns Mean                                 -2.35973
exploration/Returns Std                                   1.28063
exploration/Returns Max                                  -1.15207
exploration/Returns Min                                  -4.37707
exploration/Actions Mean                                 -0.00966113
exploration/Actions Std                                   0.10756
exploration/Actions Max                                   0.326792
exploration/Actions Min                                  -0.434043
exploration/Num Paths                                     5
exploration/Average Returns                              -2.35973
exploration/env_infos/final/reward_energy Mean           -0.129203
exploration/env_infos/final/reward_energy Std             0.0638968
exploration/env_infos/final/reward_energy Max            -0.0462211
exploration/env_infos/final/reward_energy Min            -0.225989
exploration/env_infos/initial/reward_energy Mean         -0.138758
exploration/env_infos/initial/reward_energy Std           0.0498263
exploration/env_infos/initial/reward_energy Max          -0.0616838
exploration/env_infos/initial/reward_energy Min          -0.189679
exploration/env_infos/reward_energy Mean                 -0.123039
exploration/env_infos/reward_energy Std                   0.0904799
exploration/env_infos/reward_energy Max                  -0.00495708
exploration/env_infos/reward_energy Min                  -0.445478
exploration/env_infos/final/end_effector_loc Mean        -0.0346976
exploration/env_infos/final/end_effector_loc Std          0.276101
exploration/env_infos/final/end_effector_loc Max          0.285896
exploration/env_infos/final/end_effector_loc Min         -0.444667
exploration/env_infos/initial/end_effector_loc Mean      -8.57244e-05
exploration/env_infos/initial/end_effector_loc Std        0.00521184
exploration/env_infos/initial/end_effector_loc Max        0.00878906
exploration/env_infos/initial/end_effector_loc Min       -0.00879287
exploration/env_infos/end_effector_loc Mean              -0.000503201
exploration/env_infos/end_effector_loc Std                0.172044
exploration/env_infos/end_effector_loc Max                0.385757
exploration/env_infos/end_effector_loc Min               -0.444667
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.15039
exploration/env_infos/final/reward_dist Std               0.296702
exploration/env_infos/final/reward_dist Max               0.743761
exploration/env_infos/final/reward_dist Min               3.46996e-09
exploration/env_infos/initial/reward_dist Mean            0.00842428
exploration/env_infos/initial/reward_dist Std             0.0152892
exploration/env_infos/initial/reward_dist Max             0.0389329
exploration/env_infos/initial/reward_dist Min             5.73045e-06
exploration/env_infos/reward_dist Mean                    0.10893
exploration/env_infos/reward_dist Std                     0.206275
exploration/env_infos/reward_dist Max                     0.761854
exploration/env_infos/reward_dist Min                     2.62665e-09
evaluation/num steps total                           110000
evaluation/num paths total                             5500
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0637338
evaluation/Rewards Std                                    0.0971273
evaluation/Rewards Max                                    0.155069
evaluation/Rewards Min                                   -0.786206
evaluation/Returns Mean                                  -1.27468
evaluation/Returns Std                                    1.5875
evaluation/Returns Max                                    1.6578
evaluation/Returns Min                                   -4.95752
evaluation/Actions Mean                                   0.00264934
evaluation/Actions Std                                    0.094275
evaluation/Actions Max                                    0.798326
evaluation/Actions Min                                   -0.720266
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.27468
evaluation/env_infos/final/reward_energy Mean            -0.0560884
evaluation/env_infos/final/reward_energy Std              0.0975599
evaluation/env_infos/final/reward_energy Max             -0.00221454
evaluation/env_infos/final/reward_energy Min             -0.633685
evaluation/env_infos/initial/reward_energy Mean          -0.268696
evaluation/env_infos/initial/reward_energy Std            0.263563
evaluation/env_infos/initial/reward_energy Max           -0.011079
evaluation/env_infos/initial/reward_energy Min           -1.08593
evaluation/env_infos/reward_energy Mean                  -0.0795138
evaluation/env_infos/reward_energy Std                    0.107085
evaluation/env_infos/reward_energy Max                   -0.000596465
evaluation/env_infos/reward_energy Min                   -1.08593
evaluation/env_infos/final/end_effector_loc Mean          0.0840313
evaluation/env_infos/final/end_effector_loc Std           0.328477
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00135564
evaluation/env_infos/initial/end_effector_loc Std         0.0132379
evaluation/env_infos/initial/end_effector_loc Max         0.0399163
evaluation/env_infos/initial/end_effector_loc Min        -0.0360133
evaluation/env_infos/end_effector_loc Mean                0.0433674
evaluation/env_infos/end_effector_loc Std                 0.211367
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.12066
evaluation/env_infos/final/reward_dist Std                0.235947
evaluation/env_infos/final/reward_dist Max                0.899972
evaluation/env_infos/final/reward_dist Min                5.02741e-92
evaluation/env_infos/initial/reward_dist Mean             0.00945604
evaluation/env_infos/initial/reward_dist Std              0.0233596
evaluation/env_infos/initial/reward_dist Max              0.127655
evaluation/env_infos/initial/reward_dist Min              8.4997e-07
evaluation/env_infos/reward_dist Mean                     0.163502
evaluation/env_infos/reward_dist Std                      0.268488
evaluation/env_infos/reward_dist Max                      0.983625
evaluation/env_infos/reward_dist Min                      5.02741e-92
time/data storing (s)                                    40.6308
time/evaluation sampling (s)                              0.656003
time/exploration sampling (s)                             0.0971663
time/logging (s)                                          0.0160363
time/saving (s)                                           0.871615
time/training (s)                                        38.9929
time/epoch (s)                                           81.2645
time/total (s)                                         7008.1
Epoch                                                   109
---------------------------------------------------  ----------------
2021-05-29 01:54:10.785412 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 110 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00152606
trainer/QF2 Loss                                          0.00122317
trainer/Policy Loss                                       2.90345
trainer/Q1 Predictions Mean                              -0.950124
trainer/Q1 Predictions Std                                0.774886
trainer/Q1 Predictions Max                                0.620998
trainer/Q1 Predictions Min                               -3.06824
trainer/Q2 Predictions Mean                              -0.941832
trainer/Q2 Predictions Std                                0.775716
trainer/Q2 Predictions Max                                0.596738
trainer/Q2 Predictions Min                               -3.04176
trainer/Q Targets Mean                                   -0.940966
trainer/Q Targets Std                                     0.775275
trainer/Q Targets Max                                     0.590523
trainer/Q Targets Min                                    -3.0219
trainer/Log Pis Mean                                      1.95278
trainer/Log Pis Std                                       1.33466
trainer/Log Pis Max                                       4.60133
trainer/Log Pis Min                                      -2.23911
trainer/Policy mu Mean                                    0.0320224
trainer/Policy mu Std                                     0.263193
trainer/Policy mu Max                                     1.99282
trainer/Policy mu Min                                    -1.04569
trainer/Policy log std Mean                              -2.32887
trainer/Policy log std Std                                0.595813
trainer/Policy log std Max                               -0.269259
trainer/Policy log std Min                               -3.26246
trainer/Alpha                                             0.0200233
trainer/Alpha Loss                                       -0.184689
exploration/num steps total                           12100
exploration/num paths total                             605
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0618002
exploration/Rewards Std                                   0.0493652
exploration/Rewards Max                                   0.0657695
exploration/Rewards Min                                  -0.171478
exploration/Returns Mean                                 -1.236
exploration/Returns Std                                   0.524095
exploration/Returns Max                                  -0.23532
exploration/Returns Min                                  -1.59923
exploration/Actions Mean                                 -0.0123438
exploration/Actions Std                                   0.0983813
exploration/Actions Max                                   0.337725
exploration/Actions Min                                  -0.711229
exploration/Num Paths                                     5
exploration/Average Returns                              -1.236
exploration/env_infos/final/reward_energy Mean           -0.0912648
exploration/env_infos/final/reward_energy Std             0.0487964
exploration/env_infos/final/reward_energy Max            -0.023835
exploration/env_infos/final/reward_energy Min            -0.152079
exploration/env_infos/initial/reward_energy Mean         -0.239458
exploration/env_infos/initial/reward_energy Std           0.274966
exploration/env_infos/initial/reward_energy Max          -0.0715477
exploration/env_infos/initial/reward_energy Min          -0.78734
exploration/env_infos/reward_energy Mean                 -0.101801
exploration/env_infos/reward_energy Std                   0.0964313
exploration/env_infos/reward_energy Max                  -0.00422482
exploration/env_infos/reward_energy Min                  -0.78734
exploration/env_infos/final/end_effector_loc Mean        -0.105964
exploration/env_infos/final/end_effector_loc Std          0.290167
exploration/env_infos/final/end_effector_loc Max          0.267666
exploration/env_infos/final/end_effector_loc Min         -0.806462
exploration/env_infos/initial/end_effector_loc Mean      -0.00277501
exploration/env_infos/initial/end_effector_loc Std        0.012589
exploration/env_infos/initial/end_effector_loc Max        0.0168863
exploration/env_infos/initial/end_effector_loc Min       -0.0355614
exploration/env_infos/end_effector_loc Mean              -0.0432884
exploration/env_infos/end_effector_loc Std                0.182397
exploration/env_infos/end_effector_loc Max                0.267666
exploration/env_infos/end_effector_loc Min               -0.806462
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.162845
exploration/env_infos/final/reward_dist Std               0.194551
exploration/env_infos/final/reward_dist Max               0.426821
exploration/env_infos/final/reward_dist Min               6.96761e-55
exploration/env_infos/initial/reward_dist Mean            0.00468656
exploration/env_infos/initial/reward_dist Std             0.00694381
exploration/env_infos/initial/reward_dist Max             0.0183046
exploration/env_infos/initial/reward_dist Min             9.41442e-05
exploration/env_infos/reward_dist Mean                    0.114992
exploration/env_infos/reward_dist Std                     0.238775
exploration/env_infos/reward_dist Max                     0.985396
exploration/env_infos/reward_dist Min                     6.96761e-55
evaluation/num steps total                           111000
evaluation/num paths total                             5550
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0611152
evaluation/Rewards Std                                    0.0771264
evaluation/Rewards Max                                    0.112482
evaluation/Rewards Min                                   -0.976106
evaluation/Returns Mean                                  -1.2223
evaluation/Returns Std                                    1.12891
evaluation/Returns Max                                    1.32651
evaluation/Returns Min                                   -4.29109
evaluation/Actions Mean                                  -0.00185996
evaluation/Actions Std                                    0.0819931
evaluation/Actions Max                                    0.719977
evaluation/Actions Min                                   -0.918327
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.2223
evaluation/env_infos/final/reward_energy Mean            -0.0445561
evaluation/env_infos/final/reward_energy Std              0.0432389
evaluation/env_infos/final/reward_energy Max             -0.00594368
evaluation/env_infos/final/reward_energy Min             -0.199218
evaluation/env_infos/initial/reward_energy Mean          -0.254922
evaluation/env_infos/initial/reward_energy Std            0.235571
evaluation/env_infos/initial/reward_energy Max           -0.0118196
evaluation/env_infos/initial/reward_energy Min           -1.03296
evaluation/env_infos/reward_energy Mean                  -0.0728608
evaluation/env_infos/reward_energy Std                    0.0902438
evaluation/env_infos/reward_energy Max                   -0.00136043
evaluation/env_infos/reward_energy Min                   -1.03296
evaluation/env_infos/final/end_effector_loc Mean          0.0278336
evaluation/env_infos/final/end_effector_loc Std           0.251188
evaluation/env_infos/final/end_effector_loc Max           0.825096
evaluation/env_infos/final/end_effector_loc Min          -0.57925
evaluation/env_infos/initial/end_effector_loc Mean        0.000660322
evaluation/env_infos/initial/end_effector_loc Std         0.0122541
evaluation/env_infos/initial/end_effector_loc Max         0.0359988
evaluation/env_infos/initial/end_effector_loc Min        -0.0459163
evaluation/env_infos/end_effector_loc Mean                0.0214029
evaluation/env_infos/end_effector_loc Std                 0.170911
evaluation/env_infos/end_effector_loc Max                 0.825096
evaluation/env_infos/end_effector_loc Min                -0.606556
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.159379
evaluation/env_infos/final/reward_dist Std                0.238361
evaluation/env_infos/final/reward_dist Max                0.927181
evaluation/env_infos/final/reward_dist Min                1.41749e-34
evaluation/env_infos/initial/reward_dist Mean             0.00630418
evaluation/env_infos/initial/reward_dist Std              0.00977062
evaluation/env_infos/initial/reward_dist Max              0.0461676
evaluation/env_infos/initial/reward_dist Min              9.31525e-07
evaluation/env_infos/reward_dist Mean                     0.150303
evaluation/env_infos/reward_dist Std                      0.244602
evaluation/env_infos/reward_dist Max                      0.996236
evaluation/env_infos/reward_dist Min                      8.18109e-40
time/data storing (s)                                    42.6789
time/evaluation sampling (s)                              0.649856
time/exploration sampling (s)                             0.111863
time/logging (s)                                          0.0163819
time/saving (s)                                           0.868886
time/training (s)                                        44.0499
time/epoch (s)                                           88.3758
time/total (s)                                         7097.82
Epoch                                                   110
---------------------------------------------------  ----------------
2021-05-29 01:55:32.724175 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 111 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00131112
trainer/QF2 Loss                                          0.00144233
trainer/Policy Loss                                       2.86524
trainer/Q1 Predictions Mean                              -0.889349
trainer/Q1 Predictions Std                                0.836246
trainer/Q1 Predictions Max                                0.891131
trainer/Q1 Predictions Min                               -3.01354
trainer/Q2 Predictions Mean                              -0.899685
trainer/Q2 Predictions Std                                0.839164
trainer/Q2 Predictions Max                                0.896659
trainer/Q2 Predictions Min                               -3.04734
trainer/Q Targets Mean                                   -0.895115
trainer/Q Targets Std                                     0.832763
trainer/Q Targets Max                                     0.931421
trainer/Q Targets Min                                    -3.04508
trainer/Log Pis Mean                                      1.96244
trainer/Log Pis Std                                       1.25697
trainer/Log Pis Max                                       4.5028
trainer/Log Pis Min                                      -2.99429
trainer/Policy mu Mean                                   -0.0332496
trainer/Policy mu Std                                     0.319458
trainer/Policy mu Max                                     1.35672
trainer/Policy mu Min                                    -2.21187
trainer/Policy log std Mean                              -2.29812
trainer/Policy log std Std                                0.582814
trainer/Policy log std Max                               -0.123784
trainer/Policy log std Min                               -3.2336
trainer/Alpha                                             0.0204713
trainer/Alpha Loss                                       -0.146008
exploration/num steps total                           12200
exploration/num paths total                             610
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0404907
exploration/Rewards Std                                   0.081812
exploration/Rewards Max                                   0.148473
exploration/Rewards Min                                  -0.252569
exploration/Returns Mean                                 -0.809814
exploration/Returns Std                                   1.28616
exploration/Returns Max                                   1.72272
exploration/Returns Min                                  -1.85743
exploration/Actions Mean                                 -0.00783682
exploration/Actions Std                                   0.183122
exploration/Actions Max                                   0.676747
exploration/Actions Min                                  -0.968184
exploration/Num Paths                                     5
exploration/Average Returns                              -0.809814
exploration/env_infos/final/reward_energy Mean           -0.0833824
exploration/env_infos/final/reward_energy Std             0.041941
exploration/env_infos/final/reward_energy Max            -0.0140874
exploration/env_infos/final/reward_energy Min            -0.135386
exploration/env_infos/initial/reward_energy Mean         -0.419503
exploration/env_infos/initial/reward_energy Std           0.331715
exploration/env_infos/initial/reward_energy Max          -0.0640277
exploration/env_infos/initial/reward_energy Min          -0.981837
exploration/env_infos/reward_energy Mean                 -0.190523
exploration/env_infos/reward_energy Std                   0.175758
exploration/env_infos/reward_energy Max                  -0.00876834
exploration/env_infos/reward_energy Min                  -0.981837
exploration/env_infos/final/end_effector_loc Mean        -0.0971087
exploration/env_infos/final/end_effector_loc Std          0.219988
exploration/env_infos/final/end_effector_loc Max          0.390044
exploration/env_infos/final/end_effector_loc Min         -0.446297
exploration/env_infos/initial/end_effector_loc Mean      -0.00969346
exploration/env_infos/initial/end_effector_loc Std        0.0162345
exploration/env_infos/initial/end_effector_loc Max        0.00815817
exploration/env_infos/initial/end_effector_loc Min       -0.0484092
exploration/env_infos/end_effector_loc Mean              -0.071628
exploration/env_infos/end_effector_loc Std                0.164187
exploration/env_infos/end_effector_loc Max                0.451314
exploration/env_infos/end_effector_loc Min               -0.446297
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.242194
exploration/env_infos/final/reward_dist Std               0.359354
exploration/env_infos/final/reward_dist Max               0.927871
exploration/env_infos/final/reward_dist Min               3.07943e-07
exploration/env_infos/initial/reward_dist Mean            0.00513899
exploration/env_infos/initial/reward_dist Std             0.00422709
exploration/env_infos/initial/reward_dist Max             0.013258
exploration/env_infos/initial/reward_dist Min             0.00168187
exploration/env_infos/reward_dist Mean                    0.276
exploration/env_infos/reward_dist Std                     0.352706
exploration/env_infos/reward_dist Max                     0.994265
exploration/env_infos/reward_dist Min                     3.07943e-07
evaluation/num steps total                           112000
evaluation/num paths total                             5600
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0627456
evaluation/Rewards Std                                    0.0866398
evaluation/Rewards Max                                    0.168445
evaluation/Rewards Min                                   -0.734254
evaluation/Returns Mean                                  -1.25491
evaluation/Returns Std                                    1.29985
evaluation/Returns Max                                    2.7088
evaluation/Returns Min                                   -4.32458
evaluation/Actions Mean                                  -0.0144316
evaluation/Actions Std                                    0.115859
evaluation/Actions Max                                    0.799267
evaluation/Actions Min                                   -0.956333
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.25491
evaluation/env_infos/final/reward_energy Mean            -0.0891793
evaluation/env_infos/final/reward_energy Std              0.0795127
evaluation/env_infos/final/reward_energy Max             -0.0115368
evaluation/env_infos/final/reward_energy Min             -0.443561
evaluation/env_infos/initial/reward_energy Mean          -0.33312
evaluation/env_infos/initial/reward_energy Std            0.338442
evaluation/env_infos/initial/reward_energy Max           -0.0242061
evaluation/env_infos/initial/reward_energy Min           -1.20407
evaluation/env_infos/reward_energy Mean                  -0.100751
evaluation/env_infos/reward_energy Std                    0.130815
evaluation/env_infos/reward_energy Max                   -0.00423401
evaluation/env_infos/reward_energy Min                   -1.20407
evaluation/env_infos/final/end_effector_loc Mean         -0.1277
evaluation/env_infos/final/end_effector_loc Std           0.258248
evaluation/env_infos/final/end_effector_loc Max           0.34012
evaluation/env_infos/final/end_effector_loc Min          -0.964449
evaluation/env_infos/initial/end_effector_loc Mean       -0.00385988
evaluation/env_infos/initial/end_effector_loc Std         0.0163399
evaluation/env_infos/initial/end_effector_loc Max         0.0399633
evaluation/env_infos/initial/end_effector_loc Min        -0.0478166
evaluation/env_infos/end_effector_loc Mean               -0.0526634
evaluation/env_infos/end_effector_loc Std                 0.189646
evaluation/env_infos/end_effector_loc Max                 0.431498
evaluation/env_infos/end_effector_loc Min                -0.964449
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.15956
evaluation/env_infos/final/reward_dist Std                0.272688
evaluation/env_infos/final/reward_dist Max                0.998653
evaluation/env_infos/final/reward_dist Min                3.99615e-72
evaluation/env_infos/initial/reward_dist Mean             0.00999724
evaluation/env_infos/initial/reward_dist Std              0.0182612
evaluation/env_infos/initial/reward_dist Max              0.10828
evaluation/env_infos/initial/reward_dist Min              4.46496e-06
evaluation/env_infos/reward_dist Mean                     0.156497
evaluation/env_infos/reward_dist Std                      0.250825
evaluation/env_infos/reward_dist Max                      0.998653
evaluation/env_infos/reward_dist Min                      3.99615e-72
time/data storing (s)                                    40.0078
time/evaluation sampling (s)                              0.751714
time/exploration sampling (s)                             0.096535
time/logging (s)                                          0.0181819
time/saving (s)                                           0.91679
time/training (s)                                        38.6467
time/epoch (s)                                           80.4377
time/total (s)                                         7179.75
Epoch                                                   111
---------------------------------------------------  ----------------
2021-05-29 01:56:50.659583 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 112 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00148379
trainer/QF2 Loss                                          0.00151183
trainer/Policy Loss                                       2.76826
trainer/Q1 Predictions Mean                              -0.89177
trainer/Q1 Predictions Std                                0.757706
trainer/Q1 Predictions Max                                0.893638
trainer/Q1 Predictions Min                               -2.81577
trainer/Q2 Predictions Mean                              -0.894002
trainer/Q2 Predictions Std                                0.754246
trainer/Q2 Predictions Max                                0.874684
trainer/Q2 Predictions Min                               -2.73588
trainer/Q Targets Mean                                   -0.899692
trainer/Q Targets Std                                     0.758663
trainer/Q Targets Max                                     0.883144
trainer/Q Targets Min                                    -2.7185
trainer/Log Pis Mean                                      1.87271
trainer/Log Pis Std                                       1.60539
trainer/Log Pis Max                                       5.24981
trainer/Log Pis Min                                      -6.32358
trainer/Policy mu Mean                                   -0.00915272
trainer/Policy mu Std                                     0.419166
trainer/Policy mu Max                                     1.84362
trainer/Policy mu Min                                    -2.46638
trainer/Policy log std Mean                              -2.2648
trainer/Policy log std Std                                0.663429
trainer/Policy log std Max                               -0.265661
trainer/Policy log std Min                               -3.29159
trainer/Alpha                                             0.0205642
trainer/Alpha Loss                                       -0.494085
exploration/num steps total                           12300
exploration/num paths total                             615
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.104376
exploration/Rewards Std                                   0.0679045
exploration/Rewards Max                                   0.0156599
exploration/Rewards Min                                  -0.362692
exploration/Returns Mean                                 -2.08753
exploration/Returns Std                                   0.774875
exploration/Returns Max                                  -0.711934
exploration/Returns Min                                  -2.92326
exploration/Actions Mean                                 -0.00492835
exploration/Actions Std                                   0.0895013
exploration/Actions Max                                   0.266735
exploration/Actions Min                                  -0.377053
exploration/Num Paths                                     5
exploration/Average Returns                              -2.08753
exploration/env_infos/final/reward_energy Mean           -0.0849652
exploration/env_infos/final/reward_energy Std             0.0128944
exploration/env_infos/final/reward_energy Max            -0.0674423
exploration/env_infos/final/reward_energy Min            -0.102828
exploration/env_infos/initial/reward_energy Mean         -0.105719
exploration/env_infos/initial/reward_energy Std           0.0610231
exploration/env_infos/initial/reward_energy Max          -0.0446461
exploration/env_infos/initial/reward_energy Min          -0.19935
exploration/env_infos/reward_energy Mean                 -0.103363
exploration/env_infos/reward_energy Std                   0.0733863
exploration/env_infos/reward_energy Max                  -0.00758476
exploration/env_infos/reward_energy Min                  -0.447104
exploration/env_infos/final/end_effector_loc Mean         0.0179935
exploration/env_infos/final/end_effector_loc Std          0.18518
exploration/env_infos/final/end_effector_loc Max          0.431074
exploration/env_infos/final/end_effector_loc Min         -0.193776
exploration/env_infos/initial/end_effector_loc Mean      -0.000471131
exploration/env_infos/initial/end_effector_loc Std        0.00428993
exploration/env_infos/initial/end_effector_loc Max        0.00749075
exploration/env_infos/initial/end_effector_loc Min       -0.00657573
exploration/env_infos/end_effector_loc Mean               0.0161097
exploration/env_infos/end_effector_loc Std                0.11053
exploration/env_infos/end_effector_loc Max                0.431074
exploration/env_infos/end_effector_loc Min               -0.193776
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0608686
exploration/env_infos/final/reward_dist Std               0.119797
exploration/env_infos/final/reward_dist Max               0.300454
exploration/env_infos/final/reward_dist Min               3.41735e-16
exploration/env_infos/initial/reward_dist Mean            0.00519838
exploration/env_infos/initial/reward_dist Std             0.00679221
exploration/env_infos/initial/reward_dist Max             0.0183529
exploration/env_infos/initial/reward_dist Min             2.35851e-06
exploration/env_infos/reward_dist Mean                    0.14307
exploration/env_infos/reward_dist Std                     0.261216
exploration/env_infos/reward_dist Max                     0.96656
exploration/env_infos/reward_dist Min                     3.60226e-17
evaluation/num steps total                           113000
evaluation/num paths total                             5650
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0753152
evaluation/Rewards Std                                    0.0963773
evaluation/Rewards Max                                    0.142394
evaluation/Rewards Min                                   -0.647132
evaluation/Returns Mean                                  -1.5063
evaluation/Returns Std                                    1.56241
evaluation/Returns Max                                    1.03131
evaluation/Returns Min                                   -6.763
evaluation/Actions Mean                                   0.000984922
evaluation/Actions Std                                    0.110364
evaluation/Actions Max                                    0.952125
evaluation/Actions Min                                   -0.982363
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.5063
evaluation/env_infos/final/reward_energy Mean            -0.0542482
evaluation/env_infos/final/reward_energy Std              0.0655325
evaluation/env_infos/final/reward_energy Max             -0.00266794
evaluation/env_infos/final/reward_energy Min             -0.319446
evaluation/env_infos/initial/reward_energy Mean          -0.333352
evaluation/env_infos/initial/reward_energy Std            0.302533
evaluation/env_infos/initial/reward_energy Max           -0.00927996
evaluation/env_infos/initial/reward_energy Min           -1.0356
evaluation/env_infos/reward_energy Mean                  -0.0906622
evaluation/env_infos/reward_energy Std                    0.127055
evaluation/env_infos/reward_energy Max                   -0.000824581
evaluation/env_infos/reward_energy Min                   -1.0356
evaluation/env_infos/final/end_effector_loc Mean          0.0820438
evaluation/env_infos/final/end_effector_loc Std           0.33685
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.584067
evaluation/env_infos/initial/end_effector_loc Mean        0.00175068
evaluation/env_infos/initial/end_effector_loc Std         0.0158192
evaluation/env_infos/initial/end_effector_loc Max         0.0476062
evaluation/env_infos/initial/end_effector_loc Min        -0.0491181
evaluation/env_infos/end_effector_loc Mean                0.0553552
evaluation/env_infos/end_effector_loc Std                 0.235913
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.584067
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.123065
evaluation/env_infos/final/reward_dist Std                0.219497
evaluation/env_infos/final/reward_dist Max                0.831321
evaluation/env_infos/final/reward_dist Min                6.93821e-153
evaluation/env_infos/initial/reward_dist Mean             0.00854809
evaluation/env_infos/initial/reward_dist Std              0.0172954
evaluation/env_infos/initial/reward_dist Max              0.1
evaluation/env_infos/initial/reward_dist Min              3.32307e-06
evaluation/env_infos/reward_dist Mean                     0.114649
evaluation/env_infos/reward_dist Std                      0.206341
evaluation/env_infos/reward_dist Max                      0.987261
evaluation/env_infos/reward_dist Min                      6.93821e-153
time/data storing (s)                                    38.5221
time/evaluation sampling (s)                              0.659579
time/exploration sampling (s)                             0.0919827
time/logging (s)                                          0.0149721
time/saving (s)                                           0.948996
time/training (s)                                        36.3999
time/epoch (s)                                           76.6374
time/total (s)                                         7257.68
Epoch                                                   112
---------------------------------------------------  -----------------
2021-05-29 01:58:08.554310 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 113 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0017313
trainer/QF2 Loss                                          0.00102432
trainer/Policy Loss                                       2.95688
trainer/Q1 Predictions Mean                              -0.849431
trainer/Q1 Predictions Std                                0.756781
trainer/Q1 Predictions Max                                1.00066
trainer/Q1 Predictions Min                               -3.0113
trainer/Q2 Predictions Mean                              -0.856315
trainer/Q2 Predictions Std                                0.760389
trainer/Q2 Predictions Max                                0.985191
trainer/Q2 Predictions Min                               -3.06437
trainer/Q Targets Mean                                   -0.852621
trainer/Q Targets Std                                     0.763291
trainer/Q Targets Max                                     0.964228
trainer/Q Targets Min                                    -3.1097
trainer/Log Pis Mean                                      2.08902
trainer/Log Pis Std                                       1.36936
trainer/Log Pis Max                                       4.35918
trainer/Log Pis Min                                      -2.88437
trainer/Policy mu Mean                                   -0.00686413
trainer/Policy mu Std                                     0.262038
trainer/Policy mu Max                                     0.893187
trainer/Policy mu Min                                    -1.79226
trainer/Policy log std Mean                              -2.39247
trainer/Policy log std Std                                0.552344
trainer/Policy log std Max                               -0.687092
trainer/Policy log std Min                               -3.24934
trainer/Alpha                                             0.0216589
trainer/Alpha Loss                                        0.34112
exploration/num steps total                           12400
exploration/num paths total                             620
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.134988
exploration/Rewards Std                                   0.0521075
exploration/Rewards Max                                  -0.0278452
exploration/Rewards Min                                  -0.330371
exploration/Returns Mean                                 -2.69975
exploration/Returns Std                                   0.333601
exploration/Returns Max                                  -2.43716
exploration/Returns Min                                  -3.33501
exploration/Actions Mean                                 -0.00680445
exploration/Actions Std                                   0.18805
exploration/Actions Max                                   0.548194
exploration/Actions Min                                  -0.950833
exploration/Num Paths                                     5
exploration/Average Returns                              -2.69975
exploration/env_infos/final/reward_energy Mean           -0.224411
exploration/env_infos/final/reward_energy Std             0.155522
exploration/env_infos/final/reward_energy Max            -0.0969176
exploration/env_infos/final/reward_energy Min            -0.514517
exploration/env_infos/initial/reward_energy Mean         -0.233355
exploration/env_infos/initial/reward_energy Std           0.131625
exploration/env_infos/initial/reward_energy Max          -0.0550996
exploration/env_infos/initial/reward_energy Min          -0.376158
exploration/env_infos/reward_energy Mean                 -0.189895
exploration/env_infos/reward_energy Std                   0.186435
exploration/env_infos/reward_energy Max                  -0.0239121
exploration/env_infos/reward_energy Min                  -1.00583
exploration/env_infos/final/end_effector_loc Mean        -0.0207121
exploration/env_infos/final/end_effector_loc Std          0.43791
exploration/env_infos/final/end_effector_loc Max          0.857881
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -1.99725e-05
exploration/env_infos/initial/end_effector_loc Std        0.00947229
exploration/env_infos/initial/end_effector_loc Max        0.0173665
exploration/env_infos/initial/end_effector_loc Min       -0.0149744
exploration/env_infos/end_effector_loc Mean              -0.0317586
exploration/env_infos/end_effector_loc Std                0.253892
exploration/env_infos/end_effector_loc Max                0.857881
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0187483
exploration/env_infos/final/reward_dist Std               0.0296801
exploration/env_infos/final/reward_dist Max               0.0767045
exploration/env_infos/final/reward_dist Min               2.52916e-92
exploration/env_infos/initial/reward_dist Mean            0.00863555
exploration/env_infos/initial/reward_dist Std             0.0065916
exploration/env_infos/initial/reward_dist Max             0.0200275
exploration/env_infos/initial/reward_dist Min             6.95744e-06
exploration/env_infos/reward_dist Mean                    0.062563
exploration/env_infos/reward_dist Std                     0.176539
exploration/env_infos/reward_dist Max                     0.959889
exploration/env_infos/reward_dist Min                     2.52916e-92
evaluation/num steps total                           114000
evaluation/num paths total                             5700
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0530861
evaluation/Rewards Std                                    0.088641
evaluation/Rewards Max                                    0.131857
evaluation/Rewards Min                                   -0.539446
evaluation/Returns Mean                                  -1.06172
evaluation/Returns Std                                    1.35508
evaluation/Returns Max                                    1.68833
evaluation/Returns Min                                   -4.37788
evaluation/Actions Mean                                  -0.00769053
evaluation/Actions Std                                    0.097233
evaluation/Actions Max                                    0.652312
evaluation/Actions Min                                   -0.939344
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.06172
evaluation/env_infos/final/reward_energy Mean            -0.0706056
evaluation/env_infos/final/reward_energy Std              0.0844992
evaluation/env_infos/final/reward_energy Max             -0.00532859
evaluation/env_infos/final/reward_energy Min             -0.528547
evaluation/env_infos/initial/reward_energy Mean          -0.304632
evaluation/env_infos/initial/reward_energy Std            0.268019
evaluation/env_infos/initial/reward_energy Max           -0.00622523
evaluation/env_infos/initial/reward_energy Min           -1.03829
evaluation/env_infos/reward_energy Mean                  -0.0865972
evaluation/env_infos/reward_energy Std                    0.107367
evaluation/env_infos/reward_energy Max                   -0.00153778
evaluation/env_infos/reward_energy Min                   -1.03829
evaluation/env_infos/final/end_effector_loc Mean         -0.0417348
evaluation/env_infos/final/end_effector_loc Std           0.315393
evaluation/env_infos/final/end_effector_loc Max           0.710985
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00160922
evaluation/env_infos/initial/end_effector_loc Std         0.014255
evaluation/env_infos/initial/end_effector_loc Max         0.0306749
evaluation/env_infos/initial/end_effector_loc Min        -0.0469672
evaluation/env_infos/end_effector_loc Mean               -0.00856893
evaluation/env_infos/end_effector_loc Std                 0.197737
evaluation/env_infos/end_effector_loc Max                 0.710985
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.214076
evaluation/env_infos/final/reward_dist Std                0.302881
evaluation/env_infos/final/reward_dist Max                0.991687
evaluation/env_infos/final/reward_dist Min                4.18736e-108
evaluation/env_infos/initial/reward_dist Mean             0.00584261
evaluation/env_infos/initial/reward_dist Std              0.0129936
evaluation/env_infos/initial/reward_dist Max              0.0653615
evaluation/env_infos/initial/reward_dist Min              1.17733e-06
evaluation/env_infos/reward_dist Mean                     0.197113
evaluation/env_infos/reward_dist Std                      0.272643
evaluation/env_infos/reward_dist Max                      0.993257
evaluation/env_infos/reward_dist Min                      4.18736e-108
time/data storing (s)                                    38.4118
time/evaluation sampling (s)                              0.643418
time/exploration sampling (s)                             0.0924327
time/logging (s)                                          0.0142033
time/saving (s)                                           0.784746
time/training (s)                                        36.7505
time/epoch (s)                                           76.6971
time/total (s)                                         7335.57
Epoch                                                   113
---------------------------------------------------  -----------------
2021-05-29 01:59:27.633460 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 114 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00167039
trainer/QF2 Loss                                          0.00135596
trainer/Policy Loss                                       2.99964
trainer/Q1 Predictions Mean                              -0.894388
trainer/Q1 Predictions Std                                0.775322
trainer/Q1 Predictions Max                                1.09377
trainer/Q1 Predictions Min                               -2.74489
trainer/Q2 Predictions Mean                              -0.88984
trainer/Q2 Predictions Std                                0.772784
trainer/Q2 Predictions Max                                1.10157
trainer/Q2 Predictions Min                               -2.71843
trainer/Q Targets Mean                                   -0.887133
trainer/Q Targets Std                                     0.774155
trainer/Q Targets Max                                     1.09653
trainer/Q Targets Min                                    -2.71633
trainer/Log Pis Mean                                      2.1039
trainer/Log Pis Std                                       1.33069
trainer/Log Pis Max                                       4.8617
trainer/Log Pis Min                                      -2.07401
trainer/Policy mu Mean                                   -0.0205446
trainer/Policy mu Std                                     0.318245
trainer/Policy mu Max                                     1.72787
trainer/Policy mu Min                                    -2.34092
trainer/Policy log std Mean                              -2.32924
trainer/Policy log std Std                                0.59198
trainer/Policy log std Max                               -0.551486
trainer/Policy log std Min                               -3.29998
trainer/Alpha                                             0.0207983
trainer/Alpha Loss                                        0.40237
exploration/num steps total                           12500
exploration/num paths total                             625
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.118199
exploration/Rewards Std                                   0.059471
exploration/Rewards Max                                   0.0178151
exploration/Rewards Min                                  -0.309891
exploration/Returns Mean                                 -2.36397
exploration/Returns Std                                   0.788795
exploration/Returns Max                                  -1.18803
exploration/Returns Min                                  -3.28938
exploration/Actions Mean                                  0.00389453
exploration/Actions Std                                   0.128246
exploration/Actions Max                                   0.482548
exploration/Actions Min                                  -0.606206
exploration/Num Paths                                     5
exploration/Average Returns                              -2.36397
exploration/env_infos/final/reward_energy Mean           -0.125272
exploration/env_infos/final/reward_energy Std             0.0829528
exploration/env_infos/final/reward_energy Max            -0.0323893
exploration/env_infos/final/reward_energy Min            -0.276994
exploration/env_infos/initial/reward_energy Mean         -0.285254
exploration/env_infos/initial/reward_energy Std           0.172498
exploration/env_infos/initial/reward_energy Max          -0.0801109
exploration/env_infos/initial/reward_energy Min          -0.525839
exploration/env_infos/reward_energy Mean                 -0.137812
exploration/env_infos/reward_energy Std                   0.118035
exploration/env_infos/reward_energy Max                  -0.00635119
exploration/env_infos/reward_energy Min                  -0.652878
exploration/env_infos/final/end_effector_loc Mean         0.00401122
exploration/env_infos/final/end_effector_loc Std          0.31464
exploration/env_infos/final/end_effector_loc Max          0.56858
exploration/env_infos/final/end_effector_loc Min         -0.434803
exploration/env_infos/initial/end_effector_loc Mean      -0.0011579
exploration/env_infos/initial/end_effector_loc Std        0.0117288
exploration/env_infos/initial/end_effector_loc Max        0.0148069
exploration/env_infos/initial/end_effector_loc Min       -0.0262278
exploration/env_infos/end_effector_loc Mean              -0.0133559
exploration/env_infos/end_effector_loc Std                0.197948
exploration/env_infos/end_effector_loc Max                0.56858
exploration/env_infos/end_effector_loc Min               -0.434803
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.106431
exploration/env_infos/final/reward_dist Std               0.209624
exploration/env_infos/final/reward_dist Max               0.525662
exploration/env_infos/final/reward_dist Min               4.3344e-28
exploration/env_infos/initial/reward_dist Mean            0.0139494
exploration/env_infos/initial/reward_dist Std             0.0168045
exploration/env_infos/initial/reward_dist Max             0.0443393
exploration/env_infos/initial/reward_dist Min             2.83705e-05
exploration/env_infos/reward_dist Mean                    0.158099
exploration/env_infos/reward_dist Std                     0.243125
exploration/env_infos/reward_dist Max                     0.919513
exploration/env_infos/reward_dist Min                     4.3344e-28
evaluation/num steps total                           115000
evaluation/num paths total                             5750
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0549933
evaluation/Rewards Std                                    0.0918871
evaluation/Rewards Max                                    0.134814
evaluation/Rewards Min                                   -0.532234
evaluation/Returns Mean                                  -1.09987
evaluation/Returns Std                                    1.49455
evaluation/Returns Max                                    1.84994
evaluation/Returns Min                                   -5.80033
evaluation/Actions Mean                                  -0.00363286
evaluation/Actions Std                                    0.10064
evaluation/Actions Max                                    0.666544
evaluation/Actions Min                                   -0.919911
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.09987
evaluation/env_infos/final/reward_energy Mean            -0.0462597
evaluation/env_infos/final/reward_energy Std              0.0509025
evaluation/env_infos/final/reward_energy Max             -0.0022011
evaluation/env_infos/final/reward_energy Min             -0.248144
evaluation/env_infos/initial/reward_energy Mean          -0.325545
evaluation/env_infos/initial/reward_energy Std            0.256849
evaluation/env_infos/initial/reward_energy Max           -0.00763703
evaluation/env_infos/initial/reward_energy Min           -0.98493
evaluation/env_infos/reward_energy Mean                  -0.0870575
evaluation/env_infos/reward_energy Std                    0.112713
evaluation/env_infos/reward_energy Max                   -0.000474713
evaluation/env_infos/reward_energy Min                   -0.98493
evaluation/env_infos/final/end_effector_loc Mean          0.0289167
evaluation/env_infos/final/end_effector_loc Std           0.260644
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.834045
evaluation/env_infos/initial/end_effector_loc Mean        0.00171743
evaluation/env_infos/initial/end_effector_loc Std         0.0145598
evaluation/env_infos/initial/end_effector_loc Max         0.0333272
evaluation/env_infos/initial/end_effector_loc Min        -0.0459956
evaluation/env_infos/end_effector_loc Mean                0.0292029
evaluation/env_infos/end_effector_loc Std                 0.179578
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.834045
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.238918
evaluation/env_infos/final/reward_dist Std                0.32202
evaluation/env_infos/final/reward_dist Max                0.921066
evaluation/env_infos/final/reward_dist Min                5.97076e-125
evaluation/env_infos/initial/reward_dist Mean             0.0068989
evaluation/env_infos/initial/reward_dist Std              0.0115409
evaluation/env_infos/initial/reward_dist Max              0.0494761
evaluation/env_infos/initial/reward_dist Min              5.59226e-06
evaluation/env_infos/reward_dist Mean                     0.190499
evaluation/env_infos/reward_dist Std                      0.284849
evaluation/env_infos/reward_dist Max                      0.98559
evaluation/env_infos/reward_dist Min                      5.97076e-125
time/data storing (s)                                    39.1262
time/evaluation sampling (s)                              0.67092
time/exploration sampling (s)                             0.0898346
time/logging (s)                                          0.0154703
time/saving (s)                                           0.813242
time/training (s)                                        37.12
time/epoch (s)                                           77.8357
time/total (s)                                         7414.64
Epoch                                                   114
---------------------------------------------------  -----------------
2021-05-29 02:00:49.800026 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 115 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00207034
trainer/QF2 Loss                                          0.002092
trainer/Policy Loss                                       2.74865
trainer/Q1 Predictions Mean                              -0.78681
trainer/Q1 Predictions Std                                0.76611
trainer/Q1 Predictions Max                                1.10158
trainer/Q1 Predictions Min                               -2.92845
trainer/Q2 Predictions Mean                              -0.798377
trainer/Q2 Predictions Std                                0.757247
trainer/Q2 Predictions Max                                1.15588
trainer/Q2 Predictions Min                               -2.94563
trainer/Q Targets Mean                                   -0.786516
trainer/Q Targets Std                                     0.760215
trainer/Q Targets Max                                     1.13719
trainer/Q Targets Min                                    -2.93862
trainer/Log Pis Mean                                      1.95608
trainer/Log Pis Std                                       1.46408
trainer/Log Pis Max                                       4.92257
trainer/Log Pis Min                                      -6.41459
trainer/Policy mu Mean                                   -0.0315187
trainer/Policy mu Std                                     0.366775
trainer/Policy mu Max                                     2.03236
trainer/Policy mu Min                                    -2.32474
trainer/Policy log std Mean                              -2.29745
trainer/Policy log std Std                                0.570583
trainer/Policy log std Max                               -0.365873
trainer/Policy log std Min                               -3.2521
trainer/Alpha                                             0.0194164
trainer/Alpha Loss                                       -0.173109
exploration/num steps total                           12600
exploration/num paths total                             630
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0487807
exploration/Rewards Std                                   0.0708816
exploration/Rewards Max                                   0.119986
exploration/Rewards Min                                  -0.2261
exploration/Returns Mean                                 -0.975615
exploration/Returns Std                                   1.19983
exploration/Returns Max                                   1.29674
exploration/Returns Min                                  -2.03052
exploration/Actions Mean                                  0.00870923
exploration/Actions Std                                   0.14503
exploration/Actions Max                                   0.571724
exploration/Actions Min                                  -0.5069
exploration/Num Paths                                     5
exploration/Average Returns                              -0.975615
exploration/env_infos/final/reward_energy Mean           -0.0930016
exploration/env_infos/final/reward_energy Std             0.0472255
exploration/env_infos/final/reward_energy Max            -0.00594585
exploration/env_infos/final/reward_energy Min            -0.144019
exploration/env_infos/initial/reward_energy Mean         -0.238307
exploration/env_infos/initial/reward_energy Std           0.190223
exploration/env_infos/initial/reward_energy Max          -0.0719317
exploration/env_infos/initial/reward_energy Min          -0.585716
exploration/env_infos/reward_energy Mean                 -0.159448
exploration/env_infos/reward_energy Std                   0.129599
exploration/env_infos/reward_energy Max                  -0.00594585
exploration/env_infos/reward_energy Min                  -0.585716
exploration/env_infos/final/end_effector_loc Mean         0.0726043
exploration/env_infos/final/end_effector_loc Std          0.230037
exploration/env_infos/final/end_effector_loc Max          0.386886
exploration/env_infos/final/end_effector_loc Min         -0.181373
exploration/env_infos/initial/end_effector_loc Mean       0.0028747
exploration/env_infos/initial/end_effector_loc Std        0.0103901
exploration/env_infos/initial/end_effector_loc Max        0.0285862
exploration/env_infos/initial/end_effector_loc Min       -0.0063629
exploration/env_infos/end_effector_loc Mean               0.0346453
exploration/env_infos/end_effector_loc Std                0.146828
exploration/env_infos/end_effector_loc Max                0.386886
exploration/env_infos/end_effector_loc Min               -0.18485
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.187806
exploration/env_infos/final/reward_dist Std               0.262472
exploration/env_infos/final/reward_dist Max               0.671835
exploration/env_infos/final/reward_dist Min               1.91202e-08
exploration/env_infos/initial/reward_dist Mean            0.021086
exploration/env_infos/initial/reward_dist Std             0.0273247
exploration/env_infos/initial/reward_dist Max             0.0729478
exploration/env_infos/initial/reward_dist Min             0.000159069
exploration/env_infos/reward_dist Mean                    0.227745
exploration/env_infos/reward_dist Std                     0.318632
exploration/env_infos/reward_dist Max                     0.983059
exploration/env_infos/reward_dist Min                     1.91202e-08
evaluation/num steps total                           116000
evaluation/num paths total                             5800
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.041775
evaluation/Rewards Std                                    0.0834845
evaluation/Rewards Max                                    0.14772
evaluation/Rewards Min                                   -0.412969
evaluation/Returns Mean                                  -0.8355
evaluation/Returns Std                                    1.31593
evaluation/Returns Max                                    1.74418
evaluation/Returns Min                                   -3.76275
evaluation/Actions Mean                                   0.00126631
evaluation/Actions Std                                    0.0707501
evaluation/Actions Max                                    0.592903
evaluation/Actions Min                                   -0.795286
evaluation/Num Paths                                     50
evaluation/Average Returns                               -0.8355
evaluation/env_infos/final/reward_energy Mean            -0.0466849
evaluation/env_infos/final/reward_energy Std              0.033792
evaluation/env_infos/final/reward_energy Max             -0.0139996
evaluation/env_infos/final/reward_energy Min             -0.162304
evaluation/env_infos/initial/reward_energy Mean          -0.235809
evaluation/env_infos/initial/reward_energy Std            0.231644
evaluation/env_infos/initial/reward_energy Max           -0.00873266
evaluation/env_infos/initial/reward_energy Min           -0.796525
evaluation/env_infos/reward_energy Mean                  -0.0608564
evaluation/env_infos/reward_energy Std                    0.0794409
evaluation/env_infos/reward_energy Max                   -0.000444018
evaluation/env_infos/reward_energy Min                   -0.796525
evaluation/env_infos/final/end_effector_loc Mean          0.0515378
evaluation/env_infos/final/end_effector_loc Std           0.283304
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00137141
evaluation/env_infos/initial/end_effector_loc Std         0.011606
evaluation/env_infos/initial/end_effector_loc Max         0.0296451
evaluation/env_infos/initial/end_effector_loc Min        -0.0397643
evaluation/env_infos/end_effector_loc Mean                0.0344166
evaluation/env_infos/end_effector_loc Std                 0.178385
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.215788
evaluation/env_infos/final/reward_dist Std                0.269611
evaluation/env_infos/final/reward_dist Max                0.925426
evaluation/env_infos/final/reward_dist Min                7.13895e-89
evaluation/env_infos/initial/reward_dist Mean             0.00533974
evaluation/env_infos/initial/reward_dist Std              0.0115126
evaluation/env_infos/initial/reward_dist Max              0.0700062
evaluation/env_infos/initial/reward_dist Min              1.09633e-06
evaluation/env_infos/reward_dist Mean                     0.204236
evaluation/env_infos/reward_dist Std                      0.28432
evaluation/env_infos/reward_dist Max                      0.99732
evaluation/env_infos/reward_dist Min                      7.13895e-89
time/data storing (s)                                    40.3399
time/evaluation sampling (s)                              0.771589
time/exploration sampling (s)                             0.0935681
time/logging (s)                                          0.015845
time/saving (s)                                           0.818434
time/training (s)                                        38.6855
time/epoch (s)                                           80.7248
time/total (s)                                         7496.81
Epoch                                                   115
---------------------------------------------------  ----------------
2021-05-29 02:02:17.591741 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 116 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00152393
trainer/QF2 Loss                                          0.00124551
trainer/Policy Loss                                       2.83598
trainer/Q1 Predictions Mean                              -0.835258
trainer/Q1 Predictions Std                                0.77459
trainer/Q1 Predictions Max                                0.675557
trainer/Q1 Predictions Min                               -2.766
trainer/Q2 Predictions Mean                              -0.833506
trainer/Q2 Predictions Std                                0.775985
trainer/Q2 Predictions Max                                0.720631
trainer/Q2 Predictions Min                               -2.84314
trainer/Q Targets Mean                                   -0.84132
trainer/Q Targets Std                                     0.782198
trainer/Q Targets Max                                     0.678831
trainer/Q Targets Min                                    -2.87806
trainer/Log Pis Mean                                      1.99451
trainer/Log Pis Std                                       1.28355
trainer/Log Pis Max                                       4.53047
trainer/Log Pis Min                                      -2.45706
trainer/Policy mu Mean                                    0.00131287
trainer/Policy mu Std                                     0.25629
trainer/Policy mu Max                                     1.65708
trainer/Policy mu Min                                    -1.25698
trainer/Policy log std Mean                              -2.31442
trainer/Policy log std Std                                0.534678
trainer/Policy log std Max                               -0.650875
trainer/Policy log std Min                               -3.28072
trainer/Alpha                                             0.0196625
trainer/Alpha Loss                                       -0.0215689
exploration/num steps total                           12700
exploration/num paths total                             635
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.131483
exploration/Rewards Std                                   0.0564353
exploration/Rewards Max                                  -0.0451466
exploration/Rewards Min                                  -0.355855
exploration/Returns Mean                                 -2.62967
exploration/Returns Std                                   0.507086
exploration/Returns Max                                  -2.03492
exploration/Returns Min                                  -3.26381
exploration/Actions Mean                                  0.00662351
exploration/Actions Std                                   0.103374
exploration/Actions Max                                   0.358747
exploration/Actions Min                                  -0.505566
exploration/Num Paths                                     5
exploration/Average Returns                              -2.62967
exploration/env_infos/final/reward_energy Mean           -0.20423
exploration/env_infos/final/reward_energy Std             0.135966
exploration/env_infos/final/reward_energy Max            -0.0299026
exploration/env_infos/final/reward_energy Min            -0.424806
exploration/env_infos/initial/reward_energy Mean         -0.263553
exploration/env_infos/initial/reward_energy Std           0.177351
exploration/env_infos/initial/reward_energy Max          -0.0522903
exploration/env_infos/initial/reward_energy Min          -0.506309
exploration/env_infos/reward_energy Mean                 -0.115629
exploration/env_infos/reward_energy Std                   0.0899436
exploration/env_infos/reward_energy Max                  -0.00582638
exploration/env_infos/reward_energy Min                  -0.506309
exploration/env_infos/final/end_effector_loc Mean        -0.0517871
exploration/env_infos/final/end_effector_loc Std          0.365909
exploration/env_infos/final/end_effector_loc Max          0.69343
exploration/env_infos/final/end_effector_loc Min         -0.491217
exploration/env_infos/initial/end_effector_loc Mean      -0.00320803
exploration/env_infos/initial/end_effector_loc Std        0.0107634
exploration/env_infos/initial/end_effector_loc Max        0.0113335
exploration/env_infos/initial/end_effector_loc Min       -0.0252783
exploration/env_infos/end_effector_loc Mean              -0.039698
exploration/env_infos/end_effector_loc Std                0.202571
exploration/env_infos/end_effector_loc Max                0.69343
exploration/env_infos/end_effector_loc Min               -0.491217
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00827244
exploration/env_infos/final/reward_dist Std               0.0121041
exploration/env_infos/final/reward_dist Max               0.0311525
exploration/env_infos/final/reward_dist Min               5.06276e-38
exploration/env_infos/initial/reward_dist Mean            0.0102956
exploration/env_infos/initial/reward_dist Std             0.0113248
exploration/env_infos/initial/reward_dist Max             0.0295428
exploration/env_infos/initial/reward_dist Min             4.04701e-05
exploration/env_infos/reward_dist Mean                    0.0657209
exploration/env_infos/reward_dist Std                     0.134981
exploration/env_infos/reward_dist Max                     0.585604
exploration/env_infos/reward_dist Min                     5.06276e-38
evaluation/num steps total                           117000
evaluation/num paths total                             5850
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0735282
evaluation/Rewards Std                                    0.08862
evaluation/Rewards Max                                    0.178047
evaluation/Rewards Min                                   -0.403058
evaluation/Returns Mean                                  -1.47056
evaluation/Returns Std                                    1.41157
evaluation/Returns Max                                    2.54159
evaluation/Returns Min                                   -4.51982
evaluation/Actions Mean                                   0.00113389
evaluation/Actions Std                                    0.103187
evaluation/Actions Max                                    0.856195
evaluation/Actions Min                                   -0.857116
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.47056
evaluation/env_infos/final/reward_energy Mean            -0.0428621
evaluation/env_infos/final/reward_energy Std              0.0412475
evaluation/env_infos/final/reward_energy Max             -0.000861391
evaluation/env_infos/final/reward_energy Min             -0.197312
evaluation/env_infos/initial/reward_energy Mean          -0.340727
evaluation/env_infos/initial/reward_energy Std            0.314234
evaluation/env_infos/initial/reward_energy Max           -0.0141806
evaluation/env_infos/initial/reward_energy Min           -1.00982
evaluation/env_infos/reward_energy Mean                  -0.0823001
evaluation/env_infos/reward_energy Std                    0.120517
evaluation/env_infos/reward_energy Max                   -0.000861391
evaluation/env_infos/reward_energy Min                   -1.00982
evaluation/env_infos/final/end_effector_loc Mean         -0.0268245
evaluation/env_infos/final/end_effector_loc Std           0.327425
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00234066
evaluation/env_infos/initial/end_effector_loc Std         0.0162194
evaluation/env_infos/initial/end_effector_loc Max         0.0428098
evaluation/env_infos/initial/end_effector_loc Min        -0.0428558
evaluation/env_infos/end_effector_loc Mean               -0.021336
evaluation/env_infos/end_effector_loc Std                 0.203661
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.154551
evaluation/env_infos/final/reward_dist Std                0.28248
evaluation/env_infos/final/reward_dist Max                0.983931
evaluation/env_infos/final/reward_dist Min                6.20005e-158
evaluation/env_infos/initial/reward_dist Mean             0.0066278
evaluation/env_infos/initial/reward_dist Std              0.0137471
evaluation/env_infos/initial/reward_dist Max              0.0816241
evaluation/env_infos/initial/reward_dist Min              1.15611e-06
evaluation/env_infos/reward_dist Mean                     0.170021
evaluation/env_infos/reward_dist Std                      0.280322
evaluation/env_infos/reward_dist Max                      0.998475
evaluation/env_infos/reward_dist Min                      6.20005e-158
time/data storing (s)                                    43.094
time/evaluation sampling (s)                              0.652873
time/exploration sampling (s)                             0.102991
time/logging (s)                                          0.0180132
time/saving (s)                                           0.873091
time/training (s)                                        41.7677
time/epoch (s)                                           86.5087
time/total (s)                                         7584.59
Epoch                                                   116
---------------------------------------------------  -----------------
2021-05-29 02:03:45.754056 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 117 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00230767
trainer/QF2 Loss                                          0.0012948
trainer/Policy Loss                                       2.70162
trainer/Q1 Predictions Mean                              -0.901356
trainer/Q1 Predictions Std                                0.780091
trainer/Q1 Predictions Max                                0.768002
trainer/Q1 Predictions Min                               -3.09426
trainer/Q2 Predictions Mean                              -0.907721
trainer/Q2 Predictions Std                                0.773752
trainer/Q2 Predictions Max                                0.735194
trainer/Q2 Predictions Min                               -3.13943
trainer/Q Targets Mean                                   -0.903997
trainer/Q Targets Std                                     0.772232
trainer/Q Targets Max                                     0.764529
trainer/Q Targets Min                                    -3.00051
trainer/Log Pis Mean                                      1.79894
trainer/Log Pis Std                                       1.43972
trainer/Log Pis Max                                       4.7899
trainer/Log Pis Min                                      -3.21739
trainer/Policy mu Mean                                    0.0215645
trainer/Policy mu Std                                     0.358049
trainer/Policy mu Max                                     2.37125
trainer/Policy mu Min                                    -2.50307
trainer/Policy log std Mean                              -2.23161
trainer/Policy log std Std                                0.629612
trainer/Policy log std Max                                0.044506
trainer/Policy log std Min                               -3.4648
trainer/Alpha                                             0.0202027
trainer/Alpha Loss                                       -0.784412
exploration/num steps total                           12800
exploration/num paths total                             640
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0453669
exploration/Rewards Std                                   0.0703888
exploration/Rewards Max                                   0.131192
exploration/Rewards Min                                  -0.198842
exploration/Returns Mean                                 -0.907338
exploration/Returns Std                                   0.903391
exploration/Returns Max                                   0.138075
exploration/Returns Min                                  -2.26054
exploration/Actions Mean                                  0.0110133
exploration/Actions Std                                   0.186975
exploration/Actions Max                                   0.521598
exploration/Actions Min                                  -0.74499
exploration/Num Paths                                     5
exploration/Average Returns                              -0.907338
exploration/env_infos/final/reward_energy Mean           -0.130744
exploration/env_infos/final/reward_energy Std             0.0561892
exploration/env_infos/final/reward_energy Max            -0.0338701
exploration/env_infos/final/reward_energy Min            -0.208331
exploration/env_infos/initial/reward_energy Mean         -0.361078
exploration/env_infos/initial/reward_energy Std           0.309353
exploration/env_infos/initial/reward_energy Max          -0.0101989
exploration/env_infos/initial/reward_energy Min          -0.758657
exploration/env_infos/reward_energy Mean                 -0.209028
exploration/env_infos/reward_energy Std                   0.162693
exploration/env_infos/reward_energy Max                  -0.00796873
exploration/env_infos/reward_energy Min                  -0.758657
exploration/env_infos/final/end_effector_loc Mean         0.130824
exploration/env_infos/final/end_effector_loc Std          0.216906
exploration/env_infos/final/end_effector_loc Max          0.508384
exploration/env_infos/final/end_effector_loc Min         -0.155899
exploration/env_infos/initial/end_effector_loc Mean       0.00205488
exploration/env_infos/initial/end_effector_loc Std        0.0166845
exploration/env_infos/initial/end_effector_loc Max        0.0256837
exploration/env_infos/initial/end_effector_loc Min       -0.0372495
exploration/env_infos/end_effector_loc Mean               0.0597492
exploration/env_infos/end_effector_loc Std                0.162368
exploration/env_infos/end_effector_loc Max                0.508384
exploration/env_infos/end_effector_loc Min               -0.258286
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0102262
exploration/env_infos/final/reward_dist Std               0.0142764
exploration/env_infos/final/reward_dist Max               0.0382061
exploration/env_infos/final/reward_dist Min               7.05544e-08
exploration/env_infos/initial/reward_dist Mean            0.00230278
exploration/env_infos/initial/reward_dist Std             0.00221476
exploration/env_infos/initial/reward_dist Max             0.00597555
exploration/env_infos/initial/reward_dist Min             2.53046e-05
exploration/env_infos/reward_dist Mean                    0.211691
exploration/env_infos/reward_dist Std                     0.274992
exploration/env_infos/reward_dist Max                     0.987487
exploration/env_infos/reward_dist Min                     7.05544e-08
evaluation/num steps total                           118000
evaluation/num paths total                             5900
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0426261
evaluation/Rewards Std                                    0.083792
evaluation/Rewards Max                                    0.170412
evaluation/Rewards Min                                   -0.513498
evaluation/Returns Mean                                  -0.852522
evaluation/Returns Std                                    1.25657
evaluation/Returns Max                                    2.03536
evaluation/Returns Min                                   -3.83462
evaluation/Actions Mean                                   0.000675093
evaluation/Actions Std                                    0.0860916
evaluation/Actions Max                                    0.820452
evaluation/Actions Min                                   -0.84179
evaluation/Num Paths                                     50
evaluation/Average Returns                               -0.852522
evaluation/env_infos/final/reward_energy Mean            -0.0462578
evaluation/env_infos/final/reward_energy Std              0.049641
evaluation/env_infos/final/reward_energy Max             -0.00421666
evaluation/env_infos/final/reward_energy Min             -0.258117
evaluation/env_infos/initial/reward_energy Mean          -0.276068
evaluation/env_infos/initial/reward_energy Std            0.25378
evaluation/env_infos/initial/reward_energy Max           -0.016302
evaluation/env_infos/initial/reward_energy Min           -1.17548
evaluation/env_infos/reward_energy Mean                  -0.0715292
evaluation/env_infos/reward_energy Std                    0.0985292
evaluation/env_infos/reward_energy Max                   -0.000768741
evaluation/env_infos/reward_energy Min                   -1.17548
evaluation/env_infos/final/end_effector_loc Mean          0.026123
evaluation/env_infos/final/end_effector_loc Std           0.242858
evaluation/env_infos/final/end_effector_loc Max           0.555166
evaluation/env_infos/final/end_effector_loc Min          -0.604558
evaluation/env_infos/initial/end_effector_loc Mean        0.000472543
evaluation/env_infos/initial/end_effector_loc Std         0.0132495
evaluation/env_infos/initial/end_effector_loc Max         0.0410226
evaluation/env_infos/initial/end_effector_loc Min        -0.0420895
evaluation/env_infos/end_effector_loc Mean                0.0173607
evaluation/env_infos/end_effector_loc Std                 0.165135
evaluation/env_infos/end_effector_loc Max                 0.555166
evaluation/env_infos/end_effector_loc Min                -0.604558
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.200667
evaluation/env_infos/final/reward_dist Std                0.273677
evaluation/env_infos/final/reward_dist Max                0.99132
evaluation/env_infos/final/reward_dist Min                1.10523e-27
evaluation/env_infos/initial/reward_dist Mean             0.00728184
evaluation/env_infos/initial/reward_dist Std              0.0151581
evaluation/env_infos/initial/reward_dist Max              0.0704939
evaluation/env_infos/initial/reward_dist Min              1.90715e-06
evaluation/env_infos/reward_dist Mean                     0.196712
evaluation/env_infos/reward_dist Std                      0.292213
evaluation/env_infos/reward_dist Max                      0.994895
evaluation/env_infos/reward_dist Min                      1.10523e-27
time/data storing (s)                                    42.091
time/evaluation sampling (s)                              0.594365
time/exploration sampling (s)                             0.0961822
time/logging (s)                                          0.0190653
time/saving (s)                                           0.909149
time/training (s)                                        43.1184
time/epoch (s)                                           86.8282
time/total (s)                                         7672.75
Epoch                                                   117
---------------------------------------------------  ----------------
2021-05-29 02:05:18.757025 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 118 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00120272
trainer/QF2 Loss                                          0.00164267
trainer/Policy Loss                                       2.86755
trainer/Q1 Predictions Mean                              -0.758188
trainer/Q1 Predictions Std                                0.794738
trainer/Q1 Predictions Max                                0.749584
trainer/Q1 Predictions Min                               -3.17749
trainer/Q2 Predictions Mean                              -0.75726
trainer/Q2 Predictions Std                                0.806716
trainer/Q2 Predictions Max                                0.788243
trainer/Q2 Predictions Min                               -3.14017
trainer/Q Targets Mean                                   -0.756648
trainer/Q Targets Std                                     0.805922
trainer/Q Targets Max                                     0.809705
trainer/Q Targets Min                                    -3.20496
trainer/Log Pis Mean                                      2.11271
trainer/Log Pis Std                                       1.2402
trainer/Log Pis Max                                       4.48706
trainer/Log Pis Min                                      -2.80347
trainer/Policy mu Mean                                    0.0230813
trainer/Policy mu Std                                     0.27243
trainer/Policy mu Max                                     1.94571
trainer/Policy mu Min                                    -1.5762
trainer/Policy log std Mean                              -2.38966
trainer/Policy log std Std                                0.56658
trainer/Policy log std Max                               -0.580055
trainer/Policy log std Min                               -3.47223
trainer/Alpha                                             0.0189553
trainer/Alpha Loss                                        0.447042
exploration/num steps total                           12900
exploration/num paths total                             645
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.036559
exploration/Rewards Std                                   0.0587338
exploration/Rewards Max                                   0.068163
exploration/Rewards Min                                  -0.20219
exploration/Returns Mean                                 -0.731179
exploration/Returns Std                                   0.651044
exploration/Returns Max                                   0.153847
exploration/Returns Min                                  -1.53063
exploration/Actions Mean                                  0.0059762
exploration/Actions Std                                   0.168508
exploration/Actions Max                                   0.610313
exploration/Actions Min                                  -0.653406
exploration/Num Paths                                     5
exploration/Average Returns                              -0.731179
exploration/env_infos/final/reward_energy Mean           -0.106546
exploration/env_infos/final/reward_energy Std             0.0667612
exploration/env_infos/final/reward_energy Max            -0.0551088
exploration/env_infos/final/reward_energy Min            -0.235064
exploration/env_infos/initial/reward_energy Mean         -0.385376
exploration/env_infos/initial/reward_energy Std           0.257495
exploration/env_infos/initial/reward_energy Max          -0.0234632
exploration/env_infos/initial/reward_energy Min          -0.732694
exploration/env_infos/reward_energy Mean                 -0.182123
exploration/env_infos/reward_energy Std                   0.153924
exploration/env_infos/reward_energy Max                  -0.00348432
exploration/env_infos/reward_energy Min                  -0.732694
exploration/env_infos/final/end_effector_loc Mean         0.117999
exploration/env_infos/final/end_effector_loc Std          0.173089
exploration/env_infos/final/end_effector_loc Max          0.486875
exploration/env_infos/final/end_effector_loc Min         -0.13707
exploration/env_infos/initial/end_effector_loc Mean       0.00996448
exploration/env_infos/initial/end_effector_loc Std        0.0130089
exploration/env_infos/initial/end_effector_loc Max        0.0305156
exploration/env_infos/initial/end_effector_loc Min       -0.0137428
exploration/env_infos/end_effector_loc Mean               0.0820186
exploration/env_infos/end_effector_loc Std                0.124579
exploration/env_infos/end_effector_loc Max                0.486875
exploration/env_infos/end_effector_loc Min               -0.221702
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.300593
exploration/env_infos/final/reward_dist Std               0.322541
exploration/env_infos/final/reward_dist Max               0.781453
exploration/env_infos/final/reward_dist Min               4.01579e-07
exploration/env_infos/initial/reward_dist Mean            0.00235313
exploration/env_infos/initial/reward_dist Std             0.00272721
exploration/env_infos/initial/reward_dist Max             0.0069813
exploration/env_infos/initial/reward_dist Min             3.3407e-05
exploration/env_infos/reward_dist Mean                    0.246226
exploration/env_infos/reward_dist Std                     0.289328
exploration/env_infos/reward_dist Max                     0.948737
exploration/env_infos/reward_dist Min                     4.01579e-07
evaluation/num steps total                           119000
evaluation/num paths total                             5950
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0523466
evaluation/Rewards Std                                    0.0951449
evaluation/Rewards Max                                    0.145633
evaluation/Rewards Min                                   -0.695417
evaluation/Returns Mean                                  -1.04693
evaluation/Returns Std                                    1.39323
evaluation/Returns Max                                    1.86871
evaluation/Returns Min                                   -5.7176
evaluation/Actions Mean                                   0.00961779
evaluation/Actions Std                                    0.103984
evaluation/Actions Max                                    0.905561
evaluation/Actions Min                                   -0.850596
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.04693
evaluation/env_infos/final/reward_energy Mean            -0.0953333
evaluation/env_infos/final/reward_energy Std              0.127999
evaluation/env_infos/final/reward_energy Max             -0.00285304
evaluation/env_infos/final/reward_energy Min             -0.687495
evaluation/env_infos/initial/reward_energy Mean          -0.238665
evaluation/env_infos/initial/reward_energy Std            0.267143
evaluation/env_infos/initial/reward_energy Max           -0.00583264
evaluation/env_infos/initial/reward_energy Min           -1.12163
evaluation/env_infos/reward_energy Mean                  -0.0792726
evaluation/env_infos/reward_energy Std                    0.124603
evaluation/env_infos/reward_energy Max                   -0.000756712
evaluation/env_infos/reward_energy Min                   -1.12163
evaluation/env_infos/final/end_effector_loc Mean          0.0770214
evaluation/env_infos/final/end_effector_loc Std           0.327825
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00205248
evaluation/env_infos/initial/end_effector_loc Std         0.0124978
evaluation/env_infos/initial/end_effector_loc Max         0.0434596
evaluation/env_infos/initial/end_effector_loc Min        -0.0425298
evaluation/env_infos/end_effector_loc Mean                0.0451956
evaluation/env_infos/end_effector_loc Std                 0.207008
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.151603
evaluation/env_infos/final/reward_dist Std                0.218422
evaluation/env_infos/final/reward_dist Max                0.875011
evaluation/env_infos/final/reward_dist Min                1.09303e-167
evaluation/env_infos/initial/reward_dist Mean             0.00340979
evaluation/env_infos/initial/reward_dist Std              0.0073194
evaluation/env_infos/initial/reward_dist Max              0.0342102
evaluation/env_infos/initial/reward_dist Min              2.19469e-06
evaluation/env_infos/reward_dist Mean                     0.17408
evaluation/env_infos/reward_dist Std                      0.266743
evaluation/env_infos/reward_dist Max                      0.994634
evaluation/env_infos/reward_dist Min                      1.09303e-167
time/data storing (s)                                    44.8422
time/evaluation sampling (s)                              0.809001
time/exploration sampling (s)                             0.109734
time/logging (s)                                          0.0212347
time/saving (s)                                           0.951429
time/training (s)                                        44.7803
time/epoch (s)                                           91.5138
time/total (s)                                         7765.75
Epoch                                                   118
---------------------------------------------------  -----------------
2021-05-29 02:06:48.961983 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 119 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00102095
trainer/QF2 Loss                                          0.00124408
trainer/Policy Loss                                       2.77795
trainer/Q1 Predictions Mean                              -0.775005
trainer/Q1 Predictions Std                                0.784931
trainer/Q1 Predictions Max                                0.810405
trainer/Q1 Predictions Min                               -3.25975
trainer/Q2 Predictions Mean                              -0.779601
trainer/Q2 Predictions Std                                0.786792
trainer/Q2 Predictions Max                                0.79913
trainer/Q2 Predictions Min                               -3.30492
trainer/Q Targets Mean                                   -0.783505
trainer/Q Targets Std                                     0.786605
trainer/Q Targets Max                                     0.786801
trainer/Q Targets Min                                    -3.25326
trainer/Log Pis Mean                                      1.99504
trainer/Log Pis Std                                       1.34699
trainer/Log Pis Max                                       4.70922
trainer/Log Pis Min                                      -3.49451
trainer/Policy mu Mean                                   -0.0167672
trainer/Policy mu Std                                     0.280307
trainer/Policy mu Max                                     1.62568
trainer/Policy mu Min                                    -1.45242
trainer/Policy log std Mean                              -2.35394
trainer/Policy log std Std                                0.607432
trainer/Policy log std Max                               -0.496451
trainer/Policy log std Min                               -3.4336
trainer/Alpha                                             0.0188644
trainer/Alpha Loss                                       -0.0197056
exploration/num steps total                           13000
exploration/num paths total                             650
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0949946
exploration/Rewards Std                                   0.0821645
exploration/Rewards Max                                   0.0446773
exploration/Rewards Min                                  -0.578091
exploration/Returns Mean                                 -1.89989
exploration/Returns Std                                   0.460597
exploration/Returns Max                                  -1.26085
exploration/Returns Min                                  -2.66577
exploration/Actions Mean                                  0.00457606
exploration/Actions Std                                   0.15482
exploration/Actions Max                                   0.618363
exploration/Actions Min                                  -0.604088
exploration/Num Paths                                     5
exploration/Average Returns                              -1.89989
exploration/env_infos/final/reward_energy Mean           -0.197443
exploration/env_infos/final/reward_energy Std             0.128006
exploration/env_infos/final/reward_energy Max            -0.0407189
exploration/env_infos/final/reward_energy Min            -0.38314
exploration/env_infos/initial/reward_energy Mean         -0.418464
exploration/env_infos/initial/reward_energy Std           0.18983
exploration/env_infos/initial/reward_energy Max          -0.0909127
exploration/env_infos/initial/reward_energy Min          -0.618955
exploration/env_infos/reward_energy Mean                 -0.164745
exploration/env_infos/reward_energy Std                   0.144358
exploration/env_infos/reward_energy Max                  -0.0177162
exploration/env_infos/reward_energy Min                  -0.860182
exploration/env_infos/final/end_effector_loc Mean         0.00435106
exploration/env_infos/final/end_effector_loc Std          0.425919
exploration/env_infos/final/end_effector_loc Max          0.597715
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.000677115
exploration/env_infos/initial/end_effector_loc Std        0.0162319
exploration/env_infos/initial/end_effector_loc Max        0.0309181
exploration/env_infos/initial/end_effector_loc Min       -0.026888
exploration/env_infos/end_effector_loc Mean              -0.00592137
exploration/env_infos/end_effector_loc Std                0.264595
exploration/env_infos/end_effector_loc Max                0.597715
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0573641
exploration/env_infos/final/reward_dist Std               0.112593
exploration/env_infos/final/reward_dist Max               0.282542
exploration/env_infos/final/reward_dist Min               1.32291e-37
exploration/env_infos/initial/reward_dist Mean            0.0144731
exploration/env_infos/initial/reward_dist Std             0.0124681
exploration/env_infos/initial/reward_dist Max             0.0321262
exploration/env_infos/initial/reward_dist Min             2.71491e-05
exploration/env_infos/reward_dist Mean                    0.188992
exploration/env_infos/reward_dist Std                     0.251049
exploration/env_infos/reward_dist Max                     0.940012
exploration/env_infos/reward_dist Min                     1.32291e-37
evaluation/num steps total                           120000
evaluation/num paths total                             6000
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0465127
evaluation/Rewards Std                                    0.0725169
evaluation/Rewards Max                                    0.157613
evaluation/Rewards Min                                   -0.411419
evaluation/Returns Mean                                  -0.930254
evaluation/Returns Std                                    1.06151
evaluation/Returns Max                                    2.29643
evaluation/Returns Min                                   -3.52076
evaluation/Actions Mean                                   0.000345665
evaluation/Actions Std                                    0.0736074
evaluation/Actions Max                                    0.455403
evaluation/Actions Min                                   -0.647299
evaluation/Num Paths                                     50
evaluation/Average Returns                               -0.930254
evaluation/env_infos/final/reward_energy Mean            -0.0492534
evaluation/env_infos/final/reward_energy Std              0.05295
evaluation/env_infos/final/reward_energy Max             -0.00734522
evaluation/env_infos/final/reward_energy Min             -0.2263
evaluation/env_infos/initial/reward_energy Mean          -0.225552
evaluation/env_infos/initial/reward_energy Std            0.182859
evaluation/env_infos/initial/reward_energy Max           -0.00670925
evaluation/env_infos/initial/reward_energy Min           -0.664179
evaluation/env_infos/reward_energy Mean                  -0.061929
evaluation/env_infos/reward_energy Std                    0.0836728
evaluation/env_infos/reward_energy Max                   -0.00032768
evaluation/env_infos/reward_energy Min                   -0.664179
evaluation/env_infos/final/end_effector_loc Mean         -0.0274137
evaluation/env_infos/final/end_effector_loc Std           0.313336
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.802155
evaluation/env_infos/initial/end_effector_loc Mean       -0.00118827
evaluation/env_infos/initial/end_effector_loc Std         0.0101969
evaluation/env_infos/initial/end_effector_loc Max         0.0209457
evaluation/env_infos/initial/end_effector_loc Min        -0.0323649
evaluation/env_infos/end_effector_loc Mean               -0.0101186
evaluation/env_infos/end_effector_loc Std                 0.193803
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.802155
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.134091
evaluation/env_infos/final/reward_dist Std                0.22695
evaluation/env_infos/final/reward_dist Max                0.799159
evaluation/env_infos/final/reward_dist Min                1.16638e-150
evaluation/env_infos/initial/reward_dist Mean             0.00726767
evaluation/env_infos/initial/reward_dist Std              0.0116717
evaluation/env_infos/initial/reward_dist Max              0.0472091
evaluation/env_infos/initial/reward_dist Min              1.53925e-06
evaluation/env_infos/reward_dist Mean                     0.163829
evaluation/env_infos/reward_dist Std                      0.24108
evaluation/env_infos/reward_dist Max                      0.998895
evaluation/env_infos/reward_dist Min                      1.16638e-150
time/data storing (s)                                    43.7761
time/evaluation sampling (s)                              0.864729
time/exploration sampling (s)                             0.10614
time/logging (s)                                          0.016077
time/saving (s)                                           1.07065
time/training (s)                                        42.5509
time/epoch (s)                                           88.3846
time/total (s)                                         7855.95
Epoch                                                   119
---------------------------------------------------  -----------------
2021-05-29 02:08:15.859740 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 120 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.000837689
trainer/QF2 Loss                                          0.00184936
trainer/Policy Loss                                       2.68091
trainer/Q1 Predictions Mean                              -0.673121
trainer/Q1 Predictions Std                                0.755268
trainer/Q1 Predictions Max                                0.865091
trainer/Q1 Predictions Min                               -3.02372
trainer/Q2 Predictions Mean                              -0.673368
trainer/Q2 Predictions Std                                0.748849
trainer/Q2 Predictions Max                                0.834493
trainer/Q2 Predictions Min                               -3.06081
trainer/Q Targets Mean                                   -0.670292
trainer/Q Targets Std                                     0.755059
trainer/Q Targets Max                                     0.868647
trainer/Q Targets Min                                    -3.00241
trainer/Log Pis Mean                                      2.01149
trainer/Log Pis Std                                       1.44658
trainer/Log Pis Max                                       4.63246
trainer/Log Pis Min                                      -4.22022
trainer/Policy mu Mean                                    0.0144063
trainer/Policy mu Std                                     0.332439
trainer/Policy mu Max                                     1.80245
trainer/Policy mu Min                                    -1.54517
trainer/Policy log std Mean                              -2.28082
trainer/Policy log std Std                                0.658688
trainer/Policy log std Max                               -0.171109
trainer/Policy log std Min                               -3.54758
trainer/Alpha                                             0.0178806
trainer/Alpha Loss                                        0.0462342
exploration/num steps total                           13100
exploration/num paths total                             655
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0810253
exploration/Rewards Std                                   0.0783825
exploration/Rewards Max                                   0.06806
exploration/Rewards Min                                  -0.257285
exploration/Returns Mean                                 -1.62051
exploration/Returns Std                                   1.14608
exploration/Returns Max                                  -0.163545
exploration/Returns Min                                  -3.6406
exploration/Actions Mean                                  0.00843569
exploration/Actions Std                                   0.153847
exploration/Actions Max                                   0.745032
exploration/Actions Min                                  -0.448336
exploration/Num Paths                                     5
exploration/Average Returns                              -1.62051
exploration/env_infos/final/reward_energy Mean           -0.138168
exploration/env_infos/final/reward_energy Std             0.111738
exploration/env_infos/final/reward_energy Max            -0.0354741
exploration/env_infos/final/reward_energy Min            -0.346799
exploration/env_infos/initial/reward_energy Mean         -0.409436
exploration/env_infos/initial/reward_energy Std           0.232822
exploration/env_infos/initial/reward_energy Max          -0.0846475
exploration/env_infos/initial/reward_energy Min          -0.757421
exploration/env_infos/reward_energy Mean                 -0.171738
exploration/env_infos/reward_energy Std                   0.134113
exploration/env_infos/reward_energy Max                  -0.027548
exploration/env_infos/reward_energy Min                  -0.757421
exploration/env_infos/final/end_effector_loc Mean         0.00481176
exploration/env_infos/final/end_effector_loc Std          0.423281
exploration/env_infos/final/end_effector_loc Max          0.811265
exploration/env_infos/final/end_effector_loc Min         -0.878211
exploration/env_infos/initial/end_effector_loc Mean       0.000157905
exploration/env_infos/initial/end_effector_loc Std        0.0166517
exploration/env_infos/initial/end_effector_loc Max        0.0372516
exploration/env_infos/initial/end_effector_loc Min       -0.0224168
exploration/env_infos/end_effector_loc Mean              -0.007944
exploration/env_infos/end_effector_loc Std                0.251797
exploration/env_infos/end_effector_loc Max                0.811265
exploration/env_infos/end_effector_loc Min               -0.878211
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0581704
exploration/env_infos/final/reward_dist Std               0.113211
exploration/env_infos/final/reward_dist Max               0.284575
exploration/env_infos/final/reward_dist Min               5.40842e-60
exploration/env_infos/initial/reward_dist Mean            0.00125807
exploration/env_infos/initial/reward_dist Std             0.00155499
exploration/env_infos/initial/reward_dist Max             0.00414108
exploration/env_infos/initial/reward_dist Min             1.61204e-06
exploration/env_infos/reward_dist Mean                    0.173607
exploration/env_infos/reward_dist Std                     0.22255
exploration/env_infos/reward_dist Max                     0.827227
exploration/env_infos/reward_dist Min                     5.40842e-60
evaluation/num steps total                           121000
evaluation/num paths total                             6050
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0665683
evaluation/Rewards Std                                    0.106866
evaluation/Rewards Max                                    0.135917
evaluation/Rewards Min                                   -0.989094
evaluation/Returns Mean                                  -1.33137
evaluation/Returns Std                                    1.63445
evaluation/Returns Max                                    0.972365
evaluation/Returns Min                                   -6.55403
evaluation/Actions Mean                                   0.00218348
evaluation/Actions Std                                    0.123034
evaluation/Actions Max                                    0.995702
evaluation/Actions Min                                   -0.935757
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.33137
evaluation/env_infos/final/reward_energy Mean            -0.0716287
evaluation/env_infos/final/reward_energy Std              0.0798471
evaluation/env_infos/final/reward_energy Max             -0.00884068
evaluation/env_infos/final/reward_energy Min             -0.456814
evaluation/env_infos/initial/reward_energy Mean          -0.268425
evaluation/env_infos/initial/reward_energy Std            0.258991
evaluation/env_infos/initial/reward_energy Max           -0.0097687
evaluation/env_infos/initial/reward_energy Min           -0.906091
evaluation/env_infos/reward_energy Mean                  -0.0953499
evaluation/env_infos/reward_energy Std                    0.145576
evaluation/env_infos/reward_energy Max                   -0.001458
evaluation/env_infos/reward_energy Min                   -1.35035
evaluation/env_infos/final/end_effector_loc Mean          0.0297571
evaluation/env_infos/final/end_effector_loc Std           0.316136
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000768424
evaluation/env_infos/initial/end_effector_loc Std         0.0131651
evaluation/env_infos/initial/end_effector_loc Max         0.0430526
evaluation/env_infos/initial/end_effector_loc Min        -0.0377166
evaluation/env_infos/end_effector_loc Mean                0.022344
evaluation/env_infos/end_effector_loc Std                 0.206532
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.152978
evaluation/env_infos/final/reward_dist Std                0.238861
evaluation/env_infos/final/reward_dist Max                0.859459
evaluation/env_infos/final/reward_dist Min                1.36137e-139
evaluation/env_infos/initial/reward_dist Mean             0.00596778
evaluation/env_infos/initial/reward_dist Std              0.014758
evaluation/env_infos/initial/reward_dist Max              0.0965288
evaluation/env_infos/initial/reward_dist Min              1.80731e-06
evaluation/env_infos/reward_dist Mean                     0.147961
evaluation/env_infos/reward_dist Std                      0.249787
evaluation/env_infos/reward_dist Max                      0.999983
evaluation/env_infos/reward_dist Min                      1.36137e-139
time/data storing (s)                                    42.7384
time/evaluation sampling (s)                              0.807889
time/exploration sampling (s)                             0.099203
time/logging (s)                                          0.016118
time/saving (s)                                           0.849109
time/training (s)                                        40.9197
time/epoch (s)                                           85.4303
time/total (s)                                         7942.84
Epoch                                                   120
---------------------------------------------------  -----------------
2021-05-29 02:09:44.285084 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 121 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00133366
trainer/QF2 Loss                                          0.00128455
trainer/Policy Loss                                       2.7585
trainer/Q1 Predictions Mean                              -0.703616
trainer/Q1 Predictions Std                                0.692243
trainer/Q1 Predictions Max                                0.907036
trainer/Q1 Predictions Min                               -2.72485
trainer/Q2 Predictions Mean                              -0.701964
trainer/Q2 Predictions Std                                0.689993
trainer/Q2 Predictions Max                                0.87671
trainer/Q2 Predictions Min                               -2.70067
trainer/Q Targets Mean                                   -0.70733
trainer/Q Targets Std                                     0.688471
trainer/Q Targets Max                                     0.87951
trainer/Q Targets Min                                    -2.72128
trainer/Log Pis Mean                                      2.04912
trainer/Log Pis Std                                       1.4283
trainer/Log Pis Max                                       4.82361
trainer/Log Pis Min                                      -5.544
trainer/Policy mu Mean                                    0.00161243
trainer/Policy mu Std                                     0.248081
trainer/Policy mu Max                                     1.4128
trainer/Policy mu Min                                    -1.69253
trainer/Policy log std Mean                              -2.40616
trainer/Policy log std Std                                0.599769
trainer/Policy log std Max                               -0.280511
trainer/Policy log std Min                               -3.65848
trainer/Alpha                                             0.0170389
trainer/Alpha Loss                                        0.200086
exploration/num steps total                           13200
exploration/num paths total                             660
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0756184
exploration/Rewards Std                                   0.07347
exploration/Rewards Max                                   0.0404535
exploration/Rewards Min                                  -0.512001
exploration/Returns Mean                                 -1.51237
exploration/Returns Std                                   0.466623
exploration/Returns Max                                  -0.891978
exploration/Returns Min                                  -2.03545
exploration/Actions Mean                                  0.0348648
exploration/Actions Std                                   0.143125
exploration/Actions Max                                   0.623453
exploration/Actions Min                                  -0.574457
exploration/Num Paths                                     5
exploration/Average Returns                              -1.51237
exploration/env_infos/final/reward_energy Mean           -0.209492
exploration/env_infos/final/reward_energy Std             0.17118
exploration/env_infos/final/reward_energy Max            -0.0918619
exploration/env_infos/final/reward_energy Min            -0.548505
exploration/env_infos/initial/reward_energy Mean         -0.366561
exploration/env_infos/initial/reward_energy Std           0.233608
exploration/env_infos/initial/reward_energy Max          -0.0560203
exploration/env_infos/initial/reward_energy Min          -0.694516
exploration/env_infos/reward_energy Mean                 -0.154719
exploration/env_infos/reward_energy Std                   0.139509
exploration/env_infos/reward_energy Max                  -0.00916841
exploration/env_infos/reward_energy Min                  -0.694516
exploration/env_infos/final/end_effector_loc Mean         0.161248
exploration/env_infos/final/end_effector_loc Std          0.41296
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.392743
exploration/env_infos/initial/end_effector_loc Mean      -0.00205478
exploration/env_infos/initial/end_effector_loc Std        0.01523
exploration/env_infos/initial/end_effector_loc Max        0.0271299
exploration/env_infos/initial/end_effector_loc Min       -0.0287229
exploration/env_infos/end_effector_loc Mean               0.0558894
exploration/env_infos/end_effector_loc Std                0.273998
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.392743
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00418203
exploration/env_infos/final/reward_dist Std               0.00822786
exploration/env_infos/final/reward_dist Max               0.0206369
exploration/env_infos/final/reward_dist Min               3.18927e-52
exploration/env_infos/initial/reward_dist Mean            0.00663614
exploration/env_infos/initial/reward_dist Std             0.00734898
exploration/env_infos/initial/reward_dist Max             0.0205369
exploration/env_infos/initial/reward_dist Min             2.24648e-05
exploration/env_infos/reward_dist Mean                    0.139526
exploration/env_infos/reward_dist Std                     0.211602
exploration/env_infos/reward_dist Max                     0.974223
exploration/env_infos/reward_dist Min                     3.18927e-52
evaluation/num steps total                           122000
evaluation/num paths total                             6100
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0534911
evaluation/Rewards Std                                    0.0929696
evaluation/Rewards Max                                    0.16567
evaluation/Rewards Min                                   -0.594351
evaluation/Returns Mean                                  -1.06982
evaluation/Returns Std                                    1.4619
evaluation/Returns Max                                    1.4724
evaluation/Returns Min                                   -5.19835
evaluation/Actions Mean                                   0.00913392
evaluation/Actions Std                                    0.0817354
evaluation/Actions Max                                    0.717759
evaluation/Actions Min                                   -0.949617
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.06982
evaluation/env_infos/final/reward_energy Mean            -0.07347
evaluation/env_infos/final/reward_energy Std              0.0853972
evaluation/env_infos/final/reward_energy Max             -0.00413628
evaluation/env_infos/final/reward_energy Min             -0.383601
evaluation/env_infos/initial/reward_energy Mean          -0.200982
evaluation/env_infos/initial/reward_energy Std            0.202667
evaluation/env_infos/initial/reward_energy Max           -0.0211911
evaluation/env_infos/initial/reward_energy Min           -0.95187
evaluation/env_infos/reward_energy Mean                  -0.068185
evaluation/env_infos/reward_energy Std                    0.0942286
evaluation/env_infos/reward_energy Max                   -0.000933585
evaluation/env_infos/reward_energy Min                   -0.967505
evaluation/env_infos/final/end_effector_loc Mean          0.10773
evaluation/env_infos/final/end_effector_loc Std           0.314893
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00219309
evaluation/env_infos/initial/end_effector_loc Std         0.00985012
evaluation/env_infos/initial/end_effector_loc Max         0.0343829
evaluation/env_infos/initial/end_effector_loc Min        -0.0474809
evaluation/env_infos/end_effector_loc Mean                0.057789
evaluation/env_infos/end_effector_loc Std                 0.191544
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.224197
evaluation/env_infos/final/reward_dist Std                0.316037
evaluation/env_infos/final/reward_dist Max                0.975537
evaluation/env_infos/final/reward_dist Min                1.09897e-185
evaluation/env_infos/initial/reward_dist Mean             0.00515796
evaluation/env_infos/initial/reward_dist Std              0.0114284
evaluation/env_infos/initial/reward_dist Max              0.0726735
evaluation/env_infos/initial/reward_dist Min              2.34834e-06
evaluation/env_infos/reward_dist Mean                     0.182264
evaluation/env_infos/reward_dist Std                      0.27707
evaluation/env_infos/reward_dist Max                      0.991168
evaluation/env_infos/reward_dist Min                      1.09897e-185
time/data storing (s)                                    42.5578
time/evaluation sampling (s)                              0.872235
time/exploration sampling (s)                             0.0989724
time/logging (s)                                          0.0184219
time/saving (s)                                           0.866829
time/training (s)                                        42.5321
time/epoch (s)                                           86.9463
time/total (s)                                         8031.26
Epoch                                                   121
---------------------------------------------------  -----------------
2021-05-29 02:11:15.702273 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 122 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00107556
trainer/QF2 Loss                                          0.000845425
trainer/Policy Loss                                       2.82986
trainer/Q1 Predictions Mean                              -0.806785
trainer/Q1 Predictions Std                                0.788426
trainer/Q1 Predictions Max                                0.779204
trainer/Q1 Predictions Min                               -2.78097
trainer/Q2 Predictions Mean                              -0.814708
trainer/Q2 Predictions Std                                0.784985
trainer/Q2 Predictions Max                                0.776864
trainer/Q2 Predictions Min                               -2.77658
trainer/Q Targets Mean                                   -0.811534
trainer/Q Targets Std                                     0.788608
trainer/Q Targets Max                                     0.695128
trainer/Q Targets Min                                    -2.76575
trainer/Log Pis Mean                                      2.02111
trainer/Log Pis Std                                       1.42188
trainer/Log Pis Max                                       4.84959
trainer/Log Pis Min                                      -4.57915
trainer/Policy mu Mean                                    0.0453749
trainer/Policy mu Std                                     0.273765
trainer/Policy mu Max                                     1.80226
trainer/Policy mu Min                                    -1.18447
trainer/Policy log std Mean                              -2.38157
trainer/Policy log std Std                                0.5942
trainer/Policy log std Max                               -0.355457
trainer/Policy log std Min                               -3.48023
trainer/Alpha                                             0.0176091
trainer/Alpha Loss                                        0.0852765
exploration/num steps total                           13300
exploration/num paths total                             665
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.12774
exploration/Rewards Std                                   0.0977883
exploration/Rewards Max                                   0.1302
exploration/Rewards Min                                  -0.387616
exploration/Returns Mean                                 -2.5548
exploration/Returns Std                                   1.69798
exploration/Returns Max                                   0.415118
exploration/Returns Min                                  -4.63409
exploration/Actions Mean                                 -0.00676105
exploration/Actions Std                                   0.179555
exploration/Actions Max                                   0.457776
exploration/Actions Min                                  -0.734381
exploration/Num Paths                                     5
exploration/Average Returns                              -2.5548
exploration/env_infos/final/reward_energy Mean           -0.185994
exploration/env_infos/final/reward_energy Std             0.177584
exploration/env_infos/final/reward_energy Max            -0.0322794
exploration/env_infos/final/reward_energy Min            -0.52126
exploration/env_infos/initial/reward_energy Mean         -0.288605
exploration/env_infos/initial/reward_energy Std           0.193575
exploration/env_infos/initial/reward_energy Max          -0.0471896
exploration/env_infos/initial/reward_energy Min          -0.548701
exploration/env_infos/reward_energy Mean                 -0.191254
exploration/env_infos/reward_energy Std                   0.167313
exploration/env_infos/reward_energy Max                  -0.00503087
exploration/env_infos/reward_energy Min                  -0.737848
exploration/env_infos/final/end_effector_loc Mean         0.0155732
exploration/env_infos/final/end_effector_loc Std          0.162636
exploration/env_infos/final/end_effector_loc Max          0.267904
exploration/env_infos/final/end_effector_loc Min         -0.254435
exploration/env_infos/initial/end_effector_loc Mean       0.00242149
exploration/env_infos/initial/end_effector_loc Std        0.0120454
exploration/env_infos/initial/end_effector_loc Max        0.0228888
exploration/env_infos/initial/end_effector_loc Min       -0.0231061
exploration/env_infos/end_effector_loc Mean               0.0356835
exploration/env_infos/end_effector_loc Std                0.120567
exploration/env_infos/end_effector_loc Max                0.357014
exploration/env_infos/end_effector_loc Min               -0.254435
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.151267
exploration/env_infos/final/reward_dist Std               0.145805
exploration/env_infos/final/reward_dist Max               0.382483
exploration/env_infos/final/reward_dist Min               3.11798e-05
exploration/env_infos/initial/reward_dist Mean            0.00870846
exploration/env_infos/initial/reward_dist Std             0.0100489
exploration/env_infos/initial/reward_dist Max             0.0277037
exploration/env_infos/initial/reward_dist Min             7.5908e-05
exploration/env_infos/reward_dist Mean                    0.14289
exploration/env_infos/reward_dist Std                     0.242689
exploration/env_infos/reward_dist Max                     0.952582
exploration/env_infos/reward_dist Min                     2.08796e-05
evaluation/num steps total                           123000
evaluation/num paths total                             6150
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0803277
evaluation/Rewards Std                                    0.118825
evaluation/Rewards Max                                    0.117516
evaluation/Rewards Min                                   -0.96213
evaluation/Returns Mean                                  -1.60655
evaluation/Returns Std                                    1.70473
evaluation/Returns Max                                    0.902626
evaluation/Returns Min                                   -7.36979
evaluation/Actions Mean                                   0.0029882
evaluation/Actions Std                                    0.138321
evaluation/Actions Max                                    0.994378
evaluation/Actions Min                                   -0.990952
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.60655
evaluation/env_infos/final/reward_energy Mean            -0.0459364
evaluation/env_infos/final/reward_energy Std              0.0344588
evaluation/env_infos/final/reward_energy Max             -0.0073878
evaluation/env_infos/final/reward_energy Min             -0.172126
evaluation/env_infos/initial/reward_energy Mean          -0.227997
evaluation/env_infos/initial/reward_energy Std            0.267386
evaluation/env_infos/initial/reward_energy Max           -0.0227036
evaluation/env_infos/initial/reward_energy Min           -1.02495
evaluation/env_infos/reward_energy Mean                  -0.0905478
evaluation/env_infos/reward_energy Std                    0.173448
evaluation/env_infos/reward_energy Max                   -0.00260788
evaluation/env_infos/reward_energy Min                   -1.3127
evaluation/env_infos/final/end_effector_loc Mean          0.0705423
evaluation/env_infos/final/end_effector_loc Std           0.376582
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.791778
evaluation/env_infos/initial/end_effector_loc Mean        0.00283964
evaluation/env_infos/initial/end_effector_loc Std         0.0120948
evaluation/env_infos/initial/end_effector_loc Max         0.0469641
evaluation/env_infos/initial/end_effector_loc Min        -0.0392231
evaluation/env_infos/end_effector_loc Mean                0.05373
evaluation/env_infos/end_effector_loc Std                 0.246472
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.791778
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0896567
evaluation/env_infos/final/reward_dist Std                0.159471
evaluation/env_infos/final/reward_dist Max                0.812553
evaluation/env_infos/final/reward_dist Min                1.90818e-131
evaluation/env_infos/initial/reward_dist Mean             0.00649171
evaluation/env_infos/initial/reward_dist Std              0.0115619
evaluation/env_infos/initial/reward_dist Max              0.0474796
evaluation/env_infos/initial/reward_dist Min              1.21895e-06
evaluation/env_infos/reward_dist Mean                     0.138222
evaluation/env_infos/reward_dist Std                      0.22692
evaluation/env_infos/reward_dist Max                      0.993332
evaluation/env_infos/reward_dist Min                      1.90818e-131
time/data storing (s)                                    42.1409
time/evaluation sampling (s)                              0.822304
time/exploration sampling (s)                             0.107257
time/logging (s)                                          0.0170857
time/saving (s)                                           0.919027
time/training (s)                                        45.9116
time/epoch (s)                                           89.9182
time/total (s)                                         8122.67
Epoch                                                   122
---------------------------------------------------  -----------------
2021-05-29 02:12:40.596086 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 123 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00185666
trainer/QF2 Loss                                          0.00114199
trainer/Policy Loss                                       2.59438
trainer/Q1 Predictions Mean                              -0.703479
trainer/Q1 Predictions Std                                0.738059
trainer/Q1 Predictions Max                                0.747517
trainer/Q1 Predictions Min                               -3.00006
trainer/Q2 Predictions Mean                              -0.716948
trainer/Q2 Predictions Std                                0.740787
trainer/Q2 Predictions Max                                0.718322
trainer/Q2 Predictions Min                               -2.98115
trainer/Q Targets Mean                                   -0.713124
trainer/Q Targets Std                                     0.737785
trainer/Q Targets Max                                     0.714938
trainer/Q Targets Min                                    -2.96084
trainer/Log Pis Mean                                      1.89044
trainer/Log Pis Std                                       1.47307
trainer/Log Pis Max                                       4.79842
trainer/Log Pis Min                                      -4.99866
trainer/Policy mu Mean                                    0.0276618
trainer/Policy mu Std                                     0.380127
trainer/Policy mu Max                                     2.24513
trainer/Policy mu Min                                    -2.53097
trainer/Policy log std Mean                              -2.25277
trainer/Policy log std Std                                0.639647
trainer/Policy log std Max                                0.173777
trainer/Policy log std Min                               -3.49797
trainer/Alpha                                             0.0163295
trainer/Alpha Loss                                       -0.450805
exploration/num steps total                           13400
exploration/num paths total                             670
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0542009
exploration/Rewards Std                                   0.0755684
exploration/Rewards Max                                   0.116743
exploration/Rewards Min                                  -0.225918
exploration/Returns Mean                                 -1.08402
exploration/Returns Std                                   0.987096
exploration/Returns Max                                   0.345469
exploration/Returns Min                                  -2.12353
exploration/Actions Mean                                  0.0131645
exploration/Actions Std                                   0.147637
exploration/Actions Max                                   0.589399
exploration/Actions Min                                  -0.791975
exploration/Num Paths                                     5
exploration/Average Returns                              -1.08402
exploration/env_infos/final/reward_energy Mean           -0.0752613
exploration/env_infos/final/reward_energy Std             0.0514153
exploration/env_infos/final/reward_energy Max            -0.0212779
exploration/env_infos/final/reward_energy Min            -0.151566
exploration/env_infos/initial/reward_energy Mean         -0.201698
exploration/env_infos/initial/reward_energy Std           0.0915662
exploration/env_infos/initial/reward_energy Max          -0.0553158
exploration/env_infos/initial/reward_energy Min          -0.327624
exploration/env_infos/reward_energy Mean                 -0.154705
exploration/env_infos/reward_energy Std                   0.141445
exploration/env_infos/reward_energy Max                  -0.00470743
exploration/env_infos/reward_energy Min                  -0.81268
exploration/env_infos/final/end_effector_loc Mean        -0.00539903
exploration/env_infos/final/end_effector_loc Std          0.303062
exploration/env_infos/final/end_effector_loc Max          0.512419
exploration/env_infos/final/end_effector_loc Min         -0.434695
exploration/env_infos/initial/end_effector_loc Mean       0.000529825
exploration/env_infos/initial/end_effector_loc Std        0.00781359
exploration/env_infos/initial/end_effector_loc Max        0.0130327
exploration/env_infos/initial/end_effector_loc Min       -0.0150815
exploration/env_infos/end_effector_loc Mean              -0.0331067
exploration/env_infos/end_effector_loc Std                0.175683
exploration/env_infos/end_effector_loc Max                0.512419
exploration/env_infos/end_effector_loc Min               -0.434695
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.146084
exploration/env_infos/final/reward_dist Std               0.272033
exploration/env_infos/final/reward_dist Max               0.689286
exploration/env_infos/final/reward_dist Min               1.59856e-12
exploration/env_infos/initial/reward_dist Mean            0.000290427
exploration/env_infos/initial/reward_dist Std             0.000236941
exploration/env_infos/initial/reward_dist Max             0.000658593
exploration/env_infos/initial/reward_dist Min             5.25549e-06
exploration/env_infos/reward_dist Mean                    0.149641
exploration/env_infos/reward_dist Std                     0.229333
exploration/env_infos/reward_dist Max                     0.986143
exploration/env_infos/reward_dist Min                     1.59856e-12
evaluation/num steps total                           124000
evaluation/num paths total                             6200
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0651632
evaluation/Rewards Std                                    0.0857369
evaluation/Rewards Max                                    0.112233
evaluation/Rewards Min                                   -0.585583
evaluation/Returns Mean                                  -1.30326
evaluation/Returns Std                                    1.26185
evaluation/Returns Max                                    0.733863
evaluation/Returns Min                                   -5.18025
evaluation/Actions Mean                                   0.00640468
evaluation/Actions Std                                    0.125688
evaluation/Actions Max                                    0.971183
evaluation/Actions Min                                   -0.964444
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.30326
evaluation/env_infos/final/reward_energy Mean            -0.0563991
evaluation/env_infos/final/reward_energy Std              0.0415384
evaluation/env_infos/final/reward_energy Max             -0.00250878
evaluation/env_infos/final/reward_energy Min             -0.157991
evaluation/env_infos/initial/reward_energy Mean          -0.281348
evaluation/env_infos/initial/reward_energy Std            0.320638
evaluation/env_infos/initial/reward_energy Max           -0.0127853
evaluation/env_infos/initial/reward_energy Min           -1.06108
evaluation/env_infos/reward_energy Mean                  -0.0896927
evaluation/env_infos/reward_energy Std                    0.153728
evaluation/env_infos/reward_energy Max                   -0.000781647
evaluation/env_infos/reward_energy Min                   -1.06108
evaluation/env_infos/final/end_effector_loc Mean          0.0552548
evaluation/env_infos/final/end_effector_loc Std           0.348009
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00244102
evaluation/env_infos/initial/end_effector_loc Std         0.0148828
evaluation/env_infos/initial/end_effector_loc Max         0.0470687
evaluation/env_infos/initial/end_effector_loc Min        -0.0437866
evaluation/env_infos/end_effector_loc Mean                0.0337483
evaluation/env_infos/end_effector_loc Std                 0.228198
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0581942
evaluation/env_infos/final/reward_dist Std                0.144149
evaluation/env_infos/final/reward_dist Max                0.706121
evaluation/env_infos/final/reward_dist Min                4.89352e-166
evaluation/env_infos/initial/reward_dist Mean             0.00649776
evaluation/env_infos/initial/reward_dist Std              0.0174397
evaluation/env_infos/initial/reward_dist Max              0.121027
evaluation/env_infos/initial/reward_dist Min              1.52331e-06
evaluation/env_infos/reward_dist Mean                     0.122666
evaluation/env_infos/reward_dist Std                      0.222724
evaluation/env_infos/reward_dist Max                      0.986721
evaluation/env_infos/reward_dist Min                      4.89352e-166
time/data storing (s)                                    41.676
time/evaluation sampling (s)                              0.78307
time/exploration sampling (s)                             0.102892
time/logging (s)                                          0.0193656
time/saving (s)                                           0.826777
time/training (s)                                        39.9615
time/epoch (s)                                           83.3696
time/total (s)                                         8207.56
Epoch                                                   123
---------------------------------------------------  -----------------
2021-05-29 02:14:05.921642 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 124 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00136268
trainer/QF2 Loss                                          0.00245013
trainer/Policy Loss                                       2.70112
trainer/Q1 Predictions Mean                              -0.684306
trainer/Q1 Predictions Std                                0.714374
trainer/Q1 Predictions Max                                0.749769
trainer/Q1 Predictions Min                               -2.7541
trainer/Q2 Predictions Mean                              -0.669839
trainer/Q2 Predictions Std                                0.722393
trainer/Q2 Predictions Max                                0.752425
trainer/Q2 Predictions Min                               -2.7647
trainer/Q Targets Mean                                   -0.684306
trainer/Q Targets Std                                     0.719027
trainer/Q Targets Max                                     0.771039
trainer/Q Targets Min                                    -2.77191
trainer/Log Pis Mean                                      2.01535
trainer/Log Pis Std                                       1.27636
trainer/Log Pis Max                                       4.50344
trainer/Log Pis Min                                      -1.97618
trainer/Policy mu Mean                                    0.0552333
trainer/Policy mu Std                                     0.343568
trainer/Policy mu Max                                     2.14904
trainer/Policy mu Min                                    -1.62974
trainer/Policy log std Mean                              -2.29681
trainer/Policy log std Std                                0.624117
trainer/Policy log std Max                               -0.219311
trainer/Policy log std Min                               -3.32512
trainer/Alpha                                             0.0170615
trainer/Alpha Loss                                        0.0625093
exploration/num steps total                           13500
exploration/num paths total                             675
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.141952
exploration/Rewards Std                                   0.09813
exploration/Rewards Max                                   0.0113415
exploration/Rewards Min                                  -0.423696
exploration/Returns Mean                                 -2.83904
exploration/Returns Std                                   1.2119
exploration/Returns Max                                  -0.817856
exploration/Returns Min                                  -4.45485
exploration/Actions Mean                                  0.00800744
exploration/Actions Std                                   0.248906
exploration/Actions Max                                   0.999999
exploration/Actions Min                                  -0.996756
exploration/Num Paths                                     5
exploration/Average Returns                              -2.83904
exploration/env_infos/final/reward_energy Mean           -0.21375
exploration/env_infos/final/reward_energy Std             0.16346
exploration/env_infos/final/reward_energy Max            -0.0278786
exploration/env_infos/final/reward_energy Min            -0.517627
exploration/env_infos/initial/reward_energy Mean         -0.506734
exploration/env_infos/initial/reward_energy Std           0.362317
exploration/env_infos/initial/reward_energy Max          -0.0962555
exploration/env_infos/initial/reward_energy Min          -1.02073
exploration/env_infos/reward_energy Mean                 -0.240676
exploration/env_infos/reward_energy Std                   0.257122
exploration/env_infos/reward_energy Max                  -0.00680399
exploration/env_infos/reward_energy Min                  -1.25412
exploration/env_infos/final/end_effector_loc Mean         0.235354
exploration/env_infos/final/end_effector_loc Std          0.605543
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00885383
exploration/env_infos/initial/end_effector_loc Std        0.0201662
exploration/env_infos/initial/end_effector_loc Max        0.0499825
exploration/env_infos/initial/end_effector_loc Min       -0.0254594
exploration/env_infos/end_effector_loc Mean               0.156395
exploration/env_infos/end_effector_loc Std                0.420212
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0372449
exploration/env_infos/final/reward_dist Std               0.0744893
exploration/env_infos/final/reward_dist Max               0.186223
exploration/env_infos/final/reward_dist Min               3.09711e-93
exploration/env_infos/initial/reward_dist Mean            0.000459717
exploration/env_infos/initial/reward_dist Std             0.000648191
exploration/env_infos/initial/reward_dist Max             0.00172072
exploration/env_infos/initial/reward_dist Min             5.21368e-06
exploration/env_infos/reward_dist Mean                    0.050993
exploration/env_infos/reward_dist Std                     0.156211
exploration/env_infos/reward_dist Max                     0.890367
exploration/env_infos/reward_dist Min                     3.09711e-93
evaluation/num steps total                           125000
evaluation/num paths total                             6250
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0554078
evaluation/Rewards Std                                    0.0865532
evaluation/Rewards Max                                    0.151454
evaluation/Rewards Min                                   -0.53157
evaluation/Returns Mean                                  -1.10816
evaluation/Returns Std                                    1.34221
evaluation/Returns Max                                    1.32602
evaluation/Returns Min                                   -5.12539
evaluation/Actions Mean                                   0.00449064
evaluation/Actions Std                                    0.119244
evaluation/Actions Max                                    0.957758
evaluation/Actions Min                                   -0.903245
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.10816
evaluation/env_infos/final/reward_energy Mean            -0.0559282
evaluation/env_infos/final/reward_energy Std              0.0514915
evaluation/env_infos/final/reward_energy Max             -0.00219196
evaluation/env_infos/final/reward_energy Min             -0.219397
evaluation/env_infos/initial/reward_energy Mean          -0.341172
evaluation/env_infos/initial/reward_energy Std            0.306608
evaluation/env_infos/initial/reward_energy Max           -0.0200305
evaluation/env_infos/initial/reward_energy Min           -1.01141
evaluation/env_infos/reward_energy Mean                  -0.0921609
evaluation/env_infos/reward_energy Std                    0.141369
evaluation/env_infos/reward_energy Max                   -0.00114004
evaluation/env_infos/reward_energy Min                   -1.01141
evaluation/env_infos/final/end_effector_loc Mean          0.0415048
evaluation/env_infos/final/end_effector_loc Std           0.314215
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.703334
evaluation/env_infos/initial/end_effector_loc Mean        0.00310466
evaluation/env_infos/initial/end_effector_loc Std         0.0159176
evaluation/env_infos/initial/end_effector_loc Max         0.0478879
evaluation/env_infos/initial/end_effector_loc Min        -0.0382668
evaluation/env_infos/end_effector_loc Mean                0.0285987
evaluation/env_infos/end_effector_loc Std                 0.203841
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.703334
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.149466
evaluation/env_infos/final/reward_dist Std                0.26172
evaluation/env_infos/final/reward_dist Max                0.946165
evaluation/env_infos/final/reward_dist Min                6.77414e-156
evaluation/env_infos/initial/reward_dist Mean             0.0106268
evaluation/env_infos/initial/reward_dist Std              0.0238483
evaluation/env_infos/initial/reward_dist Max              0.120015
evaluation/env_infos/initial/reward_dist Min              1.44599e-06
evaluation/env_infos/reward_dist Mean                     0.171514
evaluation/env_infos/reward_dist Std                      0.255932
evaluation/env_infos/reward_dist Max                      0.999479
evaluation/env_infos/reward_dist Min                      6.77414e-156
time/data storing (s)                                    41.9399
time/evaluation sampling (s)                              0.748488
time/exploration sampling (s)                             0.0957216
time/logging (s)                                          0.0150641
time/saving (s)                                           0.82774
time/training (s)                                        40.2243
time/epoch (s)                                           83.8512
time/total (s)                                         8292.88
Epoch                                                   124
---------------------------------------------------  -----------------
2021-05-29 02:15:34.695641 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 125 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00130448
trainer/QF2 Loss                                          0.00156596
trainer/Policy Loss                                       2.59896
trainer/Q1 Predictions Mean                              -0.679414
trainer/Q1 Predictions Std                                0.744558
trainer/Q1 Predictions Max                                0.820192
trainer/Q1 Predictions Min                               -2.83994
trainer/Q2 Predictions Mean                              -0.684303
trainer/Q2 Predictions Std                                0.742648
trainer/Q2 Predictions Max                                0.79816
trainer/Q2 Predictions Min                               -2.87521
trainer/Q Targets Mean                                   -0.680628
trainer/Q Targets Std                                     0.746194
trainer/Q Targets Max                                     0.823418
trainer/Q Targets Min                                    -2.83201
trainer/Log Pis Mean                                      1.91031
trainer/Log Pis Std                                       1.31452
trainer/Log Pis Max                                       4.71675
trainer/Log Pis Min                                      -3.00134
trainer/Policy mu Mean                                    0.0105564
trainer/Policy mu Std                                     0.366136
trainer/Policy mu Max                                     2.13104
trainer/Policy mu Min                                    -2.75001
trainer/Policy log std Mean                              -2.28565
trainer/Policy log std Std                                0.634121
trainer/Policy log std Max                               -0.250248
trainer/Policy log std Min                               -3.39639
trainer/Alpha                                             0.0156898
trainer/Alpha Loss                                       -0.37276
exploration/num steps total                           13600
exploration/num paths total                             680
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.125972
exploration/Rewards Std                                   0.0574822
exploration/Rewards Max                                  -0.033436
exploration/Rewards Min                                  -0.254503
exploration/Returns Mean                                 -2.51944
exploration/Returns Std                                   0.558761
exploration/Returns Max                                  -1.68739
exploration/Returns Min                                  -3.38544
exploration/Actions Mean                                 -0.0102188
exploration/Actions Std                                   0.198585
exploration/Actions Max                                   0.994776
exploration/Actions Min                                  -0.795697
exploration/Num Paths                                     5
exploration/Average Returns                              -2.51944
exploration/env_infos/final/reward_energy Mean           -0.0909044
exploration/env_infos/final/reward_energy Std             0.0264286
exploration/env_infos/final/reward_energy Max            -0.0641828
exploration/env_infos/final/reward_energy Min            -0.140043
exploration/env_infos/initial/reward_energy Mean         -0.370849
exploration/env_infos/initial/reward_energy Std           0.382822
exploration/env_infos/initial/reward_energy Max          -0.0583689
exploration/env_infos/initial/reward_energy Min          -1.09934
exploration/env_infos/reward_energy Mean                 -0.179339
exploration/env_infos/reward_energy Std                   0.216607
exploration/env_infos/reward_energy Max                  -0.0136179
exploration/env_infos/reward_energy Min                  -1.09934
exploration/env_infos/final/end_effector_loc Mean        -0.0167765
exploration/env_infos/final/end_effector_loc Std          0.29636
exploration/env_infos/final/end_effector_loc Max          0.563299
exploration/env_infos/final/end_effector_loc Min         -0.505777
exploration/env_infos/initial/end_effector_loc Mean       0.00798081
exploration/env_infos/initial/end_effector_loc Std        0.0170707
exploration/env_infos/initial/end_effector_loc Max        0.0497388
exploration/env_infos/initial/end_effector_loc Min       -0.0068086
exploration/env_infos/end_effector_loc Mean               0.0417759
exploration/env_infos/end_effector_loc Std                0.231117
exploration/env_infos/end_effector_loc Max                0.596958
exploration/env_infos/end_effector_loc Min               -0.505777
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.145397
exploration/env_infos/final/reward_dist Std               0.278302
exploration/env_infos/final/reward_dist Max               0.701656
exploration/env_infos/final/reward_dist Min               1.03531e-49
exploration/env_infos/initial/reward_dist Mean            0.0100205
exploration/env_infos/initial/reward_dist Std             0.00917451
exploration/env_infos/initial/reward_dist Max             0.0243811
exploration/env_infos/initial/reward_dist Min             6.18833e-06
exploration/env_infos/reward_dist Mean                    0.0504353
exploration/env_infos/reward_dist Std                     0.1086
exploration/env_infos/reward_dist Max                     0.701656
exploration/env_infos/reward_dist Min                     1.03531e-49
evaluation/num steps total                           126000
evaluation/num paths total                             6300
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0601695
evaluation/Rewards Std                                    0.0735923
evaluation/Rewards Max                                    0.118644
evaluation/Rewards Min                                   -0.523098
evaluation/Returns Mean                                  -1.20339
evaluation/Returns Std                                    1.0204
evaluation/Returns Max                                    1.52331
evaluation/Returns Min                                   -3.29499
evaluation/Actions Mean                                  -0.00597024
evaluation/Actions Std                                    0.108475
evaluation/Actions Max                                    0.856694
evaluation/Actions Min                                   -0.98239
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.20339
evaluation/env_infos/final/reward_energy Mean            -0.0374984
evaluation/env_infos/final/reward_energy Std              0.0376359
evaluation/env_infos/final/reward_energy Max             -0.00275171
evaluation/env_infos/final/reward_energy Min             -0.176354
evaluation/env_infos/initial/reward_energy Mean          -0.299195
evaluation/env_infos/initial/reward_energy Std            0.352839
evaluation/env_infos/initial/reward_energy Max           -0.00702225
evaluation/env_infos/initial/reward_energy Min           -1.17416
evaluation/env_infos/reward_energy Mean                  -0.0768739
evaluation/env_infos/reward_energy Std                    0.133023
evaluation/env_infos/reward_energy Max                   -0.0020811
evaluation/env_infos/reward_energy Min                   -1.17416
evaluation/env_infos/final/end_effector_loc Mean         -0.0718887
evaluation/env_infos/final/end_effector_loc Std           0.377241
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000491542
evaluation/env_infos/initial/end_effector_loc Std         0.0163485
evaluation/env_infos/initial/end_effector_loc Max         0.0428347
evaluation/env_infos/initial/end_effector_loc Min        -0.0491195
evaluation/env_infos/end_effector_loc Mean               -0.0276723
evaluation/env_infos/end_effector_loc Std                 0.240264
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0957677
evaluation/env_infos/final/reward_dist Std                0.196081
evaluation/env_infos/final/reward_dist Max                0.886463
evaluation/env_infos/final/reward_dist Min                5.66388e-169
evaluation/env_infos/initial/reward_dist Mean             0.00400061
evaluation/env_infos/initial/reward_dist Std              0.00860776
evaluation/env_infos/initial/reward_dist Max              0.0437044
evaluation/env_infos/initial/reward_dist Min              8.90311e-07
evaluation/env_infos/reward_dist Mean                     0.126518
evaluation/env_infos/reward_dist Std                      0.218762
evaluation/env_infos/reward_dist Max                      0.989346
evaluation/env_infos/reward_dist Min                      5.66388e-169
time/data storing (s)                                    42.7036
time/evaluation sampling (s)                              0.951071
time/exploration sampling (s)                             0.120848
time/logging (s)                                          0.0163513
time/saving (s)                                           0.855257
time/training (s)                                        42.6084
time/epoch (s)                                           87.2555
time/total (s)                                         8381.65
Epoch                                                   125
---------------------------------------------------  -----------------
2021-05-29 02:17:02.411681 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 126 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00108057
trainer/QF2 Loss                                          0.00132157
trainer/Policy Loss                                       2.76584
trainer/Q1 Predictions Mean                              -0.638809
trainer/Q1 Predictions Std                                0.760731
trainer/Q1 Predictions Max                                0.91757
trainer/Q1 Predictions Min                               -2.945
trainer/Q2 Predictions Mean                              -0.627513
trainer/Q2 Predictions Std                                0.749264
trainer/Q2 Predictions Max                                0.920151
trainer/Q2 Predictions Min                               -2.89525
trainer/Q Targets Mean                                   -0.64043
trainer/Q Targets Std                                     0.762078
trainer/Q Targets Max                                     0.957609
trainer/Q Targets Min                                    -3.03621
trainer/Log Pis Mean                                      2.13658
trainer/Log Pis Std                                       1.35321
trainer/Log Pis Max                                       4.86786
trainer/Log Pis Min                                      -4.92079
trainer/Policy mu Mean                                    0.0501772
trainer/Policy mu Std                                     0.369321
trainer/Policy mu Max                                     2.29344
trainer/Policy mu Min                                    -2.24999
trainer/Policy log std Mean                              -2.30747
trainer/Policy log std Std                                0.6029
trainer/Policy log std Max                               -0.329035
trainer/Policy log std Min                               -3.45001
trainer/Alpha                                             0.016348
trainer/Alpha Loss                                        0.561831
exploration/num steps total                           13700
exploration/num paths total                             685
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.141461
exploration/Rewards Std                                   0.111325
exploration/Rewards Max                                   0.0098006
exploration/Rewards Min                                  -0.467792
exploration/Returns Mean                                 -2.82923
exploration/Returns Std                                   1.60739
exploration/Returns Max                                  -1.09357
exploration/Returns Min                                  -5.26538
exploration/Actions Mean                                 -0.000500854
exploration/Actions Std                                   0.200653
exploration/Actions Max                                   0.944987
exploration/Actions Min                                  -0.886857
exploration/Num Paths                                     5
exploration/Average Returns                              -2.82923
exploration/env_infos/final/reward_energy Mean           -0.112854
exploration/env_infos/final/reward_energy Std             0.0665374
exploration/env_infos/final/reward_energy Max            -0.0330577
exploration/env_infos/final/reward_energy Min            -0.215087
exploration/env_infos/initial/reward_energy Mean         -0.365655
exploration/env_infos/initial/reward_energy Std           0.318841
exploration/env_infos/initial/reward_energy Max          -0.0465804
exploration/env_infos/initial/reward_energy Min          -0.950807
exploration/env_infos/reward_energy Mean                 -0.187676
exploration/env_infos/reward_energy Std                   0.212841
exploration/env_infos/reward_energy Max                  -0.0166321
exploration/env_infos/reward_energy Min                  -0.950807
exploration/env_infos/final/end_effector_loc Mean         0.0816156
exploration/env_infos/final/end_effector_loc Std          0.359573
exploration/env_infos/final/end_effector_loc Max          0.622337
exploration/env_infos/final/end_effector_loc Min         -0.614734
exploration/env_infos/initial/end_effector_loc Mean       0.00232166
exploration/env_infos/initial/end_effector_loc Std        0.0169945
exploration/env_infos/initial/end_effector_loc Max        0.0452779
exploration/env_infos/initial/end_effector_loc Min       -0.0188982
exploration/env_infos/end_effector_loc Mean               0.0564756
exploration/env_infos/end_effector_loc Std                0.19316
exploration/env_infos/end_effector_loc Max                0.622337
exploration/env_infos/end_effector_loc Min               -0.614734
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0269792
exploration/env_infos/final/reward_dist Std               0.0431927
exploration/env_infos/final/reward_dist Max               0.112073
exploration/env_infos/final/reward_dist Min               2.67495e-39
exploration/env_infos/initial/reward_dist Mean            0.000567939
exploration/env_infos/initial/reward_dist Std             0.000998955
exploration/env_infos/initial/reward_dist Max             0.00256453
exploration/env_infos/initial/reward_dist Min             2.55639e-05
exploration/env_infos/reward_dist Mean                    0.0932005
exploration/env_infos/reward_dist Std                     0.180646
exploration/env_infos/reward_dist Max                     0.807968
exploration/env_infos/reward_dist Min                     2.67495e-39
evaluation/num steps total                           127000
evaluation/num paths total                             6350
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0611633
evaluation/Rewards Std                                    0.106007
evaluation/Rewards Max                                    0.191908
evaluation/Rewards Min                                   -0.689566
evaluation/Returns Mean                                  -1.22327
evaluation/Returns Std                                    1.78743
evaluation/Returns Max                                    3.09225
evaluation/Returns Min                                   -7.71383
evaluation/Actions Mean                                  -0.00333556
evaluation/Actions Std                                    0.117746
evaluation/Actions Max                                    0.892757
evaluation/Actions Min                                   -0.948305
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.22327
evaluation/env_infos/final/reward_energy Mean            -0.0596726
evaluation/env_infos/final/reward_energy Std              0.0523497
evaluation/env_infos/final/reward_energy Max             -0.00588579
evaluation/env_infos/final/reward_energy Min             -0.257013
evaluation/env_infos/initial/reward_energy Mean          -0.392028
evaluation/env_infos/initial/reward_energy Std            0.364813
evaluation/env_infos/initial/reward_energy Max           -0.00530244
evaluation/env_infos/initial/reward_energy Min           -1.26209
evaluation/env_infos/reward_energy Mean                  -0.093446
evaluation/env_infos/reward_energy Std                    0.137907
evaluation/env_infos/reward_energy Max                   -0.00258949
evaluation/env_infos/reward_energy Min                   -1.26209
evaluation/env_infos/final/end_effector_loc Mean         -0.0578396
evaluation/env_infos/final/end_effector_loc Std           0.35247
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.976115
evaluation/env_infos/initial/end_effector_loc Mean        0.00173337
evaluation/env_infos/initial/end_effector_loc Std         0.0188537
evaluation/env_infos/initial/end_effector_loc Max         0.0446378
evaluation/env_infos/initial/end_effector_loc Min        -0.0474152
evaluation/env_infos/end_effector_loc Mean               -0.018753
evaluation/env_infos/end_effector_loc Std                 0.229203
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.976115
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.104468
evaluation/env_infos/final/reward_dist Std                0.215334
evaluation/env_infos/final/reward_dist Max                0.818141
evaluation/env_infos/final/reward_dist Min                5.66204e-137
evaluation/env_infos/initial/reward_dist Mean             0.0152902
evaluation/env_infos/initial/reward_dist Std              0.0258555
evaluation/env_infos/initial/reward_dist Max              0.100766
evaluation/env_infos/initial/reward_dist Min              1.67431e-06
evaluation/env_infos/reward_dist Mean                     0.14848
evaluation/env_infos/reward_dist Std                      0.258564
evaluation/env_infos/reward_dist Max                      0.998533
evaluation/env_infos/reward_dist Min                      5.66204e-137
time/data storing (s)                                    42.3619
time/evaluation sampling (s)                              0.573796
time/exploration sampling (s)                             0.0958351
time/logging (s)                                          0.0178668
time/saving (s)                                           0.826061
time/training (s)                                        42.3371
time/epoch (s)                                           86.2126
time/total (s)                                         8469.36
Epoch                                                   126
---------------------------------------------------  -----------------
2021-05-29 02:18:35.273111 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 127 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00187853
trainer/QF2 Loss                                          0.00159023
trainer/Policy Loss                                       2.80892
trainer/Q1 Predictions Mean                              -0.74271
trainer/Q1 Predictions Std                                0.742124
trainer/Q1 Predictions Max                                0.865485
trainer/Q1 Predictions Min                               -2.85518
trainer/Q2 Predictions Mean                              -0.739766
trainer/Q2 Predictions Std                                0.736081
trainer/Q2 Predictions Max                                0.838076
trainer/Q2 Predictions Min                               -2.83367
trainer/Q Targets Mean                                   -0.752243
trainer/Q Targets Std                                     0.744234
trainer/Q Targets Max                                     0.894054
trainer/Q Targets Min                                    -2.84953
trainer/Log Pis Mean                                      2.07797
trainer/Log Pis Std                                       1.4715
trainer/Log Pis Max                                       5.17247
trainer/Log Pis Min                                      -3.57261
trainer/Policy mu Mean                                    0.0759906
trainer/Policy mu Std                                     0.475335
trainer/Policy mu Max                                     2.91637
trainer/Policy mu Min                                    -2.16368
trainer/Policy log std Mean                              -2.31164
trainer/Policy log std Std                                0.674414
trainer/Policy log std Max                                0.111436
trainer/Policy log std Min                               -3.55476
trainer/Alpha                                             0.0155545
trainer/Alpha Loss                                        0.324819
exploration/num steps total                           13800
exploration/num paths total                             690
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.1299
exploration/Rewards Std                                   0.100506
exploration/Rewards Max                                   0.0728538
exploration/Rewards Min                                  -0.365058
exploration/Returns Mean                                 -2.59799
exploration/Returns Std                                   1.55314
exploration/Returns Max                                  -0.603269
exploration/Returns Min                                  -5.26383
exploration/Actions Mean                                 -0.00590906
exploration/Actions Std                                   0.119089
exploration/Actions Max                                   0.421252
exploration/Actions Min                                  -0.391928
exploration/Num Paths                                     5
exploration/Average Returns                              -2.59799
exploration/env_infos/final/reward_energy Mean           -0.0479617
exploration/env_infos/final/reward_energy Std             0.0281427
exploration/env_infos/final/reward_energy Max            -0.0197865
exploration/env_infos/final/reward_energy Min            -0.0999791
exploration/env_infos/initial/reward_energy Mean         -0.296744
exploration/env_infos/initial/reward_energy Std           0.127705
exploration/env_infos/initial/reward_energy Max          -0.0583813
exploration/env_infos/initial/reward_energy Min          -0.398127
exploration/env_infos/reward_energy Mean                 -0.138512
exploration/env_infos/reward_energy Std                   0.0961699
exploration/env_infos/reward_energy Max                  -0.00835537
exploration/env_infos/reward_energy Min                  -0.42333
exploration/env_infos/final/end_effector_loc Mean        -0.115159
exploration/env_infos/final/end_effector_loc Std          0.358558
exploration/env_infos/final/end_effector_loc Max          0.414074
exploration/env_infos/final/end_effector_loc Min         -0.934386
exploration/env_infos/initial/end_effector_loc Mean      -0.00100872
exploration/env_infos/initial/end_effector_loc Std        0.0113772
exploration/env_infos/initial/end_effector_loc Max        0.0198981
exploration/env_infos/initial/end_effector_loc Min       -0.0195964
exploration/env_infos/end_effector_loc Mean              -0.0607709
exploration/env_infos/end_effector_loc Std                0.244025
exploration/env_infos/end_effector_loc Max                0.416854
exploration/env_infos/end_effector_loc Min               -0.934386
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.201941
exploration/env_infos/final/reward_dist Std               0.175745
exploration/env_infos/final/reward_dist Max               0.407761
exploration/env_infos/final/reward_dist Min               3.63033e-32
exploration/env_infos/initial/reward_dist Mean            0.00155031
exploration/env_infos/initial/reward_dist Std             0.00232969
exploration/env_infos/initial/reward_dist Max             0.00610573
exploration/env_infos/initial/reward_dist Min             3.27258e-06
exploration/env_infos/reward_dist Mean                    0.122028
exploration/env_infos/reward_dist Std                     0.179746
exploration/env_infos/reward_dist Max                     0.628297
exploration/env_infos/reward_dist Min                     3.63033e-32
evaluation/num steps total                           128000
evaluation/num paths total                             6400
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0587567
evaluation/Rewards Std                                    0.103588
evaluation/Rewards Max                                    0.155293
evaluation/Rewards Min                                   -0.638033
evaluation/Returns Mean                                  -1.17513
evaluation/Returns Std                                    1.54673
evaluation/Returns Max                                    2.30073
evaluation/Returns Min                                   -4.33426
evaluation/Actions Mean                                  -0.00677794
evaluation/Actions Std                                    0.123264
evaluation/Actions Max                                    0.909659
evaluation/Actions Min                                   -0.824052
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.17513
evaluation/env_infos/final/reward_energy Mean            -0.0484893
evaluation/env_infos/final/reward_energy Std              0.0343231
evaluation/env_infos/final/reward_energy Max             -0.00331061
evaluation/env_infos/final/reward_energy Min             -0.154611
evaluation/env_infos/initial/reward_energy Mean          -0.465268
evaluation/env_infos/initial/reward_energy Std            0.322558
evaluation/env_infos/initial/reward_energy Max           -0.0256176
evaluation/env_infos/initial/reward_energy Min           -1.0065
evaluation/env_infos/reward_energy Mean                  -0.0992435
evaluation/env_infos/reward_energy Std                    0.143633
evaluation/env_infos/reward_energy Max                   -0.00179386
evaluation/env_infos/reward_energy Min                   -1.0065
evaluation/env_infos/final/end_effector_loc Mean         -0.0239237
evaluation/env_infos/final/end_effector_loc Std           0.408013
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00566632
evaluation/env_infos/initial/end_effector_loc Std         0.0191974
evaluation/env_infos/initial/end_effector_loc Max         0.0454829
evaluation/env_infos/initial/end_effector_loc Min        -0.0412026
evaluation/env_infos/end_effector_loc Mean                0.0181904
evaluation/env_infos/end_effector_loc Std                 0.270923
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.159664
evaluation/env_infos/final/reward_dist Std                0.266357
evaluation/env_infos/final/reward_dist Max                0.977819
evaluation/env_infos/final/reward_dist Min                1.1317e-157
evaluation/env_infos/initial/reward_dist Mean             0.012504
evaluation/env_infos/initial/reward_dist Std              0.0221365
evaluation/env_infos/initial/reward_dist Max              0.0819019
evaluation/env_infos/initial/reward_dist Min              1.37883e-06
evaluation/env_infos/reward_dist Mean                     0.180314
evaluation/env_infos/reward_dist Std                      0.269914
evaluation/env_infos/reward_dist Max                      0.997336
evaluation/env_infos/reward_dist Min                      1.1317e-157
time/data storing (s)                                    44.321
time/evaluation sampling (s)                              0.639602
time/exploration sampling (s)                             0.108591
time/logging (s)                                          0.0180122
time/saving (s)                                           0.871244
time/training (s)                                        45.0026
time/epoch (s)                                           90.961
time/total (s)                                         8562.22
Epoch                                                   127
---------------------------------------------------  ----------------
2021-05-29 02:20:07.677864 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 128 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00162144
trainer/QF2 Loss                                          0.00188676
trainer/Policy Loss                                       3.01426
trainer/Q1 Predictions Mean                              -0.777634
trainer/Q1 Predictions Std                                0.813641
trainer/Q1 Predictions Max                                1.18191
trainer/Q1 Predictions Min                               -2.83497
trainer/Q2 Predictions Mean                              -0.767459
trainer/Q2 Predictions Std                                0.811737
trainer/Q2 Predictions Max                                1.20067
trainer/Q2 Predictions Min                               -2.82238
trainer/Q Targets Mean                                   -0.770726
trainer/Q Targets Std                                     0.817678
trainer/Q Targets Max                                     1.22138
trainer/Q Targets Min                                    -2.90864
trainer/Log Pis Mean                                      2.25021
trainer/Log Pis Std                                       1.43638
trainer/Log Pis Max                                       7.18351
trainer/Log Pis Min                                      -5.76233
trainer/Policy mu Mean                                    0.0102466
trainer/Policy mu Std                                     0.44688
trainer/Policy mu Max                                     1.89657
trainer/Policy mu Min                                    -3.00874
trainer/Policy log std Mean                              -2.33851
trainer/Policy log std Std                                0.642259
trainer/Policy log std Max                               -0.31455
trainer/Policy log std Min                               -3.38283
trainer/Alpha                                             0.0175402
trainer/Alpha Loss                                        1.01159
exploration/num steps total                           13900
exploration/num paths total                             695
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.150708
exploration/Rewards Std                                   0.121708
exploration/Rewards Max                                  -0.0311501
exploration/Rewards Min                                  -0.646875
exploration/Returns Mean                                 -3.01416
exploration/Returns Std                                   1.76711
exploration/Returns Max                                  -1.56273
exploration/Returns Min                                  -6.0368
exploration/Actions Mean                                 -0.0205955
exploration/Actions Std                                   0.191797
exploration/Actions Max                                   0.849025
exploration/Actions Min                                  -0.835968
exploration/Num Paths                                     5
exploration/Average Returns                              -3.01416
exploration/env_infos/final/reward_energy Mean           -0.146386
exploration/env_infos/final/reward_energy Std             0.128824
exploration/env_infos/final/reward_energy Max            -0.0292042
exploration/env_infos/final/reward_energy Min            -0.394648
exploration/env_infos/initial/reward_energy Mean         -0.379106
exploration/env_infos/initial/reward_energy Std           0.321882
exploration/env_infos/initial/reward_energy Max          -0.0290859
exploration/env_infos/initial/reward_energy Min          -0.852693
exploration/env_infos/reward_energy Mean                 -0.189808
exploration/env_infos/reward_energy Std                   0.195942
exploration/env_infos/reward_energy Max                  -0.00279723
exploration/env_infos/reward_energy Min                  -0.875094
exploration/env_infos/final/end_effector_loc Mean        -0.0622043
exploration/env_infos/final/end_effector_loc Std          0.554654
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00453294
exploration/env_infos/initial/end_effector_loc Std        0.0169886
exploration/env_infos/initial/end_effector_loc Max        0.0424512
exploration/env_infos/initial/end_effector_loc Min       -0.0284046
exploration/env_infos/end_effector_loc Mean              -0.00190972
exploration/env_infos/end_effector_loc Std                0.371381
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0833859
exploration/env_infos/final/reward_dist Std               0.166772
exploration/env_infos/final/reward_dist Max               0.41693
exploration/env_infos/final/reward_dist Min               1.75614e-78
exploration/env_infos/initial/reward_dist Mean            0.0106309
exploration/env_infos/initial/reward_dist Std             0.0126476
exploration/env_infos/initial/reward_dist Max             0.0345519
exploration/env_infos/initial/reward_dist Min             2.12676e-06
exploration/env_infos/reward_dist Mean                    0.0871334
exploration/env_infos/reward_dist Std                     0.213035
exploration/env_infos/reward_dist Max                     0.973122
exploration/env_infos/reward_dist Min                     1.46409e-79
evaluation/num steps total                           129000
evaluation/num paths total                             6450
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0859579
evaluation/Rewards Std                                    0.128367
evaluation/Rewards Max                                    0.167888
evaluation/Rewards Min                                   -1.12134
evaluation/Returns Mean                                  -1.71916
evaluation/Returns Std                                    1.81775
evaluation/Returns Max                                    2.11905
evaluation/Returns Min                                   -6.64745
evaluation/Actions Mean                                  -0.00383767
evaluation/Actions Std                                    0.134799
evaluation/Actions Max                                    0.918765
evaluation/Actions Min                                   -0.962494
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.71916
evaluation/env_infos/final/reward_energy Mean            -0.0475462
evaluation/env_infos/final/reward_energy Std              0.0394164
evaluation/env_infos/final/reward_energy Max             -0.00179909
evaluation/env_infos/final/reward_energy Min             -0.17085
evaluation/env_infos/initial/reward_energy Mean          -0.378348
evaluation/env_infos/initial/reward_energy Std            0.325965
evaluation/env_infos/initial/reward_energy Max           -0.00787486
evaluation/env_infos/initial/reward_energy Min           -0.970766
evaluation/env_infos/reward_energy Mean                  -0.106211
evaluation/env_infos/reward_energy Std                    0.158398
evaluation/env_infos/reward_energy Max                   -0.000690543
evaluation/env_infos/reward_energy Min                   -1.27865
evaluation/env_infos/final/end_effector_loc Mean         -0.0118218
evaluation/env_infos/final/end_effector_loc Std           0.388652
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00500173
evaluation/env_infos/initial/end_effector_loc Std         0.0169332
evaluation/env_infos/initial/end_effector_loc Max         0.0459383
evaluation/env_infos/initial/end_effector_loc Min        -0.0481247
evaluation/env_infos/end_effector_loc Mean                0.0205039
evaluation/env_infos/end_effector_loc Std                 0.258319
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0763254
evaluation/env_infos/final/reward_dist Std                0.160661
evaluation/env_infos/final/reward_dist Max                0.6818
evaluation/env_infos/final/reward_dist Min                7.13754e-119
evaluation/env_infos/initial/reward_dist Mean             0.00905324
evaluation/env_infos/initial/reward_dist Std              0.0203311
evaluation/env_infos/initial/reward_dist Max              0.0969844
evaluation/env_infos/initial/reward_dist Min              2.33118e-07
evaluation/env_infos/reward_dist Mean                     0.118888
evaluation/env_infos/reward_dist Std                      0.231419
evaluation/env_infos/reward_dist Max                      0.985303
evaluation/env_infos/reward_dist Min                      7.13754e-119
time/data storing (s)                                    44.5445
time/evaluation sampling (s)                              0.81729
time/exploration sampling (s)                             0.116547
time/logging (s)                                          0.0184352
time/saving (s)                                           0.861182
time/training (s)                                        44.5598
time/epoch (s)                                           90.9177
time/total (s)                                         8654.61
Epoch                                                   128
---------------------------------------------------  -----------------
2021-05-29 02:21:42.801778 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 129 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00317956
trainer/QF2 Loss                                          0.00167097
trainer/Policy Loss                                       2.88422
trainer/Q1 Predictions Mean                              -0.779197
trainer/Q1 Predictions Std                                0.748307
trainer/Q1 Predictions Max                                1.08818
trainer/Q1 Predictions Min                               -2.66732
trainer/Q2 Predictions Mean                              -0.809487
trainer/Q2 Predictions Std                                0.753992
trainer/Q2 Predictions Max                                1.09689
trainer/Q2 Predictions Min                               -2.67876
trainer/Q Targets Mean                                   -0.801079
trainer/Q Targets Std                                     0.762189
trainer/Q Targets Max                                     1.0722
trainer/Q Targets Min                                    -2.72487
trainer/Log Pis Mean                                      2.09558
trainer/Log Pis Std                                       1.28128
trainer/Log Pis Max                                       5.14735
trainer/Log Pis Min                                      -2.8428
trainer/Policy mu Mean                                    0.0168586
trainer/Policy mu Std                                     0.41113
trainer/Policy mu Max                                     1.94464
trainer/Policy mu Min                                    -2.04045
trainer/Policy log std Mean                              -2.27599
trainer/Policy log std Std                                0.656128
trainer/Policy log std Max                               -0.29587
trainer/Policy log std Min                               -3.31018
trainer/Alpha                                             0.0185651
trainer/Alpha Loss                                        0.381094
exploration/num steps total                           14000
exploration/num paths total                             700
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0963054
exploration/Rewards Std                                   0.0792062
exploration/Rewards Max                                   0.134266
exploration/Rewards Min                                  -0.476492
exploration/Returns Mean                                 -1.92611
exploration/Returns Std                                   0.577605
exploration/Returns Max                                  -1.01858
exploration/Returns Min                                  -2.82198
exploration/Actions Mean                                  0.0027353
exploration/Actions Std                                   0.107471
exploration/Actions Max                                   0.501151
exploration/Actions Min                                  -0.269749
exploration/Num Paths                                     5
exploration/Average Returns                              -1.92611
exploration/env_infos/final/reward_energy Mean           -0.111395
exploration/env_infos/final/reward_energy Std             0.0586913
exploration/env_infos/final/reward_energy Max            -0.0503996
exploration/env_infos/final/reward_energy Min            -0.208308
exploration/env_infos/initial/reward_energy Mean         -0.31812
exploration/env_infos/initial/reward_energy Std           0.178341
exploration/env_infos/initial/reward_energy Max          -0.0379825
exploration/env_infos/initial/reward_energy Min          -0.513798
exploration/env_infos/reward_energy Mean                 -0.120233
exploration/env_infos/reward_energy Std                   0.0930548
exploration/env_infos/reward_energy Max                  -0.0110907
exploration/env_infos/reward_energy Min                  -0.513798
exploration/env_infos/final/end_effector_loc Mean         0.0990587
exploration/env_infos/final/end_effector_loc Std          0.330073
exploration/env_infos/final/end_effector_loc Max          0.527451
exploration/env_infos/final/end_effector_loc Min         -0.492132
exploration/env_infos/initial/end_effector_loc Mean       0.00385196
exploration/env_infos/initial/end_effector_loc Std        0.0123053
exploration/env_infos/initial/end_effector_loc Max        0.0250576
exploration/env_infos/initial/end_effector_loc Min       -0.0134875
exploration/env_infos/end_effector_loc Mean               0.0552578
exploration/env_infos/end_effector_loc Std                0.212761
exploration/env_infos/end_effector_loc Max                0.527451
exploration/env_infos/end_effector_loc Min               -0.492132
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000103407
exploration/env_infos/final/reward_dist Std               0.0002068
exploration/env_infos/final/reward_dist Max               0.000517006
exploration/env_infos/final/reward_dist Min               7.33385e-15
exploration/env_infos/initial/reward_dist Mean            0.00202367
exploration/env_infos/initial/reward_dist Std             0.00244042
exploration/env_infos/initial/reward_dist Max             0.00658904
exploration/env_infos/initial/reward_dist Min             9.40014e-06
exploration/env_infos/reward_dist Mean                    0.091675
exploration/env_infos/reward_dist Std                     0.196684
exploration/env_infos/reward_dist Max                     0.899305
exploration/env_infos/reward_dist Min                     7.33385e-15
evaluation/num steps total                           130000
evaluation/num paths total                             6500
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0697979
evaluation/Rewards Std                                    0.133138
evaluation/Rewards Max                                    0.148534
evaluation/Rewards Min                                   -1.14349
evaluation/Returns Mean                                  -1.39596
evaluation/Returns Std                                    2.06373
evaluation/Returns Max                                    2.20471
evaluation/Returns Min                                   -8.20147
evaluation/Actions Mean                                  -0.000482898
evaluation/Actions Std                                    0.137673
evaluation/Actions Max                                    0.945111
evaluation/Actions Min                                   -0.891138
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.39596
evaluation/env_infos/final/reward_energy Mean            -0.0515779
evaluation/env_infos/final/reward_energy Std              0.0378254
evaluation/env_infos/final/reward_energy Max             -0.00777144
evaluation/env_infos/final/reward_energy Min             -0.148741
evaluation/env_infos/initial/reward_energy Mean          -0.427704
evaluation/env_infos/initial/reward_energy Std            0.326972
evaluation/env_infos/initial/reward_energy Max           -0.0162779
evaluation/env_infos/initial/reward_energy Min           -1.09511
evaluation/env_infos/reward_energy Mean                  -0.107785
evaluation/env_infos/reward_energy Std                    0.162144
evaluation/env_infos/reward_energy Max                   -0.00228107
evaluation/env_infos/reward_energy Min                   -1.29325
evaluation/env_infos/final/end_effector_loc Mean          0.0412716
evaluation/env_infos/final/end_effector_loc Std           0.343089
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.871472
evaluation/env_infos/initial/end_effector_loc Mean        0.0016509
evaluation/env_infos/initial/end_effector_loc Std         0.0189625
evaluation/env_infos/initial/end_effector_loc Max         0.0472556
evaluation/env_infos/initial/end_effector_loc Min        -0.0432111
evaluation/env_infos/end_effector_loc Mean                0.0351524
evaluation/env_infos/end_effector_loc Std                 0.230504
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.871472
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.162586
evaluation/env_infos/final/reward_dist Std                0.242972
evaluation/env_infos/final/reward_dist Max                0.890095
evaluation/env_infos/final/reward_dist Min                4.96818e-115
evaluation/env_infos/initial/reward_dist Mean             0.0100623
evaluation/env_infos/initial/reward_dist Std              0.0209768
evaluation/env_infos/initial/reward_dist Max              0.116504
evaluation/env_infos/initial/reward_dist Min              3.94014e-06
evaluation/env_infos/reward_dist Mean                     0.16043
evaluation/env_infos/reward_dist Std                      0.256412
evaluation/env_infos/reward_dist Max                      0.997687
evaluation/env_infos/reward_dist Min                      4.96818e-115
time/data storing (s)                                    46.1816
time/evaluation sampling (s)                              0.858392
time/exploration sampling (s)                             0.135708
time/logging (s)                                          0.0185665
time/saving (s)                                           0.829211
time/training (s)                                        45.4626
time/epoch (s)                                           93.486
time/total (s)                                         8749.73
Epoch                                                   129
---------------------------------------------------  -----------------
2021-05-29 02:23:12.349030 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 130 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00134604
trainer/QF2 Loss                                          0.00182537
trainer/Policy Loss                                       2.74667
trainer/Q1 Predictions Mean                              -0.782196
trainer/Q1 Predictions Std                                0.790241
trainer/Q1 Predictions Max                                1.21125
trainer/Q1 Predictions Min                               -2.83308
trainer/Q2 Predictions Mean                              -0.779479
trainer/Q2 Predictions Std                                0.79669
trainer/Q2 Predictions Max                                1.22516
trainer/Q2 Predictions Min                               -2.80767
trainer/Q Targets Mean                                   -0.783024
trainer/Q Targets Std                                     0.801026
trainer/Q Targets Max                                     1.20534
trainer/Q Targets Min                                    -2.85099
trainer/Log Pis Mean                                      1.97879
trainer/Log Pis Std                                       1.25394
trainer/Log Pis Max                                       4.29924
trainer/Log Pis Min                                      -2.84852
trainer/Policy mu Mean                                    0.0250424
trainer/Policy mu Std                                     0.461045
trainer/Policy mu Max                                     2.13544
trainer/Policy mu Min                                    -2.24053
trainer/Policy log std Mean                              -2.2288
trainer/Policy log std Std                                0.650701
trainer/Policy log std Max                               -0.205833
trainer/Policy log std Min                               -3.19549
trainer/Alpha                                             0.018111
trainer/Alpha Loss                                       -0.0850664
exploration/num steps total                           14100
exploration/num paths total                             705
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0885683
exploration/Rewards Std                                   0.0902554
exploration/Rewards Max                                   0.103469
exploration/Rewards Min                                  -0.353707
exploration/Returns Mean                                 -1.77137
exploration/Returns Std                                   1.41437
exploration/Returns Max                                   0.658515
exploration/Returns Min                                  -3.58037
exploration/Actions Mean                                 -0.0102481
exploration/Actions Std                                   0.189553
exploration/Actions Max                                   0.81855
exploration/Actions Min                                  -0.756994
exploration/Num Paths                                     5
exploration/Average Returns                              -1.77137
exploration/env_infos/final/reward_energy Mean           -0.190419
exploration/env_infos/final/reward_energy Std             0.204085
exploration/env_infos/final/reward_energy Max            -0.046176
exploration/env_infos/final/reward_energy Min            -0.592252
exploration/env_infos/initial/reward_energy Mean         -0.46033
exploration/env_infos/initial/reward_energy Std           0.350097
exploration/env_infos/initial/reward_energy Max          -0.040933
exploration/env_infos/initial/reward_energy Min          -0.958968
exploration/env_infos/reward_energy Mean                 -0.212802
exploration/env_infos/reward_energy Std                   0.163664
exploration/env_infos/reward_energy Max                  -0.0198462
exploration/env_infos/reward_energy Min                  -0.958968
exploration/env_infos/final/end_effector_loc Mean        -0.13013
exploration/env_infos/final/end_effector_loc Std          0.29196
exploration/env_infos/final/end_effector_loc Max          0.285641
exploration/env_infos/final/end_effector_loc Min         -0.698372
exploration/env_infos/initial/end_effector_loc Mean      -0.00417004
exploration/env_infos/initial/end_effector_loc Std        0.0200175
exploration/env_infos/initial/end_effector_loc Max        0.0409275
exploration/env_infos/initial/end_effector_loc Min       -0.0378497
exploration/env_infos/end_effector_loc Mean              -0.0712282
exploration/env_infos/end_effector_loc Std                0.197147
exploration/env_infos/end_effector_loc Max                0.285641
exploration/env_infos/end_effector_loc Min               -0.698372
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0322609
exploration/env_infos/final/reward_dist Std               0.0590176
exploration/env_infos/final/reward_dist Max               0.150139
exploration/env_infos/final/reward_dist Min               5.42355e-19
exploration/env_infos/initial/reward_dist Mean            0.0102934
exploration/env_infos/initial/reward_dist Std             0.0144939
exploration/env_infos/initial/reward_dist Max             0.0386972
exploration/env_infos/initial/reward_dist Min             0.000117269
exploration/env_infos/reward_dist Mean                    0.145122
exploration/env_infos/reward_dist Std                     0.252536
exploration/env_infos/reward_dist Max                     0.977365
exploration/env_infos/reward_dist Min                     5.42355e-19
evaluation/num steps total                           131000
evaluation/num paths total                             6550
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0654357
evaluation/Rewards Std                                    0.0988007
evaluation/Rewards Max                                    0.143624
evaluation/Rewards Min                                   -0.608483
evaluation/Returns Mean                                  -1.30871
evaluation/Returns Std                                    1.57744
evaluation/Returns Max                                    1.30315
evaluation/Returns Min                                   -6.73942
evaluation/Actions Mean                                  -0.00769551
evaluation/Actions Std                                    0.10293
evaluation/Actions Max                                    0.889566
evaluation/Actions Min                                   -0.914
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.30871
evaluation/env_infos/final/reward_energy Mean            -0.0645962
evaluation/env_infos/final/reward_energy Std              0.0499788
evaluation/env_infos/final/reward_energy Max             -0.0219908
evaluation/env_infos/final/reward_energy Min             -0.235348
evaluation/env_infos/initial/reward_energy Mean          -0.290293
evaluation/env_infos/initial/reward_energy Std            0.260295
evaluation/env_infos/initial/reward_energy Max           -0.0272231
evaluation/env_infos/initial/reward_energy Min           -0.994731
evaluation/env_infos/reward_energy Mean                  -0.0936565
evaluation/env_infos/reward_energy Std                    0.111965
evaluation/env_infos/reward_energy Max                   -0.00234398
evaluation/env_infos/reward_energy Min                   -1.11771
evaluation/env_infos/final/end_effector_loc Mean         -0.0379118
evaluation/env_infos/final/end_effector_loc Std           0.314287
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.743959
evaluation/env_infos/initial/end_effector_loc Mean        0.000219801
evaluation/env_infos/initial/end_effector_loc Std         0.0137834
evaluation/env_infos/initial/end_effector_loc Max         0.0410766
evaluation/env_infos/initial/end_effector_loc Min        -0.0457
evaluation/env_infos/end_effector_loc Mean               -0.00537773
evaluation/env_infos/end_effector_loc Std                 0.2078
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.743959
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.101069
evaluation/env_infos/final/reward_dist Std                0.208342
evaluation/env_infos/final/reward_dist Max                0.923524
evaluation/env_infos/final/reward_dist Min                1.54884e-91
evaluation/env_infos/initial/reward_dist Mean             0.0120654
evaluation/env_infos/initial/reward_dist Std              0.0263082
evaluation/env_infos/initial/reward_dist Max              0.140305
evaluation/env_infos/initial/reward_dist Min              1.35773e-06
evaluation/env_infos/reward_dist Mean                     0.138874
evaluation/env_infos/reward_dist Std                      0.227386
evaluation/env_infos/reward_dist Max                      0.995467
evaluation/env_infos/reward_dist Min                      3.0958e-92
time/data storing (s)                                    45.2344
time/evaluation sampling (s)                              0.740234
time/exploration sampling (s)                             0.0933429
time/logging (s)                                          0.016765
time/saving (s)                                           0.909541
time/training (s)                                        41.0678
time/epoch (s)                                           88.0621
time/total (s)                                         8839.27
Epoch                                                   130
---------------------------------------------------  ----------------
2021-05-29 02:24:36.052168 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 131 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00221122
trainer/QF2 Loss                                          0.00170797
trainer/Policy Loss                                       2.89411
trainer/Q1 Predictions Mean                              -0.828896
trainer/Q1 Predictions Std                                0.801383
trainer/Q1 Predictions Max                                0.870127
trainer/Q1 Predictions Min                               -2.76514
trainer/Q2 Predictions Mean                              -0.819312
trainer/Q2 Predictions Std                                0.793691
trainer/Q2 Predictions Max                                0.87825
trainer/Q2 Predictions Min                               -2.73594
trainer/Q Targets Mean                                   -0.816647
trainer/Q Targets Std                                     0.8012
trainer/Q Targets Max                                     0.955667
trainer/Q Targets Min                                    -2.71773
trainer/Log Pis Mean                                      2.07998
trainer/Log Pis Std                                       1.4701
trainer/Log Pis Max                                       8.06176
trainer/Log Pis Min                                      -2.89267
trainer/Policy mu Mean                                    0.0103138
trainer/Policy mu Std                                     0.49163
trainer/Policy mu Max                                     2.33215
trainer/Policy mu Min                                    -2.83713
trainer/Policy log std Mean                              -2.25248
trainer/Policy log std Std                                0.654184
trainer/Policy log std Max                               -0.239645
trainer/Policy log std Min                               -3.46084
trainer/Alpha                                             0.0172952
trainer/Alpha Loss                                        0.324602
exploration/num steps total                           14200
exploration/num paths total                             710
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.122886
exploration/Rewards Std                                   0.113942
exploration/Rewards Max                                   0.145721
exploration/Rewards Min                                  -0.462184
exploration/Returns Mean                                 -2.45772
exploration/Returns Std                                   1.87798
exploration/Returns Max                                   1.13633
exploration/Returns Min                                  -4.24516
exploration/Actions Mean                                 -0.013768
exploration/Actions Std                                   0.154208
exploration/Actions Max                                   0.888508
exploration/Actions Min                                  -0.597084
exploration/Num Paths                                     5
exploration/Average Returns                              -2.45772
exploration/env_infos/final/reward_energy Mean           -0.134636
exploration/env_infos/final/reward_energy Std             0.0592435
exploration/env_infos/final/reward_energy Max            -0.0295081
exploration/env_infos/final/reward_energy Min            -0.18726
exploration/env_infos/initial/reward_energy Mean         -0.400206
exploration/env_infos/initial/reward_energy Std           0.301034
exploration/env_infos/initial/reward_energy Max          -0.0669949
exploration/env_infos/initial/reward_energy Min          -0.926835
exploration/env_infos/reward_energy Mean                 -0.165645
exploration/env_infos/reward_energy Std                   0.143182
exploration/env_infos/reward_energy Max                  -0.00806776
exploration/env_infos/reward_energy Min                  -0.926835
exploration/env_infos/final/end_effector_loc Mean        -0.0913882
exploration/env_infos/final/end_effector_loc Std          0.575137
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.694786
exploration/env_infos/initial/end_effector_loc Mean       0.00457347
exploration/env_infos/initial/end_effector_loc Std        0.0171046
exploration/env_infos/initial/end_effector_loc Max        0.0444254
exploration/env_infos/initial/end_effector_loc Min       -0.0131887
exploration/env_infos/end_effector_loc Mean              -0.00446066
exploration/env_infos/end_effector_loc Std                0.349605
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.694786
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0404607
exploration/env_infos/final/reward_dist Std               0.0803429
exploration/env_infos/final/reward_dist Max               0.201144
exploration/env_infos/final/reward_dist Min               1.04729e-79
exploration/env_infos/initial/reward_dist Mean            0.014069
exploration/env_infos/initial/reward_dist Std             0.0141258
exploration/env_infos/initial/reward_dist Max             0.041512
exploration/env_infos/initial/reward_dist Min             0.00230849
exploration/env_infos/reward_dist Mean                    0.1141
exploration/env_infos/reward_dist Std                     0.227953
exploration/env_infos/reward_dist Max                     0.998946
exploration/env_infos/reward_dist Min                     1.04729e-79
evaluation/num steps total                           132000
evaluation/num paths total                             6600
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0867592
evaluation/Rewards Std                                    0.111865
evaluation/Rewards Max                                    0.130467
evaluation/Rewards Min                                   -0.80881
evaluation/Returns Mean                                  -1.73518
evaluation/Returns Std                                    1.70628
evaluation/Returns Max                                    0.890077
evaluation/Returns Min                                   -8.10247
evaluation/Actions Mean                                  -0.0101058
evaluation/Actions Std                                    0.14353
evaluation/Actions Max                                    0.979507
evaluation/Actions Min                                   -0.941326
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.73518
evaluation/env_infos/final/reward_energy Mean            -0.0969683
evaluation/env_infos/final/reward_energy Std              0.174122
evaluation/env_infos/final/reward_energy Max             -0.0118551
evaluation/env_infos/final/reward_energy Min             -1.1951
evaluation/env_infos/initial/reward_energy Mean          -0.360025
evaluation/env_infos/initial/reward_energy Std            0.291987
evaluation/env_infos/initial/reward_energy Max           -0.00230647
evaluation/env_infos/initial/reward_energy Min           -1.01767
evaluation/env_infos/reward_energy Mean                  -0.118305
evaluation/env_infos/reward_energy Std                    0.165559
evaluation/env_infos/reward_energy Max                   -0.00230647
evaluation/env_infos/reward_energy Min                   -1.31615
evaluation/env_infos/final/end_effector_loc Mean         -0.027277
evaluation/env_infos/final/end_effector_loc Std           0.367562
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00416193
evaluation/env_infos/initial/end_effector_loc Std         0.0158515
evaluation/env_infos/initial/end_effector_loc Max         0.0489753
evaluation/env_infos/initial/end_effector_loc Min        -0.0368323
evaluation/env_infos/end_effector_loc Mean                0.0172393
evaluation/env_infos/end_effector_loc Std                 0.232468
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0300657
evaluation/env_infos/final/reward_dist Std                0.0697366
evaluation/env_infos/final/reward_dist Max                0.356571
evaluation/env_infos/final/reward_dist Min                8.19845e-152
evaluation/env_infos/initial/reward_dist Mean             0.00930306
evaluation/env_infos/initial/reward_dist Std              0.019543
evaluation/env_infos/initial/reward_dist Max              0.0823696
evaluation/env_infos/initial/reward_dist Min              2.49812e-06
evaluation/env_infos/reward_dist Mean                     0.129989
evaluation/env_infos/reward_dist Std                      0.235484
evaluation/env_infos/reward_dist Max                      0.983992
evaluation/env_infos/reward_dist Min                      8.19845e-152
time/data storing (s)                                    40.2079
time/evaluation sampling (s)                              0.679945
time/exploration sampling (s)                             0.0903381
time/logging (s)                                          0.0181822
time/saving (s)                                           0.844965
time/training (s)                                        40.316
time/epoch (s)                                           82.1573
time/total (s)                                         8922.97
Epoch                                                   131
---------------------------------------------------  -----------------
2021-05-29 02:25:59.812276 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 132 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00185294
trainer/QF2 Loss                                          0.0022187
trainer/Policy Loss                                       3.01113
trainer/Q1 Predictions Mean                              -0.87409
trainer/Q1 Predictions Std                                0.785963
trainer/Q1 Predictions Max                                0.508974
trainer/Q1 Predictions Min                               -2.88837
trainer/Q2 Predictions Mean                              -0.895494
trainer/Q2 Predictions Std                                0.785442
trainer/Q2 Predictions Max                                0.487733
trainer/Q2 Predictions Min                               -2.88332
trainer/Q Targets Mean                                   -0.890711
trainer/Q Targets Std                                     0.787454
trainer/Q Targets Max                                     0.516078
trainer/Q Targets Min                                    -2.96055
trainer/Log Pis Mean                                      2.13667
trainer/Log Pis Std                                       1.44747
trainer/Log Pis Max                                       9.36148
trainer/Log Pis Min                                      -2.42147
trainer/Policy mu Mean                                   -0.013002
trainer/Policy mu Std                                     0.480868
trainer/Policy mu Max                                     2.35527
trainer/Policy mu Min                                    -3.36965
trainer/Policy log std Mean                              -2.29097
trainer/Policy log std Std                                0.611573
trainer/Policy log std Max                               -0.158483
trainer/Policy log std Min                               -3.30184
trainer/Alpha                                             0.0177776
trainer/Alpha Loss                                        0.551077
exploration/num steps total                           14300
exploration/num paths total                             715
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.161946
exploration/Rewards Std                                   0.194164
exploration/Rewards Max                                   0.133612
exploration/Rewards Min                                  -0.959383
exploration/Returns Mean                                 -3.23891
exploration/Returns Std                                   2.50231
exploration/Returns Max                                  -0.911345
exploration/Returns Min                                  -8.05832
exploration/Actions Mean                                 -0.0354629
exploration/Actions Std                                   0.186218
exploration/Actions Max                                   0.344971
exploration/Actions Min                                  -0.852286
exploration/Num Paths                                     5
exploration/Average Returns                              -3.23891
exploration/env_infos/final/reward_energy Mean           -0.21489
exploration/env_infos/final/reward_energy Std             0.248293
exploration/env_infos/final/reward_energy Max            -0.0604334
exploration/env_infos/final/reward_energy Min            -0.709666
exploration/env_infos/initial/reward_energy Mean         -0.403732
exploration/env_infos/initial/reward_energy Std           0.309592
exploration/env_infos/initial/reward_energy Max          -0.0423976
exploration/env_infos/initial/reward_energy Min          -0.858053
exploration/env_infos/reward_energy Mean                 -0.180381
exploration/env_infos/reward_energy Std                   0.198324
exploration/env_infos/reward_energy Max                  -0.0162412
exploration/env_infos/reward_energy Min                  -0.948721
exploration/env_infos/final/end_effector_loc Mean        -0.16769
exploration/env_infos/final/end_effector_loc Std          0.481972
exploration/env_infos/final/end_effector_loc Max          0.620408
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00716579
exploration/env_infos/initial/end_effector_loc Std        0.0164988
exploration/env_infos/initial/end_effector_loc Max        0.0136736
exploration/env_infos/initial/end_effector_loc Min       -0.0423087
exploration/env_infos/end_effector_loc Mean              -0.0808106
exploration/env_infos/end_effector_loc Std                0.269884
exploration/env_infos/end_effector_loc Max                0.620408
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00658602
exploration/env_infos/final/reward_dist Std               0.0110176
exploration/env_infos/final/reward_dist Max               0.0283381
exploration/env_infos/final/reward_dist Min               2.06434e-96
exploration/env_infos/initial/reward_dist Mean            0.0160549
exploration/env_infos/initial/reward_dist Std             0.0238595
exploration/env_infos/initial/reward_dist Max             0.0619102
exploration/env_infos/initial/reward_dist Min             0.000142407
exploration/env_infos/reward_dist Mean                    0.0685282
exploration/env_infos/reward_dist Std                     0.185847
exploration/env_infos/reward_dist Max                     0.975043
exploration/env_infos/reward_dist Min                     2.06434e-96
evaluation/num steps total                           133000
evaluation/num paths total                             6650
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0768242
evaluation/Rewards Std                                    0.102997
evaluation/Rewards Max                                    0.156807
evaluation/Rewards Min                                   -0.660168
evaluation/Returns Mean                                  -1.53648
evaluation/Returns Std                                    1.64577
evaluation/Returns Max                                    2.14728
evaluation/Returns Min                                   -7.78084
evaluation/Actions Mean                                  -0.0113981
evaluation/Actions Std                                    0.0989197
evaluation/Actions Max                                    0.84897
evaluation/Actions Min                                   -0.726968
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.53648
evaluation/env_infos/final/reward_energy Mean            -0.0551478
evaluation/env_infos/final/reward_energy Std              0.0458164
evaluation/env_infos/final/reward_energy Max             -0.0065926
evaluation/env_infos/final/reward_energy Min             -0.259567
evaluation/env_infos/initial/reward_energy Mean          -0.273319
evaluation/env_infos/initial/reward_energy Std            0.257481
evaluation/env_infos/initial/reward_energy Max           -0.0234378
evaluation/env_infos/initial/reward_energy Min           -0.854401
evaluation/env_infos/reward_energy Mean                  -0.084322
evaluation/env_infos/reward_energy Std                    0.112782
evaluation/env_infos/reward_energy Max                   -0.00159658
evaluation/env_infos/reward_energy Min                   -0.854401
evaluation/env_infos/final/end_effector_loc Mean         -0.0686682
evaluation/env_infos/final/end_effector_loc Std           0.3207
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.941538
evaluation/env_infos/initial/end_effector_loc Mean        0.00196092
evaluation/env_infos/initial/end_effector_loc Std         0.0131303
evaluation/env_infos/initial/end_effector_loc Max         0.0424485
evaluation/env_infos/initial/end_effector_loc Min        -0.0363484
evaluation/env_infos/end_effector_loc Mean               -0.006956
evaluation/env_infos/end_effector_loc Std                 0.219037
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.941538
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.136299
evaluation/env_infos/final/reward_dist Std                0.26609
evaluation/env_infos/final/reward_dist Max                0.965066
evaluation/env_infos/final/reward_dist Min                1.33616e-78
evaluation/env_infos/initial/reward_dist Mean             0.00799623
evaluation/env_infos/initial/reward_dist Std              0.0147102
evaluation/env_infos/initial/reward_dist Max              0.0732918
evaluation/env_infos/initial/reward_dist Min              1.47234e-06
evaluation/env_infos/reward_dist Mean                     0.126624
evaluation/env_infos/reward_dist Std                      0.245939
evaluation/env_infos/reward_dist Max                      0.999627
evaluation/env_infos/reward_dist Min                      1.33616e-78
time/data storing (s)                                    40.5625
time/evaluation sampling (s)                              0.694147
time/exploration sampling (s)                             0.0905328
time/logging (s)                                          0.0165934
time/saving (s)                                           0.822453
time/training (s)                                        40.0331
time/epoch (s)                                           82.2194
time/total (s)                                         9006.72
Epoch                                                   132
---------------------------------------------------  ----------------
2021-05-29 02:27:23.309348 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 133 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00259084
trainer/QF2 Loss                                          0.0030738
trainer/Policy Loss                                       2.86994
trainer/Q1 Predictions Mean                              -0.83865
trainer/Q1 Predictions Std                                0.765898
trainer/Q1 Predictions Max                                0.69649
trainer/Q1 Predictions Min                               -2.71105
trainer/Q2 Predictions Mean                              -0.838276
trainer/Q2 Predictions Std                                0.758515
trainer/Q2 Predictions Max                                0.658668
trainer/Q2 Predictions Min                               -2.77337
trainer/Q Targets Mean                                   -0.823443
trainer/Q Targets Std                                     0.767168
trainer/Q Targets Max                                     0.717951
trainer/Q Targets Min                                    -2.69666
trainer/Log Pis Mean                                      2.03829
trainer/Log Pis Std                                       1.42823
trainer/Log Pis Max                                       8.61294
trainer/Log Pis Min                                      -4.40568
trainer/Policy mu Mean                                   -0.0287648
trainer/Policy mu Std                                     0.446649
trainer/Policy mu Max                                     2.05016
trainer/Policy mu Min                                    -2.63317
trainer/Policy log std Mean                              -2.23125
trainer/Policy log std Std                                0.677261
trainer/Policy log std Max                                1.27187
trainer/Policy log std Min                               -3.63302
trainer/Alpha                                             0.0180592
trainer/Alpha Loss                                        0.153699
exploration/num steps total                           14400
exploration/num paths total                             720
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.168584
exploration/Rewards Std                                   0.121186
exploration/Rewards Max                                  -0.0323799
exploration/Rewards Min                                  -0.803418
exploration/Returns Mean                                 -3.37168
exploration/Returns Std                                   1.93128
exploration/Returns Max                                  -1.40294
exploration/Returns Min                                  -6.86853
exploration/Actions Mean                                 -0.00532015
exploration/Actions Std                                   0.200732
exploration/Actions Max                                   0.868756
exploration/Actions Min                                  -0.709768
exploration/Num Paths                                     5
exploration/Average Returns                              -3.37168
exploration/env_infos/final/reward_energy Mean           -0.116187
exploration/env_infos/final/reward_energy Std             0.0710908
exploration/env_infos/final/reward_energy Max            -0.0104557
exploration/env_infos/final/reward_energy Min            -0.232034
exploration/env_infos/initial/reward_energy Mean         -0.622056
exploration/env_infos/initial/reward_energy Std           0.293147
exploration/env_infos/initial/reward_energy Max          -0.227431
exploration/env_infos/initial/reward_energy Min          -0.973139
exploration/env_infos/reward_energy Mean                 -0.220205
exploration/env_infos/reward_energy Std                   0.179313
exploration/env_infos/reward_energy Max                  -0.00760665
exploration/env_infos/reward_energy Min                  -0.973139
exploration/env_infos/final/end_effector_loc Mean        -0.0726754
exploration/env_infos/final/end_effector_loc Std          0.447695
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.745259
exploration/env_infos/initial/end_effector_loc Mean       0.00670501
exploration/env_infos/initial/end_effector_loc Std        0.0233699
exploration/env_infos/initial/end_effector_loc Max        0.0434378
exploration/env_infos/initial/end_effector_loc Min       -0.026601
exploration/env_infos/end_effector_loc Mean              -0.0105845
exploration/env_infos/end_effector_loc Std                0.317562
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.745259
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0700081
exploration/env_infos/final/reward_dist Std               0.132719
exploration/env_infos/final/reward_dist Max               0.335197
exploration/env_infos/final/reward_dist Min               4.90935e-78
exploration/env_infos/initial/reward_dist Mean            0.0118246
exploration/env_infos/initial/reward_dist Std             0.014915
exploration/env_infos/initial/reward_dist Max             0.0378668
exploration/env_infos/initial/reward_dist Min             7.94839e-05
exploration/env_infos/reward_dist Mean                    0.0653626
exploration/env_infos/reward_dist Std                     0.146177
exploration/env_infos/reward_dist Max                     0.824465
exploration/env_infos/reward_dist Min                     4.90935e-78
evaluation/num steps total                           134000
evaluation/num paths total                             6700
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0736491
evaluation/Rewards Std                                    0.118461
evaluation/Rewards Max                                    0.18017
evaluation/Rewards Min                                   -0.660984
evaluation/Returns Mean                                  -1.47298
evaluation/Returns Std                                    1.77563
evaluation/Returns Max                                    1.9922
evaluation/Returns Min                                   -6.33169
evaluation/Actions Mean                                  -0.0169438
evaluation/Actions Std                                    0.146542
evaluation/Actions Max                                    0.978081
evaluation/Actions Min                                   -0.968691
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.47298
evaluation/env_infos/final/reward_energy Mean            -0.0977572
evaluation/env_infos/final/reward_energy Std              0.178682
evaluation/env_infos/final/reward_energy Max             -0.00493698
evaluation/env_infos/final/reward_energy Min             -1.2536
evaluation/env_infos/initial/reward_energy Mean          -0.413231
evaluation/env_infos/initial/reward_energy Std            0.271395
evaluation/env_infos/initial/reward_energy Max           -0.00602796
evaluation/env_infos/initial/reward_energy Min           -1.07851
evaluation/env_infos/reward_energy Mean                  -0.125084
evaluation/env_infos/reward_energy Std                    0.166965
evaluation/env_infos/reward_energy Max                   -0.00254648
evaluation/env_infos/reward_energy Min                   -1.26377
evaluation/env_infos/final/end_effector_loc Mean         -0.0340764
evaluation/env_infos/final/end_effector_loc Std           0.388081
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00436117
evaluation/env_infos/initial/end_effector_loc Std         0.0169263
evaluation/env_infos/initial/end_effector_loc Max         0.048904
evaluation/env_infos/initial/end_effector_loc Min        -0.0414536
evaluation/env_infos/end_effector_loc Mean                0.0150953
evaluation/env_infos/end_effector_loc Std                 0.261776
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0568987
evaluation/env_infos/final/reward_dist Std                0.151023
evaluation/env_infos/final/reward_dist Max                0.813634
evaluation/env_infos/final/reward_dist Min                3.61085e-90
evaluation/env_infos/initial/reward_dist Mean             0.0100095
evaluation/env_infos/initial/reward_dist Std              0.023837
evaluation/env_infos/initial/reward_dist Max              0.150875
evaluation/env_infos/initial/reward_dist Min              2.04125e-06
evaluation/env_infos/reward_dist Mean                     0.142321
evaluation/env_infos/reward_dist Std                      0.231519
evaluation/env_infos/reward_dist Max                      0.999405
evaluation/env_infos/reward_dist Min                      5.8417e-107
time/data storing (s)                                    40.2413
time/evaluation sampling (s)                              0.688597
time/exploration sampling (s)                             0.0911666
time/logging (s)                                          0.017767
time/saving (s)                                           0.850495
time/training (s)                                        40.0586
time/epoch (s)                                           81.9479
time/total (s)                                         9090.22
Epoch                                                   133
---------------------------------------------------  ----------------
2021-05-29 02:28:44.384916 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 134 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00338156
trainer/QF2 Loss                                          0.0037098
trainer/Policy Loss                                       2.94198
trainer/Q1 Predictions Mean                              -0.915673
trainer/Q1 Predictions Std                                0.784627
trainer/Q1 Predictions Max                                0.839821
trainer/Q1 Predictions Min                               -2.85122
trainer/Q2 Predictions Mean                              -0.895487
trainer/Q2 Predictions Std                                0.774732
trainer/Q2 Predictions Max                                0.804954
trainer/Q2 Predictions Min                               -2.84662
trainer/Q Targets Mean                                   -0.895642
trainer/Q Targets Std                                     0.779257
trainer/Q Targets Max                                     0.770343
trainer/Q Targets Min                                    -2.85161
trainer/Log Pis Mean                                      2.03903
trainer/Log Pis Std                                       1.25375
trainer/Log Pis Max                                       5.83651
trainer/Log Pis Min                                      -3.5109
trainer/Policy mu Mean                                   -0.0305845
trainer/Policy mu Std                                     0.397707
trainer/Policy mu Max                                     2.04667
trainer/Policy mu Min                                    -2.3919
trainer/Policy log std Mean                              -2.28618
trainer/Policy log std Std                                0.566059
trainer/Policy log std Max                                0.0125141
trainer/Policy log std Min                               -3.90892
trainer/Alpha                                             0.0170973
trainer/Alpha Loss                                        0.158788
exploration/num steps total                           14500
exploration/num paths total                             725
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0842751
exploration/Rewards Std                                   0.0810744
exploration/Rewards Max                                   0.09146
exploration/Rewards Min                                  -0.238656
exploration/Returns Mean                                 -1.6855
exploration/Returns Std                                   1.12052
exploration/Returns Max                                  -0.063318
exploration/Returns Min                                  -3.12259
exploration/Actions Mean                                 -0.00230508
exploration/Actions Std                                   0.12184
exploration/Actions Max                                   0.722689
exploration/Actions Min                                  -0.384203
exploration/Num Paths                                     5
exploration/Average Returns                              -1.6855
exploration/env_infos/final/reward_energy Mean           -0.0632826
exploration/env_infos/final/reward_energy Std             0.0398578
exploration/env_infos/final/reward_energy Max            -0.0178073
exploration/env_infos/final/reward_energy Min            -0.132064
exploration/env_infos/initial/reward_energy Mean         -0.308741
exploration/env_infos/initial/reward_energy Std           0.262883
exploration/env_infos/initial/reward_energy Max          -0.0184567
exploration/env_infos/initial/reward_energy Min          -0.722995
exploration/env_infos/reward_energy Mean                 -0.120946
exploration/env_infos/reward_energy Std                   0.122771
exploration/env_infos/reward_energy Max                  -0.0103911
exploration/env_infos/reward_energy Min                  -0.722995
exploration/env_infos/final/end_effector_loc Mean        -0.0591696
exploration/env_infos/final/end_effector_loc Std          0.309059
exploration/env_infos/final/end_effector_loc Max          0.403605
exploration/env_infos/final/end_effector_loc Min         -0.642682
exploration/env_infos/initial/end_effector_loc Mean      -0.000821731
exploration/env_infos/initial/end_effector_loc Std        0.0143129
exploration/env_infos/initial/end_effector_loc Max        0.0361345
exploration/env_infos/initial/end_effector_loc Min       -0.0192102
exploration/env_infos/end_effector_loc Mean              -0.0273566
exploration/env_infos/end_effector_loc Std                0.221257
exploration/env_infos/end_effector_loc Max                0.512144
exploration/env_infos/end_effector_loc Min               -0.642682
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.148047
exploration/env_infos/final/reward_dist Std               0.27396
exploration/env_infos/final/reward_dist Max               0.694837
exploration/env_infos/final/reward_dist Min               1.18065e-12
exploration/env_infos/initial/reward_dist Mean            0.0205342
exploration/env_infos/initial/reward_dist Std             0.0378493
exploration/env_infos/initial/reward_dist Max             0.0960959
exploration/env_infos/initial/reward_dist Min             2.5798e-06
exploration/env_infos/reward_dist Mean                    0.128432
exploration/env_infos/reward_dist Std                     0.255371
exploration/env_infos/reward_dist Max                     0.975602
exploration/env_infos/reward_dist Min                     1.18065e-12
evaluation/num steps total                           135000
evaluation/num paths total                             6750
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0497715
evaluation/Rewards Std                                    0.0709893
evaluation/Rewards Max                                    0.129108
evaluation/Rewards Min                                   -0.418481
evaluation/Returns Mean                                  -0.995431
evaluation/Returns Std                                    1.04955
evaluation/Returns Max                                    1.27209
evaluation/Returns Min                                   -4.45969
evaluation/Actions Mean                                  -0.00455068
evaluation/Actions Std                                    0.10044
evaluation/Actions Max                                    0.977414
evaluation/Actions Min                                   -0.947885
evaluation/Num Paths                                     50
evaluation/Average Returns                               -0.995431
evaluation/env_infos/final/reward_energy Mean            -0.0413834
evaluation/env_infos/final/reward_energy Std              0.0498445
evaluation/env_infos/final/reward_energy Max             -0.000944724
evaluation/env_infos/final/reward_energy Min             -0.259413
evaluation/env_infos/initial/reward_energy Mean          -0.286829
evaluation/env_infos/initial/reward_energy Std            0.33462
evaluation/env_infos/initial/reward_energy Max           -0.00619297
evaluation/env_infos/initial/reward_energy Min           -1.15812
evaluation/env_infos/reward_energy Mean                  -0.0730247
evaluation/env_infos/reward_energy Std                    0.122005
evaluation/env_infos/reward_energy Max                   -0.000944724
evaluation/env_infos/reward_energy Min                   -1.15812
evaluation/env_infos/final/end_effector_loc Mean         -0.0205856
evaluation/env_infos/final/end_effector_loc Std           0.28671
evaluation/env_infos/final/end_effector_loc Max           0.761193
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00209655
evaluation/env_infos/initial/end_effector_loc Std         0.0154404
evaluation/env_infos/initial/end_effector_loc Max         0.0488707
evaluation/env_infos/initial/end_effector_loc Min        -0.0473942
evaluation/env_infos/end_effector_loc Mean               -0.00270882
evaluation/env_infos/end_effector_loc Std                 0.183638
evaluation/env_infos/end_effector_loc Max                 0.761193
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.229074
evaluation/env_infos/final/reward_dist Std                0.303071
evaluation/env_infos/final/reward_dist Max                0.963918
evaluation/env_infos/final/reward_dist Min                4.10214e-66
evaluation/env_infos/initial/reward_dist Mean             0.00828575
evaluation/env_infos/initial/reward_dist Std              0.0197375
evaluation/env_infos/initial/reward_dist Max              0.116402
evaluation/env_infos/initial/reward_dist Min              2.36783e-06
evaluation/env_infos/reward_dist Mean                     0.154582
evaluation/env_infos/reward_dist Std                      0.243109
evaluation/env_infos/reward_dist Max                      0.986644
evaluation/env_infos/reward_dist Min                      4.10214e-66
time/data storing (s)                                    39.1314
time/evaluation sampling (s)                              0.68643
time/exploration sampling (s)                             0.0884725
time/logging (s)                                          0.0143601
time/saving (s)                                           0.777045
time/training (s)                                        38.823
time/epoch (s)                                           79.5207
time/total (s)                                         9171.28
Epoch                                                   134
---------------------------------------------------  ----------------
2021-05-29 02:30:06.369650 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 135 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00695614
trainer/QF2 Loss                                          0.00676956
trainer/Policy Loss                                       2.91567
trainer/Q1 Predictions Mean                              -0.875779
trainer/Q1 Predictions Std                                0.798727
trainer/Q1 Predictions Max                                0.748869
trainer/Q1 Predictions Min                               -2.96439
trainer/Q2 Predictions Mean                              -0.864294
trainer/Q2 Predictions Std                                0.798818
trainer/Q2 Predictions Max                                0.761389
trainer/Q2 Predictions Min                               -2.83905
trainer/Q Targets Mean                                   -0.871266
trainer/Q Targets Std                                     0.806167
trainer/Q Targets Max                                     0.761424
trainer/Q Targets Min                                    -2.96456
trainer/Log Pis Mean                                      2.0508
trainer/Log Pis Std                                       1.25436
trainer/Log Pis Max                                       5.3983
trainer/Log Pis Min                                      -1.92031
trainer/Policy mu Mean                                   -0.0243593
trainer/Policy mu Std                                     0.471728
trainer/Policy mu Max                                     1.99585
trainer/Policy mu Min                                    -2.73208
trainer/Policy log std Mean                              -2.25264
trainer/Policy log std Std                                0.571091
trainer/Policy log std Max                                0.369198
trainer/Policy log std Min                               -3.32537
trainer/Alpha                                             0.016348
trainer/Alpha Loss                                        0.208986
exploration/num steps total                           14600
exploration/num paths total                             730
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.145325
exploration/Rewards Std                                   0.109567
exploration/Rewards Max                                   0.00600501
exploration/Rewards Min                                  -0.562582
exploration/Returns Mean                                 -2.9065
exploration/Returns Std                                   1.27764
exploration/Returns Max                                  -1.85044
exploration/Returns Min                                  -5.35066
exploration/Actions Mean                                 -0.00448874
exploration/Actions Std                                   0.116798
exploration/Actions Max                                   0.44566
exploration/Actions Min                                  -0.300961
exploration/Num Paths                                     5
exploration/Average Returns                              -2.9065
exploration/env_infos/final/reward_energy Mean           -0.125172
exploration/env_infos/final/reward_energy Std             0.0983229
exploration/env_infos/final/reward_energy Max            -0.043854
exploration/env_infos/final/reward_energy Min            -0.302535
exploration/env_infos/initial/reward_energy Mean         -0.163569
exploration/env_infos/initial/reward_energy Std           0.0864124
exploration/env_infos/initial/reward_energy Max          -0.0887916
exploration/env_infos/initial/reward_energy Min          -0.321567
exploration/env_infos/reward_energy Mean                 -0.137662
exploration/env_infos/reward_energy Std                   0.0915035
exploration/env_infos/reward_energy Max                  -0.0157154
exploration/env_infos/reward_energy Min                  -0.461295
exploration/env_infos/final/end_effector_loc Mean         0.0459859
exploration/env_infos/final/end_effector_loc Std          0.450049
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.650507
exploration/env_infos/initial/end_effector_loc Mean       0.00244024
exploration/env_infos/initial/end_effector_loc Std        0.00606816
exploration/env_infos/initial/end_effector_loc Max        0.01595
exploration/env_infos/initial/end_effector_loc Min       -0.0049551
exploration/env_infos/end_effector_loc Mean               0.0396726
exploration/env_infos/end_effector_loc Std                0.274873
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.650507
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000615321
exploration/env_infos/final/reward_dist Std               0.000704564
exploration/env_infos/final/reward_dist Max               0.00191288
exploration/env_infos/final/reward_dist Min               2.20771e-72
exploration/env_infos/initial/reward_dist Mean            0.00940167
exploration/env_infos/initial/reward_dist Std             0.0105564
exploration/env_infos/initial/reward_dist Max             0.0229952
exploration/env_infos/initial/reward_dist Min             0.000112129
exploration/env_infos/reward_dist Mean                    0.0537587
exploration/env_infos/reward_dist Std                     0.131925
exploration/env_infos/reward_dist Max                     0.611337
exploration/env_infos/reward_dist Min                     2.20771e-72
evaluation/num steps total                           136000
evaluation/num paths total                             6800
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0830723
evaluation/Rewards Std                                    0.121165
evaluation/Rewards Max                                    0.182037
evaluation/Rewards Min                                   -0.88296
evaluation/Returns Mean                                  -1.66145
evaluation/Returns Std                                    1.53705
evaluation/Returns Max                                    1.38995
evaluation/Returns Min                                   -5.39935
evaluation/Actions Mean                                  -0.00865937
evaluation/Actions Std                                    0.13146
evaluation/Actions Max                                    0.914424
evaluation/Actions Min                                   -0.991425
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.66145
evaluation/env_infos/final/reward_energy Mean            -0.0900247
evaluation/env_infos/final/reward_energy Std              0.189883
evaluation/env_infos/final/reward_energy Max             -0.00581965
evaluation/env_infos/final/reward_energy Min             -1.32327
evaluation/env_infos/initial/reward_energy Mean          -0.382754
evaluation/env_infos/initial/reward_energy Std            0.310395
evaluation/env_infos/initial/reward_energy Max           -0.00531222
evaluation/env_infos/initial/reward_energy Min           -1.06475
evaluation/env_infos/reward_energy Mean                  -0.106223
evaluation/env_infos/reward_energy Std                    0.153068
evaluation/env_infos/reward_energy Max                   -0.000950344
evaluation/env_infos/reward_energy Min                   -1.33522
evaluation/env_infos/final/end_effector_loc Mean          0.00265819
evaluation/env_infos/final/end_effector_loc Std           0.353484
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000679102
evaluation/env_infos/initial/end_effector_loc Std         0.0174096
evaluation/env_infos/initial/end_effector_loc Max         0.0457212
evaluation/env_infos/initial/end_effector_loc Min        -0.0483967
evaluation/env_infos/end_effector_loc Mean                0.0139834
evaluation/env_infos/end_effector_loc Std                 0.226306
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.115864
evaluation/env_infos/final/reward_dist Std                0.219652
evaluation/env_infos/final/reward_dist Max                0.940747
evaluation/env_infos/final/reward_dist Min                2.526e-78
evaluation/env_infos/initial/reward_dist Mean             0.00686431
evaluation/env_infos/initial/reward_dist Std              0.0126476
evaluation/env_infos/initial/reward_dist Max              0.0649746
evaluation/env_infos/initial/reward_dist Min              2.37375e-06
evaluation/env_infos/reward_dist Mean                     0.126838
evaluation/env_infos/reward_dist Std                      0.235084
evaluation/env_infos/reward_dist Max                      0.994678
evaluation/env_infos/reward_dist Min                      2.526e-78
time/data storing (s)                                    38.9916
time/evaluation sampling (s)                              1.13574
time/exploration sampling (s)                             0.0893796
time/logging (s)                                          0.0169688
time/saving (s)                                           0.823137
time/training (s)                                        39.4711
time/epoch (s)                                           80.5279
time/total (s)                                         9253.26
Epoch                                                   135
---------------------------------------------------  ----------------
2021-05-29 02:31:26.743597 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 136 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00276798
trainer/QF2 Loss                                          0.00302192
trainer/Policy Loss                                       3.14337
trainer/Q1 Predictions Mean                              -0.977511
trainer/Q1 Predictions Std                                0.777589
trainer/Q1 Predictions Max                                0.845269
trainer/Q1 Predictions Min                               -2.91994
trainer/Q2 Predictions Mean                              -0.976616
trainer/Q2 Predictions Std                                0.771663
trainer/Q2 Predictions Max                                0.794683
trainer/Q2 Predictions Min                               -2.93987
trainer/Q Targets Mean                                   -0.979818
trainer/Q Targets Std                                     0.775404
trainer/Q Targets Max                                     0.797085
trainer/Q Targets Min                                    -3.01445
trainer/Log Pis Mean                                      2.18197
trainer/Log Pis Std                                       1.07582
trainer/Log Pis Max                                       6.04665
trainer/Log Pis Min                                      -1.85105
trainer/Policy mu Mean                                   -0.0592792
trainer/Policy mu Std                                     0.466053
trainer/Policy mu Max                                     2.24267
trainer/Policy mu Min                                    -2.68368
trainer/Policy log std Mean                              -2.22923
trainer/Policy log std Std                                0.557144
trainer/Policy log std Max                               -0.337855
trainer/Policy log std Min                               -3.28523
trainer/Alpha                                             0.0185145
trainer/Alpha Loss                                        0.725849
exploration/num steps total                           14700
exploration/num paths total                             735
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.133913
exploration/Rewards Std                                   0.0877781
exploration/Rewards Max                                   0.0153502
exploration/Rewards Min                                  -0.578367
exploration/Returns Mean                                 -2.67826
exploration/Returns Std                                   0.741854
exploration/Returns Max                                  -1.81836
exploration/Returns Min                                  -3.89842
exploration/Actions Mean                                 -0.00942435
exploration/Actions Std                                   0.11103
exploration/Actions Max                                   0.360878
exploration/Actions Min                                  -0.636459
exploration/Num Paths                                     5
exploration/Average Returns                              -2.67826
exploration/env_infos/final/reward_energy Mean           -0.0824747
exploration/env_infos/final/reward_energy Std             0.0426552
exploration/env_infos/final/reward_energy Max            -0.0288275
exploration/env_infos/final/reward_energy Min            -0.153832
exploration/env_infos/initial/reward_energy Mean         -0.262826
exploration/env_infos/initial/reward_energy Std           0.207715
exploration/env_infos/initial/reward_energy Max          -0.0401731
exploration/env_infos/initial/reward_energy Min          -0.653921
exploration/env_infos/reward_energy Mean                 -0.12059
exploration/env_infos/reward_energy Std                   0.101445
exploration/env_infos/reward_energy Max                  -0.0106822
exploration/env_infos/reward_energy Min                  -0.653921
exploration/env_infos/final/end_effector_loc Mean        -0.193305
exploration/env_infos/final/end_effector_loc Std          0.318088
exploration/env_infos/final/end_effector_loc Max          0.264734
exploration/env_infos/final/end_effector_loc Min         -0.627367
exploration/env_infos/initial/end_effector_loc Mean      -0.00255118
exploration/env_infos/initial/end_effector_loc Std        0.0115659
exploration/env_infos/initial/end_effector_loc Max        0.00978012
exploration/env_infos/initial/end_effector_loc Min       -0.0318229
exploration/env_infos/end_effector_loc Mean              -0.0933091
exploration/env_infos/end_effector_loc Std                0.208106
exploration/env_infos/end_effector_loc Max                0.264734
exploration/env_infos/end_effector_loc Min               -0.627367
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              7.68672e-05
exploration/env_infos/final/reward_dist Std               0.000153323
exploration/env_infos/final/reward_dist Max               0.000383513
exploration/env_infos/final/reward_dist Min               9.55935e-16
exploration/env_infos/initial/reward_dist Mean            0.00224113
exploration/env_infos/initial/reward_dist Std             0.00438224
exploration/env_infos/initial/reward_dist Max             0.0110049
exploration/env_infos/initial/reward_dist Min             7.6875e-06
exploration/env_infos/reward_dist Mean                    0.0349845
exploration/env_infos/reward_dist Std                     0.108251
exploration/env_infos/reward_dist Max                     0.622429
exploration/env_infos/reward_dist Min                     9.55935e-16
evaluation/num steps total                           137000
evaluation/num paths total                             6850
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0968736
evaluation/Rewards Std                                    0.0972274
evaluation/Rewards Max                                    0.165138
evaluation/Rewards Min                                   -0.648938
evaluation/Returns Mean                                  -1.93747
evaluation/Returns Std                                    1.5366
evaluation/Returns Max                                    0.974977
evaluation/Returns Min                                   -6.58884
evaluation/Actions Mean                                  -0.00306985
evaluation/Actions Std                                    0.127652
evaluation/Actions Max                                    0.959774
evaluation/Actions Min                                   -0.957828
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.93747
evaluation/env_infos/final/reward_energy Mean            -0.0613058
evaluation/env_infos/final/reward_energy Std              0.109128
evaluation/env_infos/final/reward_energy Max             -0.00143046
evaluation/env_infos/final/reward_energy Min             -0.663449
evaluation/env_infos/initial/reward_energy Mean          -0.354492
evaluation/env_infos/initial/reward_energy Std            0.300119
evaluation/env_infos/initial/reward_energy Max           -0.0020923
evaluation/env_infos/initial/reward_energy Min           -0.993077
evaluation/env_infos/reward_energy Mean                  -0.103843
evaluation/env_infos/reward_energy Std                    0.147735
evaluation/env_infos/reward_energy Max                   -0.00123485
evaluation/env_infos/reward_energy Min                   -0.993077
evaluation/env_infos/final/end_effector_loc Mean         -0.0416569
evaluation/env_infos/final/end_effector_loc Std           0.344878
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.980676
evaluation/env_infos/initial/end_effector_loc Mean        0.000878285
evaluation/env_infos/initial/end_effector_loc Std         0.0163981
evaluation/env_infos/initial/end_effector_loc Max         0.0479887
evaluation/env_infos/initial/end_effector_loc Min        -0.0478914
evaluation/env_infos/end_effector_loc Mean               -0.00905625
evaluation/env_infos/end_effector_loc Std                 0.238852
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.980676
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0693983
evaluation/env_infos/final/reward_dist Std                0.180937
evaluation/env_infos/final/reward_dist Max                0.784141
evaluation/env_infos/final/reward_dist Min                1.29252e-90
evaluation/env_infos/initial/reward_dist Mean             0.00686725
evaluation/env_infos/initial/reward_dist Std              0.0228537
evaluation/env_infos/initial/reward_dist Max              0.156946
evaluation/env_infos/initial/reward_dist Min              5.05069e-07
evaluation/env_infos/reward_dist Mean                     0.0915737
evaluation/env_infos/reward_dist Std                      0.203504
evaluation/env_infos/reward_dist Max                      0.997475
evaluation/env_infos/reward_dist Min                      1.29252e-90
time/data storing (s)                                    38.382
time/evaluation sampling (s)                              0.722487
time/exploration sampling (s)                             0.0899814
time/logging (s)                                          0.0157681
time/saving (s)                                           0.795035
time/training (s)                                        38.8492
time/epoch (s)                                           78.8545
time/total (s)                                         9333.63
Epoch                                                   136
---------------------------------------------------  ----------------
2021-05-29 02:32:47.057587 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 137 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00300503
trainer/QF2 Loss                                          0.0037163
trainer/Policy Loss                                       2.86497
trainer/Q1 Predictions Mean                              -0.927737
trainer/Q1 Predictions Std                                0.76698
trainer/Q1 Predictions Max                                0.801569
trainer/Q1 Predictions Min                               -3.10935
trainer/Q2 Predictions Mean                              -0.923317
trainer/Q2 Predictions Std                                0.77027
trainer/Q2 Predictions Max                                0.827557
trainer/Q2 Predictions Min                               -3.06319
trainer/Q Targets Mean                                   -0.940135
trainer/Q Targets Std                                     0.767448
trainer/Q Targets Max                                     0.802206
trainer/Q Targets Min                                    -3.05005
trainer/Log Pis Mean                                      1.94577
trainer/Log Pis Std                                       1.1797
trainer/Log Pis Max                                       4.48093
trainer/Log Pis Min                                      -3.02142
trainer/Policy mu Mean                                   -0.0274909
trainer/Policy mu Std                                     0.428647
trainer/Policy mu Max                                     2.02016
trainer/Policy mu Min                                    -2.2897
trainer/Policy log std Mean                              -2.21915
trainer/Policy log std Std                                0.564493
trainer/Policy log std Max                                0.315183
trainer/Policy log std Min                               -3.37932
trainer/Alpha                                             0.0194191
trainer/Alpha Loss                                       -0.213627
exploration/num steps total                           14800
exploration/num paths total                             740
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.15722
exploration/Rewards Std                                   0.073506
exploration/Rewards Max                                  -0.0364829
exploration/Rewards Min                                  -0.385277
exploration/Returns Mean                                 -3.14439
exploration/Returns Std                                   0.957478
exploration/Returns Max                                  -2.12044
exploration/Returns Min                                  -4.82639
exploration/Actions Mean                                  0.00364195
exploration/Actions Std                                   0.110515
exploration/Actions Max                                   0.442081
exploration/Actions Min                                  -0.266441
exploration/Num Paths                                     5
exploration/Average Returns                              -3.14439
exploration/env_infos/final/reward_energy Mean           -0.135732
exploration/env_infos/final/reward_energy Std             0.0707025
exploration/env_infos/final/reward_energy Max            -0.0630716
exploration/env_infos/final/reward_energy Min            -0.229026
exploration/env_infos/initial/reward_energy Mean         -0.192588
exploration/env_infos/initial/reward_energy Std           0.0495458
exploration/env_infos/initial/reward_energy Max          -0.154264
exploration/env_infos/initial/reward_energy Min          -0.286985
exploration/env_infos/reward_energy Mean                 -0.1342
exploration/env_infos/reward_energy Std                   0.0802747
exploration/env_infos/reward_energy Max                  -0.0158662
exploration/env_infos/reward_energy Min                  -0.452464
exploration/env_infos/final/end_effector_loc Mean        -0.0395309
exploration/env_infos/final/end_effector_loc Std          0.430429
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.531688
exploration/env_infos/initial/end_effector_loc Mean      -0.00185673
exploration/env_infos/initial/end_effector_loc Std        0.00678113
exploration/env_infos/initial/end_effector_loc Max        0.0125182
exploration/env_infos/initial/end_effector_loc Min       -0.00787634
exploration/env_infos/end_effector_loc Mean              -0.0291505
exploration/env_infos/end_effector_loc Std                0.259444
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.531688
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              1.58632e-05
exploration/env_infos/final/reward_dist Std               2.69183e-05
exploration/env_infos/final/reward_dist Max               6.91246e-05
exploration/env_infos/final/reward_dist Min               1.71117e-45
exploration/env_infos/initial/reward_dist Mean            0.000433453
exploration/env_infos/initial/reward_dist Std             0.000573307
exploration/env_infos/initial/reward_dist Max             0.00142947
exploration/env_infos/initial/reward_dist Min             5.56656e-07
exploration/env_infos/reward_dist Mean                    0.0451247
exploration/env_infos/reward_dist Std                     0.157799
exploration/env_infos/reward_dist Max                     0.999085
exploration/env_infos/reward_dist Min                     1.71117e-45
evaluation/num steps total                           138000
evaluation/num paths total                             6900
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0932654
evaluation/Rewards Std                                    0.108331
evaluation/Rewards Max                                    0.143203
evaluation/Rewards Min                                   -0.663084
evaluation/Returns Mean                                  -1.86531
evaluation/Returns Std                                    1.82996
evaluation/Returns Max                                    1.65011
evaluation/Returns Min                                   -8.07146
evaluation/Actions Mean                                  -0.00543354
evaluation/Actions Std                                    0.113776
evaluation/Actions Max                                    0.613375
evaluation/Actions Min                                   -0.987116
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.86531
evaluation/env_infos/final/reward_energy Mean            -0.055966
evaluation/env_infos/final/reward_energy Std              0.0518796
evaluation/env_infos/final/reward_energy Max             -0.00747963
evaluation/env_infos/final/reward_energy Min             -0.292029
evaluation/env_infos/initial/reward_energy Mean          -0.297478
evaluation/env_infos/initial/reward_energy Std            0.287484
evaluation/env_infos/initial/reward_energy Max           -0.0141035
evaluation/env_infos/initial/reward_energy Min           -1.10583
evaluation/env_infos/reward_energy Mean                  -0.0960087
evaluation/env_infos/reward_energy Std                    0.12935
evaluation/env_infos/reward_energy Max                   -0.00181858
evaluation/env_infos/reward_energy Min                   -1.10583
evaluation/env_infos/final/end_effector_loc Mean         -0.0635573
evaluation/env_infos/final/end_effector_loc Std           0.316891
evaluation/env_infos/final/end_effector_loc Max           0.84322
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000614794
evaluation/env_infos/initial/end_effector_loc Std         0.0146133
evaluation/env_infos/initial/end_effector_loc Max         0.0287162
evaluation/env_infos/initial/end_effector_loc Min        -0.0493558
evaluation/env_infos/end_effector_loc Mean               -0.0275699
evaluation/env_infos/end_effector_loc Std                 0.211349
evaluation/env_infos/end_effector_loc Max                 0.84322
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0752367
evaluation/env_infos/final/reward_dist Std                0.180077
evaluation/env_infos/final/reward_dist Max                0.861557
evaluation/env_infos/final/reward_dist Min                2.61359e-74
evaluation/env_infos/initial/reward_dist Mean             0.00626784
evaluation/env_infos/initial/reward_dist Std              0.0135212
evaluation/env_infos/initial/reward_dist Max              0.0617954
evaluation/env_infos/initial/reward_dist Min              8.04182e-07
evaluation/env_infos/reward_dist Mean                     0.09924
evaluation/env_infos/reward_dist Std                      0.207092
evaluation/env_infos/reward_dist Max                      0.995732
evaluation/env_infos/reward_dist Min                      2.61359e-74
time/data storing (s)                                    38.8396
time/evaluation sampling (s)                              0.541313
time/exploration sampling (s)                             0.0898738
time/logging (s)                                          0.0151262
time/saving (s)                                           0.77301
time/training (s)                                        38.5553
time/epoch (s)                                           78.8143
time/total (s)                                         9413.94
Epoch                                                   137
---------------------------------------------------  ----------------
2021-05-29 02:34:07.430974 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 138 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00348651
trainer/QF2 Loss                                          0.00186499
trainer/Policy Loss                                       3.04125
trainer/Q1 Predictions Mean                              -0.900371
trainer/Q1 Predictions Std                                0.776506
trainer/Q1 Predictions Max                                0.793249
trainer/Q1 Predictions Min                               -2.9416
trainer/Q2 Predictions Mean                              -0.904224
trainer/Q2 Predictions Std                                0.781721
trainer/Q2 Predictions Max                                0.79318
trainer/Q2 Predictions Min                               -2.94521
trainer/Q Targets Mean                                   -0.903319
trainer/Q Targets Std                                     0.784854
trainer/Q Targets Max                                     0.855743
trainer/Q Targets Min                                    -2.96867
trainer/Log Pis Mean                                      2.15152
trainer/Log Pis Std                                       1.21235
trainer/Log Pis Max                                       5.20926
trainer/Log Pis Min                                      -3.69645
trainer/Policy mu Mean                                   -0.0530801
trainer/Policy mu Std                                     0.447691
trainer/Policy mu Max                                     1.70381
trainer/Policy mu Min                                    -2.79501
trainer/Policy log std Mean                              -2.29391
trainer/Policy log std Std                                0.536558
trainer/Policy log std Max                               -0.346485
trainer/Policy log std Min                               -3.12241
trainer/Alpha                                             0.0204859
trainer/Alpha Loss                                        0.589214
exploration/num steps total                           14900
exploration/num paths total                             745
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.119132
exploration/Rewards Std                                   0.0814061
exploration/Rewards Max                                   0.0240223
exploration/Rewards Min                                  -0.387242
exploration/Returns Mean                                 -2.38264
exploration/Returns Std                                   0.993674
exploration/Returns Max                                  -0.594697
exploration/Returns Min                                  -3.36917
exploration/Actions Mean                                 -0.00546489
exploration/Actions Std                                   0.146334
exploration/Actions Max                                   0.549594
exploration/Actions Min                                  -0.790451
exploration/Num Paths                                     5
exploration/Average Returns                              -2.38264
exploration/env_infos/final/reward_energy Mean           -0.0959806
exploration/env_infos/final/reward_energy Std             0.0386351
exploration/env_infos/final/reward_energy Max            -0.0534416
exploration/env_infos/final/reward_energy Min            -0.154819
exploration/env_infos/initial/reward_energy Mean         -0.301394
exploration/env_infos/initial/reward_energy Std           0.33598
exploration/env_infos/initial/reward_energy Max          -0.0622253
exploration/env_infos/initial/reward_energy Min          -0.96274
exploration/env_infos/reward_energy Mean                 -0.152538
exploration/env_infos/reward_energy Std                   0.14007
exploration/env_infos/reward_energy Max                  -0.0152299
exploration/env_infos/reward_energy Min                  -0.96274
exploration/env_infos/final/end_effector_loc Mean        -0.0236021
exploration/env_infos/final/end_effector_loc Std          0.338073
exploration/env_infos/final/end_effector_loc Max          0.394312
exploration/env_infos/final/end_effector_loc Min         -0.699617
exploration/env_infos/initial/end_effector_loc Mean       0.000415362
exploration/env_infos/initial/end_effector_loc Std        0.0159524
exploration/env_infos/initial/end_effector_loc Max        0.0274797
exploration/env_infos/initial/end_effector_loc Min       -0.0395226
exploration/env_infos/end_effector_loc Mean               0.00634015
exploration/env_infos/end_effector_loc Std                0.215611
exploration/env_infos/end_effector_loc Max                0.394312
exploration/env_infos/end_effector_loc Min               -0.699617
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.166571
exploration/env_infos/final/reward_dist Std               0.333141
exploration/env_infos/final/reward_dist Max               0.832853
exploration/env_infos/final/reward_dist Min               5.05909e-24
exploration/env_infos/initial/reward_dist Mean            0.00212158
exploration/env_infos/initial/reward_dist Std             0.00298778
exploration/env_infos/initial/reward_dist Max             0.00782576
exploration/env_infos/initial/reward_dist Min             6.5264e-06
exploration/env_infos/reward_dist Mean                    0.0909785
exploration/env_infos/reward_dist Std                     0.217875
exploration/env_infos/reward_dist Max                     0.832853
exploration/env_infos/reward_dist Min                     5.05909e-24
evaluation/num steps total                           139000
evaluation/num paths total                             6950
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.119451
evaluation/Rewards Std                                    0.112788
evaluation/Rewards Max                                    0.113131
evaluation/Rewards Min                                   -0.807095
evaluation/Returns Mean                                  -2.38902
evaluation/Returns Std                                    1.75834
evaluation/Returns Max                                    1.33473
evaluation/Returns Min                                   -7.43723
evaluation/Actions Mean                                   0.00945207
evaluation/Actions Std                                    0.126179
evaluation/Actions Max                                    0.720194
evaluation/Actions Min                                   -0.994927
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.38902
evaluation/env_infos/final/reward_energy Mean            -0.0686476
evaluation/env_infos/final/reward_energy Std              0.0933167
evaluation/env_infos/final/reward_energy Max             -0.00812515
evaluation/env_infos/final/reward_energy Min             -0.487462
evaluation/env_infos/initial/reward_energy Mean          -0.336517
evaluation/env_infos/initial/reward_energy Std            0.333946
evaluation/env_infos/initial/reward_energy Max           -0.0179648
evaluation/env_infos/initial/reward_energy Min           -1.22647
evaluation/env_infos/reward_energy Mean                  -0.107723
evaluation/env_infos/reward_energy Std                    0.142887
evaluation/env_infos/reward_energy Max                   -0.000891807
evaluation/env_infos/reward_energy Min                   -1.22647
evaluation/env_infos/final/end_effector_loc Mean          0.0123649
evaluation/env_infos/final/end_effector_loc Std           0.429276
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00299524
evaluation/env_infos/initial/end_effector_loc Std         0.0164919
evaluation/env_infos/initial/end_effector_loc Max         0.0360097
evaluation/env_infos/initial/end_effector_loc Min        -0.0497464
evaluation/env_infos/end_effector_loc Mean               -0.0221926
evaluation/env_infos/end_effector_loc Std                 0.283443
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0747131
evaluation/env_infos/final/reward_dist Std                0.206534
evaluation/env_infos/final/reward_dist Max                0.970158
evaluation/env_infos/final/reward_dist Min                5.19026e-154
evaluation/env_infos/initial/reward_dist Mean             0.00563529
evaluation/env_infos/initial/reward_dist Std              0.013969
evaluation/env_infos/initial/reward_dist Max              0.0845382
evaluation/env_infos/initial/reward_dist Min              9.93514e-07
evaluation/env_infos/reward_dist Mean                     0.07434
evaluation/env_infos/reward_dist Std                      0.185313
evaluation/env_infos/reward_dist Max                      0.990093
evaluation/env_infos/reward_dist Min                      5.19026e-154
time/data storing (s)                                    38.5755
time/evaluation sampling (s)                              0.564322
time/exploration sampling (s)                             0.0892023
time/logging (s)                                          0.0182064
time/saving (s)                                           0.83254
time/training (s)                                        38.8469
time/epoch (s)                                           78.9267
time/total (s)                                         9494.31
Epoch                                                   138
---------------------------------------------------  -----------------
2021-05-29 02:35:27.978153 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 139 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00705824
trainer/QF2 Loss                                          0.00326465
trainer/Policy Loss                                       2.83599
trainer/Q1 Predictions Mean                              -0.927073
trainer/Q1 Predictions Std                                0.791575
trainer/Q1 Predictions Max                                0.86158
trainer/Q1 Predictions Min                               -3.2499
trainer/Q2 Predictions Mean                              -0.926963
trainer/Q2 Predictions Std                                0.789019
trainer/Q2 Predictions Max                                0.840648
trainer/Q2 Predictions Min                               -3.22382
trainer/Q Targets Mean                                   -0.944517
trainer/Q Targets Std                                     0.792581
trainer/Q Targets Max                                     0.825137
trainer/Q Targets Min                                    -3.25644
trainer/Log Pis Mean                                      1.89945
trainer/Log Pis Std                                       1.37375
trainer/Log Pis Max                                       8.88362
trainer/Log Pis Min                                      -3.7351
trainer/Policy mu Mean                                   -0.061178
trainer/Policy mu Std                                     0.451947
trainer/Policy mu Max                                     1.68968
trainer/Policy mu Min                                    -3.76065
trainer/Policy log std Mean                              -2.2303
trainer/Policy log std Std                                0.539062
trainer/Policy log std Max                                0.0747067
trainer/Policy log std Min                               -3.20443
trainer/Alpha                                             0.0197646
trainer/Alpha Loss                                       -0.394496
exploration/num steps total                           15000
exploration/num paths total                             750
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0502908
exploration/Rewards Std                                   0.10916
exploration/Rewards Max                                   0.144028
exploration/Rewards Min                                  -0.310435
exploration/Returns Mean                                 -1.00582
exploration/Returns Std                                   1.68901
exploration/Returns Max                                   1.77178
exploration/Returns Min                                  -2.90172
exploration/Actions Mean                                 -0.00328559
exploration/Actions Std                                   0.19689
exploration/Actions Max                                   0.858961
exploration/Actions Min                                  -0.86864
exploration/Num Paths                                     5
exploration/Average Returns                              -1.00582
exploration/env_infos/final/reward_energy Mean           -0.200673
exploration/env_infos/final/reward_energy Std             0.118257
exploration/env_infos/final/reward_energy Max            -0.0511222
exploration/env_infos/final/reward_energy Min            -0.359302
exploration/env_infos/initial/reward_energy Mean         -0.669868
exploration/env_infos/initial/reward_energy Std           0.296278
exploration/env_infos/initial/reward_energy Max          -0.184496
exploration/env_infos/initial/reward_energy Min          -1.00344
exploration/env_infos/reward_energy Mean                 -0.212784
exploration/env_infos/reward_energy Std                   0.179655
exploration/env_infos/reward_energy Max                  -0.00877317
exploration/env_infos/reward_energy Min                  -1.00344
exploration/env_infos/final/end_effector_loc Mean        -0.0452609
exploration/env_infos/final/end_effector_loc Std          0.24298
exploration/env_infos/final/end_effector_loc Max          0.35272
exploration/env_infos/final/end_effector_loc Min         -0.424277
exploration/env_infos/initial/end_effector_loc Mean       0.00736328
exploration/env_infos/initial/end_effector_loc Std        0.0248276
exploration/env_infos/initial/end_effector_loc Max        0.042948
exploration/env_infos/initial/end_effector_loc Min       -0.043432
exploration/env_infos/end_effector_loc Mean              -0.00713358
exploration/env_infos/end_effector_loc Std                0.190199
exploration/env_infos/end_effector_loc Max                0.35272
exploration/env_infos/end_effector_loc Min               -0.427372
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.427861
exploration/env_infos/final/reward_dist Std               0.420791
exploration/env_infos/final/reward_dist Max               0.967418
exploration/env_infos/final/reward_dist Min               1.08983e-16
exploration/env_infos/initial/reward_dist Mean            0.0139067
exploration/env_infos/initial/reward_dist Std             0.0110638
exploration/env_infos/initial/reward_dist Max             0.0298769
exploration/env_infos/initial/reward_dist Min             0.00116713
exploration/env_infos/reward_dist Mean                    0.262948
exploration/env_infos/reward_dist Std                     0.330156
exploration/env_infos/reward_dist Max                     0.967418
exploration/env_infos/reward_dist Min                     1.08983e-16
evaluation/num steps total                           140000
evaluation/num paths total                             7000
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0958718
evaluation/Rewards Std                                    0.103083
evaluation/Rewards Max                                    0.120725
evaluation/Rewards Min                                   -0.591371
evaluation/Returns Mean                                  -1.91744
evaluation/Returns Std                                    1.64649
evaluation/Returns Max                                    1.10919
evaluation/Returns Min                                   -8.23284
evaluation/Actions Mean                                   0.00143841
evaluation/Actions Std                                    0.103688
evaluation/Actions Max                                    0.933615
evaluation/Actions Min                                   -0.820963
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.91744
evaluation/env_infos/final/reward_energy Mean            -0.0573647
evaluation/env_infos/final/reward_energy Std              0.0617752
evaluation/env_infos/final/reward_energy Max             -0.000248891
evaluation/env_infos/final/reward_energy Min             -0.254731
evaluation/env_infos/initial/reward_energy Mean          -0.281808
evaluation/env_infos/initial/reward_energy Std            0.269329
evaluation/env_infos/initial/reward_energy Max           -0.0106716
evaluation/env_infos/initial/reward_energy Min           -0.936651
evaluation/env_infos/reward_energy Mean                  -0.0886437
evaluation/env_infos/reward_energy Std                    0.116827
evaluation/env_infos/reward_energy Max                   -0.000248891
evaluation/env_infos/reward_energy Min                   -0.936651
evaluation/env_infos/final/end_effector_loc Mean         -0.030646
evaluation/env_infos/final/end_effector_loc Std           0.360185
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00192355
evaluation/env_infos/initial/end_effector_loc Std         0.0136471
evaluation/env_infos/initial/end_effector_loc Max         0.0466808
evaluation/env_infos/initial/end_effector_loc Min        -0.0410482
evaluation/env_infos/end_effector_loc Mean               -0.0257318
evaluation/env_infos/end_effector_loc Std                 0.238417
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.120334
evaluation/env_infos/final/reward_dist Std                0.238157
evaluation/env_infos/final/reward_dist Max                0.929915
evaluation/env_infos/final/reward_dist Min                8.72317e-143
evaluation/env_infos/initial/reward_dist Mean             0.00517516
evaluation/env_infos/initial/reward_dist Std              0.0108406
evaluation/env_infos/initial/reward_dist Max              0.0441505
evaluation/env_infos/initial/reward_dist Min              2.06278e-06
evaluation/env_infos/reward_dist Mean                     0.0990329
evaluation/env_infos/reward_dist Std                      0.210576
evaluation/env_infos/reward_dist Max                      0.975384
evaluation/env_infos/reward_dist Min                      8.72317e-143
time/data storing (s)                                    38.4788
time/evaluation sampling (s)                              0.651544
time/exploration sampling (s)                             0.0919071
time/logging (s)                                          0.015436
time/saving (s)                                           0.802079
time/training (s)                                        38.9354
time/epoch (s)                                           78.9752
time/total (s)                                         9574.85
Epoch                                                   139
---------------------------------------------------  -----------------
2021-05-29 02:36:48.570395 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 140 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00316247
trainer/QF2 Loss                                          0.00225254
trainer/Policy Loss                                       2.73853
trainer/Q1 Predictions Mean                              -0.947347
trainer/Q1 Predictions Std                                0.841785
trainer/Q1 Predictions Max                                0.879755
trainer/Q1 Predictions Min                               -3.34681
trainer/Q2 Predictions Mean                              -0.961868
trainer/Q2 Predictions Std                                0.838446
trainer/Q2 Predictions Max                                0.832816
trainer/Q2 Predictions Min                               -3.35597
trainer/Q Targets Mean                                   -0.953568
trainer/Q Targets Std                                     0.848772
trainer/Q Targets Max                                     0.831783
trainer/Q Targets Min                                    -3.36588
trainer/Log Pis Mean                                      1.81019
trainer/Log Pis Std                                       1.30813
trainer/Log Pis Max                                       6.50603
trainer/Log Pis Min                                      -3.08756
trainer/Policy mu Mean                                    0.00287739
trainer/Policy mu Std                                     0.49335
trainer/Policy mu Max                                     2.20221
trainer/Policy mu Min                                    -2.73191
trainer/Policy log std Mean                              -2.15011
trainer/Policy log std Std                                0.544853
trainer/Policy log std Max                                0.414032
trainer/Policy log std Min                               -3.28001
trainer/Alpha                                             0.0180357
trainer/Alpha Loss                                       -0.761988
exploration/num steps total                           15100
exploration/num paths total                             755
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.142358
exploration/Rewards Std                                   0.204233
exploration/Rewards Max                                   0.0345391
exploration/Rewards Min                                  -1.09281
exploration/Returns Mean                                 -2.84715
exploration/Returns Std                                   2.9365
exploration/Returns Max                                  -0.133292
exploration/Returns Min                                  -8.49915
exploration/Actions Mean                                 -0.0259637
exploration/Actions Std                                   0.161644
exploration/Actions Max                                   0.352874
exploration/Actions Min                                  -0.788537
exploration/Num Paths                                     5
exploration/Average Returns                              -2.84715
exploration/env_infos/final/reward_energy Mean           -0.244182
exploration/env_infos/final/reward_energy Std             0.297112
exploration/env_infos/final/reward_energy Max            -0.0628998
exploration/env_infos/final/reward_energy Min            -0.835018
exploration/env_infos/initial/reward_energy Mean         -0.206606
exploration/env_infos/initial/reward_energy Std           0.16445
exploration/env_infos/initial/reward_energy Max          -0.0145801
exploration/env_infos/initial/reward_energy Min          -0.474426
exploration/env_infos/reward_energy Mean                 -0.164102
exploration/env_infos/reward_energy Std                   0.163329
exploration/env_infos/reward_energy Max                  -0.00484371
exploration/env_infos/reward_energy Min                  -0.891495
exploration/env_infos/final/end_effector_loc Mean        -0.0718622
exploration/env_infos/final/end_effector_loc Std          0.369842
exploration/env_infos/final/end_effector_loc Max          0.366037
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00493294
exploration/env_infos/initial/end_effector_loc Std        0.00792643
exploration/env_infos/initial/end_effector_loc Max        0.007717
exploration/env_infos/initial/end_effector_loc Min       -0.0216049
exploration/env_infos/end_effector_loc Mean              -0.00956378
exploration/env_infos/end_effector_loc Std                0.212011
exploration/env_infos/end_effector_loc Max                0.585243
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0044492
exploration/env_infos/final/reward_dist Std               0.0065926
exploration/env_infos/final/reward_dist Max               0.0171237
exploration/env_infos/final/reward_dist Min               2.25486e-84
exploration/env_infos/initial/reward_dist Mean            0.00324678
exploration/env_infos/initial/reward_dist Std             0.00469176
exploration/env_infos/initial/reward_dist Max             0.0122019
exploration/env_infos/initial/reward_dist Min             2.50118e-05
exploration/env_infos/reward_dist Mean                    0.0795772
exploration/env_infos/reward_dist Std                     0.21619
exploration/env_infos/reward_dist Max                     0.884059
exploration/env_infos/reward_dist Min                     2.25486e-84
evaluation/num steps total                           141000
evaluation/num paths total                             7050
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0987611
evaluation/Rewards Std                                    0.127684
evaluation/Rewards Max                                    0.161234
evaluation/Rewards Min                                   -1.0118
evaluation/Returns Mean                                  -1.97522
evaluation/Returns Std                                    1.94987
evaluation/Returns Max                                    1.80322
evaluation/Returns Min                                   -8.76216
evaluation/Actions Mean                                  -0.00222456
evaluation/Actions Std                                    0.116694
evaluation/Actions Max                                    0.867639
evaluation/Actions Min                                   -0.999873
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.97522
evaluation/env_infos/final/reward_energy Mean            -0.0977829
evaluation/env_infos/final/reward_energy Std              0.18809
evaluation/env_infos/final/reward_energy Max             -0.00874058
evaluation/env_infos/final/reward_energy Min             -1.35095
evaluation/env_infos/initial/reward_energy Mean          -0.248592
evaluation/env_infos/initial/reward_energy Std            0.269415
evaluation/env_infos/initial/reward_energy Max           -0.0142753
evaluation/env_infos/initial/reward_energy Min           -1.19569
evaluation/env_infos/reward_energy Mean                  -0.0940794
evaluation/env_infos/reward_energy Std                    0.135624
evaluation/env_infos/reward_energy Max                   -0.00142219
evaluation/env_infos/reward_energy Min                   -1.41101
evaluation/env_infos/final/end_effector_loc Mean         -0.00219026
evaluation/env_infos/final/end_effector_loc Std           0.444771
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000692405
evaluation/env_infos/initial/end_effector_loc Std         0.0129421
evaluation/env_infos/initial/end_effector_loc Max         0.043382
evaluation/env_infos/initial/end_effector_loc Min        -0.0480888
evaluation/env_infos/end_effector_loc Mean                0.00737908
evaluation/env_infos/end_effector_loc Std                 0.278037
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0889763
evaluation/env_infos/final/reward_dist Std                0.199583
evaluation/env_infos/final/reward_dist Max                0.918595
evaluation/env_infos/final/reward_dist Min                8.39064e-154
evaluation/env_infos/initial/reward_dist Mean             0.00437698
evaluation/env_infos/initial/reward_dist Std              0.00851789
evaluation/env_infos/initial/reward_dist Max              0.044156
evaluation/env_infos/initial/reward_dist Min              1.06605e-06
evaluation/env_infos/reward_dist Mean                     0.112839
evaluation/env_infos/reward_dist Std                      0.220109
evaluation/env_infos/reward_dist Max                      0.999722
evaluation/env_infos/reward_dist Min                      1.71761e-157
time/data storing (s)                                    38.3922
time/evaluation sampling (s)                              0.671436
time/exploration sampling (s)                             0.0892157
time/logging (s)                                          0.0164594
time/saving (s)                                           0.800629
time/training (s)                                        39.0929
time/epoch (s)                                           79.0628
time/total (s)                                         9655.44
Epoch                                                   140
---------------------------------------------------  -----------------
2021-05-29 02:38:08.738951 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 141 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00295687
trainer/QF2 Loss                                          0.00242968
trainer/Policy Loss                                       2.80008
trainer/Q1 Predictions Mean                              -0.879797
trainer/Q1 Predictions Std                                0.793051
trainer/Q1 Predictions Max                                0.84141
trainer/Q1 Predictions Min                               -3.35425
trainer/Q2 Predictions Mean                              -0.888457
trainer/Q2 Predictions Std                                0.789914
trainer/Q2 Predictions Max                                0.839716
trainer/Q2 Predictions Min                               -3.33009
trainer/Q Targets Mean                                   -0.889089
trainer/Q Targets Std                                     0.793606
trainer/Q Targets Max                                     0.82752
trainer/Q Targets Min                                    -3.38202
trainer/Log Pis Mean                                      1.9285
trainer/Log Pis Std                                       1.18848
trainer/Log Pis Max                                       4.59074
trainer/Log Pis Min                                      -2.03832
trainer/Policy mu Mean                                   -0.0143255
trainer/Policy mu Std                                     0.48069
trainer/Policy mu Max                                     2.5488
trainer/Policy mu Min                                    -2.42659
trainer/Policy log std Mean                              -2.20624
trainer/Policy log std Std                                0.537703
trainer/Policy log std Max                                0.457605
trainer/Policy log std Min                               -3.15837
trainer/Alpha                                             0.0184216
trainer/Alpha Loss                                       -0.285665
exploration/num steps total                           15200
exploration/num paths total                             760
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.110386
exploration/Rewards Std                                   0.09477
exploration/Rewards Max                                   0.127446
exploration/Rewards Min                                  -0.361139
exploration/Returns Mean                                 -2.20773
exploration/Returns Std                                   1.59883
exploration/Returns Max                                   0.666409
exploration/Returns Min                                  -3.6301
exploration/Actions Mean                                 -0.00481374
exploration/Actions Std                                   0.107517
exploration/Actions Max                                   0.351114
exploration/Actions Min                                  -0.45352
exploration/Num Paths                                     5
exploration/Average Returns                              -2.20773
exploration/env_infos/final/reward_energy Mean           -0.135106
exploration/env_infos/final/reward_energy Std             0.0854865
exploration/env_infos/final/reward_energy Max            -0.0493902
exploration/env_infos/final/reward_energy Min            -0.288152
exploration/env_infos/initial/reward_energy Mean         -0.113789
exploration/env_infos/initial/reward_energy Std           0.132087
exploration/env_infos/initial/reward_energy Max          -0.0102742
exploration/env_infos/initial/reward_energy Min          -0.374626
exploration/env_infos/reward_energy Mean                 -0.120603
exploration/env_infos/reward_energy Std                   0.0928491
exploration/env_infos/reward_energy Max                  -0.00826044
exploration/env_infos/reward_energy Min                  -0.598104
exploration/env_infos/final/end_effector_loc Mean         0.0311885
exploration/env_infos/final/end_effector_loc Std          0.230569
exploration/env_infos/final/end_effector_loc Max          0.367489
exploration/env_infos/final/end_effector_loc Min         -0.290955
exploration/env_infos/initial/end_effector_loc Mean       0.00171705
exploration/env_infos/initial/end_effector_loc Std        0.00591989
exploration/env_infos/initial/end_effector_loc Max        0.0175557
exploration/env_infos/initial/end_effector_loc Min       -0.00349714
exploration/env_infos/end_effector_loc Mean               0.0236947
exploration/env_infos/end_effector_loc Std                0.157767
exploration/env_infos/end_effector_loc Max                0.367489
exploration/env_infos/end_effector_loc Min               -0.290955
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0102783
exploration/env_infos/final/reward_dist Std               0.0197551
exploration/env_infos/final/reward_dist Max               0.0497786
exploration/env_infos/final/reward_dist Min               8.46089e-16
exploration/env_infos/initial/reward_dist Mean            0.00618323
exploration/env_infos/initial/reward_dist Std             0.00592616
exploration/env_infos/initial/reward_dist Max             0.0152881
exploration/env_infos/initial/reward_dist Min             0.000995142
exploration/env_infos/reward_dist Mean                    0.0569279
exploration/env_infos/reward_dist Std                     0.164148
exploration/env_infos/reward_dist Max                     0.944945
exploration/env_infos/reward_dist Min                     5.25235e-17
evaluation/num steps total                           142000
evaluation/num paths total                             7100
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0757686
evaluation/Rewards Std                                    0.120149
evaluation/Rewards Max                                    0.148763
evaluation/Rewards Min                                   -1.41865
evaluation/Returns Mean                                  -1.51537
evaluation/Returns Std                                    1.6031
evaluation/Returns Max                                    2.08551
evaluation/Returns Min                                   -5.95435
evaluation/Actions Mean                                  -0.0103375
evaluation/Actions Std                                    0.114632
evaluation/Actions Max                                    0.820056
evaluation/Actions Min                                   -0.993939
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.51537
evaluation/env_infos/final/reward_energy Mean            -0.113708
evaluation/env_infos/final/reward_energy Std              0.208015
evaluation/env_infos/final/reward_energy Max             -0.00402498
evaluation/env_infos/final/reward_energy Min             -1.38215
evaluation/env_infos/initial/reward_energy Mean          -0.236398
evaluation/env_infos/initial/reward_energy Std            0.235346
evaluation/env_infos/initial/reward_energy Max           -0.0148309
evaluation/env_infos/initial/reward_energy Min           -0.997411
evaluation/env_infos/reward_energy Mean                  -0.0859297
evaluation/env_infos/reward_energy Std                    0.138242
evaluation/env_infos/reward_energy Max                   -0.00313898
evaluation/env_infos/reward_energy Min                   -1.38215
evaluation/env_infos/final/end_effector_loc Mean          0.0517993
evaluation/env_infos/final/end_effector_loc Std           0.329633
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00272793
evaluation/env_infos/initial/end_effector_loc Std         0.0114738
evaluation/env_infos/initial/end_effector_loc Max         0.0410028
evaluation/env_infos/initial/end_effector_loc Min        -0.0302285
evaluation/env_infos/end_effector_loc Mean                0.0455384
evaluation/env_infos/end_effector_loc Std                 0.191023
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0962482
evaluation/env_infos/final/reward_dist Std                0.214663
evaluation/env_infos/final/reward_dist Max                0.985807
evaluation/env_infos/final/reward_dist Min                9.80417e-138
evaluation/env_infos/initial/reward_dist Mean             0.00748393
evaluation/env_infos/initial/reward_dist Std              0.0198718
evaluation/env_infos/initial/reward_dist Max              0.114155
evaluation/env_infos/initial/reward_dist Min              1.72605e-06
evaluation/env_infos/reward_dist Mean                     0.127137
evaluation/env_infos/reward_dist Std                      0.251277
evaluation/env_infos/reward_dist Max                      0.999551
evaluation/env_infos/reward_dist Min                      9.80417e-138
time/data storing (s)                                    38.6885
time/evaluation sampling (s)                              0.649955
time/exploration sampling (s)                             0.0872747
time/logging (s)                                          0.0159765
time/saving (s)                                           0.79657
time/training (s)                                        38.4004
time/epoch (s)                                           78.6386
time/total (s)                                         9735.6
Epoch                                                   141
---------------------------------------------------  -----------------
2021-05-29 02:39:28.977875 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 142 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00200338
trainer/QF2 Loss                                          0.00191929
trainer/Policy Loss                                       2.82176
trainer/Q1 Predictions Mean                              -0.916659
trainer/Q1 Predictions Std                                0.875425
trainer/Q1 Predictions Max                                1.02656
trainer/Q1 Predictions Min                               -3.34941
trainer/Q2 Predictions Mean                              -0.924535
trainer/Q2 Predictions Std                                0.87564
trainer/Q2 Predictions Max                                1.03981
trainer/Q2 Predictions Min                               -3.28483
trainer/Q Targets Mean                                   -0.922717
trainer/Q Targets Std                                     0.878172
trainer/Q Targets Max                                     0.993554
trainer/Q Targets Min                                    -3.35421
trainer/Log Pis Mean                                      1.90598
trainer/Log Pis Std                                       1.20761
trainer/Log Pis Max                                       4.05159
trainer/Log Pis Min                                      -1.68732
trainer/Policy mu Mean                                   -0.00103672
trainer/Policy mu Std                                     0.339306
trainer/Policy mu Max                                     1.35311
trainer/Policy mu Min                                    -1.80435
trainer/Policy log std Mean                              -2.26472
trainer/Policy log std Std                                0.503046
trainer/Policy log std Max                               -0.658584
trainer/Policy log std Min                               -3.25835
trainer/Alpha                                             0.0196629
trainer/Alpha Loss                                       -0.369523
exploration/num steps total                           15300
exploration/num paths total                             765
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0411793
exploration/Rewards Std                                   0.0729221
exploration/Rewards Max                                   0.0900191
exploration/Rewards Min                                  -0.284605
exploration/Returns Mean                                 -0.823587
exploration/Returns Std                                   1.062
exploration/Returns Max                                   0.731878
exploration/Returns Min                                  -1.96388
exploration/Actions Mean                                 -0.00596643
exploration/Actions Std                                   0.120838
exploration/Actions Max                                   0.73386
exploration/Actions Min                                  -0.371138
exploration/Num Paths                                     5
exploration/Average Returns                              -0.823587
exploration/env_infos/final/reward_energy Mean           -0.100025
exploration/env_infos/final/reward_energy Std             0.0682784
exploration/env_infos/final/reward_energy Max            -0.058386
exploration/env_infos/final/reward_energy Min            -0.235643
exploration/env_infos/initial/reward_energy Mean         -0.344214
exploration/env_infos/initial/reward_energy Std           0.277654
exploration/env_infos/initial/reward_energy Max          -0.06088
exploration/env_infos/initial/reward_energy Min          -0.822371
exploration/env_infos/reward_energy Mean                 -0.130434
exploration/env_infos/reward_energy Std                   0.110732
exploration/env_infos/reward_energy Max                  -0.0213977
exploration/env_infos/reward_energy Min                  -0.822371
exploration/env_infos/final/end_effector_loc Mean        -0.0183803
exploration/env_infos/final/end_effector_loc Std          0.175436
exploration/env_infos/final/end_effector_loc Max          0.313363
exploration/env_infos/final/end_effector_loc Min         -0.319202
exploration/env_infos/initial/end_effector_loc Mean       0.00366278
exploration/env_infos/initial/end_effector_loc Std        0.0152004
exploration/env_infos/initial/end_effector_loc Max        0.036693
exploration/env_infos/initial/end_effector_loc Min       -0.0185569
exploration/env_infos/end_effector_loc Mean               0.0137266
exploration/env_infos/end_effector_loc Std                0.124585
exploration/env_infos/end_effector_loc Max                0.313363
exploration/env_infos/end_effector_loc Min               -0.319202
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.201937
exploration/env_infos/final/reward_dist Std               0.187797
exploration/env_infos/final/reward_dist Max               0.510339
exploration/env_infos/final/reward_dist Min               0.00386468
exploration/env_infos/initial/reward_dist Mean            0.00756041
exploration/env_infos/initial/reward_dist Std             0.00969491
exploration/env_infos/initial/reward_dist Max             0.0240075
exploration/env_infos/initial/reward_dist Min             1.13271e-05
exploration/env_infos/reward_dist Mean                    0.185492
exploration/env_infos/reward_dist Std                     0.222471
exploration/env_infos/reward_dist Max                     0.909497
exploration/env_infos/reward_dist Min                     1.13271e-05
evaluation/num steps total                           143000
evaluation/num paths total                             7150
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0930406
evaluation/Rewards Std                                    0.133202
evaluation/Rewards Max                                    0.174991
evaluation/Rewards Min                                   -0.794806
evaluation/Returns Mean                                  -1.86081
evaluation/Returns Std                                    2.32868
evaluation/Returns Max                                    1.85861
evaluation/Returns Min                                   -8.95333
evaluation/Actions Mean                                   0.00140778
evaluation/Actions Std                                    0.125067
evaluation/Actions Max                                    0.915103
evaluation/Actions Min                                   -0.934309
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.86081
evaluation/env_infos/final/reward_energy Mean            -0.0753567
evaluation/env_infos/final/reward_energy Std              0.113683
evaluation/env_infos/final/reward_energy Max             -0.007111
evaluation/env_infos/final/reward_energy Min             -0.627213
evaluation/env_infos/initial/reward_energy Mean          -0.280892
evaluation/env_infos/initial/reward_energy Std            0.237692
evaluation/env_infos/initial/reward_energy Max           -0.0133712
evaluation/env_infos/initial/reward_energy Min           -0.845033
evaluation/env_infos/reward_energy Mean                  -0.101639
evaluation/env_infos/reward_energy Std                    0.144765
evaluation/env_infos/reward_energy Max                   -0.00275111
evaluation/env_infos/reward_energy Min                   -0.995144
evaluation/env_infos/final/end_effector_loc Mean          0.00567906
evaluation/env_infos/final/end_effector_loc Std           0.386278
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000251983
evaluation/env_infos/initial/end_effector_loc Std         0.0130071
evaluation/env_infos/initial/end_effector_loc Max         0.0413379
evaluation/env_infos/initial/end_effector_loc Min        -0.0348402
evaluation/env_infos/end_effector_loc Mean                0.00680049
evaluation/env_infos/end_effector_loc Std                 0.256653
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.109294
evaluation/env_infos/final/reward_dist Std                0.244442
evaluation/env_infos/final/reward_dist Max                0.956669
evaluation/env_infos/final/reward_dist Min                3.15165e-141
evaluation/env_infos/initial/reward_dist Mean             0.0106362
evaluation/env_infos/initial/reward_dist Std              0.0203216
evaluation/env_infos/initial/reward_dist Max              0.123778
evaluation/env_infos/initial/reward_dist Min              1.39405e-06
evaluation/env_infos/reward_dist Mean                     0.130456
evaluation/env_infos/reward_dist Std                      0.250228
evaluation/env_infos/reward_dist Max                      0.999993
evaluation/env_infos/reward_dist Min                      3.15165e-141
time/data storing (s)                                    38.3993
time/evaluation sampling (s)                              0.647783
time/exploration sampling (s)                             0.0882928
time/logging (s)                                          0.0168376
time/saving (s)                                           0.777549
time/training (s)                                        38.7204
time/epoch (s)                                           78.6502
time/total (s)                                         9815.83
Epoch                                                   142
---------------------------------------------------  -----------------
2021-05-29 02:40:50.143110 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 143 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00198139
trainer/QF2 Loss                                          0.00351314
trainer/Policy Loss                                       3.04313
trainer/Q1 Predictions Mean                              -0.936153
trainer/Q1 Predictions Std                                0.822347
trainer/Q1 Predictions Max                                1.06496
trainer/Q1 Predictions Min                               -3.42939
trainer/Q2 Predictions Mean                              -0.933948
trainer/Q2 Predictions Std                                0.829315
trainer/Q2 Predictions Max                                1.04138
trainer/Q2 Predictions Min                               -3.46054
trainer/Q Targets Mean                                   -0.928787
trainer/Q Targets Std                                     0.824293
trainer/Q Targets Max                                     1.11822
trainer/Q Targets Min                                    -3.52157
trainer/Log Pis Mean                                      2.11426
trainer/Log Pis Std                                       1.18935
trainer/Log Pis Max                                       4.83038
trainer/Log Pis Min                                      -2.62853
trainer/Policy mu Mean                                    0.0407935
trainer/Policy mu Std                                     0.355394
trainer/Policy mu Max                                     2.37475
trainer/Policy mu Min                                    -1.83657
trainer/Policy log std Mean                              -2.31963
trainer/Policy log std Std                                0.54066
trainer/Policy log std Max                               -0.223084
trainer/Policy log std Min                               -3.42582
trainer/Alpha                                             0.0204146
trainer/Alpha Loss                                        0.444859
exploration/num steps total                           15400
exploration/num paths total                             770
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.23492
exploration/Rewards Std                                   0.315803
exploration/Rewards Max                                   0.0581372
exploration/Rewards Min                                  -1.13501
exploration/Returns Mean                                 -4.6984
exploration/Returns Std                                   6.08154
exploration/Returns Max                                  -0.316293
exploration/Returns Min                                 -16.7761
exploration/Actions Mean                                  0.0313267
exploration/Actions Std                                   0.218349
exploration/Actions Max                                   0.89126
exploration/Actions Min                                  -0.497691
exploration/Num Paths                                     5
exploration/Average Returns                              -4.6984
exploration/env_infos/final/reward_energy Mean           -0.0993298
exploration/env_infos/final/reward_energy Std             0.0647747
exploration/env_infos/final/reward_energy Max            -0.014645
exploration/env_infos/final/reward_energy Min            -0.189741
exploration/env_infos/initial/reward_energy Mean         -0.376656
exploration/env_infos/initial/reward_energy Std           0.315926
exploration/env_infos/initial/reward_energy Max          -0.0410307
exploration/env_infos/initial/reward_energy Min          -0.802052
exploration/env_infos/reward_energy Mean                 -0.21352
exploration/env_infos/reward_energy Std                   0.227431
exploration/env_infos/reward_energy Max                  -0.00344941
exploration/env_infos/reward_energy Min                  -0.916161
exploration/env_infos/final/end_effector_loc Mean         0.0507181
exploration/env_infos/final/end_effector_loc Std          0.381894
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.367277
exploration/env_infos/initial/end_effector_loc Mean       0.00135008
exploration/env_infos/initial/end_effector_loc Std        0.0173285
exploration/env_infos/initial/end_effector_loc Max        0.0377941
exploration/env_infos/initial/end_effector_loc Min       -0.0248846
exploration/env_infos/end_effector_loc Mean               0.0642636
exploration/env_infos/end_effector_loc Std                0.296062
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.367277
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.143803
exploration/env_infos/final/reward_dist Std               0.243279
exploration/env_infos/final/reward_dist Max               0.624904
exploration/env_infos/final/reward_dist Min               1.62304e-113
exploration/env_infos/initial/reward_dist Mean            0.0135844
exploration/env_infos/initial/reward_dist Std             0.0247546
exploration/env_infos/initial/reward_dist Max             0.0630425
exploration/env_infos/initial/reward_dist Min             6.52846e-08
exploration/env_infos/reward_dist Mean                    0.089847
exploration/env_infos/reward_dist Std                     0.180644
exploration/env_infos/reward_dist Max                     0.751725
exploration/env_infos/reward_dist Min                     1.33664e-116
evaluation/num steps total                           144000
evaluation/num paths total                             7200
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.119013
evaluation/Rewards Std                                    0.171064
evaluation/Rewards Max                                    0.121948
evaluation/Rewards Min                                   -0.950309
evaluation/Returns Mean                                  -2.38026
evaluation/Returns Std                                    3.12443
evaluation/Returns Max                                    1.60722
evaluation/Returns Min                                  -16.1781
evaluation/Actions Mean                                   0.0118761
evaluation/Actions Std                                    0.158656
evaluation/Actions Max                                    0.971906
evaluation/Actions Min                                   -0.939264
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.38026
evaluation/env_infos/final/reward_energy Mean            -0.0993628
evaluation/env_infos/final/reward_energy Std              0.132215
evaluation/env_infos/final/reward_energy Max             -0.00509785
evaluation/env_infos/final/reward_energy Min             -0.774283
evaluation/env_infos/initial/reward_energy Mean          -0.291779
evaluation/env_infos/initial/reward_energy Std            0.301021
evaluation/env_infos/initial/reward_energy Max           -0.0165687
evaluation/env_infos/initial/reward_energy Min           -1.17219
evaluation/env_infos/reward_energy Mean                  -0.124827
evaluation/env_infos/reward_energy Std                    0.1872
evaluation/env_infos/reward_energy Max                   -0.00258796
evaluation/env_infos/reward_energy Min                   -1.17219
evaluation/env_infos/final/end_effector_loc Mean          0.0311029
evaluation/env_infos/final/end_effector_loc Std           0.414198
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000213737
evaluation/env_infos/initial/end_effector_loc Std         0.0148202
evaluation/env_infos/initial/end_effector_loc Max         0.0434562
evaluation/env_infos/initial/end_effector_loc Min        -0.0469632
evaluation/env_infos/end_effector_loc Mean                0.0226522
evaluation/env_infos/end_effector_loc Std                 0.295597
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0905273
evaluation/env_infos/final/reward_dist Std                0.183453
evaluation/env_infos/final/reward_dist Max                0.72496
evaluation/env_infos/final/reward_dist Min                2.13189e-128
evaluation/env_infos/initial/reward_dist Mean             0.00680114
evaluation/env_infos/initial/reward_dist Std              0.015862
evaluation/env_infos/initial/reward_dist Max              0.0835735
evaluation/env_infos/initial/reward_dist Min              1.31183e-06
evaluation/env_infos/reward_dist Mean                     0.102836
evaluation/env_infos/reward_dist Std                      0.208688
evaluation/env_infos/reward_dist Max                      0.997691
evaluation/env_infos/reward_dist Min                      2.13189e-128
time/data storing (s)                                    38.3603
time/evaluation sampling (s)                              0.650929
time/exploration sampling (s)                             0.0855495
time/logging (s)                                          0.0171473
time/saving (s)                                           1.02703
time/training (s)                                        39.4742
time/epoch (s)                                           79.6152
time/total (s)                                         9896.99
Epoch                                                   143
---------------------------------------------------  -----------------
2021-05-29 02:42:10.926257 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 144 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00188699
trainer/QF2 Loss                                          0.00331252
trainer/Policy Loss                                       2.71323
trainer/Q1 Predictions Mean                              -0.90589
trainer/Q1 Predictions Std                                0.805084
trainer/Q1 Predictions Max                                0.789947
trainer/Q1 Predictions Min                               -3.01347
trainer/Q2 Predictions Mean                              -0.894994
trainer/Q2 Predictions Std                                0.814909
trainer/Q2 Predictions Max                                0.840963
trainer/Q2 Predictions Min                               -3.0253
trainer/Q Targets Mean                                   -0.901001
trainer/Q Targets Std                                     0.808999
trainer/Q Targets Max                                     0.837974
trainer/Q Targets Min                                    -3.03422
trainer/Log Pis Mean                                      1.802
trainer/Log Pis Std                                       1.28253
trainer/Log Pis Max                                       4.27884
trainer/Log Pis Min                                      -2.58972
trainer/Policy mu Mean                                    0.0159619
trainer/Policy mu Std                                     0.261219
trainer/Policy mu Max                                     1.90257
trainer/Policy mu Min                                    -1.42855
trainer/Policy log std Mean                              -2.29057
trainer/Policy log std Std                                0.488142
trainer/Policy log std Max                                0.278839
trainer/Policy log std Min                               -3.23376
trainer/Alpha                                             0.021892
trainer/Alpha Loss                                       -0.756526
exploration/num steps total                           15500
exploration/num paths total                             775
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0913328
exploration/Rewards Std                                   0.0811061
exploration/Rewards Max                                   0.0968113
exploration/Rewards Min                                  -0.262338
exploration/Returns Mean                                 -1.82666
exploration/Returns Std                                   1.26411
exploration/Returns Max                                  -0.0975924
exploration/Returns Min                                  -3.44636
exploration/Actions Mean                                  0.0044782
exploration/Actions Std                                   0.12982
exploration/Actions Max                                   0.914912
exploration/Actions Min                                  -0.557685
exploration/Num Paths                                     5
exploration/Average Returns                              -1.82666
exploration/env_infos/final/reward_energy Mean           -0.204147
exploration/env_infos/final/reward_energy Std             0.204316
exploration/env_infos/final/reward_energy Max            -0.013164
exploration/env_infos/final/reward_energy Min            -0.601048
exploration/env_infos/initial/reward_energy Mean         -0.322458
exploration/env_infos/initial/reward_energy Std           0.333083
exploration/env_infos/initial/reward_energy Max          -0.0654675
exploration/env_infos/initial/reward_energy Min          -0.945941
exploration/env_infos/reward_energy Mean                 -0.128179
exploration/env_infos/reward_energy Std                   0.131594
exploration/env_infos/reward_energy Max                  -0.00487671
exploration/env_infos/reward_energy Min                  -0.945941
exploration/env_infos/final/end_effector_loc Mean         0.128089
exploration/env_infos/final/end_effector_loc Std          0.129961
exploration/env_infos/final/end_effector_loc Max          0.379256
exploration/env_infos/final/end_effector_loc Min         -0.0742718
exploration/env_infos/initial/end_effector_loc Mean       0.00304608
exploration/env_infos/initial/end_effector_loc Std        0.0161051
exploration/env_infos/initial/end_effector_loc Max        0.0457456
exploration/env_infos/initial/end_effector_loc Min       -0.0184831
exploration/env_infos/end_effector_loc Mean               0.0680702
exploration/env_infos/end_effector_loc Std                0.107982
exploration/env_infos/end_effector_loc Max                0.379256
exploration/env_infos/end_effector_loc Min               -0.127568
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.145629
exploration/env_infos/final/reward_dist Std               0.183144
exploration/env_infos/final/reward_dist Max               0.429854
exploration/env_infos/final/reward_dist Min               2.6065e-18
exploration/env_infos/initial/reward_dist Mean            0.0215671
exploration/env_infos/initial/reward_dist Std             0.0412424
exploration/env_infos/initial/reward_dist Max             0.104024
exploration/env_infos/initial/reward_dist Min             7.51544e-06
exploration/env_infos/reward_dist Mean                    0.103665
exploration/env_infos/reward_dist Std                     0.23048
exploration/env_infos/reward_dist Max                     0.969553
exploration/env_infos/reward_dist Min                     2.6065e-18
evaluation/num steps total                           145000
evaluation/num paths total                             7250
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0858263
evaluation/Rewards Std                                    0.11074
evaluation/Rewards Max                                    0.145672
evaluation/Rewards Min                                   -1.03572
evaluation/Returns Mean                                  -1.71653
evaluation/Returns Std                                    1.58419
evaluation/Returns Max                                    1.69519
evaluation/Returns Min                                   -7.82361
evaluation/Actions Mean                                  -0.00300228
evaluation/Actions Std                                    0.126643
evaluation/Actions Max                                    0.86088
evaluation/Actions Min                                   -0.999186
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.71653
evaluation/env_infos/final/reward_energy Mean            -0.0902548
evaluation/env_infos/final/reward_energy Std              0.186124
evaluation/env_infos/final/reward_energy Max             -0.00746955
evaluation/env_infos/final/reward_energy Min             -1.30721
evaluation/env_infos/initial/reward_energy Mean          -0.312492
evaluation/env_infos/initial/reward_energy Std            0.303156
evaluation/env_infos/initial/reward_energy Max           -0.00619735
evaluation/env_infos/initial/reward_energy Min           -1.16641
evaluation/env_infos/reward_energy Mean                  -0.0992129
evaluation/env_infos/reward_energy Std                    0.14917
evaluation/env_infos/reward_energy Max                   -0.00086578
evaluation/env_infos/reward_energy Min                   -1.30721
evaluation/env_infos/final/end_effector_loc Mean          0.0358625
evaluation/env_infos/final/end_effector_loc Std           0.334239
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00150881
evaluation/env_infos/initial/end_effector_loc Std         0.0153189
evaluation/env_infos/initial/end_effector_loc Max         0.043044
evaluation/env_infos/initial/end_effector_loc Min        -0.0499593
evaluation/env_infos/end_effector_loc Mean                0.0246047
evaluation/env_infos/end_effector_loc Std                 0.212043
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0543187
evaluation/env_infos/final/reward_dist Std                0.135568
evaluation/env_infos/final/reward_dist Max                0.608028
evaluation/env_infos/final/reward_dist Min                1.49796e-137
evaluation/env_infos/initial/reward_dist Mean             0.00688656
evaluation/env_infos/initial/reward_dist Std              0.0122604
evaluation/env_infos/initial/reward_dist Max              0.055678
evaluation/env_infos/initial/reward_dist Min              2.97362e-06
evaluation/env_infos/reward_dist Mean                     0.110176
evaluation/env_infos/reward_dist Std                      0.21312
evaluation/env_infos/reward_dist Max                      0.993853
evaluation/env_infos/reward_dist Min                      1.49796e-137
time/data storing (s)                                    38.4678
time/evaluation sampling (s)                              0.650635
time/exploration sampling (s)                             0.0869097
time/logging (s)                                          0.0154901
time/saving (s)                                           0.818733
time/training (s)                                        39.157
time/epoch (s)                                           79.1966
time/total (s)                                         9977.77
Epoch                                                   144
---------------------------------------------------  -----------------
2021-05-29 02:43:31.026086 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 145 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00248657
trainer/QF2 Loss                                          0.00227125
trainer/Policy Loss                                       3.11273
trainer/Q1 Predictions Mean                              -0.989348
trainer/Q1 Predictions Std                                0.920978
trainer/Q1 Predictions Max                                1.44573
trainer/Q1 Predictions Min                               -3.44499
trainer/Q2 Predictions Mean                              -0.984178
trainer/Q2 Predictions Std                                0.915755
trainer/Q2 Predictions Max                                1.41212
trainer/Q2 Predictions Min                               -3.3545
trainer/Q Targets Mean                                   -0.976691
trainer/Q Targets Std                                     0.919713
trainer/Q Targets Max                                     1.47838
trainer/Q Targets Min                                    -3.40422
trainer/Log Pis Mean                                      2.12815
trainer/Log Pis Std                                       1.22064
trainer/Log Pis Max                                       5.60178
trainer/Log Pis Min                                      -4.11872
trainer/Policy mu Mean                                   -0.0315831
trainer/Policy mu Std                                     0.392828
trainer/Policy mu Max                                     1.53209
trainer/Policy mu Min                                    -2.36185
trainer/Policy log std Mean                              -2.33571
trainer/Policy log std Std                                0.541652
trainer/Policy log std Max                                0.0887051
trainer/Policy log std Min                               -3.27236
trainer/Alpha                                             0.0222375
trainer/Alpha Loss                                        0.48801
exploration/num steps total                           15600
exploration/num paths total                             780
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.094924
exploration/Rewards Std                                   0.0501693
exploration/Rewards Max                                  -0.0211723
exploration/Rewards Min                                  -0.254732
exploration/Returns Mean                                 -1.89848
exploration/Returns Std                                   0.624183
exploration/Returns Max                                  -1.06022
exploration/Returns Min                                  -2.74632
exploration/Actions Mean                                  0.0107794
exploration/Actions Std                                   0.167802
exploration/Actions Max                                   0.592944
exploration/Actions Min                                  -0.840859
exploration/Num Paths                                     5
exploration/Average Returns                              -1.89848
exploration/env_infos/final/reward_energy Mean           -0.154159
exploration/env_infos/final/reward_energy Std             0.106007
exploration/env_infos/final/reward_energy Max            -0.0289541
exploration/env_infos/final/reward_energy Min            -0.349353
exploration/env_infos/initial/reward_energy Mean         -0.417021
exploration/env_infos/initial/reward_energy Std           0.348377
exploration/env_infos/initial/reward_energy Max          -0.0879063
exploration/env_infos/initial/reward_energy Min          -1.01693
exploration/env_infos/reward_energy Mean                 -0.163451
exploration/env_infos/reward_energy Std                   0.172716
exploration/env_infos/reward_energy Max                  -0.0212808
exploration/env_infos/reward_energy Min                  -1.01693
exploration/env_infos/final/end_effector_loc Mean         0.0804055
exploration/env_infos/final/end_effector_loc Std          0.326316
exploration/env_infos/final/end_effector_loc Max          0.491342
exploration/env_infos/final/end_effector_loc Min         -0.674072
exploration/env_infos/initial/end_effector_loc Mean       0.00118463
exploration/env_infos/initial/end_effector_loc Std        0.0191752
exploration/env_infos/initial/end_effector_loc Max        0.0292182
exploration/env_infos/initial/end_effector_loc Min       -0.0420429
exploration/env_infos/end_effector_loc Mean               0.0299912
exploration/env_infos/end_effector_loc Std                0.193852
exploration/env_infos/end_effector_loc Max                0.491342
exploration/env_infos/end_effector_loc Min               -0.674072
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0366099
exploration/env_infos/final/reward_dist Std               0.0682532
exploration/env_infos/final/reward_dist Max               0.172889
exploration/env_infos/final/reward_dist Min               1.41904e-23
exploration/env_infos/initial/reward_dist Mean            0.0143406
exploration/env_infos/initial/reward_dist Std             0.017017
exploration/env_infos/initial/reward_dist Max             0.044512
exploration/env_infos/initial/reward_dist Min             8.4324e-05
exploration/env_infos/reward_dist Mean                    0.120064
exploration/env_infos/reward_dist Std                     0.181462
exploration/env_infos/reward_dist Max                     0.854067
exploration/env_infos/reward_dist Min                     1.41904e-23
evaluation/num steps total                           146000
evaluation/num paths total                             7300
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.076359
evaluation/Rewards Std                                    0.107587
evaluation/Rewards Max                                    0.1108
evaluation/Rewards Min                                   -0.61305
evaluation/Returns Mean                                  -1.52718
evaluation/Returns Std                                    1.75851
evaluation/Returns Max                                    1.15331
evaluation/Returns Min                                   -7.81937
evaluation/Actions Mean                                  -0.00763579
evaluation/Actions Std                                    0.109616
evaluation/Actions Max                                    0.691739
evaluation/Actions Min                                   -0.996444
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.52718
evaluation/env_infos/final/reward_energy Mean            -0.0498112
evaluation/env_infos/final/reward_energy Std              0.0450158
evaluation/env_infos/final/reward_energy Max             -0.00101564
evaluation/env_infos/final/reward_energy Min             -0.194439
evaluation/env_infos/initial/reward_energy Mean          -0.24269
evaluation/env_infos/initial/reward_energy Std            0.238137
evaluation/env_infos/initial/reward_energy Max           -0.0136413
evaluation/env_infos/initial/reward_energy Min           -1.19179
evaluation/env_infos/reward_energy Mean                  -0.0923226
evaluation/env_infos/reward_energy Std                    0.124998
evaluation/env_infos/reward_energy Max                   -0.00101564
evaluation/env_infos/reward_energy Min                   -1.19179
evaluation/env_infos/final/end_effector_loc Mean         -0.0430816
evaluation/env_infos/final/end_effector_loc Std           0.340737
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -3.25985e-05
evaluation/env_infos/initial/end_effector_loc Std         0.0120212
evaluation/env_infos/initial/end_effector_loc Max         0.0345869
evaluation/env_infos/initial/end_effector_loc Min        -0.0498222
evaluation/env_infos/end_effector_loc Mean               -0.0131992
evaluation/env_infos/end_effector_loc Std                 0.228569
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.151455
evaluation/env_infos/final/reward_dist Std                0.237819
evaluation/env_infos/final/reward_dist Max                0.84467
evaluation/env_infos/final/reward_dist Min                3.10269e-136
evaluation/env_infos/initial/reward_dist Mean             0.00580559
evaluation/env_infos/initial/reward_dist Std              0.011584
evaluation/env_infos/initial/reward_dist Max              0.0622302
evaluation/env_infos/initial/reward_dist Min              7.00742e-07
evaluation/env_infos/reward_dist Mean                     0.153969
evaluation/env_infos/reward_dist Std                      0.252753
evaluation/env_infos/reward_dist Max                      0.999669
evaluation/env_infos/reward_dist Min                      3.10269e-136
time/data storing (s)                                    38.0319
time/evaluation sampling (s)                              0.646533
time/exploration sampling (s)                             0.0906097
time/logging (s)                                          0.0153515
time/saving (s)                                           0.803626
time/training (s)                                        38.9312
time/epoch (s)                                           78.5192
time/total (s)                                        10057.9
Epoch                                                   145
---------------------------------------------------  -----------------
2021-05-29 02:44:51.182365 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 146 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00350509
trainer/QF2 Loss                                          0.002743
trainer/Policy Loss                                       2.74533
trainer/Q1 Predictions Mean                              -0.809451
trainer/Q1 Predictions Std                                0.91443
trainer/Q1 Predictions Max                                1.25476
trainer/Q1 Predictions Min                               -3.10294
trainer/Q2 Predictions Mean                              -0.814085
trainer/Q2 Predictions Std                                0.913547
trainer/Q2 Predictions Max                                1.21893
trainer/Q2 Predictions Min                               -3.12998
trainer/Q Targets Mean                                   -0.832046
trainer/Q Targets Std                                     0.903957
trainer/Q Targets Max                                     1.25218
trainer/Q Targets Min                                    -3.07428
trainer/Log Pis Mean                                      1.92743
trainer/Log Pis Std                                       1.37142
trainer/Log Pis Max                                       4.29297
trainer/Log Pis Min                                      -3.61684
trainer/Policy mu Mean                                    0.0142207
trainer/Policy mu Std                                     0.267205
trainer/Policy mu Max                                     1.5913
trainer/Policy mu Min                                    -1.6285
trainer/Policy log std Mean                              -2.34824
trainer/Policy log std Std                                0.498288
trainer/Policy log std Max                               -0.393322
trainer/Policy log std Min                               -3.20774
trainer/Alpha                                             0.0212645
trainer/Alpha Loss                                       -0.279478
exploration/num steps total                           15700
exploration/num paths total                             785
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.057087
exploration/Rewards Std                                   0.0630741
exploration/Rewards Max                                   0.0537612
exploration/Rewards Min                                  -0.240088
exploration/Returns Mean                                 -1.14174
exploration/Returns Std                                   0.649411
exploration/Returns Max                                  -0.653534
exploration/Returns Min                                  -2.40861
exploration/Actions Mean                                 -0.00897377
exploration/Actions Std                                   0.136394
exploration/Actions Max                                   0.413329
exploration/Actions Min                                  -0.386626
exploration/Num Paths                                     5
exploration/Average Returns                              -1.14174
exploration/env_infos/final/reward_energy Mean           -0.0798047
exploration/env_infos/final/reward_energy Std             0.0672977
exploration/env_infos/final/reward_energy Max            -0.0187456
exploration/env_infos/final/reward_energy Min            -0.206589
exploration/env_infos/initial/reward_energy Mean         -0.296451
exploration/env_infos/initial/reward_energy Std           0.0673586
exploration/env_infos/initial/reward_energy Max          -0.205996
exploration/env_infos/initial/reward_energy Min          -0.361544
exploration/env_infos/reward_energy Mean                 -0.163762
exploration/env_infos/reward_energy Std                   0.102714
exploration/env_infos/reward_energy Max                  -0.0187456
exploration/env_infos/reward_energy Min                  -0.424254
exploration/env_infos/final/end_effector_loc Mean        -0.0257466
exploration/env_infos/final/end_effector_loc Std          0.254378
exploration/env_infos/final/end_effector_loc Max          0.436033
exploration/env_infos/final/end_effector_loc Min         -0.487532
exploration/env_infos/initial/end_effector_loc Mean       0.000438265
exploration/env_infos/initial/end_effector_loc Std        0.0107393
exploration/env_infos/initial/end_effector_loc Max        0.0146905
exploration/env_infos/initial/end_effector_loc Min       -0.0171363
exploration/env_infos/end_effector_loc Mean              -0.00512401
exploration/env_infos/end_effector_loc Std                0.165603
exploration/env_infos/end_effector_loc Max                0.436033
exploration/env_infos/end_effector_loc Min               -0.487532
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.178609
exploration/env_infos/final/reward_dist Std               0.231348
exploration/env_infos/final/reward_dist Max               0.568931
exploration/env_infos/final/reward_dist Min               7.70392e-09
exploration/env_infos/initial/reward_dist Mean            0.00149312
exploration/env_infos/initial/reward_dist Std             0.00123341
exploration/env_infos/initial/reward_dist Max             0.00316211
exploration/env_infos/initial/reward_dist Min             4.37587e-05
exploration/env_infos/reward_dist Mean                    0.158871
exploration/env_infos/reward_dist Std                     0.226752
exploration/env_infos/reward_dist Max                     0.811216
exploration/env_infos/reward_dist Min                     7.70392e-09
evaluation/num steps total                           147000
evaluation/num paths total                             7350
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0670859
evaluation/Rewards Std                                    0.101804
evaluation/Rewards Max                                    0.160846
evaluation/Rewards Min                                   -0.601932
evaluation/Returns Mean                                  -1.34172
evaluation/Returns Std                                    1.6893
evaluation/Returns Max                                    1.52857
evaluation/Returns Min                                   -6.64252
evaluation/Actions Mean                                  -0.00651592
evaluation/Actions Std                                    0.0984293
evaluation/Actions Max                                    0.837081
evaluation/Actions Min                                   -0.907588
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.34172
evaluation/env_infos/final/reward_energy Mean            -0.0759496
evaluation/env_infos/final/reward_energy Std              0.0786366
evaluation/env_infos/final/reward_energy Max             -0.00145697
evaluation/env_infos/final/reward_energy Min             -0.462897
evaluation/env_infos/initial/reward_energy Mean          -0.296155
evaluation/env_infos/initial/reward_energy Std            0.281679
evaluation/env_infos/initial/reward_energy Max           -0.00633768
evaluation/env_infos/initial/reward_energy Min           -1.02968
evaluation/env_infos/reward_energy Mean                  -0.0868311
evaluation/env_infos/reward_energy Std                    0.109188
evaluation/env_infos/reward_energy Max                   -0.00145697
evaluation/env_infos/reward_energy Min                   -1.02968
evaluation/env_infos/final/end_effector_loc Mean          0.0221374
evaluation/env_infos/final/end_effector_loc Std           0.331706
evaluation/env_infos/final/end_effector_loc Max           0.956533
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00388928
evaluation/env_infos/initial/end_effector_loc Std         0.0139172
evaluation/env_infos/initial/end_effector_loc Max         0.041854
evaluation/env_infos/initial/end_effector_loc Min        -0.0453794
evaluation/env_infos/end_effector_loc Mean                0.035153
evaluation/env_infos/end_effector_loc Std                 0.209046
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0763655
evaluation/env_infos/final/reward_dist Std                0.185868
evaluation/env_infos/final/reward_dist Max                0.786507
evaluation/env_infos/final/reward_dist Min                2.20786e-95
evaluation/env_infos/initial/reward_dist Mean             0.00528932
evaluation/env_infos/initial/reward_dist Std              0.0111054
evaluation/env_infos/initial/reward_dist Max              0.0518356
evaluation/env_infos/initial/reward_dist Min              1.68709e-06
evaluation/env_infos/reward_dist Mean                     0.132508
evaluation/env_infos/reward_dist Std                      0.240467
evaluation/env_infos/reward_dist Max                      0.999249
evaluation/env_infos/reward_dist Min                      2.20786e-95
time/data storing (s)                                    38.2214
time/evaluation sampling (s)                              0.668294
time/exploration sampling (s)                             0.0858014
time/logging (s)                                          0.0152719
time/saving (s)                                           0.797922
time/training (s)                                        38.7411
time/epoch (s)                                           78.5298
time/total (s)                                        10138
Epoch                                                   146
---------------------------------------------------  ----------------
2021-05-29 02:46:12.491034 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 147 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00179656
trainer/QF2 Loss                                          0.00308458
trainer/Policy Loss                                       2.66638
trainer/Q1 Predictions Mean                              -0.766612
trainer/Q1 Predictions Std                                0.857111
trainer/Q1 Predictions Max                                1.09598
trainer/Q1 Predictions Min                               -4.26061
trainer/Q2 Predictions Mean                              -0.765227
trainer/Q2 Predictions Std                                0.867773
trainer/Q2 Predictions Max                                1.1182
trainer/Q2 Predictions Min                               -4.3618
trainer/Q Targets Mean                                   -0.770074
trainer/Q Targets Std                                     0.862762
trainer/Q Targets Max                                     1.14055
trainer/Q Targets Min                                    -4.14888
trainer/Log Pis Mean                                      1.90934
trainer/Log Pis Std                                       1.20912
trainer/Log Pis Max                                       5.70573
trainer/Log Pis Min                                      -2.42099
trainer/Policy mu Mean                                    0.0115575
trainer/Policy mu Std                                     0.337222
trainer/Policy mu Max                                     1.48233
trainer/Policy mu Min                                    -2.73687
trainer/Policy log std Mean                              -2.24085
trainer/Policy log std Std                                0.494285
trainer/Policy log std Max                               -0.602076
trainer/Policy log std Min                               -3.21624
trainer/Alpha                                             0.0213012
trainer/Alpha Loss                                       -0.349058
exploration/num steps total                           15800
exploration/num paths total                             790
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0725112
exploration/Rewards Std                                   0.0725105
exploration/Rewards Max                                   0.108238
exploration/Rewards Min                                  -0.219585
exploration/Returns Mean                                 -1.45022
exploration/Returns Std                                   1.26228
exploration/Returns Max                                   0.358123
exploration/Returns Min                                  -2.96096
exploration/Actions Mean                                 -0.000194303
exploration/Actions Std                                   0.16947
exploration/Actions Max                                   0.718099
exploration/Actions Min                                  -0.459533
exploration/Num Paths                                     5
exploration/Average Returns                              -1.45022
exploration/env_infos/final/reward_energy Mean           -0.188556
exploration/env_infos/final/reward_energy Std             0.0914781
exploration/env_infos/final/reward_energy Max            -0.0449607
exploration/env_infos/final/reward_energy Min            -0.281927
exploration/env_infos/initial/reward_energy Mean         -0.438245
exploration/env_infos/initial/reward_energy Std           0.238685
exploration/env_infos/initial/reward_energy Max          -0.139197
exploration/env_infos/initial/reward_energy Min          -0.724088
exploration/env_infos/reward_energy Mean                 -0.196159
exploration/env_infos/reward_energy Std                   0.137701
exploration/env_infos/reward_energy Max                  -0.00379548
exploration/env_infos/reward_energy Min                  -0.724088
exploration/env_infos/final/end_effector_loc Mean         0.136889
exploration/env_infos/final/end_effector_loc Std          0.40028
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.501728
exploration/env_infos/initial/end_effector_loc Mean       0.00780026
exploration/env_infos/initial/end_effector_loc Std        0.0158254
exploration/env_infos/initial/end_effector_loc Max        0.035905
exploration/env_infos/initial/end_effector_loc Min       -0.00968183
exploration/env_infos/end_effector_loc Mean               0.0963922
exploration/env_infos/end_effector_loc Std                0.261047
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.501728
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.16101
exploration/env_infos/final/reward_dist Std               0.276232
exploration/env_infos/final/reward_dist Max               0.711558
exploration/env_infos/final/reward_dist Min               1.2645e-92
exploration/env_infos/initial/reward_dist Mean            0.00820442
exploration/env_infos/initial/reward_dist Std             0.0089272
exploration/env_infos/initial/reward_dist Max             0.0218355
exploration/env_infos/initial/reward_dist Min             1.78921e-07
exploration/env_infos/reward_dist Mean                    0.107214
exploration/env_infos/reward_dist Std                     0.208193
exploration/env_infos/reward_dist Max                     0.864676
exploration/env_infos/reward_dist Min                     1.2645e-92
evaluation/num steps total                           148000
evaluation/num paths total                             7400
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0740956
evaluation/Rewards Std                                    0.11495
evaluation/Rewards Max                                    0.142884
evaluation/Rewards Min                                   -0.681026
evaluation/Returns Mean                                  -1.48191
evaluation/Returns Std                                    1.99668
evaluation/Returns Max                                    1.94777
evaluation/Returns Min                                   -7.40857
evaluation/Actions Mean                                  -0.00384381
evaluation/Actions Std                                    0.113152
evaluation/Actions Max                                    0.888722
evaluation/Actions Min                                   -0.854099
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.48191
evaluation/env_infos/final/reward_energy Mean            -0.0577089
evaluation/env_infos/final/reward_energy Std              0.0438072
evaluation/env_infos/final/reward_energy Max             -0.00747963
evaluation/env_infos/final/reward_energy Min             -0.201204
evaluation/env_infos/initial/reward_energy Mean          -0.343207
evaluation/env_infos/initial/reward_energy Std            0.273622
evaluation/env_infos/initial/reward_energy Max           -0.0206794
evaluation/env_infos/initial/reward_energy Min           -1.08779
evaluation/env_infos/reward_energy Mean                  -0.100745
evaluation/env_infos/reward_energy Std                    0.124445
evaluation/env_infos/reward_energy Max                   -0.000526453
evaluation/env_infos/reward_energy Min                   -1.08779
evaluation/env_infos/final/end_effector_loc Mean          0.0377144
evaluation/env_infos/final/end_effector_loc Std           0.341436
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.983724
evaluation/env_infos/initial/end_effector_loc Mean        0.0037747
evaluation/env_infos/initial/end_effector_loc Std         0.0150525
evaluation/env_infos/initial/end_effector_loc Max         0.0444361
evaluation/env_infos/initial/end_effector_loc Min        -0.042705
evaluation/env_infos/end_effector_loc Mean                0.0433645
evaluation/env_infos/end_effector_loc Std                 0.231913
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.983724
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.157039
evaluation/env_infos/final/reward_dist Std                0.256352
evaluation/env_infos/final/reward_dist Max                0.975183
evaluation/env_infos/final/reward_dist Min                4.24089e-132
evaluation/env_infos/initial/reward_dist Mean             0.00596477
evaluation/env_infos/initial/reward_dist Std              0.011536
evaluation/env_infos/initial/reward_dist Max              0.0519581
evaluation/env_infos/initial/reward_dist Min              1.46943e-07
evaluation/env_infos/reward_dist Mean                     0.154996
evaluation/env_infos/reward_dist Std                      0.262258
evaluation/env_infos/reward_dist Max                      0.997327
evaluation/env_infos/reward_dist Min                      4.24089e-132
time/data storing (s)                                    38.4012
time/evaluation sampling (s)                              0.658971
time/exploration sampling (s)                             0.0937074
time/logging (s)                                          0.0169611
time/saving (s)                                           0.793589
time/training (s)                                        39.75
time/epoch (s)                                           79.7144
time/total (s)                                        10219.3
Epoch                                                   147
---------------------------------------------------  -----------------
2021-05-29 02:47:33.147136 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 148 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00208421
trainer/QF2 Loss                                          0.00179665
trainer/Policy Loss                                       2.71299
trainer/Q1 Predictions Mean                              -0.738043
trainer/Q1 Predictions Std                                0.876926
trainer/Q1 Predictions Max                                1.14674
trainer/Q1 Predictions Min                               -3.81641
trainer/Q2 Predictions Mean                              -0.740661
trainer/Q2 Predictions Std                                0.882121
trainer/Q2 Predictions Max                                1.15271
trainer/Q2 Predictions Min                               -3.82746
trainer/Q Targets Mean                                   -0.736099
trainer/Q Targets Std                                     0.884858
trainer/Q Targets Max                                     1.14875
trainer/Q Targets Min                                    -3.83154
trainer/Log Pis Mean                                      1.97532
trainer/Log Pis Std                                       1.25806
trainer/Log Pis Max                                       4.48164
trainer/Log Pis Min                                      -2.74794
trainer/Policy mu Mean                                    0.0226857
trainer/Policy mu Std                                     0.326812
trainer/Policy mu Max                                     1.57483
trainer/Policy mu Min                                    -2.42197
trainer/Policy log std Mean                              -2.28351
trainer/Policy log std Std                                0.487359
trainer/Policy log std Max                               -0.400839
trainer/Policy log std Min                               -3.26762
trainer/Alpha                                             0.0193824
trainer/Alpha Loss                                       -0.0973177
exploration/num steps total                           15900
exploration/num paths total                             795
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.105437
exploration/Rewards Std                                   0.10199
exploration/Rewards Max                                   0.0543106
exploration/Rewards Min                                  -0.424689
exploration/Returns Mean                                 -2.10873
exploration/Returns Std                                   1.57999
exploration/Returns Max                                  -0.577747
exploration/Returns Min                                  -5.08262
exploration/Actions Mean                                  0.0124705
exploration/Actions Std                                   0.141472
exploration/Actions Max                                   0.662549
exploration/Actions Min                                  -0.508474
exploration/Num Paths                                     5
exploration/Average Returns                              -2.10873
exploration/env_infos/final/reward_energy Mean           -0.0813951
exploration/env_infos/final/reward_energy Std             0.0321657
exploration/env_infos/final/reward_energy Max            -0.0316994
exploration/env_infos/final/reward_energy Min            -0.114173
exploration/env_infos/initial/reward_energy Mean         -0.248085
exploration/env_infos/initial/reward_energy Std           0.284602
exploration/env_infos/initial/reward_energy Max          -0.0638912
exploration/env_infos/initial/reward_energy Min          -0.810242
exploration/env_infos/reward_energy Mean                 -0.156732
exploration/env_infos/reward_energy Std                   0.125599
exploration/env_infos/reward_energy Max                  -0.0126735
exploration/env_infos/reward_energy Min                  -0.810242
exploration/env_infos/final/end_effector_loc Mean         0.150011
exploration/env_infos/final/end_effector_loc Std          0.241424
exploration/env_infos/final/end_effector_loc Max          0.646731
exploration/env_infos/final/end_effector_loc Min         -0.159417
exploration/env_infos/initial/end_effector_loc Mean      -0.000698688
exploration/env_infos/initial/end_effector_loc Std        0.0133301
exploration/env_infos/initial/end_effector_loc Max        0.0315415
exploration/env_infos/initial/end_effector_loc Min       -0.0254237
exploration/env_infos/end_effector_loc Mean               0.0601413
exploration/env_infos/end_effector_loc Std                0.173525
exploration/env_infos/end_effector_loc Max                0.646731
exploration/env_infos/end_effector_loc Min               -0.183609
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0597228
exploration/env_infos/final/reward_dist Std               0.065917
exploration/env_infos/final/reward_dist Max               0.185453
exploration/env_infos/final/reward_dist Min               3.68317e-49
exploration/env_infos/initial/reward_dist Mean            0.00598914
exploration/env_infos/initial/reward_dist Std             0.00981397
exploration/env_infos/initial/reward_dist Max             0.0253261
exploration/env_infos/initial/reward_dist Min             1.93099e-05
exploration/env_infos/reward_dist Mean                    0.0805598
exploration/env_infos/reward_dist Std                     0.155328
exploration/env_infos/reward_dist Max                     0.878808
exploration/env_infos/reward_dist Min                     3.68317e-49
evaluation/num steps total                           149000
evaluation/num paths total                             7450
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0789265
evaluation/Rewards Std                                    0.119321
evaluation/Rewards Max                                    0.17228
evaluation/Rewards Min                                   -0.877095
evaluation/Returns Mean                                  -1.57853
evaluation/Returns Std                                    2.04808
evaluation/Returns Max                                    2.30442
evaluation/Returns Min                                   -7.75812
evaluation/Actions Mean                                   0.00186845
evaluation/Actions Std                                    0.117903
evaluation/Actions Max                                    0.977757
evaluation/Actions Min                                   -0.934139
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.57853
evaluation/env_infos/final/reward_energy Mean            -0.0666863
evaluation/env_infos/final/reward_energy Std              0.0653034
evaluation/env_infos/final/reward_energy Max             -0.0107822
evaluation/env_infos/final/reward_energy Min             -0.387248
evaluation/env_infos/initial/reward_energy Mean          -0.362564
evaluation/env_infos/initial/reward_energy Std            0.318678
evaluation/env_infos/initial/reward_energy Max           -0.0135858
evaluation/env_infos/initial/reward_energy Min           -1.20873
evaluation/env_infos/reward_energy Mean                  -0.102216
evaluation/env_infos/reward_energy Std                    0.131762
evaluation/env_infos/reward_energy Max                   -0.00110786
evaluation/env_infos/reward_energy Min                   -1.20873
evaluation/env_infos/final/end_effector_loc Mean          0.0838813
evaluation/env_infos/final/end_effector_loc Std           0.394518
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00320125
evaluation/env_infos/initial/end_effector_loc Std         0.0167634
evaluation/env_infos/initial/end_effector_loc Max         0.0488878
evaluation/env_infos/initial/end_effector_loc Min        -0.046707
evaluation/env_infos/end_effector_loc Mean                0.0534958
evaluation/env_infos/end_effector_loc Std                 0.269089
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.131085
evaluation/env_infos/final/reward_dist Std                0.253063
evaluation/env_infos/final/reward_dist Max                0.938717
evaluation/env_infos/final/reward_dist Min                3.71533e-157
evaluation/env_infos/initial/reward_dist Mean             0.0101037
evaluation/env_infos/initial/reward_dist Std              0.0308533
evaluation/env_infos/initial/reward_dist Max              0.140751
evaluation/env_infos/initial/reward_dist Min              9.41001e-07
evaluation/env_infos/reward_dist Mean                     0.158882
evaluation/env_infos/reward_dist Std                      0.257643
evaluation/env_infos/reward_dist Max                      0.997536
evaluation/env_infos/reward_dist Min                      3.71533e-157
time/data storing (s)                                    38.4982
time/evaluation sampling (s)                              0.656044
time/exploration sampling (s)                             0.0922044
time/logging (s)                                          0.0151948
time/saving (s)                                           0.781513
time/training (s)                                        38.9933
time/epoch (s)                                           79.0365
time/total (s)                                        10300
Epoch                                                   148
---------------------------------------------------  -----------------
2021-05-29 02:48:53.733479 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 149 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00260722
trainer/QF2 Loss                                          0.00183141
trainer/Policy Loss                                       2.7026
trainer/Q1 Predictions Mean                              -0.79625
trainer/Q1 Predictions Std                                0.906666
trainer/Q1 Predictions Max                                1.29076
trainer/Q1 Predictions Min                               -4.51469
trainer/Q2 Predictions Mean                              -0.783415
trainer/Q2 Predictions Std                                0.921499
trainer/Q2 Predictions Max                                1.31193
trainer/Q2 Predictions Min                               -4.50379
trainer/Q Targets Mean                                   -0.799507
trainer/Q Targets Std                                     0.910894
trainer/Q Targets Max                                     1.28021
trainer/Q Targets Min                                    -4.51969
trainer/Log Pis Mean                                      1.92127
trainer/Log Pis Std                                       1.37849
trainer/Log Pis Max                                       6.8678
trainer/Log Pis Min                                      -3.64194
trainer/Policy mu Mean                                    0.0208037
trainer/Policy mu Std                                     0.365583
trainer/Policy mu Max                                     1.67914
trainer/Policy mu Min                                    -2.66158
trainer/Policy log std Mean                              -2.27802
trainer/Policy log std Std                                0.522799
trainer/Policy log std Max                               -0.347491
trainer/Policy log std Min                               -3.37956
trainer/Alpha                                             0.019245
trainer/Alpha Loss                                       -0.310957
exploration/num steps total                           16000
exploration/num paths total                             800
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0926973
exploration/Rewards Std                                   0.0731795
exploration/Rewards Max                                   0.0497666
exploration/Rewards Min                                  -0.40086
exploration/Returns Mean                                 -1.85395
exploration/Returns Std                                   0.867801
exploration/Returns Max                                  -0.286627
exploration/Returns Min                                  -2.66595
exploration/Actions Mean                                 -0.0152508
exploration/Actions Std                                   0.164708
exploration/Actions Max                                   0.987667
exploration/Actions Min                                  -0.481778
exploration/Num Paths                                     5
exploration/Average Returns                              -1.85395
exploration/env_infos/final/reward_energy Mean           -0.100814
exploration/env_infos/final/reward_energy Std             0.0584882
exploration/env_infos/final/reward_energy Max            -0.0491719
exploration/env_infos/final/reward_energy Min            -0.214824
exploration/env_infos/initial/reward_energy Mean         -0.430056
exploration/env_infos/initial/reward_energy Std           0.465541
exploration/env_infos/initial/reward_energy Max          -0.0542558
exploration/env_infos/initial/reward_energy Min          -1.33253
exploration/env_infos/reward_energy Mean                 -0.159052
exploration/env_infos/reward_energy Std                   0.171538
exploration/env_infos/reward_energy Max                  -0.00852223
exploration/env_infos/reward_energy Min                  -1.33253
exploration/env_infos/final/end_effector_loc Mean         0.025462
exploration/env_infos/final/end_effector_loc Std          0.495975
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.0101553
exploration/env_infos/initial/end_effector_loc Std        0.0199741
exploration/env_infos/initial/end_effector_loc Max        0.0493833
exploration/env_infos/initial/end_effector_loc Min       -0.0150331
exploration/env_infos/end_effector_loc Mean               0.0550618
exploration/env_infos/end_effector_loc Std                0.346447
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0225573
exploration/env_infos/final/reward_dist Std               0.042731
exploration/env_infos/final/reward_dist Max               0.107985
exploration/env_infos/final/reward_dist Min               1.84081e-153
exploration/env_infos/initial/reward_dist Mean            0.000435912
exploration/env_infos/initial/reward_dist Std             0.000579907
exploration/env_infos/initial/reward_dist Max             0.00155476
exploration/env_infos/initial/reward_dist Min             1.12416e-06
exploration/env_infos/reward_dist Mean                    0.11061
exploration/env_infos/reward_dist Std                     0.183169
exploration/env_infos/reward_dist Max                     0.806978
exploration/env_infos/reward_dist Min                     1.84081e-153
evaluation/num steps total                           150000
evaluation/num paths total                             7500
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0774506
evaluation/Rewards Std                                    0.108295
evaluation/Rewards Max                                    0.164965
evaluation/Rewards Min                                   -0.627899
evaluation/Returns Mean                                  -1.54901
evaluation/Returns Std                                    1.80988
evaluation/Returns Max                                    1.95761
evaluation/Returns Min                                   -7.55293
evaluation/Actions Mean                                  -0.00154194
evaluation/Actions Std                                    0.109969
evaluation/Actions Max                                    0.991646
evaluation/Actions Min                                   -0.755627
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.54901
evaluation/env_infos/final/reward_energy Mean            -0.0499809
evaluation/env_infos/final/reward_energy Std              0.0456807
evaluation/env_infos/final/reward_energy Max             -0.00595089
evaluation/env_infos/final/reward_energy Min             -0.209493
evaluation/env_infos/initial/reward_energy Mean          -0.304085
evaluation/env_infos/initial/reward_energy Std            0.301313
evaluation/env_infos/initial/reward_energy Max           -0.0069742
evaluation/env_infos/initial/reward_energy Min           -1.32741
evaluation/env_infos/reward_energy Mean                  -0.0914788
evaluation/env_infos/reward_energy Std                    0.125789
evaluation/env_infos/reward_energy Max                   -0.00532675
evaluation/env_infos/reward_energy Min                   -1.32741
evaluation/env_infos/final/end_effector_loc Mean          0.0342386
evaluation/env_infos/final/end_effector_loc Std           0.348451
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00362966
evaluation/env_infos/initial/end_effector_loc Std         0.0146934
evaluation/env_infos/initial/end_effector_loc Max         0.0495823
evaluation/env_infos/initial/end_effector_loc Min        -0.0377813
evaluation/env_infos/end_effector_loc Mean                0.0343836
evaluation/env_infos/end_effector_loc Std                 0.236093
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.128539
evaluation/env_infos/final/reward_dist Std                0.202302
evaluation/env_infos/final/reward_dist Max                0.837054
evaluation/env_infos/final/reward_dist Min                4.27534e-158
evaluation/env_infos/initial/reward_dist Mean             0.00895783
evaluation/env_infos/initial/reward_dist Std              0.0185482
evaluation/env_infos/initial/reward_dist Max              0.0849969
evaluation/env_infos/initial/reward_dist Min              3.60533e-06
evaluation/env_infos/reward_dist Mean                     0.153743
evaluation/env_infos/reward_dist Std                      0.2577
evaluation/env_infos/reward_dist Max                      0.998739
evaluation/env_infos/reward_dist Min                      4.27534e-158
time/data storing (s)                                    38.0353
time/evaluation sampling (s)                              0.525937
time/exploration sampling (s)                             0.0862437
time/logging (s)                                          0.0150994
time/saving (s)                                           0.817899
time/training (s)                                        39.5196
time/epoch (s)                                           79.0001
time/total (s)                                        10380.5
Epoch                                                   149
---------------------------------------------------  -----------------
2021-05-29 02:50:14.797210 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 150 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00747771
trainer/QF2 Loss                                          0.00623986
trainer/Policy Loss                                       2.95994
trainer/Q1 Predictions Mean                              -0.856024
trainer/Q1 Predictions Std                                0.821476
trainer/Q1 Predictions Max                                1.36154
trainer/Q1 Predictions Min                               -3.91844
trainer/Q2 Predictions Mean                              -0.867447
trainer/Q2 Predictions Std                                0.818962
trainer/Q2 Predictions Max                                1.33962
trainer/Q2 Predictions Min                               -3.79433
trainer/Q Targets Mean                                   -0.84543
trainer/Q Targets Std                                     0.829122
trainer/Q Targets Max                                     1.3725
trainer/Q Targets Min                                    -4.00068
trainer/Log Pis Mean                                      2.0966
trainer/Log Pis Std                                       1.30242
trainer/Log Pis Max                                       5.75595
trainer/Log Pis Min                                      -5.3605
trainer/Policy mu Mean                                    0.00386475
trainer/Policy mu Std                                     0.346755
trainer/Policy mu Max                                     2.39625
trainer/Policy mu Min                                    -2.82934
trainer/Policy log std Mean                              -2.34167
trainer/Policy log std Std                                0.531922
trainer/Policy log std Max                               -0.115014
trainer/Policy log std Min                               -3.34565
trainer/Alpha                                             0.0194093
trainer/Alpha Loss                                        0.381038
exploration/num steps total                           16100
exploration/num paths total                             805
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0901681
exploration/Rewards Std                                   0.103966
exploration/Rewards Max                                   0.114319
exploration/Rewards Min                                  -0.42927
exploration/Returns Mean                                 -1.80336
exploration/Returns Std                                   1.69245
exploration/Returns Max                                   0.595595
exploration/Returns Min                                  -4.31182
exploration/Actions Mean                                 -0.00757944
exploration/Actions Std                                   0.120734
exploration/Actions Max                                   0.548759
exploration/Actions Min                                  -0.3898
exploration/Num Paths                                     5
exploration/Average Returns                              -1.80336
exploration/env_infos/final/reward_energy Mean           -0.0875174
exploration/env_infos/final/reward_energy Std             0.0373606
exploration/env_infos/final/reward_energy Max            -0.0464562
exploration/env_infos/final/reward_energy Min            -0.136316
exploration/env_infos/initial/reward_energy Mean         -0.257893
exploration/env_infos/initial/reward_energy Std           0.192015
exploration/env_infos/initial/reward_energy Max          -0.0770112
exploration/env_infos/initial/reward_energy Min          -0.623936
exploration/env_infos/reward_energy Mean                 -0.135347
exploration/env_infos/reward_energy Std                   0.104639
exploration/env_infos/reward_energy Max                  -0.00762016
exploration/env_infos/reward_energy Min                  -0.623936
exploration/env_infos/final/end_effector_loc Mean        -0.00889193
exploration/env_infos/final/end_effector_loc Std          0.411149
exploration/env_infos/final/end_effector_loc Max          0.780982
exploration/env_infos/final/end_effector_loc Min         -0.66868
exploration/env_infos/initial/end_effector_loc Mean       0.00301088
exploration/env_infos/initial/end_effector_loc Std        0.0109616
exploration/env_infos/initial/end_effector_loc Max        0.0272889
exploration/env_infos/initial/end_effector_loc Min       -0.00970702
exploration/env_infos/end_effector_loc Mean               0.0212192
exploration/env_infos/end_effector_loc Std                0.252779
exploration/env_infos/end_effector_loc Max                0.780982
exploration/env_infos/end_effector_loc Min               -0.66868
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.214799
exploration/env_infos/final/reward_dist Std               0.386721
exploration/env_infos/final/reward_dist Max               0.987208
exploration/env_infos/final/reward_dist Min               1.89639e-40
exploration/env_infos/initial/reward_dist Mean            0.00528615
exploration/env_infos/initial/reward_dist Std             0.00925322
exploration/env_infos/initial/reward_dist Max             0.023757
exploration/env_infos/initial/reward_dist Min             5.36074e-06
exploration/env_infos/reward_dist Mean                    0.223408
exploration/env_infos/reward_dist Std                     0.315756
exploration/env_infos/reward_dist Max                     0.995264
exploration/env_infos/reward_dist Min                     1.89639e-40
evaluation/num steps total                           151000
evaluation/num paths total                             7550
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0661792
evaluation/Rewards Std                                    0.104152
evaluation/Rewards Max                                    0.164798
evaluation/Rewards Min                                   -0.616459
evaluation/Returns Mean                                  -1.32358
evaluation/Returns Std                                    1.828
evaluation/Returns Max                                    2.43528
evaluation/Returns Min                                   -8.39822
evaluation/Actions Mean                                  -0.00220296
evaluation/Actions Std                                    0.121785
evaluation/Actions Max                                    0.960362
evaluation/Actions Min                                   -0.823743
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.32358
evaluation/env_infos/final/reward_energy Mean            -0.0535469
evaluation/env_infos/final/reward_energy Std              0.0490882
evaluation/env_infos/final/reward_energy Max             -0.00400464
evaluation/env_infos/final/reward_energy Min             -0.285508
evaluation/env_infos/initial/reward_energy Mean          -0.364761
evaluation/env_infos/initial/reward_energy Std            0.329991
evaluation/env_infos/initial/reward_energy Max           -0.0276383
evaluation/env_infos/initial/reward_energy Min           -1.18296
evaluation/env_infos/reward_energy Mean                  -0.102602
evaluation/env_infos/reward_energy Std                    0.138369
evaluation/env_infos/reward_energy Max                   -0.000680644
evaluation/env_infos/reward_energy Min                   -1.18296
evaluation/env_infos/final/end_effector_loc Mean          0.0273403
evaluation/env_infos/final/end_effector_loc Std           0.356511
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.0036396
evaluation/env_infos/initial/end_effector_loc Std         0.0170054
evaluation/env_infos/initial/end_effector_loc Max         0.0480181
evaluation/env_infos/initial/end_effector_loc Min        -0.0411871
evaluation/env_infos/end_effector_loc Mean                0.0289447
evaluation/env_infos/end_effector_loc Std                 0.252507
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.19419
evaluation/env_infos/final/reward_dist Std                0.289065
evaluation/env_infos/final/reward_dist Max                0.964389
evaluation/env_infos/final/reward_dist Min                3.02029e-114
evaluation/env_infos/initial/reward_dist Mean             0.0104724
evaluation/env_infos/initial/reward_dist Std              0.0271677
evaluation/env_infos/initial/reward_dist Max              0.139867
evaluation/env_infos/initial/reward_dist Min              9.76786e-07
evaluation/env_infos/reward_dist Mean                     0.160786
evaluation/env_infos/reward_dist Std                      0.264634
evaluation/env_infos/reward_dist Max                      0.995593
evaluation/env_infos/reward_dist Min                      3.02029e-114
time/data storing (s)                                    38.211
time/evaluation sampling (s)                              0.530721
time/exploration sampling (s)                             0.0827268
time/logging (s)                                          0.0155922
time/saving (s)                                           1.57928
time/training (s)                                        39.0239
time/epoch (s)                                           79.4433
time/total (s)                                        10461.6
Epoch                                                   150
---------------------------------------------------  -----------------
2021-05-29 02:51:36.094541 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 151 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00182293
trainer/QF2 Loss                                          0.00240614
trainer/Policy Loss                                       2.8477
trainer/Q1 Predictions Mean                              -0.832147
trainer/Q1 Predictions Std                                0.862888
trainer/Q1 Predictions Max                                0.725625
trainer/Q1 Predictions Min                               -4.25931
trainer/Q2 Predictions Mean                              -0.836491
trainer/Q2 Predictions Std                                0.857409
trainer/Q2 Predictions Max                                0.698157
trainer/Q2 Predictions Min                               -4.20162
trainer/Q Targets Mean                                   -0.836377
trainer/Q Targets Std                                     0.855091
trainer/Q Targets Max                                     0.716813
trainer/Q Targets Min                                    -4.29772
trainer/Log Pis Mean                                      2.03442
trainer/Log Pis Std                                       1.20514
trainer/Log Pis Max                                       4.30154
trainer/Log Pis Min                                      -1.84668
trainer/Policy mu Mean                                   -0.00722166
trainer/Policy mu Std                                     0.440512
trainer/Policy mu Max                                     2.0294
trainer/Policy mu Min                                    -2.8296
trainer/Policy log std Mean                              -2.21546
trainer/Policy log std Std                                0.569052
trainer/Policy log std Max                               -0.0952358
trainer/Policy log std Min                               -3.20388
trainer/Alpha                                             0.0190373
trainer/Alpha Loss                                        0.136349
exploration/num steps total                           16200
exploration/num paths total                             810
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0839152
exploration/Rewards Std                                   0.0816919
exploration/Rewards Max                                   0.0872918
exploration/Rewards Min                                  -0.315866
exploration/Returns Mean                                 -1.6783
exploration/Returns Std                                   0.8942
exploration/Returns Max                                  -0.4177
exploration/Returns Min                                  -3.10218
exploration/Actions Mean                                 -0.0131833
exploration/Actions Std                                   0.194436
exploration/Actions Max                                   0.931456
exploration/Actions Min                                  -0.61169
exploration/Num Paths                                     5
exploration/Average Returns                              -1.6783
exploration/env_infos/final/reward_energy Mean           -0.233515
exploration/env_infos/final/reward_energy Std             0.183382
exploration/env_infos/final/reward_energy Max            -0.0999826
exploration/env_infos/final/reward_energy Min            -0.597169
exploration/env_infos/initial/reward_energy Mean         -0.631614
exploration/env_infos/initial/reward_energy Std           0.339605
exploration/env_infos/initial/reward_energy Max          -0.0872451
exploration/env_infos/initial/reward_energy Min          -1.12945
exploration/env_infos/reward_energy Mean                 -0.197927
exploration/env_infos/reward_energy Std                   0.19179
exploration/env_infos/reward_energy Max                  -0.00336913
exploration/env_infos/reward_energy Min                  -1.12945
exploration/env_infos/final/end_effector_loc Mean         0.0934723
exploration/env_infos/final/end_effector_loc Std          0.204633
exploration/env_infos/final/end_effector_loc Max          0.297143
exploration/env_infos/final/end_effector_loc Min         -0.321316
exploration/env_infos/initial/end_effector_loc Mean       0.00716961
exploration/env_infos/initial/end_effector_loc Std        0.0243194
exploration/env_infos/initial/end_effector_loc Max        0.0465728
exploration/env_infos/initial/end_effector_loc Min       -0.0249764
exploration/env_infos/end_effector_loc Mean               0.081475
exploration/env_infos/end_effector_loc Std                0.193739
exploration/env_infos/end_effector_loc Max                0.577
exploration/env_infos/end_effector_loc Min               -0.321316
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0326251
exploration/env_infos/final/reward_dist Std               0.0401527
exploration/env_infos/final/reward_dist Max               0.0903507
exploration/env_infos/final/reward_dist Min               4.31903e-11
exploration/env_infos/initial/reward_dist Mean            0.0252557
exploration/env_infos/initial/reward_dist Std             0.048228
exploration/env_infos/initial/reward_dist Max             0.121691
exploration/env_infos/initial/reward_dist Min             3.75062e-05
exploration/env_infos/reward_dist Mean                    0.135542
exploration/env_infos/reward_dist Std                     0.231644
exploration/env_infos/reward_dist Max                     0.980907
exploration/env_infos/reward_dist Min                     7.15045e-16
evaluation/num steps total                           152000
evaluation/num paths total                             7600
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0714942
evaluation/Rewards Std                                    0.125505
evaluation/Rewards Max                                    0.130828
evaluation/Rewards Min                                   -0.839031
evaluation/Returns Mean                                  -1.42988
evaluation/Returns Std                                    2.01507
evaluation/Returns Max                                    1.56491
evaluation/Returns Min                                   -9.31061
evaluation/Actions Mean                                   0.0053297
evaluation/Actions Std                                    0.140698
evaluation/Actions Max                                    0.999927
evaluation/Actions Min                                   -0.923263
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.42988
evaluation/env_infos/final/reward_energy Mean            -0.0640326
evaluation/env_infos/final/reward_energy Std              0.121939
evaluation/env_infos/final/reward_energy Max             -0.00891585
evaluation/env_infos/final/reward_energy Min             -0.886563
evaluation/env_infos/initial/reward_energy Mean          -0.360343
evaluation/env_infos/initial/reward_energy Std            0.331013
evaluation/env_infos/initial/reward_energy Max           -0.0156883
evaluation/env_infos/initial/reward_energy Min           -1.41382
evaluation/env_infos/reward_energy Mean                  -0.0988916
evaluation/env_infos/reward_energy Std                    0.172826
evaluation/env_infos/reward_energy Max                   -0.00136153
evaluation/env_infos/reward_energy Min                   -1.41382
evaluation/env_infos/final/end_effector_loc Mean          0.0225834
evaluation/env_infos/final/end_effector_loc Std           0.324341
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.955987
evaluation/env_infos/initial/end_effector_loc Mean        0.00306993
evaluation/env_infos/initial/end_effector_loc Std         0.0170249
evaluation/env_infos/initial/end_effector_loc Max         0.0499964
evaluation/env_infos/initial/end_effector_loc Min        -0.0391402
evaluation/env_infos/end_effector_loc Mean                0.023848
evaluation/env_infos/end_effector_loc Std                 0.229423
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.104269
evaluation/env_infos/final/reward_dist Std                0.202419
evaluation/env_infos/final/reward_dist Max                0.95905
evaluation/env_infos/final/reward_dist Min                6.46526e-99
evaluation/env_infos/initial/reward_dist Mean             0.00885124
evaluation/env_infos/initial/reward_dist Std              0.0140112
evaluation/env_infos/initial/reward_dist Max              0.0622968
evaluation/env_infos/initial/reward_dist Min              1.16462e-06
evaluation/env_infos/reward_dist Mean                     0.17098
evaluation/env_infos/reward_dist Std                      0.26581
evaluation/env_infos/reward_dist Max                      0.996758
evaluation/env_infos/reward_dist Min                      3.51214e-99
time/data storing (s)                                    38.3071
time/evaluation sampling (s)                              0.647396
time/exploration sampling (s)                             0.0909634
time/logging (s)                                          0.0170727
time/saving (s)                                           0.818749
time/training (s)                                        39.7568
time/epoch (s)                                           79.6381
time/total (s)                                        10542.9
Epoch                                                   151
---------------------------------------------------  ----------------
2021-05-29 02:52:57.344884 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 152 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00242526
trainer/QF2 Loss                                          0.00220957
trainer/Policy Loss                                       2.77026
trainer/Q1 Predictions Mean                              -0.802354
trainer/Q1 Predictions Std                                0.765983
trainer/Q1 Predictions Max                                0.47806
trainer/Q1 Predictions Min                               -3.2445
trainer/Q2 Predictions Mean                              -0.80263
trainer/Q2 Predictions Std                                0.762793
trainer/Q2 Predictions Max                                0.44937
trainer/Q2 Predictions Min                               -3.28458
trainer/Q Targets Mean                                   -0.802121
trainer/Q Targets Std                                     0.764957
trainer/Q Targets Max                                     0.462831
trainer/Q Targets Min                                    -3.26867
trainer/Log Pis Mean                                      1.97197
trainer/Log Pis Std                                       1.28279
trainer/Log Pis Max                                       4.61489
trainer/Log Pis Min                                      -1.79946
trainer/Policy mu Mean                                   -0.0259973
trainer/Policy mu Std                                     0.359405
trainer/Policy mu Max                                     1.56357
trainer/Policy mu Min                                    -1.8613
trainer/Policy log std Mean                              -2.30486
trainer/Policy log std Std                                0.539195
trainer/Policy log std Max                               -0.603616
trainer/Policy log std Min                               -3.3112
trainer/Alpha                                             0.0194735
trainer/Alpha Loss                                       -0.110397
exploration/num steps total                           16300
exploration/num paths total                             815
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0900575
exploration/Rewards Std                                   0.135183
exploration/Rewards Max                                   0.158001
exploration/Rewards Min                                  -0.798903
exploration/Returns Mean                                 -1.80115
exploration/Returns Std                                   2.15622
exploration/Returns Max                                   1.57441
exploration/Returns Min                                  -5.1263
exploration/Actions Mean                                  0.0047
exploration/Actions Std                                   0.16306
exploration/Actions Max                                   0.935744
exploration/Actions Min                                  -0.956651
exploration/Num Paths                                     5
exploration/Average Returns                              -1.80115
exploration/env_infos/final/reward_energy Mean           -0.132962
exploration/env_infos/final/reward_energy Std             0.0994512
exploration/env_infos/final/reward_energy Max            -0.034023
exploration/env_infos/final/reward_energy Min            -0.314597
exploration/env_infos/initial/reward_energy Mean         -0.604491
exploration/env_infos/initial/reward_energy Std           0.509633
exploration/env_infos/initial/reward_energy Max          -0.104759
exploration/env_infos/initial/reward_energy Min          -1.33821
exploration/env_infos/reward_energy Mean                 -0.151113
exploration/env_infos/reward_energy Std                   0.174316
exploration/env_infos/reward_energy Max                  -0.014982
exploration/env_infos/reward_energy Min                  -1.33821
exploration/env_infos/final/end_effector_loc Mean         0.107886
exploration/env_infos/final/end_effector_loc Std          0.353337
exploration/env_infos/final/end_effector_loc Max          0.838872
exploration/env_infos/final/end_effector_loc Min         -0.407903
exploration/env_infos/initial/end_effector_loc Mean      -0.000671783
exploration/env_infos/initial/end_effector_loc Std        0.0279458
exploration/env_infos/initial/end_effector_loc Max        0.0467872
exploration/env_infos/initial/end_effector_loc Min       -0.0478325
exploration/env_infos/end_effector_loc Mean               0.0499773
exploration/env_infos/end_effector_loc Std                0.243015
exploration/env_infos/end_effector_loc Max                0.838872
exploration/env_infos/end_effector_loc Min               -0.407903
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.141988
exploration/env_infos/final/reward_dist Std               0.255764
exploration/env_infos/final/reward_dist Max               0.65157
exploration/env_infos/final/reward_dist Min               4.46063e-44
exploration/env_infos/initial/reward_dist Mean            0.00549017
exploration/env_infos/initial/reward_dist Std             0.0104896
exploration/env_infos/initial/reward_dist Max             0.0264674
exploration/env_infos/initial/reward_dist Min             1.94925e-05
exploration/env_infos/reward_dist Mean                    0.164272
exploration/env_infos/reward_dist Std                     0.264783
exploration/env_infos/reward_dist Max                     0.987701
exploration/env_infos/reward_dist Min                     4.46063e-44
evaluation/num steps total                           153000
evaluation/num paths total                             7650
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.123837
evaluation/Rewards Std                                    0.188013
evaluation/Rewards Max                                    0.109265
evaluation/Rewards Min                                   -1.06407
evaluation/Returns Mean                                  -2.47675
evaluation/Returns Std                                    3.29949
evaluation/Returns Max                                    1.14388
evaluation/Returns Min                                  -18.2476
evaluation/Actions Mean                                   0.00892131
evaluation/Actions Std                                    0.145603
evaluation/Actions Max                                    0.851506
evaluation/Actions Min                                   -0.99056
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.47675
evaluation/env_infos/final/reward_energy Mean            -0.0626802
evaluation/env_infos/final/reward_energy Std              0.0806759
evaluation/env_infos/final/reward_energy Max             -0.00372208
evaluation/env_infos/final/reward_energy Min             -0.500817
evaluation/env_infos/initial/reward_energy Mean          -0.344693
evaluation/env_infos/initial/reward_energy Std            0.298153
evaluation/env_infos/initial/reward_energy Max           -0.0269115
evaluation/env_infos/initial/reward_energy Min           -1.14794
evaluation/env_infos/reward_energy Mean                  -0.111871
evaluation/env_infos/reward_energy Std                    0.173333
evaluation/env_infos/reward_energy Max                   -0.00273078
evaluation/env_infos/reward_energy Min                   -1.21375
evaluation/env_infos/final/end_effector_loc Mean          0.00895803
evaluation/env_infos/final/end_effector_loc Std           0.45652
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00253578
evaluation/env_infos/initial/end_effector_loc Std         0.0159124
evaluation/env_infos/initial/end_effector_loc Max         0.0394808
evaluation/env_infos/initial/end_effector_loc Min        -0.044711
evaluation/env_infos/end_effector_loc Mean                0.0168819
evaluation/env_infos/end_effector_loc Std                 0.320234
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0886279
evaluation/env_infos/final/reward_dist Std                0.206595
evaluation/env_infos/final/reward_dist Max                0.967603
evaluation/env_infos/final/reward_dist Min                1.07743e-170
evaluation/env_infos/initial/reward_dist Mean             0.0111347
evaluation/env_infos/initial/reward_dist Std              0.0236768
evaluation/env_infos/initial/reward_dist Max              0.118849
evaluation/env_infos/initial/reward_dist Min              6.64682e-08
evaluation/env_infos/reward_dist Mean                     0.0989341
evaluation/env_infos/reward_dist Std                      0.19601
evaluation/env_infos/reward_dist Max                      0.998384
evaluation/env_infos/reward_dist Min                      1.07743e-170
time/data storing (s)                                    38.5527
time/evaluation sampling (s)                              0.669627
time/exploration sampling (s)                             0.0863884
time/logging (s)                                          0.0151514
time/saving (s)                                           0.781682
time/training (s)                                        39.1696
time/epoch (s)                                           79.2752
time/total (s)                                        10624.1
Epoch                                                   152
---------------------------------------------------  -----------------
2021-05-29 02:54:18.354030 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 153 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00150566
trainer/QF2 Loss                                          0.00163768
trainer/Policy Loss                                       2.92906
trainer/Q1 Predictions Mean                              -0.848842
trainer/Q1 Predictions Std                                0.804224
trainer/Q1 Predictions Max                                0.51262
trainer/Q1 Predictions Min                               -3.24439
trainer/Q2 Predictions Mean                              -0.838934
trainer/Q2 Predictions Std                                0.809668
trainer/Q2 Predictions Max                                0.532143
trainer/Q2 Predictions Min                               -3.19563
trainer/Q Targets Mean                                   -0.842656
trainer/Q Targets Std                                     0.804191
trainer/Q Targets Max                                     0.491583
trainer/Q Targets Min                                    -3.19828
trainer/Log Pis Mean                                      2.08938
trainer/Log Pis Std                                       1.43178
trainer/Log Pis Max                                       4.47902
trainer/Log Pis Min                                      -6.93799
trainer/Policy mu Mean                                   -0.0166305
trainer/Policy mu Std                                     0.318015
trainer/Policy mu Max                                     2.36584
trainer/Policy mu Min                                    -1.59164
trainer/Policy log std Mean                              -2.37414
trainer/Policy log std Std                                0.56967
trainer/Policy log std Max                               -0.346589
trainer/Policy log std Min                               -3.32958
trainer/Alpha                                             0.0177983
trainer/Alpha Loss                                        0.360119
exploration/num steps total                           16400
exploration/num paths total                             820
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.128118
exploration/Rewards Std                                   0.256696
exploration/Rewards Max                                   0.103258
exploration/Rewards Min                                  -0.922756
exploration/Returns Mean                                 -2.56237
exploration/Returns Std                                   4.63245
exploration/Returns Max                                   0.75535
exploration/Returns Min                                 -11.7551
exploration/Actions Mean                                  0.0182673
exploration/Actions Std                                   0.227235
exploration/Actions Max                                   0.996661
exploration/Actions Min                                  -0.606407
exploration/Num Paths                                     5
exploration/Average Returns                              -2.56237
exploration/env_infos/final/reward_energy Mean           -0.122154
exploration/env_infos/final/reward_energy Std             0.0587461
exploration/env_infos/final/reward_energy Max            -0.0479498
exploration/env_infos/final/reward_energy Min            -0.182213
exploration/env_infos/initial/reward_energy Mean         -0.322526
exploration/env_infos/initial/reward_energy Std           0.201248
exploration/env_infos/initial/reward_energy Max          -0.0385847
exploration/env_infos/initial/reward_energy Min          -0.614576
exploration/env_infos/reward_energy Mean                 -0.215781
exploration/env_infos/reward_energy Std                   0.239535
exploration/env_infos/reward_energy Max                  -0.0120637
exploration/env_infos/reward_energy Min                  -1.0286
exploration/env_infos/final/end_effector_loc Mean         0.125406
exploration/env_infos/final/end_effector_loc Std          0.360957
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.278701
exploration/env_infos/initial/end_effector_loc Mean      -0.0042931
exploration/env_infos/initial/end_effector_loc Std        0.0127367
exploration/env_infos/initial/end_effector_loc Max        0.012811
exploration/env_infos/initial/end_effector_loc Min       -0.0303204
exploration/env_infos/end_effector_loc Mean               0.063941
exploration/env_infos/end_effector_loc Std                0.273638
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.278701
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.244508
exploration/env_infos/final/reward_dist Std               0.297008
exploration/env_infos/final/reward_dist Max               0.773869
exploration/env_infos/final/reward_dist Min               8.27297e-107
exploration/env_infos/initial/reward_dist Mean            0.00543324
exploration/env_infos/initial/reward_dist Std             0.010564
exploration/env_infos/initial/reward_dist Max             0.0265597
exploration/env_infos/initial/reward_dist Min             3.16253e-06
exploration/env_infos/reward_dist Mean                    0.198779
exploration/env_infos/reward_dist Std                     0.265483
exploration/env_infos/reward_dist Max                     0.920385
exploration/env_infos/reward_dist Min                     4.22783e-107
evaluation/num steps total                           154000
evaluation/num paths total                             7700
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0713341
evaluation/Rewards Std                                    0.159145
evaluation/Rewards Max                                    0.17672
evaluation/Rewards Min                                   -1.14903
evaluation/Returns Mean                                  -1.42668
evaluation/Returns Std                                    2.59894
evaluation/Returns Max                                    1.29155
evaluation/Returns Min                                  -11.5116
evaluation/Actions Mean                                   0.00829301
evaluation/Actions Std                                    0.136404
evaluation/Actions Max                                    0.979638
evaluation/Actions Min                                   -0.900177
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.42668
evaluation/env_infos/final/reward_energy Mean            -0.0782719
evaluation/env_infos/final/reward_energy Std              0.163274
evaluation/env_infos/final/reward_energy Max             -0.00658452
evaluation/env_infos/final/reward_energy Min             -0.929257
evaluation/env_infos/initial/reward_energy Mean          -0.344971
evaluation/env_infos/initial/reward_energy Std            0.281755
evaluation/env_infos/initial/reward_energy Max           -0.0264111
evaluation/env_infos/initial/reward_energy Min           -1.16824
evaluation/env_infos/reward_energy Mean                  -0.101586
evaluation/env_infos/reward_energy Std                    0.164408
evaluation/env_infos/reward_energy Max                   -0.000438187
evaluation/env_infos/reward_energy Min                   -1.16824
evaluation/env_infos/final/end_effector_loc Mean          0.0421307
evaluation/env_infos/final/end_effector_loc Std           0.328235
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00105504
evaluation/env_infos/initial/end_effector_loc Std         0.0157123
evaluation/env_infos/initial/end_effector_loc Max         0.0462828
evaluation/env_infos/initial/end_effector_loc Min        -0.0450088
evaluation/env_infos/end_effector_loc Mean                0.0306801
evaluation/env_infos/end_effector_loc Std                 0.239684
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.163587
evaluation/env_infos/final/reward_dist Std                0.256471
evaluation/env_infos/final/reward_dist Max                0.93432
evaluation/env_infos/final/reward_dist Min                1.76394e-190
evaluation/env_infos/initial/reward_dist Mean             0.0111328
evaluation/env_infos/initial/reward_dist Std              0.0250227
evaluation/env_infos/initial/reward_dist Max              0.14083
evaluation/env_infos/initial/reward_dist Min              4.43475e-06
evaluation/env_infos/reward_dist Mean                     0.185288
evaluation/env_infos/reward_dist Std                      0.263953
evaluation/env_infos/reward_dist Max                      0.997229
evaluation/env_infos/reward_dist Min                      1.76394e-190
time/data storing (s)                                    38.3408
time/evaluation sampling (s)                              0.65054
time/exploration sampling (s)                             0.0878557
time/logging (s)                                          0.0178309
time/saving (s)                                           0.785348
time/training (s)                                        39.4389
time/epoch (s)                                           79.3213
time/total (s)                                        10705.1
Epoch                                                   153
---------------------------------------------------  -----------------
2021-05-29 02:55:39.745003 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 154 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00221352
trainer/QF2 Loss                                          0.00300772
trainer/Policy Loss                                       2.70362
trainer/Q1 Predictions Mean                              -0.82506
trainer/Q1 Predictions Std                                0.73833
trainer/Q1 Predictions Max                                0.481199
trainer/Q1 Predictions Min                               -2.81627
trainer/Q2 Predictions Mean                              -0.821087
trainer/Q2 Predictions Std                                0.735595
trainer/Q2 Predictions Max                                0.482572
trainer/Q2 Predictions Min                               -2.78375
trainer/Q Targets Mean                                   -0.83885
trainer/Q Targets Std                                     0.741356
trainer/Q Targets Max                                     0.486377
trainer/Q Targets Min                                    -2.79826
trainer/Log Pis Mean                                      1.87517
trainer/Log Pis Std                                       1.38146
trainer/Log Pis Max                                       4.47735
trainer/Log Pis Min                                      -3.35286
trainer/Policy mu Mean                                   -0.00446678
trainer/Policy mu Std                                     0.28242
trainer/Policy mu Max                                     1.61537
trainer/Policy mu Min                                    -1.99725
trainer/Policy log std Mean                              -2.31065
trainer/Policy log std Std                                0.573023
trainer/Policy log std Max                               -0.184353
trainer/Policy log std Min                               -3.31525
trainer/Alpha                                             0.0176787
trainer/Alpha Loss                                       -0.503643
exploration/num steps total                           16500
exploration/num paths total                             825
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.083626
exploration/Rewards Std                                   0.066284
exploration/Rewards Max                                   0.0483772
exploration/Rewards Min                                  -0.267802
exploration/Returns Mean                                 -1.67252
exploration/Returns Std                                   0.90527
exploration/Returns Max                                  -0.428763
exploration/Returns Min                                  -3.03987
exploration/Actions Mean                                 -0.00651568
exploration/Actions Std                                   0.119861
exploration/Actions Max                                   0.509657
exploration/Actions Min                                  -0.393747
exploration/Num Paths                                     5
exploration/Average Returns                              -1.67252
exploration/env_infos/final/reward_energy Mean           -0.115812
exploration/env_infos/final/reward_energy Std             0.0688265
exploration/env_infos/final/reward_energy Max            -0.0550205
exploration/env_infos/final/reward_energy Min            -0.244667
exploration/env_infos/initial/reward_energy Mean         -0.256988
exploration/env_infos/initial/reward_energy Std           0.178891
exploration/env_infos/initial/reward_energy Max          -0.0515332
exploration/env_infos/initial/reward_energy Min          -0.509966
exploration/env_infos/reward_energy Mean                 -0.133495
exploration/env_infos/reward_energy Std                   0.104867
exploration/env_infos/reward_energy Max                  -0.0107004
exploration/env_infos/reward_energy Min                  -0.509966
exploration/env_infos/final/end_effector_loc Mean         0.00509393
exploration/env_infos/final/end_effector_loc Std          0.216543
exploration/env_infos/final/end_effector_loc Max          0.497946
exploration/env_infos/final/end_effector_loc Min         -0.266957
exploration/env_infos/initial/end_effector_loc Mean       0.00464928
exploration/env_infos/initial/end_effector_loc Std        0.0100469
exploration/env_infos/initial/end_effector_loc Max        0.0254829
exploration/env_infos/initial/end_effector_loc Min       -0.0125805
exploration/env_infos/end_effector_loc Mean               0.0322757
exploration/env_infos/end_effector_loc Std                0.141058
exploration/env_infos/end_effector_loc Max                0.497946
exploration/env_infos/end_effector_loc Min               -0.266957
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0449645
exploration/env_infos/final/reward_dist Std               0.0555582
exploration/env_infos/final/reward_dist Max               0.124042
exploration/env_infos/final/reward_dist Min               1.10619e-12
exploration/env_infos/initial/reward_dist Mean            0.00805265
exploration/env_infos/initial/reward_dist Std             0.0136467
exploration/env_infos/initial/reward_dist Max             0.0352553
exploration/env_infos/initial/reward_dist Min             0.000113276
exploration/env_infos/reward_dist Mean                    0.132713
exploration/env_infos/reward_dist Std                     0.236913
exploration/env_infos/reward_dist Max                     0.921333
exploration/env_infos/reward_dist Min                     1.10619e-12
evaluation/num steps total                           155000
evaluation/num paths total                             7750
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0793226
evaluation/Rewards Std                                    0.105346
evaluation/Rewards Max                                    0.150617
evaluation/Rewards Min                                   -0.640425
evaluation/Returns Mean                                  -1.58645
evaluation/Returns Std                                    1.69796
evaluation/Returns Max                                    1.42252
evaluation/Returns Min                                   -8.38565
evaluation/Actions Mean                                  -0.00209731
evaluation/Actions Std                                    0.121211
evaluation/Actions Max                                    0.835264
evaluation/Actions Min                                   -0.954138
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.58645
evaluation/env_infos/final/reward_energy Mean            -0.0786208
evaluation/env_infos/final/reward_energy Std              0.124043
evaluation/env_infos/final/reward_energy Max             -0.000616633
evaluation/env_infos/final/reward_energy Min             -0.661613
evaluation/env_infos/initial/reward_energy Mean          -0.358417
evaluation/env_infos/initial/reward_energy Std            0.300759
evaluation/env_infos/initial/reward_energy Max           -0.00865729
evaluation/env_infos/initial/reward_energy Min           -1.05347
evaluation/env_infos/reward_energy Mean                  -0.104662
evaluation/env_infos/reward_energy Std                    0.13579
evaluation/env_infos/reward_energy Max                   -0.000616633
evaluation/env_infos/reward_energy Min                   -1.05347
evaluation/env_infos/final/end_effector_loc Mean         -0.0464109
evaluation/env_infos/final/end_effector_loc Std           0.397202
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000966967
evaluation/env_infos/initial/end_effector_loc Std         0.016514
evaluation/env_infos/initial/end_effector_loc Max         0.0417632
evaluation/env_infos/initial/end_effector_loc Min        -0.0477069
evaluation/env_infos/end_effector_loc Mean               -0.0124099
evaluation/env_infos/end_effector_loc Std                 0.26973
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.126039
evaluation/env_infos/final/reward_dist Std                0.268636
evaluation/env_infos/final/reward_dist Max                0.965792
evaluation/env_infos/final/reward_dist Min                8.70806e-172
evaluation/env_infos/initial/reward_dist Mean             0.00980582
evaluation/env_infos/initial/reward_dist Std              0.01879
evaluation/env_infos/initial/reward_dist Max              0.103679
evaluation/env_infos/initial/reward_dist Min              1.17935e-06
evaluation/env_infos/reward_dist Mean                     0.144362
evaluation/env_infos/reward_dist Std                      0.243074
evaluation/env_infos/reward_dist Max                      0.984626
evaluation/env_infos/reward_dist Min                      8.70806e-172
time/data storing (s)                                    38.7078
time/evaluation sampling (s)                              0.680941
time/exploration sampling (s)                             0.0888252
time/logging (s)                                          0.0156924
time/saving (s)                                           0.793276
time/training (s)                                        39.3718
time/epoch (s)                                           79.6583
time/total (s)                                        10786.5
Epoch                                                   154
---------------------------------------------------  -----------------
2021-05-29 02:57:00.661937 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 155 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00301948
trainer/QF2 Loss                                          0.00247563
trainer/Policy Loss                                       2.75253
trainer/Q1 Predictions Mean                              -0.722963
trainer/Q1 Predictions Std                                0.736106
trainer/Q1 Predictions Max                                0.577831
trainer/Q1 Predictions Min                               -3.42909
trainer/Q2 Predictions Mean                              -0.715416
trainer/Q2 Predictions Std                                0.74076
trainer/Q2 Predictions Max                                0.581443
trainer/Q2 Predictions Min                               -3.50109
trainer/Q Targets Mean                                   -0.725031
trainer/Q Targets Std                                     0.73667
trainer/Q Targets Max                                     0.620978
trainer/Q Targets Min                                    -3.40133
trainer/Log Pis Mean                                      2.04264
trainer/Log Pis Std                                       1.35663
trainer/Log Pis Max                                       4.84393
trainer/Log Pis Min                                      -3.48191
trainer/Policy mu Mean                                   -0.0459
trainer/Policy mu Std                                     0.358827
trainer/Policy mu Max                                     1.31238
trainer/Policy mu Min                                    -2.41869
trainer/Policy log std Mean                              -2.31969
trainer/Policy log std Std                                0.562292
trainer/Policy log std Max                               -0.486365
trainer/Policy log std Min                               -3.44947
trainer/Alpha                                             0.0178217
trainer/Alpha Loss                                        0.171755
exploration/num steps total                           16600
exploration/num paths total                             830
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.095749
exploration/Rewards Std                                   0.119624
exploration/Rewards Max                                   0.0821031
exploration/Rewards Min                                  -0.428445
exploration/Returns Mean                                 -1.91498
exploration/Returns Std                                   1.30137
exploration/Returns Max                                  -0.085017
exploration/Returns Min                                  -3.6518
exploration/Actions Mean                                 -0.000843405
exploration/Actions Std                                   0.157103
exploration/Actions Max                                   0.451996
exploration/Actions Min                                  -0.838907
exploration/Num Paths                                     5
exploration/Average Returns                              -1.91498
exploration/env_infos/final/reward_energy Mean           -0.0945803
exploration/env_infos/final/reward_energy Std             0.0295237
exploration/env_infos/final/reward_energy Max            -0.0414469
exploration/env_infos/final/reward_energy Min            -0.128745
exploration/env_infos/initial/reward_energy Mean         -0.43651
exploration/env_infos/initial/reward_energy Std           0.304997
exploration/env_infos/initial/reward_energy Max          -0.0379637
exploration/env_infos/initial/reward_energy Min          -0.842518
exploration/env_infos/reward_energy Mean                 -0.167855
exploration/env_infos/reward_energy Std                   0.145565
exploration/env_infos/reward_energy Max                  -0.00463721
exploration/env_infos/reward_energy Min                  -0.842518
exploration/env_infos/final/end_effector_loc Mean        -0.0148532
exploration/env_infos/final/end_effector_loc Std          0.468134
exploration/env_infos/final/end_effector_loc Max          0.54498
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00419254
exploration/env_infos/initial/end_effector_loc Std        0.0183542
exploration/env_infos/initial/end_effector_loc Max        0.0225998
exploration/env_infos/initial/end_effector_loc Min       -0.0419454
exploration/env_infos/end_effector_loc Mean              -0.0154399
exploration/env_infos/end_effector_loc Std                0.281514
exploration/env_infos/end_effector_loc Max                0.54498
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0636589
exploration/env_infos/final/reward_dist Std               0.127314
exploration/env_infos/final/reward_dist Max               0.318287
exploration/env_infos/final/reward_dist Min               4.59428e-52
exploration/env_infos/initial/reward_dist Mean            0.0036619
exploration/env_infos/initial/reward_dist Std             0.00680206
exploration/env_infos/initial/reward_dist Max             0.0172508
exploration/env_infos/initial/reward_dist Min             4.53247e-06
exploration/env_infos/reward_dist Mean                    0.145498
exploration/env_infos/reward_dist Std                     0.245257
exploration/env_infos/reward_dist Max                     0.913271
exploration/env_infos/reward_dist Min                     4.59428e-52
evaluation/num steps total                           156000
evaluation/num paths total                             7800
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.102394
evaluation/Rewards Std                                    0.143647
evaluation/Rewards Max                                    0.15624
evaluation/Rewards Min                                   -0.661732
evaluation/Returns Mean                                  -2.04787
evaluation/Returns Std                                    2.5583
evaluation/Returns Max                                    1.8551
evaluation/Returns Min                                   -8.61908
evaluation/Actions Mean                                   0.0136225
evaluation/Actions Std                                    0.16156
evaluation/Actions Max                                    0.8861
evaluation/Actions Min                                   -0.895057
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.04787
evaluation/env_infos/final/reward_energy Mean            -0.0932844
evaluation/env_infos/final/reward_energy Std              0.109279
evaluation/env_infos/final/reward_energy Max             -0.00218407
evaluation/env_infos/final/reward_energy Min             -0.463787
evaluation/env_infos/initial/reward_energy Mean          -0.342787
evaluation/env_infos/initial/reward_energy Std            0.282356
evaluation/env_infos/initial/reward_energy Max           -0.0018288
evaluation/env_infos/initial/reward_energy Min           -0.949202
evaluation/env_infos/reward_energy Mean                  -0.136103
evaluation/env_infos/reward_energy Std                    0.184527
evaluation/env_infos/reward_energy Max                   -0.0018288
evaluation/env_infos/reward_energy Min                   -1.21392
evaluation/env_infos/final/end_effector_loc Mean         -0.0449104
evaluation/env_infos/final/end_effector_loc Std           0.511798
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -4.60143e-05
evaluation/env_infos/initial/end_effector_loc Std         0.0157014
evaluation/env_infos/initial/end_effector_loc Max         0.0411334
evaluation/env_infos/initial/end_effector_loc Min        -0.0447528
evaluation/env_infos/end_effector_loc Mean               -0.0199876
evaluation/env_infos/end_effector_loc Std                 0.354641
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0980736
evaluation/env_infos/final/reward_dist Std                0.209525
evaluation/env_infos/final/reward_dist Max                0.843983
evaluation/env_infos/final/reward_dist Min                1.21028e-180
evaluation/env_infos/initial/reward_dist Mean             0.00452558
evaluation/env_infos/initial/reward_dist Std              0.0102309
evaluation/env_infos/initial/reward_dist Max              0.0602362
evaluation/env_infos/initial/reward_dist Min              2.45004e-07
evaluation/env_infos/reward_dist Mean                     0.132172
evaluation/env_infos/reward_dist Std                      0.248273
evaluation/env_infos/reward_dist Max                      0.999463
evaluation/env_infos/reward_dist Min                      1.21028e-180
time/data storing (s)                                    38.472
time/evaluation sampling (s)                              0.636157
time/exploration sampling (s)                             0.0819849
time/logging (s)                                          0.0159901
time/saving (s)                                           0.812247
time/training (s)                                        39.2071
time/epoch (s)                                           79.2255
time/total (s)                                        10867.4
Epoch                                                   155
---------------------------------------------------  -----------------
2021-05-29 02:58:21.796729 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 156 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00288311
trainer/QF2 Loss                                          0.00203325
trainer/Policy Loss                                       2.74535
trainer/Q1 Predictions Mean                              -0.739063
trainer/Q1 Predictions Std                                0.734591
trainer/Q1 Predictions Max                                0.526075
trainer/Q1 Predictions Min                               -4.30303
trainer/Q2 Predictions Mean                              -0.75126
trainer/Q2 Predictions Std                                0.737415
trainer/Q2 Predictions Max                                0.522595
trainer/Q2 Predictions Min                               -4.48648
trainer/Q Targets Mean                                   -0.747775
trainer/Q Targets Std                                     0.737291
trainer/Q Targets Max                                     0.52293
trainer/Q Targets Min                                    -4.26213
trainer/Log Pis Mean                                      2.01067
trainer/Log Pis Std                                       1.29981
trainer/Log Pis Max                                       6.74658
trainer/Log Pis Min                                      -1.76092
trainer/Policy mu Mean                                   -0.0810105
trainer/Policy mu Std                                     0.416159
trainer/Policy mu Max                                     1.4021
trainer/Policy mu Min                                    -2.78043
trainer/Policy log std Mean                              -2.26583
trainer/Policy log std Std                                0.629396
trainer/Policy log std Max                                0.0700938
trainer/Policy log std Min                               -3.44756
trainer/Alpha                                             0.0167474
trainer/Alpha Loss                                        0.0436481
exploration/num steps total                           16700
exploration/num paths total                             835
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.108145
exploration/Rewards Std                                   0.149354
exploration/Rewards Max                                   0.0972158
exploration/Rewards Min                                  -0.610537
exploration/Returns Mean                                 -2.1629
exploration/Returns Std                                   2.25985
exploration/Returns Max                                   0.695496
exploration/Returns Min                                  -5.60907
exploration/Actions Mean                                 -0.00962588
exploration/Actions Std                                   0.211293
exploration/Actions Max                                   0.785714
exploration/Actions Min                                  -0.995258
exploration/Num Paths                                     5
exploration/Average Returns                              -2.1629
exploration/env_infos/final/reward_energy Mean           -0.0906069
exploration/env_infos/final/reward_energy Std             0.0436095
exploration/env_infos/final/reward_energy Max            -0.00801519
exploration/env_infos/final/reward_energy Min            -0.136063
exploration/env_infos/initial/reward_energy Mean         -0.302844
exploration/env_infos/initial/reward_energy Std           0.296176
exploration/env_infos/initial/reward_energy Max          -0.0471984
exploration/env_infos/initial/reward_energy Min          -0.849136
exploration/env_infos/reward_energy Mean                 -0.194086
exploration/env_infos/reward_energy Std                   0.227609
exploration/env_infos/reward_energy Max                  -0.00801519
exploration/env_infos/reward_energy Min                  -1.21398
exploration/env_infos/final/end_effector_loc Mean        -0.0880183
exploration/env_infos/final/end_effector_loc Std          0.368765
exploration/env_infos/final/end_effector_loc Max          0.356972
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00392141
exploration/env_infos/initial/end_effector_loc Std        0.0144539
exploration/env_infos/initial/end_effector_loc Max        0.0392857
exploration/env_infos/initial/end_effector_loc Min       -0.0190321
exploration/env_infos/end_effector_loc Mean              -0.00625939
exploration/env_infos/end_effector_loc Std                0.206165
exploration/env_infos/end_effector_loc Max                0.356972
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.189661
exploration/env_infos/final/reward_dist Std               0.237483
exploration/env_infos/final/reward_dist Max               0.552343
exploration/env_infos/final/reward_dist Min               1.26964e-45
exploration/env_infos/initial/reward_dist Mean            0.0010121
exploration/env_infos/initial/reward_dist Std             0.00149593
exploration/env_infos/initial/reward_dist Max             0.00397837
exploration/env_infos/initial/reward_dist Min             1.60695e-05
exploration/env_infos/reward_dist Mean                    0.21049
exploration/env_infos/reward_dist Std                     0.325678
exploration/env_infos/reward_dist Max                     0.93359
exploration/env_infos/reward_dist Min                     1.26964e-45
evaluation/num steps total                           157000
evaluation/num paths total                             7850
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0705892
evaluation/Rewards Std                                    0.120298
evaluation/Rewards Max                                    0.175094
evaluation/Rewards Min                                   -0.643661
evaluation/Returns Mean                                  -1.41178
evaluation/Returns Std                                    2.02197
evaluation/Returns Max                                    2.59549
evaluation/Returns Min                                  -10.1406
evaluation/Actions Mean                                   0.00639854
evaluation/Actions Std                                    0.139839
evaluation/Actions Max                                    0.943704
evaluation/Actions Min                                   -0.964174
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.41178
evaluation/env_infos/final/reward_energy Mean            -0.110454
evaluation/env_infos/final/reward_energy Std              0.186405
evaluation/env_infos/final/reward_energy Max             -0.00194347
evaluation/env_infos/final/reward_energy Min             -1.23568
evaluation/env_infos/initial/reward_energy Mean          -0.349998
evaluation/env_infos/initial/reward_energy Std            0.316565
evaluation/env_infos/initial/reward_energy Max           -0.0145252
evaluation/env_infos/initial/reward_energy Min           -1.34915
evaluation/env_infos/reward_energy Mean                  -0.118696
evaluation/env_infos/reward_energy Std                    0.158439
evaluation/env_infos/reward_energy Max                   -0.00114687
evaluation/env_infos/reward_energy Min                   -1.34915
evaluation/env_infos/final/end_effector_loc Mean         -0.0716667
evaluation/env_infos/final/end_effector_loc Std           0.415347
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000386159
evaluation/env_infos/initial/end_effector_loc Std         0.0166805
evaluation/env_infos/initial/end_effector_loc Max         0.0471852
evaluation/env_infos/initial/end_effector_loc Min        -0.0482087
evaluation/env_infos/end_effector_loc Mean               -0.0283286
evaluation/env_infos/end_effector_loc Std                 0.276717
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.106759
evaluation/env_infos/final/reward_dist Std                0.213311
evaluation/env_infos/final/reward_dist Max                0.848792
evaluation/env_infos/final/reward_dist Min                7.52312e-166
evaluation/env_infos/initial/reward_dist Mean             0.00918128
evaluation/env_infos/initial/reward_dist Std              0.0197474
evaluation/env_infos/initial/reward_dist Max              0.125307
evaluation/env_infos/initial/reward_dist Min              9.06798e-07
evaluation/env_infos/reward_dist Mean                     0.151369
evaluation/env_infos/reward_dist Std                      0.248963
evaluation/env_infos/reward_dist Max                      0.985077
evaluation/env_infos/reward_dist Min                      7.52312e-166
time/data storing (s)                                    38.3661
time/evaluation sampling (s)                              0.65511
time/exploration sampling (s)                             0.0897755
time/logging (s)                                          0.0149699
time/saving (s)                                           0.828372
time/training (s)                                        39.473
time/epoch (s)                                           79.4273
time/total (s)                                        10948.6
Epoch                                                   156
---------------------------------------------------  -----------------
2021-05-29 02:59:42.371687 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 157 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00219351
trainer/QF2 Loss                                          0.001731
trainer/Policy Loss                                       2.9218
trainer/Q1 Predictions Mean                              -0.790979
trainer/Q1 Predictions Std                                0.672851
trainer/Q1 Predictions Max                                0.74394
trainer/Q1 Predictions Min                               -3.11358
trainer/Q2 Predictions Mean                              -0.780152
trainer/Q2 Predictions Std                                0.668038
trainer/Q2 Predictions Max                                0.697607
trainer/Q2 Predictions Min                               -3.05372
trainer/Q Targets Mean                                   -0.781034
trainer/Q Targets Std                                     0.669173
trainer/Q Targets Max                                     0.696637
trainer/Q Targets Min                                    -3.0012
trainer/Log Pis Mean                                      2.14845
trainer/Log Pis Std                                       1.27334
trainer/Log Pis Max                                       7.51117
trainer/Log Pis Min                                      -1.82052
trainer/Policy mu Mean                                   -0.0181657
trainer/Policy mu Std                                     0.480598
trainer/Policy mu Max                                     2.41437
trainer/Policy mu Min                                    -3.02613
trainer/Policy log std Mean                              -2.26226
trainer/Policy log std Std                                0.63434
trainer/Policy log std Max                               -0.377224
trainer/Policy log std Min                               -3.39906
trainer/Alpha                                             0.018018
trainer/Alpha Loss                                        0.596322
exploration/num steps total                           16800
exploration/num paths total                             840
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0987475
exploration/Rewards Std                                   0.201492
exploration/Rewards Max                                   0.148233
exploration/Rewards Min                                  -0.713737
exploration/Returns Mean                                 -1.97495
exploration/Returns Std                                   3.58102
exploration/Returns Max                                   1.95793
exploration/Returns Min                                  -8.07532
exploration/Actions Mean                                  0.0064075
exploration/Actions Std                                   0.195565
exploration/Actions Max                                   0.856006
exploration/Actions Min                                  -0.766256
exploration/Num Paths                                     5
exploration/Average Returns                              -1.97495
exploration/env_infos/final/reward_energy Mean           -0.182916
exploration/env_infos/final/reward_energy Std             0.161787
exploration/env_infos/final/reward_energy Max            -0.032977
exploration/env_infos/final/reward_energy Min            -0.489862
exploration/env_infos/initial/reward_energy Mean         -0.443206
exploration/env_infos/initial/reward_energy Std           0.255952
exploration/env_infos/initial/reward_energy Max          -0.206177
exploration/env_infos/initial/reward_energy Min          -0.92277
exploration/env_infos/reward_energy Mean                 -0.205059
exploration/env_infos/reward_energy Std                   0.185806
exploration/env_infos/reward_energy Max                  -0.0253619
exploration/env_infos/reward_energy Min                  -1.11422
exploration/env_infos/final/end_effector_loc Mean        -0.026603
exploration/env_infos/final/end_effector_loc Std          0.191248
exploration/env_infos/final/end_effector_loc Max          0.265433
exploration/env_infos/final/end_effector_loc Min         -0.360278
exploration/env_infos/initial/end_effector_loc Mean       0.000924303
exploration/env_infos/initial/end_effector_loc Std        0.0180714
exploration/env_infos/initial/end_effector_loc Max        0.0428003
exploration/env_infos/initial/end_effector_loc Min       -0.0223736
exploration/env_infos/end_effector_loc Mean              -0.0333626
exploration/env_infos/end_effector_loc Std                0.172835
exploration/env_infos/end_effector_loc Max                0.265433
exploration/env_infos/end_effector_loc Min               -0.419133
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0326773
exploration/env_infos/final/reward_dist Std               0.0413561
exploration/env_infos/final/reward_dist Max               0.106795
exploration/env_infos/final/reward_dist Min               3.50781e-11
exploration/env_infos/initial/reward_dist Mean            0.0123034
exploration/env_infos/initial/reward_dist Std             0.0159041
exploration/env_infos/initial/reward_dist Max             0.0424942
exploration/env_infos/initial/reward_dist Min             1.86576e-05
exploration/env_infos/reward_dist Mean                    0.217855
exploration/env_infos/reward_dist Std                     0.281354
exploration/env_infos/reward_dist Max                     0.990377
exploration/env_infos/reward_dist Min                     3.14008e-32
evaluation/num steps total                           158000
evaluation/num paths total                             7900
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.088156
evaluation/Rewards Std                                    0.144558
evaluation/Rewards Max                                    0.131444
evaluation/Rewards Min                                   -1.03646
evaluation/Returns Mean                                  -1.76312
evaluation/Returns Std                                    2.58658
evaluation/Returns Max                                    1.16547
evaluation/Returns Min                                  -16.4921
evaluation/Actions Mean                                   0.0275475
evaluation/Actions Std                                    0.181257
evaluation/Actions Max                                    0.998295
evaluation/Actions Min                                   -0.949037
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.76312
evaluation/env_infos/final/reward_energy Mean            -0.106058
evaluation/env_infos/final/reward_energy Std              0.163851
evaluation/env_infos/final/reward_energy Max             -0.000443919
evaluation/env_infos/final/reward_energy Min             -0.761416
evaluation/env_infos/initial/reward_energy Mean          -0.371152
evaluation/env_infos/initial/reward_energy Std            0.367259
evaluation/env_infos/initial/reward_energy Max           -0.0168456
evaluation/env_infos/initial/reward_energy Min           -1.34843
evaluation/env_infos/reward_energy Mean                  -0.133096
evaluation/env_infos/reward_energy Std                    0.222511
evaluation/env_infos/reward_energy Max                   -4.976e-05
evaluation/env_infos/reward_energy Min                   -1.36007
evaluation/env_infos/final/end_effector_loc Mean          0.068562
evaluation/env_infos/final/end_effector_loc Std           0.400027
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.0015026
evaluation/env_infos/initial/end_effector_loc Std         0.0183993
evaluation/env_infos/initial/end_effector_loc Max         0.0498454
evaluation/env_infos/initial/end_effector_loc Min        -0.0474519
evaluation/env_infos/end_effector_loc Mean                0.0312214
evaluation/env_infos/end_effector_loc Std                 0.280016
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0902548
evaluation/env_infos/final/reward_dist Std                0.175976
evaluation/env_infos/final/reward_dist Max                0.768325
evaluation/env_infos/final/reward_dist Min                9.03236e-189
evaluation/env_infos/initial/reward_dist Mean             0.00729484
evaluation/env_infos/initial/reward_dist Std              0.0209275
evaluation/env_infos/initial/reward_dist Max              0.13802
evaluation/env_infos/initial/reward_dist Min              1.55691e-06
evaluation/env_infos/reward_dist Mean                     0.169267
evaluation/env_infos/reward_dist Std                      0.260998
evaluation/env_infos/reward_dist Max                      0.999016
evaluation/env_infos/reward_dist Min                      9.03236e-189
time/data storing (s)                                    38.0843
time/evaluation sampling (s)                              0.692064
time/exploration sampling (s)                             0.0864273
time/logging (s)                                          0.016579
time/saving (s)                                           0.779079
time/training (s)                                        39.1721
time/epoch (s)                                           78.8306
time/total (s)                                        11029.1
Epoch                                                   157
---------------------------------------------------  -----------------
2021-05-29 03:01:03.731537 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 158 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0021896
trainer/QF2 Loss                                          0.00316973
trainer/Policy Loss                                       2.86668
trainer/Q1 Predictions Mean                              -0.76838
trainer/Q1 Predictions Std                                0.843513
trainer/Q1 Predictions Max                                0.819667
trainer/Q1 Predictions Min                               -5.28015
trainer/Q2 Predictions Mean                              -0.776744
trainer/Q2 Predictions Std                                0.843357
trainer/Q2 Predictions Max                                0.833806
trainer/Q2 Predictions Min                               -5.19168
trainer/Q Targets Mean                                   -0.772612
trainer/Q Targets Std                                     0.853161
trainer/Q Targets Max                                     0.826059
trainer/Q Targets Min                                    -5.32752
trainer/Log Pis Mean                                      2.11432
trainer/Log Pis Std                                       1.43965
trainer/Log Pis Max                                       9.22774
trainer/Log Pis Min                                      -1.29365
trainer/Policy mu Mean                                   -0.100906
trainer/Policy mu Std                                     0.54324
trainer/Policy mu Max                                     2.55465
trainer/Policy mu Min                                    -3.13527
trainer/Policy log std Mean                              -2.24008
trainer/Policy log std Std                                0.609379
trainer/Policy log std Max                               -0.115308
trainer/Policy log std Min                               -3.3206
trainer/Alpha                                             0.0185599
trainer/Alpha Loss                                        0.455836
exploration/num steps total                           16900
exploration/num paths total                             845
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.113487
exploration/Rewards Std                                   0.111822
exploration/Rewards Max                                   0.0411372
exploration/Rewards Min                                  -0.554073
exploration/Returns Mean                                 -2.26974
exploration/Returns Std                                   1.48406
exploration/Returns Max                                  -0.820626
exploration/Returns Min                                  -4.9804
exploration/Actions Mean                                  0.004643
exploration/Actions Std                                   0.114344
exploration/Actions Max                                   0.551981
exploration/Actions Min                                  -0.517529
exploration/Num Paths                                     5
exploration/Average Returns                              -2.26974
exploration/env_infos/final/reward_energy Mean           -0.185689
exploration/env_infos/final/reward_energy Std             0.195696
exploration/env_infos/final/reward_energy Max            -0.0219456
exploration/env_infos/final/reward_energy Min            -0.570569
exploration/env_infos/initial/reward_energy Mean         -0.115548
exploration/env_infos/initial/reward_energy Std           0.0289468
exploration/env_infos/initial/reward_energy Max          -0.0719453
exploration/env_infos/initial/reward_energy Min          -0.150665
exploration/env_infos/reward_energy Mean                 -0.125996
exploration/env_infos/reward_energy Std                   0.101574
exploration/env_infos/reward_energy Max                  -0.0129095
exploration/env_infos/reward_energy Min                  -0.570569
exploration/env_infos/final/end_effector_loc Mean        -0.0014235
exploration/env_infos/final/end_effector_loc Std          0.497998
exploration/env_infos/final/end_effector_loc Max          0.860697
exploration/env_infos/final/end_effector_loc Min         -0.957105
exploration/env_infos/initial/end_effector_loc Mean      -0.000925759
exploration/env_infos/initial/end_effector_loc Std        0.00410846
exploration/env_infos/initial/end_effector_loc Max        0.00570622
exploration/env_infos/initial/end_effector_loc Min       -0.00579563
exploration/env_infos/end_effector_loc Mean              -0.0050328
exploration/env_infos/end_effector_loc Std                0.235342
exploration/env_infos/end_effector_loc Max                0.860697
exploration/env_infos/end_effector_loc Min               -0.957105
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.105948
exploration/env_infos/final/reward_dist Std               0.135032
exploration/env_infos/final/reward_dist Max               0.323957
exploration/env_infos/final/reward_dist Min               3.28019e-142
exploration/env_infos/initial/reward_dist Mean            0.000543309
exploration/env_infos/initial/reward_dist Std             0.000450345
exploration/env_infos/initial/reward_dist Max             0.001146
exploration/env_infos/initial/reward_dist Min             6.3259e-05
exploration/env_infos/reward_dist Mean                    0.111307
exploration/env_infos/reward_dist Std                     0.176116
exploration/env_infos/reward_dist Max                     0.621709
exploration/env_infos/reward_dist Min                     3.28019e-142
evaluation/num steps total                           159000
evaluation/num paths total                             7950
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0977956
evaluation/Rewards Std                                    0.195851
evaluation/Rewards Max                                    0.152543
evaluation/Rewards Min                                   -0.990728
evaluation/Returns Mean                                  -1.95591
evaluation/Returns Std                                    3.47205
evaluation/Returns Max                                    1.6624
evaluation/Returns Min                                  -12.8366
evaluation/Actions Mean                                   0.0132226
evaluation/Actions Std                                    0.142717
evaluation/Actions Max                                    0.83855
evaluation/Actions Min                                   -0.907637
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.95591
evaluation/env_infos/final/reward_energy Mean            -0.0629395
evaluation/env_infos/final/reward_energy Std              0.083312
evaluation/env_infos/final/reward_energy Max             -0.00358165
evaluation/env_infos/final/reward_energy Min             -0.512439
evaluation/env_infos/initial/reward_energy Mean          -0.38183
evaluation/env_infos/initial/reward_energy Std            0.302471
evaluation/env_infos/initial/reward_energy Max           -0.0117102
evaluation/env_infos/initial/reward_energy Min           -1.19445
evaluation/env_infos/reward_energy Mean                  -0.120758
evaluation/env_infos/reward_energy Std                    0.162798
evaluation/env_infos/reward_energy Max                   -0.000251244
evaluation/env_infos/reward_energy Min                   -1.19445
evaluation/env_infos/final/end_effector_loc Mean         -0.00245189
evaluation/env_infos/final/end_effector_loc Std           0.437834
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000761774
evaluation/env_infos/initial/end_effector_loc Std         0.0172053
evaluation/env_infos/initial/end_effector_loc Max         0.0419275
evaluation/env_infos/initial/end_effector_loc Min        -0.0453818
evaluation/env_infos/end_effector_loc Mean               -0.0010352
evaluation/env_infos/end_effector_loc Std                 0.314763
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.13433
evaluation/env_infos/final/reward_dist Std                0.228031
evaluation/env_infos/final/reward_dist Max                0.903092
evaluation/env_infos/final/reward_dist Min                3.93264e-180
evaluation/env_infos/initial/reward_dist Mean             0.0069036
evaluation/env_infos/initial/reward_dist Std              0.00955276
evaluation/env_infos/initial/reward_dist Max              0.0297401
evaluation/env_infos/initial/reward_dist Min              2.18175e-06
evaluation/env_infos/reward_dist Mean                     0.163632
evaluation/env_infos/reward_dist Std                      0.25348
evaluation/env_infos/reward_dist Max                      0.99774
evaluation/env_infos/reward_dist Min                      3.93264e-180
time/data storing (s)                                    38.898
time/evaluation sampling (s)                              0.647654
time/exploration sampling (s)                             0.0901037
time/logging (s)                                          0.0140119
time/saving (s)                                           0.776933
time/training (s)                                        39.2566
time/epoch (s)                                           79.6834
time/total (s)                                        11110.5
Epoch                                                   158
---------------------------------------------------  -----------------
2021-05-29 03:02:24.525462 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 159 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00295138
trainer/QF2 Loss                                          0.00289665
trainer/Policy Loss                                       2.83694
trainer/Q1 Predictions Mean                              -0.803249
trainer/Q1 Predictions Std                                0.750411
trainer/Q1 Predictions Max                                0.756772
trainer/Q1 Predictions Min                               -2.72801
trainer/Q2 Predictions Mean                              -0.797452
trainer/Q2 Predictions Std                                0.744958
trainer/Q2 Predictions Max                                0.765311
trainer/Q2 Predictions Min                               -2.70816
trainer/Q Targets Mean                                   -0.786576
trainer/Q Targets Std                                     0.752162
trainer/Q Targets Max                                     0.810207
trainer/Q Targets Min                                    -2.64896
trainer/Log Pis Mean                                      2.04116
trainer/Log Pis Std                                       1.34476
trainer/Log Pis Max                                       5.76027
trainer/Log Pis Min                                      -3.44939
trainer/Policy mu Mean                                   -0.0662106
trainer/Policy mu Std                                     0.441438
trainer/Policy mu Max                                     2.27597
trainer/Policy mu Min                                    -2.84337
trainer/Policy log std Mean                              -2.27082
trainer/Policy log std Std                                0.594479
trainer/Policy log std Max                               -0.0756359
trainer/Policy log std Min                               -3.32212
trainer/Alpha                                             0.0200296
trainer/Alpha Loss                                        0.160968
exploration/num steps total                           17000
exploration/num paths total                             850
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.235286
exploration/Rewards Std                                   0.236588
exploration/Rewards Max                                  -0.0110053
exploration/Rewards Min                                  -0.841393
exploration/Returns Mean                                 -4.70573
exploration/Returns Std                                   3.75866
exploration/Returns Max                                  -1.11515
exploration/Returns Min                                 -11.2318
exploration/Actions Mean                                  0.000668169
exploration/Actions Std                                   0.154007
exploration/Actions Max                                   0.703782
exploration/Actions Min                                  -0.859312
exploration/Num Paths                                     5
exploration/Average Returns                              -4.70573
exploration/env_infos/final/reward_energy Mean           -0.138184
exploration/env_infos/final/reward_energy Std             0.0981619
exploration/env_infos/final/reward_energy Max            -0.0658273
exploration/env_infos/final/reward_energy Min            -0.332764
exploration/env_infos/initial/reward_energy Mean         -0.287736
exploration/env_infos/initial/reward_energy Std           0.334478
exploration/env_infos/initial/reward_energy Max          -0.0153729
exploration/env_infos/initial/reward_energy Min          -0.891053
exploration/env_infos/reward_energy Mean                 -0.143224
exploration/env_infos/reward_energy Std                   0.164086
exploration/env_infos/reward_energy Max                  -0.0125087
exploration/env_infos/reward_energy Min                  -0.891053
exploration/env_infos/final/end_effector_loc Mean         0.0827167
exploration/env_infos/final/end_effector_loc Std          0.428802
exploration/env_infos/final/end_effector_loc Max          0.612128
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00230765
exploration/env_infos/initial/end_effector_loc Std        0.0154275
exploration/env_infos/initial/end_effector_loc Max        0.0177235
exploration/env_infos/initial/end_effector_loc Min       -0.0429656
exploration/env_infos/end_effector_loc Mean               0.0317266
exploration/env_infos/end_effector_loc Std                0.312944
exploration/env_infos/end_effector_loc Max                0.674531
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0222626
exploration/env_infos/final/reward_dist Std               0.0414992
exploration/env_infos/final/reward_dist Max               0.105122
exploration/env_infos/final/reward_dist Min               2.8515e-70
exploration/env_infos/initial/reward_dist Mean            0.00334938
exploration/env_infos/initial/reward_dist Std             0.00494984
exploration/env_infos/initial/reward_dist Max             0.013097
exploration/env_infos/initial/reward_dist Min             5.54664e-05
exploration/env_infos/reward_dist Mean                    0.0227965
exploration/env_infos/reward_dist Std                     0.0552007
exploration/env_infos/reward_dist Max                     0.381809
exploration/env_infos/reward_dist Min                     3.51935e-74
evaluation/num steps total                           160000
evaluation/num paths total                             8000
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0917678
evaluation/Rewards Std                                    0.140934
evaluation/Rewards Max                                    0.141226
evaluation/Rewards Min                                   -1.00478
evaluation/Returns Mean                                  -1.83536
evaluation/Returns Std                                    2.34165
evaluation/Returns Max                                    1.42483
evaluation/Returns Min                                  -13.4813
evaluation/Actions Mean                                  -0.000714807
evaluation/Actions Std                                    0.142189
evaluation/Actions Max                                    0.875104
evaluation/Actions Min                                   -0.96795
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.83536
evaluation/env_infos/final/reward_energy Mean            -0.0729471
evaluation/env_infos/final/reward_energy Std              0.112188
evaluation/env_infos/final/reward_energy Max             -0.00430874
evaluation/env_infos/final/reward_energy Min             -0.631439
evaluation/env_infos/initial/reward_energy Mean          -0.490873
evaluation/env_infos/initial/reward_energy Std            0.332605
evaluation/env_infos/initial/reward_energy Max           -0.0129208
evaluation/env_infos/initial/reward_energy Min           -1.23447
evaluation/env_infos/reward_energy Mean                  -0.120752
evaluation/env_infos/reward_energy Std                    0.160796
evaluation/env_infos/reward_energy Max                   -0.000391612
evaluation/env_infos/reward_energy Min                   -1.23447
evaluation/env_infos/final/end_effector_loc Mean         -0.0337489
evaluation/env_infos/final/end_effector_loc Std           0.423323
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00269185
evaluation/env_infos/initial/end_effector_loc Std         0.0207902
evaluation/env_infos/initial/end_effector_loc Max         0.0437552
evaluation/env_infos/initial/end_effector_loc Min        -0.0483975
evaluation/env_infos/end_effector_loc Mean               -0.0191032
evaluation/env_infos/end_effector_loc Std                 0.29829
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0933412
evaluation/env_infos/final/reward_dist Std                0.189399
evaluation/env_infos/final/reward_dist Max                0.890231
evaluation/env_infos/final/reward_dist Min                3.50834e-175
evaluation/env_infos/initial/reward_dist Mean             0.0127405
evaluation/env_infos/initial/reward_dist Std              0.0294195
evaluation/env_infos/initial/reward_dist Max              0.181465
evaluation/env_infos/initial/reward_dist Min              3.95779e-06
evaluation/env_infos/reward_dist Mean                     0.143718
evaluation/env_infos/reward_dist Std                      0.235709
evaluation/env_infos/reward_dist Max                      0.997769
evaluation/env_infos/reward_dist Min                      3.50834e-175
time/data storing (s)                                    38.5249
time/evaluation sampling (s)                              0.632111
time/exploration sampling (s)                             0.0839429
time/logging (s)                                          0.015745
time/saving (s)                                           0.79513
time/training (s)                                        39.0705
time/epoch (s)                                           79.1223
time/total (s)                                        11191.3
Epoch                                                   159
---------------------------------------------------  -----------------
2021-05-29 03:03:45.649411 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 160 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0193617
trainer/QF2 Loss                                          0.0127033
trainer/Policy Loss                                       2.85007
trainer/Q1 Predictions Mean                              -0.810426
trainer/Q1 Predictions Std                                0.870248
trainer/Q1 Predictions Max                                1.16982
trainer/Q1 Predictions Min                               -6.24834
trainer/Q2 Predictions Mean                              -0.812397
trainer/Q2 Predictions Std                                0.865543
trainer/Q2 Predictions Max                                1.18392
trainer/Q2 Predictions Min                               -6.1778
trainer/Q Targets Mean                                   -0.827576
trainer/Q Targets Std                                     0.85124
trainer/Q Targets Max                                     1.16908
trainer/Q Targets Min                                    -6.25766
trainer/Log Pis Mean                                      2.02374
trainer/Log Pis Std                                       1.2742
trainer/Log Pis Max                                       4.44013
trainer/Log Pis Min                                      -3.59149
trainer/Policy mu Mean                                   -0.0567797
trainer/Policy mu Std                                     0.367345
trainer/Policy mu Max                                     2.25061
trainer/Policy mu Min                                    -2.49865
trainer/Policy log std Mean                              -2.28852
trainer/Policy log std Std                                0.537052
trainer/Policy log std Max                                0.0194904
trainer/Policy log std Min                               -3.3356
trainer/Alpha                                             0.0202198
trainer/Alpha Loss                                        0.0926221
exploration/num steps total                           17100
exploration/num paths total                             855
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.141805
exploration/Rewards Std                                   0.0991591
exploration/Rewards Max                                   0.0510944
exploration/Rewards Min                                  -0.41121
exploration/Returns Mean                                 -2.83611
exploration/Returns Std                                   1.55804
exploration/Returns Max                                  -0.442974
exploration/Returns Min                                  -5.30634
exploration/Actions Mean                                  0.0208195
exploration/Actions Std                                   0.276019
exploration/Actions Max                                   0.988319
exploration/Actions Min                                  -0.830424
exploration/Num Paths                                     5
exploration/Average Returns                              -2.83611
exploration/env_infos/final/reward_energy Mean           -0.131235
exploration/env_infos/final/reward_energy Std             0.0418651
exploration/env_infos/final/reward_energy Max            -0.0825708
exploration/env_infos/final/reward_energy Min            -0.201074
exploration/env_infos/initial/reward_energy Mean         -0.358768
exploration/env_infos/initial/reward_energy Std           0.250232
exploration/env_infos/initial/reward_energy Max          -0.150538
exploration/env_infos/initial/reward_energy Min          -0.840685
exploration/env_infos/reward_energy Mean                 -0.258822
exploration/env_infos/reward_energy Std                   0.293684
exploration/env_infos/reward_energy Max                  -0.0100947
exploration/env_infos/reward_energy Min                  -1.20986
exploration/env_infos/final/end_effector_loc Mean        -0.114825
exploration/env_infos/final/end_effector_loc Std          0.690928
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00361781
exploration/env_infos/initial/end_effector_loc Std        0.0150358
exploration/env_infos/initial/end_effector_loc Max        0.0383764
exploration/env_infos/initial/end_effector_loc Min       -0.0171501
exploration/env_infos/end_effector_loc Mean              -0.0214802
exploration/env_infos/end_effector_loc Std                0.510676
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0352767
exploration/env_infos/final/reward_dist Std               0.0705534
exploration/env_infos/final/reward_dist Max               0.176384
exploration/env_infos/final/reward_dist Min               3.15976e-160
exploration/env_infos/initial/reward_dist Mean            0.00730855
exploration/env_infos/initial/reward_dist Std             0.00946249
exploration/env_infos/initial/reward_dist Max             0.0236808
exploration/env_infos/initial/reward_dist Min             8.87492e-07
exploration/env_infos/reward_dist Mean                    0.0830162
exploration/env_infos/reward_dist Std                     0.174626
exploration/env_infos/reward_dist Max                     0.722438
exploration/env_infos/reward_dist Min                     3.15976e-160
evaluation/num steps total                           161000
evaluation/num paths total                             8050
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0700915
evaluation/Rewards Std                                    0.120196
evaluation/Rewards Max                                    0.151102
evaluation/Rewards Min                                   -0.884631
evaluation/Returns Mean                                  -1.40183
evaluation/Returns Std                                    1.92031
evaluation/Returns Max                                    1.55077
evaluation/Returns Min                                   -7.29454
evaluation/Actions Mean                                   0.0027945
evaluation/Actions Std                                    0.134513
evaluation/Actions Max                                    0.847007
evaluation/Actions Min                                   -0.996939
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.40183
evaluation/env_infos/final/reward_energy Mean            -0.0727786
evaluation/env_infos/final/reward_energy Std              0.120469
evaluation/env_infos/final/reward_energy Max             -0.00444716
evaluation/env_infos/final/reward_energy Min             -0.710198
evaluation/env_infos/initial/reward_energy Mean          -0.36833
evaluation/env_infos/initial/reward_energy Std            0.368125
evaluation/env_infos/initial/reward_energy Max           -0.0175084
evaluation/env_infos/initial/reward_energy Min           -1.36657
evaluation/env_infos/reward_energy Mean                  -0.103553
evaluation/env_infos/reward_energy Std                    0.159624
evaluation/env_infos/reward_energy Max                   -0.000712532
evaluation/env_infos/reward_energy Min                   -1.36657
evaluation/env_infos/final/end_effector_loc Mean         -0.0779617
evaluation/env_infos/final/end_effector_loc Std           0.395724
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00294586
evaluation/env_infos/initial/end_effector_loc Std         0.0181742
evaluation/env_infos/initial/end_effector_loc Max         0.0423503
evaluation/env_infos/initial/end_effector_loc Min        -0.0498469
evaluation/env_infos/end_effector_loc Mean               -0.0364374
evaluation/env_infos/end_effector_loc Std                 0.269399
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.141754
evaluation/env_infos/final/reward_dist Std                0.218098
evaluation/env_infos/final/reward_dist Max                0.82838
evaluation/env_infos/final/reward_dist Min                4.07484e-180
evaluation/env_infos/initial/reward_dist Mean             0.0131679
evaluation/env_infos/initial/reward_dist Std              0.0389006
evaluation/env_infos/initial/reward_dist Max              0.24633
evaluation/env_infos/initial/reward_dist Min              8.30533e-07
evaluation/env_infos/reward_dist Mean                     0.154345
evaluation/env_infos/reward_dist Std                      0.242059
evaluation/env_infos/reward_dist Max                      0.995302
evaluation/env_infos/reward_dist Min                      4.07484e-180
time/data storing (s)                                    38.2604
time/evaluation sampling (s)                              0.7179
time/exploration sampling (s)                             0.0890971
time/logging (s)                                          0.0175158
time/saving (s)                                           0.798837
time/training (s)                                        39.4855
time/epoch (s)                                           79.3692
time/total (s)                                        11272.4
Epoch                                                   160
---------------------------------------------------  -----------------
2021-05-29 03:05:06.720327 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 161 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00321072
trainer/QF2 Loss                                          0.00329274
trainer/Policy Loss                                       2.80566
trainer/Q1 Predictions Mean                              -0.863604
trainer/Q1 Predictions Std                                0.892995
trainer/Q1 Predictions Max                                1.21749
trainer/Q1 Predictions Min                               -5.67133
trainer/Q2 Predictions Mean                              -0.856268
trainer/Q2 Predictions Std                                0.898712
trainer/Q2 Predictions Max                                1.19691
trainer/Q2 Predictions Min                               -5.75839
trainer/Q Targets Mean                                   -0.865819
trainer/Q Targets Std                                     0.898528
trainer/Q Targets Max                                     1.19815
trainer/Q Targets Min                                    -5.63205
trainer/Log Pis Mean                                      1.95581
trainer/Log Pis Std                                       1.40895
trainer/Log Pis Max                                       4.65471
trainer/Log Pis Min                                      -5.97919
trainer/Policy mu Mean                                   -0.0396763
trainer/Policy mu Std                                     0.42869
trainer/Policy mu Max                                     2.33707
trainer/Policy mu Min                                    -2.54097
trainer/Policy log std Mean                              -2.25346
trainer/Policy log std Std                                0.566734
trainer/Policy log std Max                               -0.304395
trainer/Policy log std Min                               -3.21432
trainer/Alpha                                             0.0207881
trainer/Alpha Loss                                       -0.171194
exploration/num steps total                           17200
exploration/num paths total                             860
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.12934
exploration/Rewards Std                                   0.095993
exploration/Rewards Max                                   0.0118783
exploration/Rewards Min                                  -0.526281
exploration/Returns Mean                                 -2.58681
exploration/Returns Std                                   0.672406
exploration/Returns Max                                  -1.47724
exploration/Returns Min                                  -3.56506
exploration/Actions Mean                                  0.0112386
exploration/Actions Std                                   0.205831
exploration/Actions Max                                   0.998907
exploration/Actions Min                                  -0.872267
exploration/Num Paths                                     5
exploration/Average Returns                              -2.58681
exploration/env_infos/final/reward_energy Mean           -0.141808
exploration/env_infos/final/reward_energy Std             0.132868
exploration/env_infos/final/reward_energy Max            -0.0312187
exploration/env_infos/final/reward_energy Min            -0.399174
exploration/env_infos/initial/reward_energy Mean         -0.274772
exploration/env_infos/initial/reward_energy Std           0.247929
exploration/env_infos/initial/reward_energy Max          -0.0167662
exploration/env_infos/initial/reward_energy Min          -0.658547
exploration/env_infos/reward_energy Mean                 -0.19432
exploration/env_infos/reward_energy Std                   0.217313
exploration/env_infos/reward_energy Max                  -0.0131029
exploration/env_infos/reward_energy Min                  -1.15757
exploration/env_infos/final/end_effector_loc Mean         0.224018
exploration/env_infos/final/end_effector_loc Std          0.525307
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.0011248
exploration/env_infos/initial/end_effector_loc Std        0.0130363
exploration/env_infos/initial/end_effector_loc Max        0.014403
exploration/env_infos/initial/end_effector_loc Min       -0.031131
exploration/env_infos/end_effector_loc Mean               0.0928249
exploration/env_infos/end_effector_loc Std                0.404632
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0169189
exploration/env_infos/final/reward_dist Std               0.0211871
exploration/env_infos/final/reward_dist Max               0.0494336
exploration/env_infos/final/reward_dist Min               1.03012e-98
exploration/env_infos/initial/reward_dist Mean            0.000933441
exploration/env_infos/initial/reward_dist Std             0.00115453
exploration/env_infos/initial/reward_dist Max             0.00291601
exploration/env_infos/initial/reward_dist Min             1.33666e-05
exploration/env_infos/reward_dist Mean                    0.0609021
exploration/env_infos/reward_dist Std                     0.168488
exploration/env_infos/reward_dist Max                     0.986857
exploration/env_infos/reward_dist Min                     1.03012e-98
evaluation/num steps total                           162000
evaluation/num paths total                             8100
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0566085
evaluation/Rewards Std                                    0.116921
evaluation/Rewards Max                                    0.17284
evaluation/Rewards Min                                   -1.16602
evaluation/Returns Mean                                  -1.13217
evaluation/Returns Std                                    1.64623
evaluation/Returns Max                                    2.1653
evaluation/Returns Min                                   -8.78243
evaluation/Actions Mean                                  -0.00405952
evaluation/Actions Std                                    0.119535
evaluation/Actions Max                                    0.987792
evaluation/Actions Min                                   -0.999962
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.13217
evaluation/env_infos/final/reward_energy Mean            -0.0944127
evaluation/env_infos/final/reward_energy Std              0.182403
evaluation/env_infos/final/reward_energy Max             -0.00510698
evaluation/env_infos/final/reward_energy Min             -1.22424
evaluation/env_infos/initial/reward_energy Mean          -0.283539
evaluation/env_infos/initial/reward_energy Std            0.222396
evaluation/env_infos/initial/reward_energy Max           -0.0236501
evaluation/env_infos/initial/reward_energy Min           -1.01192
evaluation/env_infos/reward_energy Mean                  -0.0893828
evaluation/env_infos/reward_energy Std                    0.1436
evaluation/env_infos/reward_energy Max                   -0.000973876
evaluation/env_infos/reward_energy Min                   -1.35626
evaluation/env_infos/final/end_effector_loc Mean         -0.0596266
evaluation/env_infos/final/end_effector_loc Std           0.408276
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00133416
evaluation/env_infos/initial/end_effector_loc Std         0.0126704
evaluation/env_infos/initial/end_effector_loc Max         0.0479926
evaluation/env_infos/initial/end_effector_loc Min        -0.0356458
evaluation/env_infos/end_effector_loc Mean               -0.0289283
evaluation/env_infos/end_effector_loc Std                 0.265154
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0568927
evaluation/env_infos/final/reward_dist Std                0.167912
evaluation/env_infos/final/reward_dist Max                0.97717
evaluation/env_infos/final/reward_dist Min                2.2723e-178
evaluation/env_infos/initial/reward_dist Mean             0.00592115
evaluation/env_infos/initial/reward_dist Std              0.0103231
evaluation/env_infos/initial/reward_dist Max              0.0443825
evaluation/env_infos/initial/reward_dist Min              1.26662e-07
evaluation/env_infos/reward_dist Mean                     0.141884
evaluation/env_infos/reward_dist Std                      0.237179
evaluation/env_infos/reward_dist Max                      0.999052
evaluation/env_infos/reward_dist Min                      2.2723e-178
time/data storing (s)                                    38.3091
time/evaluation sampling (s)                              0.545431
time/exploration sampling (s)                             0.0877131
time/logging (s)                                          0.0168088
time/saving (s)                                           0.794096
time/training (s)                                        39.2578
time/epoch (s)                                           79.0109
time/total (s)                                        11353.5
Epoch                                                   161
---------------------------------------------------  ----------------
2021-05-29 03:06:28.343629 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 162 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00258986
trainer/QF2 Loss                                          0.002809
trainer/Policy Loss                                       3.01096
trainer/Q1 Predictions Mean                              -0.969765
trainer/Q1 Predictions Std                                0.972389
trainer/Q1 Predictions Max                                1.39794
trainer/Q1 Predictions Min                               -6.82186
trainer/Q2 Predictions Mean                              -0.987422
trainer/Q2 Predictions Std                                0.96888
trainer/Q2 Predictions Max                                1.40192
trainer/Q2 Predictions Min                               -6.85461
trainer/Q Targets Mean                                   -0.982882
trainer/Q Targets Std                                     0.970333
trainer/Q Targets Max                                     1.38057
trainer/Q Targets Min                                    -6.70121
trainer/Log Pis Mean                                      2.05773
trainer/Log Pis Std                                       1.27775
trainer/Log Pis Max                                       4.94867
trainer/Log Pis Min                                      -3.96579
trainer/Policy mu Mean                                   -0.040134
trainer/Policy mu Std                                     0.440702
trainer/Policy mu Max                                     2.66299
trainer/Policy mu Min                                    -2.47518
trainer/Policy log std Mean                              -2.24336
trainer/Policy log std Std                                0.58774
trainer/Policy log std Max                               -0.0586213
trainer/Policy log std Min                               -3.42494
trainer/Alpha                                             0.0210512
trainer/Alpha Loss                                        0.222862
exploration/num steps total                           17300
exploration/num paths total                             865
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.11977
exploration/Rewards Std                                   0.0639101
exploration/Rewards Max                                   0.0276479
exploration/Rewards Min                                  -0.343368
exploration/Returns Mean                                 -2.39539
exploration/Returns Std                                   0.812212
exploration/Returns Max                                  -0.955977
exploration/Returns Min                                  -3.44261
exploration/Actions Mean                                  0.00570005
exploration/Actions Std                                   0.10269
exploration/Actions Max                                   0.499912
exploration/Actions Min                                  -0.438638
exploration/Num Paths                                     5
exploration/Average Returns                              -2.39539
exploration/env_infos/final/reward_energy Mean           -0.142046
exploration/env_infos/final/reward_energy Std             0.0573259
exploration/env_infos/final/reward_energy Max            -0.0968929
exploration/env_infos/final/reward_energy Min            -0.246436
exploration/env_infos/initial/reward_energy Mean         -0.222085
exploration/env_infos/initial/reward_energy Std           0.162856
exploration/env_infos/initial/reward_energy Max          -0.0780202
exploration/env_infos/initial/reward_energy Min          -0.5408
exploration/env_infos/reward_energy Mean                 -0.120132
exploration/env_infos/reward_energy Std                   0.0819989
exploration/env_infos/reward_energy Max                  -0.00312468
exploration/env_infos/reward_energy Min                  -0.5408
exploration/env_infos/final/end_effector_loc Mean         0.0565456
exploration/env_infos/final/end_effector_loc Std          0.310337
exploration/env_infos/final/end_effector_loc Max          0.456689
exploration/env_infos/final/end_effector_loc Min         -0.580229
exploration/env_infos/initial/end_effector_loc Mean       0.00221923
exploration/env_infos/initial/end_effector_loc Std        0.00948051
exploration/env_infos/initial/end_effector_loc Max        0.0249956
exploration/env_infos/initial/end_effector_loc Min       -0.0103141
exploration/env_infos/end_effector_loc Mean               0.0246882
exploration/env_infos/end_effector_loc Std                0.196715
exploration/env_infos/end_effector_loc Max                0.456689
exploration/env_infos/end_effector_loc Min               -0.580229
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.26886
exploration/env_infos/final/reward_dist Std               0.364787
exploration/env_infos/final/reward_dist Max               0.924565
exploration/env_infos/final/reward_dist Min               2.15681e-16
exploration/env_infos/initial/reward_dist Mean            0.00077572
exploration/env_infos/initial/reward_dist Std             0.00119545
exploration/env_infos/initial/reward_dist Max             0.0031242
exploration/env_infos/initial/reward_dist Min             2.04406e-05
exploration/env_infos/reward_dist Mean                    0.145523
exploration/env_infos/reward_dist Std                     0.280493
exploration/env_infos/reward_dist Max                     0.992001
exploration/env_infos/reward_dist Min                     2.15681e-16
evaluation/num steps total                           163000
evaluation/num paths total                             8150
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.088099
evaluation/Rewards Std                                    0.127835
evaluation/Rewards Max                                    0.17834
evaluation/Rewards Min                                   -0.664319
evaluation/Returns Mean                                  -1.76198
evaluation/Returns Std                                    2.15518
evaluation/Returns Max                                    1.58608
evaluation/Returns Min                                   -9.69338
evaluation/Actions Mean                                  -0.00907913
evaluation/Actions Std                                    0.133889
evaluation/Actions Max                                    0.857861
evaluation/Actions Min                                   -0.993754
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.76198
evaluation/env_infos/final/reward_energy Mean            -0.0671409
evaluation/env_infos/final/reward_energy Std              0.0774224
evaluation/env_infos/final/reward_energy Max             -0.00245164
evaluation/env_infos/final/reward_energy Min             -0.387999
evaluation/env_infos/initial/reward_energy Mean          -0.368822
evaluation/env_infos/initial/reward_energy Std            0.303231
evaluation/env_infos/initial/reward_energy Max           -0.0105861
evaluation/env_infos/initial/reward_energy Min           -1.39416
evaluation/env_infos/reward_energy Mean                  -0.112044
evaluation/env_infos/reward_energy Std                    0.153177
evaluation/env_infos/reward_energy Max                   -0.000715512
evaluation/env_infos/reward_energy Min                   -1.39416
evaluation/env_infos/final/end_effector_loc Mean         -0.0361818
evaluation/env_infos/final/end_effector_loc Std           0.4706
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000720145
evaluation/env_infos/initial/end_effector_loc Std         0.0168658
evaluation/env_infos/initial/end_effector_loc Max         0.0385972
evaluation/env_infos/initial/end_effector_loc Min        -0.0496877
evaluation/env_infos/end_effector_loc Mean               -0.00145959
evaluation/env_infos/end_effector_loc Std                 0.319951
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0816167
evaluation/env_infos/final/reward_dist Std                0.198769
evaluation/env_infos/final/reward_dist Max                0.807186
evaluation/env_infos/final/reward_dist Min                2.46741e-190
evaluation/env_infos/initial/reward_dist Mean             0.0121895
evaluation/env_infos/initial/reward_dist Std              0.0251951
evaluation/env_infos/initial/reward_dist Max              0.134523
evaluation/env_infos/initial/reward_dist Min              4.21323e-06
evaluation/env_infos/reward_dist Mean                     0.129593
evaluation/env_infos/reward_dist Std                      0.230453
evaluation/env_infos/reward_dist Max                      0.998341
evaluation/env_infos/reward_dist Min                      2.46741e-190
time/data storing (s)                                    38.7152
time/evaluation sampling (s)                              0.598142
time/exploration sampling (s)                             0.0858951
time/logging (s)                                          0.0151956
time/saving (s)                                           0.801074
time/training (s)                                        39.6566
time/epoch (s)                                           79.8721
time/total (s)                                        11435.1
Epoch                                                   162
---------------------------------------------------  -----------------
2021-05-29 03:07:49.371913 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 163 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00275559
trainer/QF2 Loss                                          0.00230356
trainer/Policy Loss                                       2.91337
trainer/Q1 Predictions Mean                              -0.949755
trainer/Q1 Predictions Std                                0.893368
trainer/Q1 Predictions Max                                1.47304
trainer/Q1 Predictions Min                               -5.16662
trainer/Q2 Predictions Mean                              -0.948846
trainer/Q2 Predictions Std                                0.890444
trainer/Q2 Predictions Max                                1.51221
trainer/Q2 Predictions Min                               -5.11625
trainer/Q Targets Mean                                   -0.946749
trainer/Q Targets Std                                     0.897097
trainer/Q Targets Max                                     1.45985
trainer/Q Targets Min                                    -5.16724
trainer/Log Pis Mean                                      1.97013
trainer/Log Pis Std                                       1.34288
trainer/Log Pis Max                                       6.35891
trainer/Log Pis Min                                      -1.63369
trainer/Policy mu Mean                                    0.00355505
trainer/Policy mu Std                                     0.42345
trainer/Policy mu Max                                     1.92069
trainer/Policy mu Min                                    -2.28988
trainer/Policy log std Mean                              -2.27816
trainer/Policy log std Std                                0.591026
trainer/Policy log std Max                               -0.494977
trainer/Policy log std Min                               -3.53391
trainer/Alpha                                             0.0212134
trainer/Alpha Loss                                       -0.115129
exploration/num steps total                           17400
exploration/num paths total                             870
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.141764
exploration/Rewards Std                                   0.132448
exploration/Rewards Max                                   0.0980522
exploration/Rewards Min                                  -0.512628
exploration/Returns Mean                                 -2.83529
exploration/Returns Std                                   2.0537
exploration/Returns Max                                   0.232142
exploration/Returns Min                                  -5.38739
exploration/Actions Mean                                 -0.00505772
exploration/Actions Std                                   0.174573
exploration/Actions Max                                   0.743614
exploration/Actions Min                                  -0.896255
exploration/Num Paths                                     5
exploration/Average Returns                              -2.83529
exploration/env_infos/final/reward_energy Mean           -0.131656
exploration/env_infos/final/reward_energy Std             0.113109
exploration/env_infos/final/reward_energy Max            -0.0276005
exploration/env_infos/final/reward_energy Min            -0.347014
exploration/env_infos/initial/reward_energy Mean         -0.198967
exploration/env_infos/initial/reward_energy Std           0.106132
exploration/env_infos/initial/reward_energy Max          -0.0929553
exploration/env_infos/initial/reward_energy Min          -0.385422
exploration/env_infos/reward_energy Mean                 -0.17569
exploration/env_infos/reward_energy Std                   0.173597
exploration/env_infos/reward_energy Max                  -0.0243349
exploration/env_infos/reward_energy Min                  -1.16457
exploration/env_infos/final/end_effector_loc Mean        -0.0951033
exploration/env_infos/final/end_effector_loc Std          0.563357
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.000987661
exploration/env_infos/initial/end_effector_loc Std        0.00791135
exploration/env_infos/initial/end_effector_loc Max        0.00710442
exploration/env_infos/initial/end_effector_loc Min       -0.0191238
exploration/env_infos/end_effector_loc Mean              -0.0413959
exploration/env_infos/end_effector_loc Std                0.345086
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.168396
exploration/env_infos/final/reward_dist Std               0.207695
exploration/env_infos/final/reward_dist Max               0.473737
exploration/env_infos/final/reward_dist Min               5.1024e-103
exploration/env_infos/initial/reward_dist Mean            0.000428381
exploration/env_infos/initial/reward_dist Std             0.000614418
exploration/env_infos/initial/reward_dist Max             0.00164761
exploration/env_infos/initial/reward_dist Min             7.08127e-06
exploration/env_infos/reward_dist Mean                    0.13495
exploration/env_infos/reward_dist Std                     0.210021
exploration/env_infos/reward_dist Max                     0.784117
exploration/env_infos/reward_dist Min                     5.1024e-103
evaluation/num steps total                           164000
evaluation/num paths total                             8200
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0985206
evaluation/Rewards Std                                    0.136137
evaluation/Rewards Max                                    0.147425
evaluation/Rewards Min                                   -0.930577
evaluation/Returns Mean                                  -1.97041
evaluation/Returns Std                                    2.43525
evaluation/Returns Max                                    1.80201
evaluation/Returns Min                                  -10.19
evaluation/Actions Mean                                   0.00202195
evaluation/Actions Std                                    0.15389
evaluation/Actions Max                                    0.987075
evaluation/Actions Min                                   -0.98648
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.97041
evaluation/env_infos/final/reward_energy Mean            -0.0681329
evaluation/env_infos/final/reward_energy Std              0.063756
evaluation/env_infos/final/reward_energy Max             -0.00399108
evaluation/env_infos/final/reward_energy Min             -0.35016
evaluation/env_infos/initial/reward_energy Mean          -0.386903
evaluation/env_infos/initial/reward_energy Std            0.354371
evaluation/env_infos/initial/reward_energy Max           -0.0127409
evaluation/env_infos/initial/reward_energy Min           -1.39399
evaluation/env_infos/reward_energy Mean                  -0.122053
evaluation/env_infos/reward_energy Std                    0.18021
evaluation/env_infos/reward_energy Max                   -0.003178
evaluation/env_infos/reward_energy Min                   -1.39399
evaluation/env_infos/final/end_effector_loc Mean         -0.0418137
evaluation/env_infos/final/end_effector_loc Std           0.417996
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00203936
evaluation/env_infos/initial/end_effector_loc Std         0.0184372
evaluation/env_infos/initial/end_effector_loc Max         0.0457701
evaluation/env_infos/initial/end_effector_loc Min        -0.049324
evaluation/env_infos/end_effector_loc Mean               -0.0168524
evaluation/env_infos/end_effector_loc Std                 0.299372
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0302613
evaluation/env_infos/final/reward_dist Std                0.0823838
evaluation/env_infos/final/reward_dist Max                0.448029
evaluation/env_infos/final/reward_dist Min                1.18168e-195
evaluation/env_infos/initial/reward_dist Mean             0.0148766
evaluation/env_infos/initial/reward_dist Std              0.0440657
evaluation/env_infos/initial/reward_dist Max              0.268878
evaluation/env_infos/initial/reward_dist Min              1.09042e-06
evaluation/env_infos/reward_dist Mean                     0.120533
evaluation/env_infos/reward_dist Std                      0.23445
evaluation/env_infos/reward_dist Max                      0.994512
evaluation/env_infos/reward_dist Min                      1.18168e-195
time/data storing (s)                                    38.4426
time/evaluation sampling (s)                              0.6452
time/exploration sampling (s)                             0.0915507
time/logging (s)                                          0.0141078
time/saving (s)                                           0.77454
time/training (s)                                        39.2629
time/epoch (s)                                           79.231
time/total (s)                                        11516.1
Epoch                                                   163
---------------------------------------------------  -----------------
2021-05-29 03:09:10.437547 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 164 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00262347
trainer/QF2 Loss                                          0.00317778
trainer/Policy Loss                                       3.02057
trainer/Q1 Predictions Mean                              -0.979448
trainer/Q1 Predictions Std                                0.898729
trainer/Q1 Predictions Max                                1.25846
trainer/Q1 Predictions Min                               -4.35425
trainer/Q2 Predictions Mean                              -0.975803
trainer/Q2 Predictions Std                                0.894805
trainer/Q2 Predictions Max                                1.2351
trainer/Q2 Predictions Min                               -4.25327
trainer/Q Targets Mean                                   -0.98412
trainer/Q Targets Std                                     0.904639
trainer/Q Targets Max                                     1.2655
trainer/Q Targets Min                                    -4.42344
trainer/Log Pis Mean                                      2.05805
trainer/Log Pis Std                                       1.41919
trainer/Log Pis Max                                       7.09112
trainer/Log Pis Min                                      -4.30898
trainer/Policy mu Mean                                   -0.0304844
trainer/Policy mu Std                                     0.450247
trainer/Policy mu Max                                     2.39439
trainer/Policy mu Min                                    -2.74583
trainer/Policy log std Mean                              -2.28558
trainer/Policy log std Std                                0.574327
trainer/Policy log std Max                                0.152355
trainer/Policy log std Min                               -3.09814
trainer/Alpha                                             0.0229784
trainer/Alpha Loss                                        0.219016
exploration/num steps total                           17500
exploration/num paths total                             875
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0931356
exploration/Rewards Std                                   0.072801
exploration/Rewards Max                                   0.0514544
exploration/Rewards Min                                  -0.298968
exploration/Returns Mean                                 -1.86271
exploration/Returns Std                                   0.857082
exploration/Returns Max                                  -0.797544
exploration/Returns Min                                  -3.19178
exploration/Actions Mean                                 -0.00916697
exploration/Actions Std                                   0.139349
exploration/Actions Max                                   0.612083
exploration/Actions Min                                  -0.676759
exploration/Num Paths                                     5
exploration/Average Returns                              -1.86271
exploration/env_infos/final/reward_energy Mean           -0.0870014
exploration/env_infos/final/reward_energy Std             0.0400644
exploration/env_infos/final/reward_energy Max            -0.0273413
exploration/env_infos/final/reward_energy Min            -0.14104
exploration/env_infos/initial/reward_energy Mean         -0.316888
exploration/env_infos/initial/reward_energy Std           0.193441
exploration/env_infos/initial/reward_energy Max          -0.0327211
exploration/env_infos/initial/reward_energy Min          -0.623416
exploration/env_infos/reward_energy Mean                 -0.14072
exploration/env_infos/reward_energy Std                   0.138572
exploration/env_infos/reward_energy Max                  -0.0192147
exploration/env_infos/reward_energy Min                  -0.888428
exploration/env_infos/final/end_effector_loc Mean        -0.0501098
exploration/env_infos/final/end_effector_loc Std          0.3113
exploration/env_infos/final/end_effector_loc Max          0.393147
exploration/env_infos/final/end_effector_loc Min         -0.704578
exploration/env_infos/initial/end_effector_loc Mean       0.0012646
exploration/env_infos/initial/end_effector_loc Std        0.0130651
exploration/env_infos/initial/end_effector_loc Max        0.0306042
exploration/env_infos/initial/end_effector_loc Min       -0.0188617
exploration/env_infos/end_effector_loc Mean              -0.00416157
exploration/env_infos/end_effector_loc Std                0.200103
exploration/env_infos/end_effector_loc Max                0.393147
exploration/env_infos/end_effector_loc Min               -0.704578
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0386783
exploration/env_infos/final/reward_dist Std               0.0699381
exploration/env_infos/final/reward_dist Max               0.178473
exploration/env_infos/final/reward_dist Min               2.30248e-23
exploration/env_infos/initial/reward_dist Mean            0.0210319
exploration/env_infos/initial/reward_dist Std             0.0314647
exploration/env_infos/initial/reward_dist Max             0.0820916
exploration/env_infos/initial/reward_dist Min             2.34809e-05
exploration/env_infos/reward_dist Mean                    0.14318
exploration/env_infos/reward_dist Std                     0.24807
exploration/env_infos/reward_dist Max                     0.986417
exploration/env_infos/reward_dist Min                     2.30248e-23
evaluation/num steps total                           165000
evaluation/num paths total                             8250
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0763025
evaluation/Rewards Std                                    0.0969643
evaluation/Rewards Max                                    0.124965
evaluation/Rewards Min                                   -0.761835
evaluation/Returns Mean                                  -1.52605
evaluation/Returns Std                                    1.55015
evaluation/Returns Max                                    1.08442
evaluation/Returns Min                                   -7.62165
evaluation/Actions Mean                                  -2.28168e-05
evaluation/Actions Std                                    0.120103
evaluation/Actions Max                                    0.961832
evaluation/Actions Min                                   -0.980152
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.52605
evaluation/env_infos/final/reward_energy Mean            -0.0727356
evaluation/env_infos/final/reward_energy Std              0.0892956
evaluation/env_infos/final/reward_energy Max             -0.00293222
evaluation/env_infos/final/reward_energy Min             -0.41902
evaluation/env_infos/initial/reward_energy Mean          -0.384481
evaluation/env_infos/initial/reward_energy Std            0.366499
evaluation/env_infos/initial/reward_energy Max           -0.00268852
evaluation/env_infos/initial/reward_energy Min           -1.37978
evaluation/env_infos/reward_energy Mean                  -0.0966654
evaluation/env_infos/reward_energy Std                    0.139662
evaluation/env_infos/reward_energy Max                   -0.00190702
evaluation/env_infos/reward_energy Min                   -1.37978
evaluation/env_infos/final/end_effector_loc Mean         -0.0162241
evaluation/env_infos/final/end_effector_loc Std           0.331022
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00250119
evaluation/env_infos/initial/end_effector_loc Std         0.0186126
evaluation/env_infos/initial/end_effector_loc Max         0.0480916
evaluation/env_infos/initial/end_effector_loc Min        -0.0490076
evaluation/env_infos/end_effector_loc Mean               -0.00537966
evaluation/env_infos/end_effector_loc Std                 0.230984
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.132509
evaluation/env_infos/final/reward_dist Std                0.266204
evaluation/env_infos/final/reward_dist Max                0.955318
evaluation/env_infos/final/reward_dist Min                3.38778e-142
evaluation/env_infos/initial/reward_dist Mean             0.0109824
evaluation/env_infos/initial/reward_dist Std              0.0239682
evaluation/env_infos/initial/reward_dist Max              0.146601
evaluation/env_infos/initial/reward_dist Min              1.92117e-06
evaluation/env_infos/reward_dist Mean                     0.140995
evaluation/env_infos/reward_dist Std                      0.252521
evaluation/env_infos/reward_dist Max                      0.998878
evaluation/env_infos/reward_dist Min                      3.38778e-142
time/data storing (s)                                    38.2277
time/evaluation sampling (s)                              0.633997
time/exploration sampling (s)                             0.0860163
time/logging (s)                                          0.0176088
time/saving (s)                                           0.806521
time/training (s)                                        39.5592
time/epoch (s)                                           79.331
time/total (s)                                        11597.2
Epoch                                                   164
---------------------------------------------------  -----------------
2021-05-29 03:10:30.946868 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 165 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00256483
trainer/QF2 Loss                                          0.00323354
trainer/Policy Loss                                       2.89277
trainer/Q1 Predictions Mean                              -1.01062
trainer/Q1 Predictions Std                                0.907337
trainer/Q1 Predictions Max                                1.503
trainer/Q1 Predictions Min                               -4.19653
trainer/Q2 Predictions Mean                              -1.01556
trainer/Q2 Predictions Std                                0.906123
trainer/Q2 Predictions Max                                1.50946
trainer/Q2 Predictions Min                               -4.35197
trainer/Q Targets Mean                                   -0.998567
trainer/Q Targets Std                                     0.908613
trainer/Q Targets Max                                     1.58636
trainer/Q Targets Min                                    -4.41225
trainer/Log Pis Mean                                      1.89621
trainer/Log Pis Std                                       1.4591
trainer/Log Pis Max                                       5.48402
trainer/Log Pis Min                                      -3.24777
trainer/Policy mu Mean                                   -0.0191614
trainer/Policy mu Std                                     0.495998
trainer/Policy mu Max                                     2.42125
trainer/Policy mu Min                                    -3.27908
trainer/Policy log std Mean                              -2.26692
trainer/Policy log std Std                                0.584583
trainer/Policy log std Max                               -0.129273
trainer/Policy log std Min                               -3.20804
trainer/Alpha                                             0.0228056
trainer/Alpha Loss                                       -0.392209
exploration/num steps total                           17600
exploration/num paths total                             880
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.134214
exploration/Rewards Std                                   0.0537916
exploration/Rewards Max                                   0.000743364
exploration/Rewards Min                                  -0.279569
exploration/Returns Mean                                 -2.68428
exploration/Returns Std                                   0.8286
exploration/Returns Max                                  -1.12619
exploration/Returns Min                                  -3.4546
exploration/Actions Mean                                  0.0131901
exploration/Actions Std                                   0.158339
exploration/Actions Max                                   0.716678
exploration/Actions Min                                  -0.947412
exploration/Num Paths                                     5
exploration/Average Returns                              -2.68428
exploration/env_infos/final/reward_energy Mean           -0.220979
exploration/env_infos/final/reward_energy Std             0.12558
exploration/env_infos/final/reward_energy Max            -0.104135
exploration/env_infos/final/reward_energy Min            -0.451228
exploration/env_infos/initial/reward_energy Mean         -0.39736
exploration/env_infos/initial/reward_energy Std           0.405082
exploration/env_infos/initial/reward_energy Max          -0.0754802
exploration/env_infos/initial/reward_energy Min          -1.18795
exploration/env_infos/reward_energy Mean                 -0.164263
exploration/env_infos/reward_energy Std                   0.153324
exploration/env_infos/reward_energy Max                  -0.0135346
exploration/env_infos/reward_energy Min                  -1.18795
exploration/env_infos/final/end_effector_loc Mean         0.0516553
exploration/env_infos/final/end_effector_loc Std          0.255451
exploration/env_infos/final/end_effector_loc Max          0.513592
exploration/env_infos/final/end_effector_loc Min         -0.289836
exploration/env_infos/initial/end_effector_loc Mean      -0.00406105
exploration/env_infos/initial/end_effector_loc Std        0.0196467
exploration/env_infos/initial/end_effector_loc Max        0.0358339
exploration/env_infos/initial/end_effector_loc Min       -0.0473706
exploration/env_infos/end_effector_loc Mean              -0.00675291
exploration/env_infos/end_effector_loc Std                0.165584
exploration/env_infos/end_effector_loc Max                0.513592
exploration/env_infos/end_effector_loc Min               -0.31472
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00889528
exploration/env_infos/final/reward_dist Std               0.0139185
exploration/env_infos/final/reward_dist Max               0.0359423
exploration/env_infos/final/reward_dist Min               7.51514e-13
exploration/env_infos/initial/reward_dist Mean            0.00443028
exploration/env_infos/initial/reward_dist Std             0.00484799
exploration/env_infos/initial/reward_dist Max             0.0117746
exploration/env_infos/initial/reward_dist Min             2.8224e-06
exploration/env_infos/reward_dist Mean                    0.0489695
exploration/env_infos/reward_dist Std                     0.149372
exploration/env_infos/reward_dist Max                     0.908153
exploration/env_infos/reward_dist Min                     7.51514e-13
evaluation/num steps total                           166000
evaluation/num paths total                             8300
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0934077
evaluation/Rewards Std                                    0.115475
evaluation/Rewards Max                                    0.167849
evaluation/Rewards Min                                   -0.585251
evaluation/Returns Mean                                  -1.86815
evaluation/Returns Std                                    1.93506
evaluation/Returns Max                                    1.72146
evaluation/Returns Min                                   -8.64542
evaluation/Actions Mean                                  -0.00596414
evaluation/Actions Std                                    0.156462
evaluation/Actions Max                                    0.972033
evaluation/Actions Min                                   -0.833855
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.86815
evaluation/env_infos/final/reward_energy Mean            -0.0933034
evaluation/env_infos/final/reward_energy Std              0.130475
evaluation/env_infos/final/reward_energy Max             -0.00440303
evaluation/env_infos/final/reward_energy Min             -0.713896
evaluation/env_infos/initial/reward_energy Mean          -0.357364
evaluation/env_infos/initial/reward_energy Std            0.310684
evaluation/env_infos/initial/reward_energy Max           -0.0105005
evaluation/env_infos/initial/reward_energy Min           -0.994406
evaluation/env_infos/reward_energy Mean                  -0.132011
evaluation/env_infos/reward_energy Std                    0.177777
evaluation/env_infos/reward_energy Max                   -0.00106029
evaluation/env_infos/reward_energy Min                   -1.0499
evaluation/env_infos/final/end_effector_loc Mean          0.0411915
evaluation/env_infos/final/end_effector_loc Std           0.443309
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00454409
evaluation/env_infos/initial/end_effector_loc Std         0.0161134
evaluation/env_infos/initial/end_effector_loc Max         0.0486017
evaluation/env_infos/initial/end_effector_loc Min        -0.0311769
evaluation/env_infos/end_effector_loc Mean                0.0393785
evaluation/env_infos/end_effector_loc Std                 0.294081
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0904789
evaluation/env_infos/final/reward_dist Std                0.217523
evaluation/env_infos/final/reward_dist Max                0.903013
evaluation/env_infos/final/reward_dist Min                7.20949e-120
evaluation/env_infos/initial/reward_dist Mean             0.00902072
evaluation/env_infos/initial/reward_dist Std              0.0156797
evaluation/env_infos/initial/reward_dist Max              0.0665342
evaluation/env_infos/initial/reward_dist Min              7.59162e-08
evaluation/env_infos/reward_dist Mean                     0.112138
evaluation/env_infos/reward_dist Std                      0.211667
evaluation/env_infos/reward_dist Max                      0.997977
evaluation/env_infos/reward_dist Min                      5.53634e-154
time/data storing (s)                                    38.1352
time/evaluation sampling (s)                              0.663
time/exploration sampling (s)                             0.0849159
time/logging (s)                                          0.0156311
time/saving (s)                                           0.798431
time/training (s)                                        39.0332
time/epoch (s)                                           78.7304
time/total (s)                                        11677.7
Epoch                                                   165
---------------------------------------------------  -----------------
2021-05-29 03:11:52.832232 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 166 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00449455
trainer/QF2 Loss                                          0.00312855
trainer/Policy Loss                                       3.02857
trainer/Q1 Predictions Mean                              -1.01839
trainer/Q1 Predictions Std                                0.905485
trainer/Q1 Predictions Max                                1.67561
trainer/Q1 Predictions Min                               -3.73482
trainer/Q2 Predictions Mean                              -1.01637
trainer/Q2 Predictions Std                                0.911845
trainer/Q2 Predictions Max                                1.66595
trainer/Q2 Predictions Min                               -3.7781
trainer/Q Targets Mean                                   -1.00624
trainer/Q Targets Std                                     0.91281
trainer/Q Targets Max                                     1.67912
trainer/Q Targets Min                                    -3.70004
trainer/Log Pis Mean                                      2.01449
trainer/Log Pis Std                                       1.37895
trainer/Log Pis Max                                       4.30066
trainer/Log Pis Min                                      -7.50692
trainer/Policy mu Mean                                    0.0185449
trainer/Policy mu Std                                     0.412231
trainer/Policy mu Max                                     2.72684
trainer/Policy mu Min                                    -2.3155
trainer/Policy log std Mean                              -2.28458
trainer/Policy log std Std                                0.546209
trainer/Policy log std Max                               -0.205419
trainer/Policy log std Min                               -3.1403
trainer/Alpha                                             0.0217027
trainer/Alpha Loss                                        0.0554764
exploration/num steps total                           17700
exploration/num paths total                             885
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.118796
exploration/Rewards Std                                   0.0953123
exploration/Rewards Max                                   0.0379944
exploration/Rewards Min                                  -0.532292
exploration/Returns Mean                                 -2.37593
exploration/Returns Std                                   1.19815
exploration/Returns Max                                  -0.660343
exploration/Returns Min                                  -4.27736
exploration/Actions Mean                                 -0.016728
exploration/Actions Std                                   0.129931
exploration/Actions Max                                   0.388577
exploration/Actions Min                                  -0.514393
exploration/Num Paths                                     5
exploration/Average Returns                              -2.37593
exploration/env_infos/final/reward_energy Mean           -0.0844213
exploration/env_infos/final/reward_energy Std             0.0505141
exploration/env_infos/final/reward_energy Max            -0.0157451
exploration/env_infos/final/reward_energy Min            -0.149369
exploration/env_infos/initial/reward_energy Mean         -0.272433
exploration/env_infos/initial/reward_energy Std           0.21491
exploration/env_infos/initial/reward_energy Max          -0.073628
exploration/env_infos/initial/reward_energy Min          -0.666269
exploration/env_infos/reward_energy Mean                 -0.143061
exploration/env_infos/reward_energy Std                   0.117718
exploration/env_infos/reward_energy Max                  -0.0057169
exploration/env_infos/reward_energy Min                  -0.666269
exploration/env_infos/final/end_effector_loc Mean        -0.0727607
exploration/env_infos/final/end_effector_loc Std          0.270661
exploration/env_infos/final/end_effector_loc Max          0.232266
exploration/env_infos/final/end_effector_loc Min         -0.666202
exploration/env_infos/initial/end_effector_loc Mean      -0.0010179
exploration/env_infos/initial/end_effector_loc Std        0.0122258
exploration/env_infos/initial/end_effector_loc Max        0.0120631
exploration/env_infos/initial/end_effector_loc Min       -0.0257197
exploration/env_infos/end_effector_loc Mean               0.00268291
exploration/env_infos/end_effector_loc Std                0.195729
exploration/env_infos/end_effector_loc Max                0.359852
exploration/env_infos/end_effector_loc Min               -0.666202
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0830083
exploration/env_infos/final/reward_dist Std               0.123216
exploration/env_infos/final/reward_dist Max               0.317595
exploration/env_infos/final/reward_dist Min               2.90856e-29
exploration/env_infos/initial/reward_dist Mean            0.00877572
exploration/env_infos/initial/reward_dist Std             0.0141318
exploration/env_infos/initial/reward_dist Max             0.0364778
exploration/env_infos/initial/reward_dist Min             5.22784e-06
exploration/env_infos/reward_dist Mean                    0.0800515
exploration/env_infos/reward_dist Std                     0.171158
exploration/env_infos/reward_dist Max                     0.706557
exploration/env_infos/reward_dist Min                     2.90856e-29
evaluation/num steps total                           167000
evaluation/num paths total                             8350
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.11219
evaluation/Rewards Std                                    0.167535
evaluation/Rewards Max                                    0.14343
evaluation/Rewards Min                                   -1.1052
evaluation/Returns Mean                                  -2.2438
evaluation/Returns Std                                    2.92139
evaluation/Returns Max                                    1.88824
evaluation/Returns Min                                  -14.4641
evaluation/Actions Mean                                  -0.00931359
evaluation/Actions Std                                    0.199504
evaluation/Actions Max                                    0.965497
evaluation/Actions Min                                   -0.978171
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.2438
evaluation/env_infos/final/reward_energy Mean            -0.100399
evaluation/env_infos/final/reward_energy Std              0.116842
evaluation/env_infos/final/reward_energy Max             -0.00311969
evaluation/env_infos/final/reward_energy Min             -0.504365
evaluation/env_infos/initial/reward_energy Mean          -0.354211
evaluation/env_infos/initial/reward_energy Std            0.318873
evaluation/env_infos/initial/reward_energy Max           -0.0154498
evaluation/env_infos/initial/reward_energy Min           -1.05691
evaluation/env_infos/reward_energy Mean                  -0.152972
evaluation/env_infos/reward_energy Std                    0.237439
evaluation/env_infos/reward_energy Max                   -0.00303228
evaluation/env_infos/reward_energy Min                   -1.32447
evaluation/env_infos/final/end_effector_loc Mean         -0.029879
evaluation/env_infos/final/end_effector_loc Std           0.422116
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00147405
evaluation/env_infos/initial/end_effector_loc Std         0.0167857
evaluation/env_infos/initial/end_effector_loc Max         0.0480674
evaluation/env_infos/initial/end_effector_loc Min        -0.0433553
evaluation/env_infos/end_effector_loc Mean                0.0155359
evaluation/env_infos/end_effector_loc Std                 0.292191
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0428451
evaluation/env_infos/final/reward_dist Std                0.154174
evaluation/env_infos/final/reward_dist Max                0.995893
evaluation/env_infos/final/reward_dist Min                1.39285e-148
evaluation/env_infos/initial/reward_dist Mean             0.00505586
evaluation/env_infos/initial/reward_dist Std              0.0102703
evaluation/env_infos/initial/reward_dist Max              0.0506284
evaluation/env_infos/initial/reward_dist Min              2.2684e-06
evaluation/env_infos/reward_dist Mean                     0.105268
evaluation/env_infos/reward_dist Std                      0.203223
evaluation/env_infos/reward_dist Max                      0.995893
evaluation/env_infos/reward_dist Min                      8.94328e-173
time/data storing (s)                                    38.3378
time/evaluation sampling (s)                              0.649292
time/exploration sampling (s)                             0.0893081
time/logging (s)                                          0.0151569
time/saving (s)                                           0.823619
time/training (s)                                        40.1392
time/epoch (s)                                           80.0544
time/total (s)                                        11759.5
Epoch                                                   166
---------------------------------------------------  -----------------
2021-05-29 03:13:13.926268 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 167 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00469291
trainer/QF2 Loss                                          0.00429149
trainer/Policy Loss                                       3.09301
trainer/Q1 Predictions Mean                              -1.03663
trainer/Q1 Predictions Std                                0.847471
trainer/Q1 Predictions Max                                1.09241
trainer/Q1 Predictions Min                               -3.31203
trainer/Q2 Predictions Mean                              -1.03618
trainer/Q2 Predictions Std                                0.859751
trainer/Q2 Predictions Max                                1.14281
trainer/Q2 Predictions Min                               -3.29921
trainer/Q Targets Mean                                   -1.04339
trainer/Q Targets Std                                     0.865048
trainer/Q Targets Max                                     1.15848
trainer/Q Targets Min                                    -3.4347
trainer/Log Pis Mean                                      2.05707
trainer/Log Pis Std                                       1.37078
trainer/Log Pis Max                                       6.56689
trainer/Log Pis Min                                      -3.83386
trainer/Policy mu Mean                                   -0.0134313
trainer/Policy mu Std                                     0.347374
trainer/Policy mu Max                                     1.99382
trainer/Policy mu Min                                    -2.59799
trainer/Policy log std Mean                              -2.34008
trainer/Policy log std Std                                0.570728
trainer/Policy log std Max                               -0.258514
trainer/Policy log std Min                               -3.16886
trainer/Alpha                                             0.0207265
trainer/Alpha Loss                                        0.221221
exploration/num steps total                           17800
exploration/num paths total                             890
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.14118
exploration/Rewards Std                                   0.129308
exploration/Rewards Max                                   0.0641474
exploration/Rewards Min                                  -0.88626
exploration/Returns Mean                                 -2.8236
exploration/Returns Std                                   1.77996
exploration/Returns Max                                  -0.294563
exploration/Returns Min                                  -4.70646
exploration/Actions Mean                                  0.000168135
exploration/Actions Std                                   0.195337
exploration/Actions Max                                   0.776141
exploration/Actions Min                                  -0.965073
exploration/Num Paths                                     5
exploration/Average Returns                              -2.8236
exploration/env_infos/final/reward_energy Mean           -0.169582
exploration/env_infos/final/reward_energy Std             0.140438
exploration/env_infos/final/reward_energy Max            -0.0725789
exploration/env_infos/final/reward_energy Min            -0.443977
exploration/env_infos/initial/reward_energy Mean         -0.44153
exploration/env_infos/initial/reward_energy Std           0.433299
exploration/env_infos/initial/reward_energy Max          -0.0569391
exploration/env_infos/initial/reward_energy Min          -1.20221
exploration/env_infos/reward_energy Mean                 -0.190286
exploration/env_infos/reward_energy Std                   0.20026
exploration/env_infos/reward_energy Max                  -0.0166681
exploration/env_infos/reward_energy Min                  -1.20221
exploration/env_infos/final/end_effector_loc Mean        -0.0319197
exploration/env_infos/final/end_effector_loc Std          0.376847
exploration/env_infos/final/end_effector_loc Max          0.5354
exploration/env_infos/final/end_effector_loc Min         -0.705969
exploration/env_infos/initial/end_effector_loc Mean      -0.000992676
exploration/env_infos/initial/end_effector_loc Std        0.0218492
exploration/env_infos/initial/end_effector_loc Max        0.0358452
exploration/env_infos/initial/end_effector_loc Min       -0.0482537
exploration/env_infos/end_effector_loc Mean              -0.0265336
exploration/env_infos/end_effector_loc Std                0.22538
exploration/env_infos/end_effector_loc Max                0.5354
exploration/env_infos/end_effector_loc Min               -0.705969
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00539352
exploration/env_infos/final/reward_dist Std               0.00779042
exploration/env_infos/final/reward_dist Max               0.0200136
exploration/env_infos/final/reward_dist Min               1.13013e-15
exploration/env_infos/initial/reward_dist Mean            0.0103275
exploration/env_infos/initial/reward_dist Std             0.0125516
exploration/env_infos/initial/reward_dist Max             0.0284566
exploration/env_infos/initial/reward_dist Min             8.59653e-06
exploration/env_infos/reward_dist Mean                    0.130998
exploration/env_infos/reward_dist Std                     0.196826
exploration/env_infos/reward_dist Max                     0.901522
exploration/env_infos/reward_dist Min                     1.13013e-15
evaluation/num steps total                           168000
evaluation/num paths total                             8400
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.106941
evaluation/Rewards Std                                    0.17269
evaluation/Rewards Max                                    0.157083
evaluation/Rewards Min                                   -1.17992
evaluation/Returns Mean                                  -2.13882
evaluation/Returns Std                                    2.77963
evaluation/Returns Max                                    1.00604
evaluation/Returns Min                                  -13.8831
evaluation/Actions Mean                                  -0.0420136
evaluation/Actions Std                                    0.194242
evaluation/Actions Max                                    0.895175
evaluation/Actions Min                                   -0.976579
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.13882
evaluation/env_infos/final/reward_energy Mean            -0.131587
evaluation/env_infos/final/reward_energy Std              0.251492
evaluation/env_infos/final/reward_energy Max             -0.00290308
evaluation/env_infos/final/reward_energy Min             -0.975542
evaluation/env_infos/initial/reward_energy Mean          -0.321256
evaluation/env_infos/initial/reward_energy Std            0.298167
evaluation/env_infos/initial/reward_energy Max           -0.0135994
evaluation/env_infos/initial/reward_energy Min           -1.13058
evaluation/env_infos/reward_energy Mean                  -0.150715
evaluation/env_infos/reward_energy Std                    0.237224
evaluation/env_infos/reward_energy Max                   -0.000150511
evaluation/env_infos/reward_energy Min                   -1.34854
evaluation/env_infos/final/end_effector_loc Mean         -0.147261
evaluation/env_infos/final/end_effector_loc Std           0.47297
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00255879
evaluation/env_infos/initial/end_effector_loc Std         0.0152836
evaluation/env_infos/initial/end_effector_loc Max         0.0447587
evaluation/env_infos/initial/end_effector_loc Min        -0.0468706
evaluation/env_infos/end_effector_loc Mean               -0.0757616
evaluation/env_infos/end_effector_loc Std                 0.303455
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.118257
evaluation/env_infos/final/reward_dist Std                0.206753
evaluation/env_infos/final/reward_dist Max                0.822711
evaluation/env_infos/final/reward_dist Min                2.28944e-169
evaluation/env_infos/initial/reward_dist Mean             0.00844849
evaluation/env_infos/initial/reward_dist Std              0.0224357
evaluation/env_infos/initial/reward_dist Max              0.145812
evaluation/env_infos/initial/reward_dist Min              1.46302e-06
evaluation/env_infos/reward_dist Mean                     0.139545
evaluation/env_infos/reward_dist Std                      0.240323
evaluation/env_infos/reward_dist Max                      0.998991
evaluation/env_infos/reward_dist Min                      2.28944e-169
time/data storing (s)                                    38.3697
time/evaluation sampling (s)                              0.668577
time/exploration sampling (s)                             0.0893731
time/logging (s)                                          0.0144922
time/saving (s)                                           0.779029
time/training (s)                                        39.3067
time/epoch (s)                                           79.2279
time/total (s)                                        11840.6
Epoch                                                   167
---------------------------------------------------  -----------------
2021-05-29 03:14:34.607981 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 168 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00538363
trainer/QF2 Loss                                          0.00519247
trainer/Policy Loss                                       2.83318
trainer/Q1 Predictions Mean                              -1.03396
trainer/Q1 Predictions Std                                0.857329
trainer/Q1 Predictions Max                                0.513073
trainer/Q1 Predictions Min                               -3.32581
trainer/Q2 Predictions Mean                              -1.03793
trainer/Q2 Predictions Std                                0.850464
trainer/Q2 Predictions Max                                0.559586
trainer/Q2 Predictions Min                               -3.33631
trainer/Q Targets Mean                                   -1.04595
trainer/Q Targets Std                                     0.854941
trainer/Q Targets Max                                     0.51272
trainer/Q Targets Min                                    -3.38638
trainer/Log Pis Mean                                      1.80932
trainer/Log Pis Std                                       1.37308
trainer/Log Pis Max                                       4.28917
trainer/Log Pis Min                                      -5.64976
trainer/Policy mu Mean                                    0.0276448
trainer/Policy mu Std                                     0.423091
trainer/Policy mu Max                                     2.62065
trainer/Policy mu Min                                    -1.95116
trainer/Policy log std Mean                              -2.20216
trainer/Policy log std Std                                0.597269
trainer/Policy log std Max                               -0.428755
trainer/Policy log std Min                               -3.30538
trainer/Alpha                                             0.0202292
trainer/Alpha Loss                                       -0.743586
exploration/num steps total                           17900
exploration/num paths total                             895
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.109685
exploration/Rewards Std                                   0.108131
exploration/Rewards Max                                   0.0993998
exploration/Rewards Min                                  -0.441517
exploration/Returns Mean                                 -2.19369
exploration/Returns Std                                   1.57036
exploration/Returns Max                                  -0.343326
exploration/Returns Min                                  -4.69606
exploration/Actions Mean                                  0.00392723
exploration/Actions Std                                   0.186819
exploration/Actions Max                                   0.72508
exploration/Actions Min                                  -0.629723
exploration/Num Paths                                     5
exploration/Average Returns                              -2.19369
exploration/env_infos/final/reward_energy Mean           -0.121992
exploration/env_infos/final/reward_energy Std             0.0581511
exploration/env_infos/final/reward_energy Max            -0.0620998
exploration/env_infos/final/reward_energy Min            -0.214671
exploration/env_infos/initial/reward_energy Mean         -0.281179
exploration/env_infos/initial/reward_energy Std           0.154739
exploration/env_infos/initial/reward_energy Max          -0.0729704
exploration/env_infos/initial/reward_energy Min          -0.497227
exploration/env_infos/reward_energy Mean                 -0.201118
exploration/env_infos/reward_energy Std                   0.17142
exploration/env_infos/reward_energy Max                  -0.0191009
exploration/env_infos/reward_energy Min                  -0.808392
exploration/env_infos/final/end_effector_loc Mean         0.0416173
exploration/env_infos/final/end_effector_loc Std          0.481933
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.769081
exploration/env_infos/initial/end_effector_loc Mean       0.00267222
exploration/env_infos/initial/end_effector_loc Std        0.011028
exploration/env_infos/initial/end_effector_loc Max        0.0248545
exploration/env_infos/initial/end_effector_loc Min       -0.0162016
exploration/env_infos/end_effector_loc Mean               0.0160578
exploration/env_infos/end_effector_loc Std                0.280568
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.769081
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0844223
exploration/env_infos/final/reward_dist Std               0.167755
exploration/env_infos/final/reward_dist Max               0.419929
exploration/env_infos/final/reward_dist Min               9.0742e-108
exploration/env_infos/initial/reward_dist Mean            0.000116054
exploration/env_infos/initial/reward_dist Std             0.00016034
exploration/env_infos/initial/reward_dist Max             0.000419997
exploration/env_infos/initial/reward_dist Min             5.36682e-06
exploration/env_infos/reward_dist Mean                    0.104844
exploration/env_infos/reward_dist Std                     0.216379
exploration/env_infos/reward_dist Max                     0.978819
exploration/env_infos/reward_dist Min                     9.0742e-108
evaluation/num steps total                           169000
evaluation/num paths total                             8450
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0725839
evaluation/Rewards Std                                    0.101349
evaluation/Rewards Max                                    0.168962
evaluation/Rewards Min                                   -0.475301
evaluation/Returns Mean                                  -1.45168
evaluation/Returns Std                                    1.62809
evaluation/Returns Max                                    1.33435
evaluation/Returns Min                                   -5.77917
evaluation/Actions Mean                                  -0.00222717
evaluation/Actions Std                                    0.103497
evaluation/Actions Max                                    0.913749
evaluation/Actions Min                                   -0.836605
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.45168
evaluation/env_infos/final/reward_energy Mean            -0.0705019
evaluation/env_infos/final/reward_energy Std              0.0688358
evaluation/env_infos/final/reward_energy Max             -0.00332768
evaluation/env_infos/final/reward_energy Min             -0.273858
evaluation/env_infos/initial/reward_energy Mean          -0.257379
evaluation/env_infos/initial/reward_energy Std            0.233761
evaluation/env_infos/initial/reward_energy Max           -0.0196688
evaluation/env_infos/initial/reward_energy Min           -1.1152
evaluation/env_infos/reward_energy Mean                  -0.0930196
evaluation/env_infos/reward_energy Std                    0.113052
evaluation/env_infos/reward_energy Max                   -0.00139186
evaluation/env_infos/reward_energy Min                   -1.1152
evaluation/env_infos/final/end_effector_loc Mean         -0.0377193
evaluation/env_infos/final/end_effector_loc Std           0.375822
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000354549
evaluation/env_infos/initial/end_effector_loc Std         0.0122876
evaluation/env_infos/initial/end_effector_loc Max         0.0456875
evaluation/env_infos/initial/end_effector_loc Min        -0.0312875
evaluation/env_infos/end_effector_loc Mean               -0.016674
evaluation/env_infos/end_effector_loc Std                 0.218326
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0881619
evaluation/env_infos/final/reward_dist Std                0.182737
evaluation/env_infos/final/reward_dist Max                0.772388
evaluation/env_infos/final/reward_dist Min                8.25927e-106
evaluation/env_infos/initial/reward_dist Mean             0.00476332
evaluation/env_infos/initial/reward_dist Std              0.00858068
evaluation/env_infos/initial/reward_dist Max              0.0410426
evaluation/env_infos/initial/reward_dist Min              3.74635e-07
evaluation/env_infos/reward_dist Mean                     0.142122
evaluation/env_infos/reward_dist Std                      0.245703
evaluation/env_infos/reward_dist Max                      0.994806
evaluation/env_infos/reward_dist Min                      8.25927e-106
time/data storing (s)                                    38.1384
time/evaluation sampling (s)                              0.64408
time/exploration sampling (s)                             0.0902052
time/logging (s)                                          0.0153578
time/saving (s)                                           0.796584
time/training (s)                                        39.2117
time/epoch (s)                                           78.8964
time/total (s)                                        11921.3
Epoch                                                   168
---------------------------------------------------  -----------------
2021-05-29 03:15:56.206187 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 169 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00337855
trainer/QF2 Loss                                          0.0053177
trainer/Policy Loss                                       3.32858
trainer/Q1 Predictions Mean                              -1.18212
trainer/Q1 Predictions Std                                0.887967
trainer/Q1 Predictions Max                                0.681127
trainer/Q1 Predictions Min                               -3.38272
trainer/Q2 Predictions Mean                              -1.18566
trainer/Q2 Predictions Std                                0.896536
trainer/Q2 Predictions Max                                0.683373
trainer/Q2 Predictions Min                               -3.3614
trainer/Q Targets Mean                                   -1.16719
trainer/Q Targets Std                                     0.885107
trainer/Q Targets Max                                     0.781664
trainer/Q Targets Min                                    -3.24299
trainer/Log Pis Mean                                      2.15329
trainer/Log Pis Std                                       1.3653
trainer/Log Pis Max                                       7.02785
trainer/Log Pis Min                                      -3.46679
trainer/Policy mu Mean                                   -0.0133102
trainer/Policy mu Std                                     0.514271
trainer/Policy mu Max                                     3.2777
trainer/Policy mu Min                                    -2.86132
trainer/Policy log std Mean                              -2.27673
trainer/Policy log std Std                                0.605401
trainer/Policy log std Max                               -0.232341
trainer/Policy log std Min                               -3.29739
trainer/Alpha                                             0.021259
trainer/Alpha Loss                                        0.590188
exploration/num steps total                           18000
exploration/num paths total                             900
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.148669
exploration/Rewards Std                                   0.113236
exploration/Rewards Max                                   0.00248925
exploration/Rewards Min                                  -0.708514
exploration/Returns Mean                                 -2.97339
exploration/Returns Std                                   1.24273
exploration/Returns Max                                  -1.80636
exploration/Returns Min                                  -5.31861
exploration/Actions Mean                                 -0.0076663
exploration/Actions Std                                   0.153876
exploration/Actions Max                                   0.976062
exploration/Actions Min                                  -0.771711
exploration/Num Paths                                     5
exploration/Average Returns                              -2.97339
exploration/env_infos/final/reward_energy Mean           -0.138035
exploration/env_infos/final/reward_energy Std             0.0525901
exploration/env_infos/final/reward_energy Max            -0.040829
exploration/env_infos/final/reward_energy Min            -0.187749
exploration/env_infos/initial/reward_energy Mean         -0.473422
exploration/env_infos/initial/reward_energy Std           0.446498
exploration/env_infos/initial/reward_energy Max          -0.075919
exploration/env_infos/initial/reward_energy Min          -1.13291
exploration/env_infos/reward_energy Mean                 -0.140658
exploration/env_infos/reward_energy Std                   0.166399
exploration/env_infos/reward_energy Max                  -0.00748122
exploration/env_infos/reward_energy Min                  -1.13291
exploration/env_infos/final/end_effector_loc Mean        -0.0750924
exploration/env_infos/final/end_effector_loc Std          0.54931
exploration/env_infos/final/end_effector_loc Max          0.852906
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -1.81859e-05
exploration/env_infos/initial/end_effector_loc Std        0.0230078
exploration/env_infos/initial/end_effector_loc Max        0.0488031
exploration/env_infos/initial/end_effector_loc Min       -0.0385856
exploration/env_infos/end_effector_loc Mean              -0.0363606
exploration/env_infos/end_effector_loc Std                0.331283
exploration/env_infos/end_effector_loc Max                0.852906
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000122677
exploration/env_infos/final/reward_dist Std               0.000245334
exploration/env_infos/final/reward_dist Max               0.000613345
exploration/env_infos/final/reward_dist Min               3.22024e-85
exploration/env_infos/initial/reward_dist Mean            0.000713506
exploration/env_infos/initial/reward_dist Std             0.00108494
exploration/env_infos/initial/reward_dist Max             0.00287172
exploration/env_infos/initial/reward_dist Min             1.70791e-05
exploration/env_infos/reward_dist Mean                    0.0317553
exploration/env_infos/reward_dist Std                     0.0589313
exploration/env_infos/reward_dist Max                     0.267486
exploration/env_infos/reward_dist Min                     3.22024e-85
evaluation/num steps total                           170000
evaluation/num paths total                             8500
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0702962
evaluation/Rewards Std                                    0.119664
evaluation/Rewards Max                                    0.155273
evaluation/Rewards Min                                   -0.782824
evaluation/Returns Mean                                  -1.40592
evaluation/Returns Std                                    2.0234
evaluation/Returns Max                                    2.31319
evaluation/Returns Min                                   -8.30956
evaluation/Actions Mean                                  -0.00170076
evaluation/Actions Std                                    0.132444
evaluation/Actions Max                                    0.971548
evaluation/Actions Min                                   -0.997464
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.40592
evaluation/env_infos/final/reward_energy Mean            -0.0923972
evaluation/env_infos/final/reward_energy Std              0.12737
evaluation/env_infos/final/reward_energy Max             -0.00919746
evaluation/env_infos/final/reward_energy Min             -0.65347
evaluation/env_infos/initial/reward_energy Mean          -0.360338
evaluation/env_infos/initial/reward_energy Std            0.332991
evaluation/env_infos/initial/reward_energy Max           -0.0193829
evaluation/env_infos/initial/reward_energy Min           -1.28576
evaluation/env_infos/reward_energy Mean                  -0.113165
evaluation/env_infos/reward_energy Std                    0.149273
evaluation/env_infos/reward_energy Max                   -0.0021973
evaluation/env_infos/reward_energy Min                   -1.28576
evaluation/env_infos/final/end_effector_loc Mean          0.000494183
evaluation/env_infos/final/end_effector_loc Std           0.354674
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.876023
evaluation/env_infos/initial/end_effector_loc Mean       -0.000105523
evaluation/env_infos/initial/end_effector_loc Std         0.0173464
evaluation/env_infos/initial/end_effector_loc Max         0.0485774
evaluation/env_infos/initial/end_effector_loc Min        -0.0498732
evaluation/env_infos/end_effector_loc Mean                0.00162781
evaluation/env_infos/end_effector_loc Std                 0.227961
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.106782
evaluation/env_infos/final/reward_dist Std                0.213916
evaluation/env_infos/final/reward_dist Max                0.941038
evaluation/env_infos/final/reward_dist Min                2.32077e-146
evaluation/env_infos/initial/reward_dist Mean             0.00814489
evaluation/env_infos/initial/reward_dist Std              0.0185184
evaluation/env_infos/initial/reward_dist Max              0.0820687
evaluation/env_infos/initial/reward_dist Min              3.04895e-07
evaluation/env_infos/reward_dist Mean                     0.138025
evaluation/env_infos/reward_dist Std                      0.239555
evaluation/env_infos/reward_dist Max                      0.990635
evaluation/env_infos/reward_dist Min                      2.32077e-146
time/data storing (s)                                    38.7708
time/evaluation sampling (s)                              0.651976
time/exploration sampling (s)                             0.0894137
time/logging (s)                                          0.0154521
time/saving (s)                                           0.786715
time/training (s)                                        39.4404
time/epoch (s)                                           79.7547
time/total (s)                                        12002.9
Epoch                                                   169
---------------------------------------------------  -----------------
2021-05-29 03:17:17.469500 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 170 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00308849
trainer/QF2 Loss                                          0.00265462
trainer/Policy Loss                                       3.20527
trainer/Q1 Predictions Mean                              -1.00245
trainer/Q1 Predictions Std                                0.881814
trainer/Q1 Predictions Max                                1.37507
trainer/Q1 Predictions Min                               -3.1708
trainer/Q2 Predictions Mean                              -0.994214
trainer/Q2 Predictions Std                                0.875083
trainer/Q2 Predictions Max                                1.34334
trainer/Q2 Predictions Min                               -3.14015
trainer/Q Targets Mean                                   -1.00326
trainer/Q Targets Std                                     0.873979
trainer/Q Targets Max                                     1.37446
trainer/Q Targets Min                                    -3.1355
trainer/Log Pis Mean                                      2.20367
trainer/Log Pis Std                                       1.21859
trainer/Log Pis Max                                       4.36386
trainer/Log Pis Min                                      -1.81108
trainer/Policy mu Mean                                   -0.00606375
trainer/Policy mu Std                                     0.290661
trainer/Policy mu Max                                     1.9147
trainer/Policy mu Min                                    -1.96448
trainer/Policy log std Mean                              -2.411
trainer/Policy log std Std                                0.502188
trainer/Policy log std Max                               -0.687198
trainer/Policy log std Min                               -3.30872
trainer/Alpha                                             0.0214361
trainer/Alpha Loss                                        0.783228
exploration/num steps total                           18100
exploration/num paths total                             905
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.165796
exploration/Rewards Std                                   0.0740042
exploration/Rewards Max                                  -0.0224604
exploration/Rewards Min                                  -0.442058
exploration/Returns Mean                                 -3.31592
exploration/Returns Std                                   0.816429
exploration/Returns Max                                  -1.73103
exploration/Returns Min                                  -3.90466
exploration/Actions Mean                                  0.00809034
exploration/Actions Std                                   0.205343
exploration/Actions Max                                   0.710482
exploration/Actions Min                                  -0.854121
exploration/Num Paths                                     5
exploration/Average Returns                              -3.31592
exploration/env_infos/final/reward_energy Mean           -0.292842
exploration/env_infos/final/reward_energy Std             0.245257
exploration/env_infos/final/reward_energy Max            -0.0150139
exploration/env_infos/final/reward_energy Min            -0.627306
exploration/env_infos/initial/reward_energy Mean         -0.39679
exploration/env_infos/initial/reward_energy Std           0.361779
exploration/env_infos/initial/reward_energy Max          -0.140809
exploration/env_infos/initial/reward_energy Min          -1.11099
exploration/env_infos/reward_energy Mean                 -0.229238
exploration/env_infos/reward_energy Std                   0.178641
exploration/env_infos/reward_energy Max                  -0.0150139
exploration/env_infos/reward_energy Min                  -1.11099
exploration/env_infos/final/end_effector_loc Mean         0.0565548
exploration/env_infos/final/end_effector_loc Std          0.457654
exploration/env_infos/final/end_effector_loc Max          0.774239
exploration/env_infos/final/end_effector_loc Min         -0.968836
exploration/env_infos/initial/end_effector_loc Mean      -0.00087509
exploration/env_infos/initial/end_effector_loc Std        0.0189642
exploration/env_infos/initial/end_effector_loc Max        0.0355241
exploration/env_infos/initial/end_effector_loc Min       -0.0427061
exploration/env_infos/end_effector_loc Mean               0.0205418
exploration/env_infos/end_effector_loc Std                0.258134
exploration/env_infos/end_effector_loc Max                0.774239
exploration/env_infos/end_effector_loc Min               -0.968836
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00110297
exploration/env_infos/final/reward_dist Std               0.00220585
exploration/env_infos/final/reward_dist Max               0.00551467
exploration/env_infos/final/reward_dist Min               7.4556e-123
exploration/env_infos/initial/reward_dist Mean            0.00123805
exploration/env_infos/initial/reward_dist Std             0.00156866
exploration/env_infos/initial/reward_dist Max             0.00402954
exploration/env_infos/initial/reward_dist Min             3.73164e-07
exploration/env_infos/reward_dist Mean                    0.0328496
exploration/env_infos/reward_dist Std                     0.0954704
exploration/env_infos/reward_dist Max                     0.645048
exploration/env_infos/reward_dist Min                     7.4556e-123
evaluation/num steps total                           171000
evaluation/num paths total                             8550
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0838598
evaluation/Rewards Std                                    0.0883881
evaluation/Rewards Max                                    0.151128
evaluation/Rewards Min                                   -0.655444
evaluation/Returns Mean                                  -1.6772
evaluation/Returns Std                                    1.3986
evaluation/Returns Max                                    1.07274
evaluation/Returns Min                                   -5.51005
evaluation/Actions Mean                                   0.00245641
evaluation/Actions Std                                    0.110352
evaluation/Actions Max                                    0.763817
evaluation/Actions Min                                   -0.898291
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.6772
evaluation/env_infos/final/reward_energy Mean            -0.0923585
evaluation/env_infos/final/reward_energy Std              0.118384
evaluation/env_infos/final/reward_energy Max             -0.0110052
evaluation/env_infos/final/reward_energy Min             -0.659528
evaluation/env_infos/initial/reward_energy Mean          -0.199186
evaluation/env_infos/initial/reward_energy Std            0.205739
evaluation/env_infos/initial/reward_energy Max           -0.0061857
evaluation/env_infos/initial/reward_energy Min           -0.908092
evaluation/env_infos/reward_energy Mean                  -0.0942054
evaluation/env_infos/reward_energy Std                    0.124469
evaluation/env_infos/reward_energy Max                   -0.00288232
evaluation/env_infos/reward_energy Min                   -1.01982
evaluation/env_infos/final/end_effector_loc Mean          0.0558041
evaluation/env_infos/final/end_effector_loc Std           0.38839
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00119105
evaluation/env_infos/initial/end_effector_loc Std         0.0100541
evaluation/env_infos/initial/end_effector_loc Max         0.0354376
evaluation/env_infos/initial/end_effector_loc Min        -0.0449146
evaluation/env_infos/end_effector_loc Mean                0.0196881
evaluation/env_infos/end_effector_loc Std                 0.235737
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0461433
evaluation/env_infos/final/reward_dist Std                0.148602
evaluation/env_infos/final/reward_dist Max                0.820932
evaluation/env_infos/final/reward_dist Min                8.75635e-148
evaluation/env_infos/initial/reward_dist Mean             0.00574949
evaluation/env_infos/initial/reward_dist Std              0.0100523
evaluation/env_infos/initial/reward_dist Max              0.0458897
evaluation/env_infos/initial/reward_dist Min              4.4771e-07
evaluation/env_infos/reward_dist Mean                     0.0816578
evaluation/env_infos/reward_dist Std                      0.191291
evaluation/env_infos/reward_dist Max                      0.991583
evaluation/env_infos/reward_dist Min                      8.75635e-148
time/data storing (s)                                    38.3115
time/evaluation sampling (s)                              0.63384
time/exploration sampling (s)                             0.0869801
time/logging (s)                                          0.0148079
time/saving (s)                                           0.793402
time/training (s)                                        39.3157
time/epoch (s)                                           79.1562
time/total (s)                                        12084.2
Epoch                                                   170
---------------------------------------------------  -----------------
2021-05-29 03:18:38.507534 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 171 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00377933
trainer/QF2 Loss                                          0.00541682
trainer/Policy Loss                                       2.92372
trainer/Q1 Predictions Mean                              -1.01092
trainer/Q1 Predictions Std                                0.797786
trainer/Q1 Predictions Max                                1.25882
trainer/Q1 Predictions Min                               -3.54235
trainer/Q2 Predictions Mean                              -1.02079
trainer/Q2 Predictions Std                                0.794865
trainer/Q2 Predictions Max                                1.17692
trainer/Q2 Predictions Min                               -3.46507
trainer/Q Targets Mean                                   -1.01106
trainer/Q Targets Std                                     0.807638
trainer/Q Targets Max                                     1.26138
trainer/Q Targets Min                                    -3.56611
trainer/Log Pis Mean                                      1.90015
trainer/Log Pis Std                                       1.19334
trainer/Log Pis Max                                       5.51438
trainer/Log Pis Min                                      -2.66537
trainer/Policy mu Mean                                    0.0238007
trainer/Policy mu Std                                     0.390692
trainer/Policy mu Max                                     2.95232
trainer/Policy mu Min                                    -1.85782
trainer/Policy log std Mean                              -2.24663
trainer/Policy log std Std                                0.515089
trainer/Policy log std Max                               -0.444684
trainer/Policy log std Min                               -3.19507
trainer/Alpha                                             0.021969
trainer/Alpha Loss                                       -0.38105
exploration/num steps total                           18200
exploration/num paths total                             910
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.200317
exploration/Rewards Std                                   0.212529
exploration/Rewards Max                                   0.00592136
exploration/Rewards Min                                  -0.900975
exploration/Returns Mean                                 -4.00634
exploration/Returns Std                                   3.55366
exploration/Returns Max                                  -2.11749
exploration/Returns Min                                 -11.1106
exploration/Actions Mean                                 -0.0473005
exploration/Actions Std                                   0.281824
exploration/Actions Max                                   0.998978
exploration/Actions Min                                  -0.99997
exploration/Num Paths                                     5
exploration/Average Returns                              -4.00634
exploration/env_infos/final/reward_energy Mean           -0.102142
exploration/env_infos/final/reward_energy Std             0.0486007
exploration/env_infos/final/reward_energy Max            -0.0368349
exploration/env_infos/final/reward_energy Min            -0.184672
exploration/env_infos/initial/reward_energy Mean         -0.177509
exploration/env_infos/initial/reward_energy Std           0.12177
exploration/env_infos/initial/reward_energy Max          -0.0251821
exploration/env_infos/initial/reward_energy Min          -0.376346
exploration/env_infos/reward_energy Mean                 -0.239875
exploration/env_infos/reward_energy Std                   0.325246
exploration/env_infos/reward_energy Max                  -0.0115596
exploration/env_infos/reward_energy Min                  -1.41155
exploration/env_infos/final/end_effector_loc Mean        -0.113537
exploration/env_infos/final/end_effector_loc Std          0.567918
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00274317
exploration/env_infos/initial/end_effector_loc Std        0.00709907
exploration/env_infos/initial/end_effector_loc Max        0.00742603
exploration/env_infos/initial/end_effector_loc Min       -0.0140827
exploration/env_infos/end_effector_loc Mean              -0.0664459
exploration/env_infos/end_effector_loc Std                0.370247
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00180829
exploration/env_infos/final/reward_dist Std               0.00221472
exploration/env_infos/final/reward_dist Max               0.00454181
exploration/env_infos/final/reward_dist Min               8.06565e-157
exploration/env_infos/initial/reward_dist Mean            0.00374513
exploration/env_infos/initial/reward_dist Std             0.00364623
exploration/env_infos/initial/reward_dist Max             0.00929112
exploration/env_infos/initial/reward_dist Min             3.117e-06
exploration/env_infos/reward_dist Mean                    0.0495439
exploration/env_infos/reward_dist Std                     0.143616
exploration/env_infos/reward_dist Max                     0.782122
exploration/env_infos/reward_dist Min                     8.06565e-157
evaluation/num steps total                           172000
evaluation/num paths total                             8600
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0855858
evaluation/Rewards Std                                    0.150389
evaluation/Rewards Max                                    0.130474
evaluation/Rewards Min                                   -0.91507
evaluation/Returns Mean                                  -1.71172
evaluation/Returns Std                                    2.55946
evaluation/Returns Max                                    1.56916
evaluation/Returns Min                                   -9.64746
evaluation/Actions Mean                                  -0.00999966
evaluation/Actions Std                                    0.138033
evaluation/Actions Max                                    0.990598
evaluation/Actions Min                                   -0.974569
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.71172
evaluation/env_infos/final/reward_energy Mean            -0.114975
evaluation/env_infos/final/reward_energy Std              0.163555
evaluation/env_infos/final/reward_energy Max             -0.00687182
evaluation/env_infos/final/reward_energy Min             -0.949673
evaluation/env_infos/initial/reward_energy Mean          -0.359323
evaluation/env_infos/initial/reward_energy Std            0.335611
evaluation/env_infos/initial/reward_energy Max           -0.00695748
evaluation/env_infos/initial/reward_energy Min           -1.25431
evaluation/env_infos/reward_energy Mean                  -0.115496
evaluation/env_infos/reward_energy Std                    0.158009
evaluation/env_infos/reward_energy Max                   -0.000571965
evaluation/env_infos/reward_energy Min                   -1.3798
evaluation/env_infos/final/end_effector_loc Mean         -0.0873617
evaluation/env_infos/final/end_effector_loc Std           0.434617
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00432794
evaluation/env_infos/initial/end_effector_loc Std         0.0168361
evaluation/env_infos/initial/end_effector_loc Max         0.039481
evaluation/env_infos/initial/end_effector_loc Min        -0.0487285
evaluation/env_infos/end_effector_loc Mean               -0.0484331
evaluation/env_infos/end_effector_loc Std                 0.258103
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.180534
evaluation/env_infos/final/reward_dist Std                0.27617
evaluation/env_infos/final/reward_dist Max                0.935039
evaluation/env_infos/final/reward_dist Min                1.67748e-133
evaluation/env_infos/initial/reward_dist Mean             0.0100843
evaluation/env_infos/initial/reward_dist Std              0.0189852
evaluation/env_infos/initial/reward_dist Max              0.0889906
evaluation/env_infos/initial/reward_dist Min              1.44259e-07
evaluation/env_infos/reward_dist Mean                     0.172157
evaluation/env_infos/reward_dist Std                      0.262822
evaluation/env_infos/reward_dist Max                      0.998034
evaluation/env_infos/reward_dist Min                      1.67748e-133
time/data storing (s)                                    38.2763
time/evaluation sampling (s)                              0.676559
time/exploration sampling (s)                             0.0859349
time/logging (s)                                          0.0152452
time/saving (s)                                           0.793002
time/training (s)                                        39.3258
time/epoch (s)                                           79.1728
time/total (s)                                        12165.2
Epoch                                                   171
---------------------------------------------------  -----------------
2021-05-29 03:19:59.531282 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 172 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00335318
trainer/QF2 Loss                                          0.00350771
trainer/Policy Loss                                       3.17697
trainer/Q1 Predictions Mean                              -1.09442
trainer/Q1 Predictions Std                                0.826262
trainer/Q1 Predictions Max                                0.880311
trainer/Q1 Predictions Min                               -3.3507
trainer/Q2 Predictions Mean                              -1.09168
trainer/Q2 Predictions Std                                0.824279
trainer/Q2 Predictions Max                                1.00254
trainer/Q2 Predictions Min                               -3.31098
trainer/Q Targets Mean                                   -1.10369
trainer/Q Targets Std                                     0.833761
trainer/Q Targets Max                                     1.05091
trainer/Q Targets Min                                    -3.32272
trainer/Log Pis Mean                                      2.08468
trainer/Log Pis Std                                       1.23478
trainer/Log Pis Max                                       4.53961
trainer/Log Pis Min                                      -2.98301
trainer/Policy mu Mean                                    0.00558079
trainer/Policy mu Std                                     0.353983
trainer/Policy mu Max                                     2.09105
trainer/Policy mu Min                                    -2.19799
trainer/Policy log std Mean                              -2.35647
trainer/Policy log std Std                                0.546444
trainer/Policy log std Max                               -0.242676
trainer/Policy log std Min                               -3.36576
trainer/Alpha                                             0.0196569
trainer/Alpha Loss                                        0.332859
exploration/num steps total                           18300
exploration/num paths total                             915
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.123535
exploration/Rewards Std                                   0.126849
exploration/Rewards Max                                   0.0848467
exploration/Rewards Min                                  -0.48632
exploration/Returns Mean                                 -2.4707
exploration/Returns Std                                   2.17419
exploration/Returns Max                                   0.593868
exploration/Returns Min                                  -5.39087
exploration/Actions Mean                                  0.0467821
exploration/Actions Std                                   0.160728
exploration/Actions Max                                   0.748911
exploration/Actions Min                                  -0.679759
exploration/Num Paths                                     5
exploration/Average Returns                              -2.4707
exploration/env_infos/final/reward_energy Mean           -0.232245
exploration/env_infos/final/reward_energy Std             0.252845
exploration/env_infos/final/reward_energy Max            -0.0676027
exploration/env_infos/final/reward_energy Min            -0.7312
exploration/env_infos/initial/reward_energy Mean         -0.166885
exploration/env_infos/initial/reward_energy Std           0.126552
exploration/env_infos/initial/reward_energy Max          -0.00937158
exploration/env_infos/initial/reward_energy Min          -0.37894
exploration/env_infos/reward_energy Mean                 -0.160566
exploration/env_infos/reward_energy Std                   0.173962
exploration/env_infos/reward_energy Max                  -0.00502516
exploration/env_infos/reward_energy Min                  -0.980114
exploration/env_infos/final/end_effector_loc Mean         0.451899
exploration/env_infos/final/end_effector_loc Std          0.331489
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min          0.0818892
exploration/env_infos/initial/end_effector_loc Mean       0.00210988
exploration/env_infos/initial/end_effector_loc Std        0.00709795
exploration/env_infos/initial/end_effector_loc Max        0.0128732
exploration/env_infos/initial/end_effector_loc Min       -0.0139021
exploration/env_infos/end_effector_loc Mean               0.22008
exploration/env_infos/end_effector_loc Std                0.276048
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.0848143
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0597027
exploration/env_infos/final/reward_dist Std               0.119405
exploration/env_infos/final/reward_dist Max               0.298513
exploration/env_infos/final/reward_dist Min               2.27989e-96
exploration/env_infos/initial/reward_dist Mean            0.0105421
exploration/env_infos/initial/reward_dist Std             0.00798622
exploration/env_infos/initial/reward_dist Max             0.0179454
exploration/env_infos/initial/reward_dist Min             0.000150951
exploration/env_infos/reward_dist Mean                    0.135211
exploration/env_infos/reward_dist Std                     0.245622
exploration/env_infos/reward_dist Max                     0.981667
exploration/env_infos/reward_dist Min                     2.27989e-96
evaluation/num steps total                           173000
evaluation/num paths total                             8650
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.113039
evaluation/Rewards Std                                    0.148357
evaluation/Rewards Max                                    0.134129
evaluation/Rewards Min                                   -1.14802
evaluation/Returns Mean                                  -2.26078
evaluation/Returns Std                                    2.57092
evaluation/Returns Max                                    1.19189
evaluation/Returns Min                                  -12.4967
evaluation/Actions Mean                                  -0.00255354
evaluation/Actions Std                                    0.136387
evaluation/Actions Max                                    0.919546
evaluation/Actions Min                                   -0.986411
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.26078
evaluation/env_infos/final/reward_energy Mean            -0.0737496
evaluation/env_infos/final/reward_energy Std              0.04815
evaluation/env_infos/final/reward_energy Max             -0.0184141
evaluation/env_infos/final/reward_energy Min             -0.311321
evaluation/env_infos/initial/reward_energy Mean          -0.268892
evaluation/env_infos/initial/reward_energy Std            0.312378
evaluation/env_infos/initial/reward_energy Max           -0.0124964
evaluation/env_infos/initial/reward_energy Min           -1.11462
evaluation/env_infos/reward_energy Mean                  -0.104392
evaluation/env_infos/reward_energy Std                    0.162229
evaluation/env_infos/reward_energy Max                   -0.0021101
evaluation/env_infos/reward_energy Min                   -1.39145
evaluation/env_infos/final/end_effector_loc Mean         -0.0641485
evaluation/env_infos/final/end_effector_loc Std           0.432326
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00365697
evaluation/env_infos/initial/end_effector_loc Std         0.014106
evaluation/env_infos/initial/end_effector_loc Max         0.0394031
evaluation/env_infos/initial/end_effector_loc Min        -0.0481171
evaluation/env_infos/end_effector_loc Mean               -0.0367809
evaluation/env_infos/end_effector_loc Std                 0.260472
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0628309
evaluation/env_infos/final/reward_dist Std                0.161199
evaluation/env_infos/final/reward_dist Max                0.892039
evaluation/env_infos/final/reward_dist Min                4.4951e-103
evaluation/env_infos/initial/reward_dist Mean             0.00620635
evaluation/env_infos/initial/reward_dist Std              0.0159723
evaluation/env_infos/initial/reward_dist Max              0.106055
evaluation/env_infos/initial/reward_dist Min              6.21596e-08
evaluation/env_infos/reward_dist Mean                     0.0800827
evaluation/env_infos/reward_dist Std                      0.17842
evaluation/env_infos/reward_dist Max                      0.994727
evaluation/env_infos/reward_dist Min                      4.4951e-103
time/data storing (s)                                    38.4221
time/evaluation sampling (s)                              0.54566
time/exploration sampling (s)                             0.084446
time/logging (s)                                          0.0146669
time/saving (s)                                           0.778381
time/training (s)                                        39.3085
time/epoch (s)                                           79.1537
time/total (s)                                        12246.2
Epoch                                                   172
---------------------------------------------------  ----------------
2021-05-29 03:21:21.861365 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 173 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00388258
trainer/QF2 Loss                                          0.00470163
trainer/Policy Loss                                       3.03478
trainer/Q1 Predictions Mean                              -1.13369
trainer/Q1 Predictions Std                                0.848281
trainer/Q1 Predictions Max                                0.986365
trainer/Q1 Predictions Min                               -3.25407
trainer/Q2 Predictions Mean                              -1.12317
trainer/Q2 Predictions Std                                0.856753
trainer/Q2 Predictions Max                                1.00734
trainer/Q2 Predictions Min                               -3.26158
trainer/Q Targets Mean                                   -1.13593
trainer/Q Targets Std                                     0.854066
trainer/Q Targets Max                                     0.987473
trainer/Q Targets Min                                    -3.30813
trainer/Log Pis Mean                                      1.90259
trainer/Log Pis Std                                       1.32052
trainer/Log Pis Max                                       4.61828
trainer/Log Pis Min                                      -2.71646
trainer/Policy mu Mean                                   -0.00129697
trainer/Policy mu Std                                     0.275811
trainer/Policy mu Max                                     2.16317
trainer/Policy mu Min                                    -1.25153
trainer/Policy log std Mean                              -2.33503
trainer/Policy log std Std                                0.501269
trainer/Policy log std Max                                0.768371
trainer/Policy log std Min                               -3.17334
trainer/Alpha                                             0.0208549
trainer/Alpha Loss                                       -0.376985
exploration/num steps total                           18400
exploration/num paths total                             920
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0115367
exploration/Rewards Std                                   0.0809663
exploration/Rewards Max                                   0.142687
exploration/Rewards Min                                  -0.16481
exploration/Returns Mean                                 -0.230733
exploration/Returns Std                                   1.3859
exploration/Returns Max                                   1.93914
exploration/Returns Min                                  -2.05099
exploration/Actions Mean                                  0.0107782
exploration/Actions Std                                   0.152471
exploration/Actions Max                                   0.661358
exploration/Actions Min                                  -0.836037
exploration/Num Paths                                     5
exploration/Average Returns                              -0.230733
exploration/env_infos/final/reward_energy Mean           -0.0708757
exploration/env_infos/final/reward_energy Std             0.0345346
exploration/env_infos/final/reward_energy Max            -0.0328727
exploration/env_infos/final/reward_energy Min            -0.11561
exploration/env_infos/initial/reward_energy Mean         -0.371283
exploration/env_infos/initial/reward_energy Std           0.369756
exploration/env_infos/initial/reward_energy Max          -0.0424796
exploration/env_infos/initial/reward_energy Min          -0.932369
exploration/env_infos/reward_energy Mean                 -0.147442
exploration/env_infos/reward_energy Std                   0.158077
exploration/env_infos/reward_energy Max                  -0.000979489
exploration/env_infos/reward_energy Min                  -0.932369
exploration/env_infos/final/end_effector_loc Mean         0.0729857
exploration/env_infos/final/end_effector_loc Std          0.152367
exploration/env_infos/final/end_effector_loc Max          0.342329
exploration/env_infos/final/end_effector_loc Min         -0.161054
exploration/env_infos/initial/end_effector_loc Mean       0.00150903
exploration/env_infos/initial/end_effector_loc Std        0.0184645
exploration/env_infos/initial/end_effector_loc Max        0.0330679
exploration/env_infos/initial/end_effector_loc Min       -0.0418019
exploration/env_infos/end_effector_loc Mean               0.0242118
exploration/env_infos/end_effector_loc Std                0.124495
exploration/env_infos/end_effector_loc Max                0.342329
exploration/env_infos/end_effector_loc Min               -0.313014
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.260332
exploration/env_infos/final/reward_dist Std               0.228752
exploration/env_infos/final/reward_dist Max               0.557211
exploration/env_infos/final/reward_dist Min               0.00275865
exploration/env_infos/initial/reward_dist Mean            0.0292643
exploration/env_infos/initial/reward_dist Std             0.0428956
exploration/env_infos/initial/reward_dist Max             0.113163
exploration/env_infos/initial/reward_dist Min             9.85261e-07
exploration/env_infos/reward_dist Mean                    0.264233
exploration/env_infos/reward_dist Std                     0.320441
exploration/env_infos/reward_dist Max                     0.985221
exploration/env_infos/reward_dist Min                     9.48041e-07
evaluation/num steps total                           174000
evaluation/num paths total                             8700
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.106037
evaluation/Rewards Std                                    0.15683
evaluation/Rewards Max                                    0.179271
evaluation/Rewards Min                                   -1.02851
evaluation/Returns Mean                                  -2.12074
evaluation/Returns Std                                    2.78231
evaluation/Returns Max                                    1.46157
evaluation/Returns Min                                  -11.5023
evaluation/Actions Mean                                  -0.00524769
evaluation/Actions Std                                    0.101331
evaluation/Actions Max                                    0.717573
evaluation/Actions Min                                   -0.983265
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.12074
evaluation/env_infos/final/reward_energy Mean            -0.0640337
evaluation/env_infos/final/reward_energy Std              0.0503951
evaluation/env_infos/final/reward_energy Max             -0.00973036
evaluation/env_infos/final/reward_energy Min             -0.305443
evaluation/env_infos/initial/reward_energy Mean          -0.232332
evaluation/env_infos/initial/reward_energy Std            0.266633
evaluation/env_infos/initial/reward_energy Max           -0.00427549
evaluation/env_infos/initial/reward_energy Min           -1.21726
evaluation/env_infos/reward_energy Mean                  -0.0879426
evaluation/env_infos/reward_energy Std                    0.113388
evaluation/env_infos/reward_energy Max                   -0.00153047
evaluation/env_infos/reward_energy Min                   -1.21726
evaluation/env_infos/final/end_effector_loc Mean         -0.0211801
evaluation/env_infos/final/end_effector_loc Std           0.490718
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00122166
evaluation/env_infos/initial/end_effector_loc Std         0.0124438
evaluation/env_infos/initial/end_effector_loc Max         0.0358787
evaluation/env_infos/initial/end_effector_loc Min        -0.0491632
evaluation/env_infos/end_effector_loc Mean               -0.0155519
evaluation/env_infos/end_effector_loc Std                 0.323031
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.107644
evaluation/env_infos/final/reward_dist Std                0.224559
evaluation/env_infos/final/reward_dist Max                0.993944
evaluation/env_infos/final/reward_dist Min                6.0839e-178
evaluation/env_infos/initial/reward_dist Mean             0.00505037
evaluation/env_infos/initial/reward_dist Std              0.00791597
evaluation/env_infos/initial/reward_dist Max              0.03212
evaluation/env_infos/initial/reward_dist Min              1.65447e-07
evaluation/env_infos/reward_dist Mean                     0.103333
evaluation/env_infos/reward_dist Std                      0.219047
evaluation/env_infos/reward_dist Max                      0.996428
evaluation/env_infos/reward_dist Min                      6.0839e-178
time/data storing (s)                                    38.8188
time/evaluation sampling (s)                              0.637944
time/exploration sampling (s)                             0.0859319
time/logging (s)                                          0.0155405
time/saving (s)                                           0.800281
time/training (s)                                        40.1397
time/epoch (s)                                           80.4982
time/total (s)                                        12328.5
Epoch                                                   173
---------------------------------------------------  ----------------
2021-05-29 03:22:42.863858 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 174 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00391501
trainer/QF2 Loss                                          0.00389871
trainer/Policy Loss                                       3.08614
trainer/Q1 Predictions Mean                              -1.16528
trainer/Q1 Predictions Std                                0.816576
trainer/Q1 Predictions Max                                0.568727
trainer/Q1 Predictions Min                               -3.22827
trainer/Q2 Predictions Mean                              -1.15748
trainer/Q2 Predictions Std                                0.815956
trainer/Q2 Predictions Max                                0.56237
trainer/Q2 Predictions Min                               -3.1341
trainer/Q Targets Mean                                   -1.1653
trainer/Q Targets Std                                     0.817486
trainer/Q Targets Max                                     0.560537
trainer/Q Targets Min                                    -3.21826
trainer/Log Pis Mean                                      1.93736
trainer/Log Pis Std                                       1.41665
trainer/Log Pis Max                                       5.24897
trainer/Log Pis Min                                      -3.18116
trainer/Policy mu Mean                                   -0.0316074
trainer/Policy mu Std                                     0.385863
trainer/Policy mu Max                                     1.37552
trainer/Policy mu Min                                    -2.53674
trainer/Policy log std Mean                              -2.2593
trainer/Policy log std Std                                0.533731
trainer/Policy log std Max                               -0.167676
trainer/Policy log std Min                               -3.23304
trainer/Alpha                                             0.0204467
trainer/Alpha Loss                                       -0.243627
exploration/num steps total                           18500
exploration/num paths total                             925
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.212263
exploration/Rewards Std                                   0.128554
exploration/Rewards Max                                   0.030834
exploration/Rewards Min                                  -0.539567
exploration/Returns Mean                                 -4.24527
exploration/Returns Std                                   1.90291
exploration/Returns Max                                  -1.55342
exploration/Returns Min                                  -6.91502
exploration/Actions Mean                                  0.000300395
exploration/Actions Std                                   0.173615
exploration/Actions Max                                   0.494708
exploration/Actions Min                                  -0.901747
exploration/Num Paths                                     5
exploration/Average Returns                              -4.24527
exploration/env_infos/final/reward_energy Mean           -0.0685919
exploration/env_infos/final/reward_energy Std             0.0225072
exploration/env_infos/final/reward_energy Max            -0.0397438
exploration/env_infos/final/reward_energy Min            -0.107159
exploration/env_infos/initial/reward_energy Mean         -0.437138
exploration/env_infos/initial/reward_energy Std           0.335919
exploration/env_infos/initial/reward_energy Max          -0.0849596
exploration/env_infos/initial/reward_energy Min          -1.02853
exploration/env_infos/reward_energy Mean                 -0.187136
exploration/env_infos/reward_energy Std                   0.158949
exploration/env_infos/reward_energy Max                  -0.00967777
exploration/env_infos/reward_energy Min                  -1.02853
exploration/env_infos/final/end_effector_loc Mean        -0.00360483
exploration/env_infos/final/end_effector_loc Std          0.460851
exploration/env_infos/final/end_effector_loc Max          0.670926
exploration/env_infos/final/end_effector_loc Min         -0.711031
exploration/env_infos/initial/end_effector_loc Mean      -0.00261817
exploration/env_infos/initial/end_effector_loc Std        0.0193147
exploration/env_infos/initial/end_effector_loc Max        0.0247354
exploration/env_infos/initial/end_effector_loc Min       -0.0450874
exploration/env_infos/end_effector_loc Mean              -0.0233542
exploration/env_infos/end_effector_loc Std                0.282229
exploration/env_infos/end_effector_loc Max                0.670926
exploration/env_infos/end_effector_loc Min               -0.711031
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000677748
exploration/env_infos/final/reward_dist Std               0.000869904
exploration/env_infos/final/reward_dist Max               0.00210583
exploration/env_infos/final/reward_dist Min               1.72089e-50
exploration/env_infos/initial/reward_dist Mean            0.00469968
exploration/env_infos/initial/reward_dist Std             0.00687702
exploration/env_infos/initial/reward_dist Max             0.0182543
exploration/env_infos/initial/reward_dist Min             3.72918e-05
exploration/env_infos/reward_dist Mean                    0.0500899
exploration/env_infos/reward_dist Std                     0.173753
exploration/env_infos/reward_dist Max                     0.968771
exploration/env_infos/reward_dist Min                     1.72089e-50
evaluation/num steps total                           175000
evaluation/num paths total                             8750
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.151103
evaluation/Rewards Std                                    0.195809
evaluation/Rewards Max                                    0.152849
evaluation/Rewards Min                                   -1.15304
evaluation/Returns Mean                                  -3.02206
evaluation/Returns Std                                    3.50749
evaluation/Returns Max                                    1.72648
evaluation/Returns Min                                  -15.4631
evaluation/Actions Mean                                   0.000391862
evaluation/Actions Std                                    0.124279
evaluation/Actions Max                                    0.660392
evaluation/Actions Min                                   -0.969388
evaluation/Num Paths                                     50
evaluation/Average Returns                               -3.02206
evaluation/env_infos/final/reward_energy Mean            -0.0634408
evaluation/env_infos/final/reward_energy Std              0.0495587
evaluation/env_infos/final/reward_energy Max             -0.00596648
evaluation/env_infos/final/reward_energy Min             -0.234837
evaluation/env_infos/initial/reward_energy Mean          -0.329779
evaluation/env_infos/initial/reward_energy Std            0.293621
evaluation/env_infos/initial/reward_energy Max           -0.0244925
evaluation/env_infos/initial/reward_energy Min           -1.16819
evaluation/env_infos/reward_energy Mean                  -0.109336
evaluation/env_infos/reward_energy Std                    0.13761
evaluation/env_infos/reward_energy Max                   -0.000694724
evaluation/env_infos/reward_energy Min                   -1.16819
evaluation/env_infos/final/end_effector_loc Mean         -0.0105143
evaluation/env_infos/final/end_effector_loc Std           0.505481
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00171086
evaluation/env_infos/initial/end_effector_loc Std         0.0155172
evaluation/env_infos/initial/end_effector_loc Max         0.0330196
evaluation/env_infos/initial/end_effector_loc Min        -0.0484694
evaluation/env_infos/end_effector_loc Mean               -0.0167407
evaluation/env_infos/end_effector_loc Std                 0.335607
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.107582
evaluation/env_infos/final/reward_dist Std                0.22333
evaluation/env_infos/final/reward_dist Max                0.788004
evaluation/env_infos/final/reward_dist Min                6.0541e-161
evaluation/env_infos/initial/reward_dist Mean             0.00388519
evaluation/env_infos/initial/reward_dist Std              0.00848583
evaluation/env_infos/initial/reward_dist Max              0.037155
evaluation/env_infos/initial/reward_dist Min              1.9573e-07
evaluation/env_infos/reward_dist Mean                     0.124892
evaluation/env_infos/reward_dist Std                      0.245391
evaluation/env_infos/reward_dist Max                      0.990939
evaluation/env_infos/reward_dist Min                      6.0541e-161
time/data storing (s)                                    38.2611
time/evaluation sampling (s)                              0.536676
time/exploration sampling (s)                             0.08829
time/logging (s)                                          0.013949
time/saving (s)                                           0.775496
time/training (s)                                        39.4237
time/epoch (s)                                           79.0993
time/total (s)                                        12409.5
Epoch                                                   174
---------------------------------------------------  ----------------
2021-05-29 03:24:03.880215 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 175 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0245142
trainer/QF2 Loss                                          0.0117136
trainer/Policy Loss                                       3.21681
trainer/Q1 Predictions Mean                              -1.08553
trainer/Q1 Predictions Std                                0.916701
trainer/Q1 Predictions Max                                1.00731
trainer/Q1 Predictions Min                               -3.76744
trainer/Q2 Predictions Mean                              -1.10123
trainer/Q2 Predictions Std                                0.894209
trainer/Q2 Predictions Max                                0.993302
trainer/Q2 Predictions Min                               -3.33289
trainer/Q Targets Mean                                   -1.09983
trainer/Q Targets Std                                     0.903002
trainer/Q Targets Max                                     1.04047
trainer/Q Targets Min                                    -3.6609
trainer/Log Pis Mean                                      2.11772
trainer/Log Pis Std                                       1.23457
trainer/Log Pis Max                                       4.56837
trainer/Log Pis Min                                      -4.0755
trainer/Policy mu Mean                                   -0.0474589
trainer/Policy mu Std                                     0.308931
trainer/Policy mu Max                                     1.35558
trainer/Policy mu Min                                    -1.86398
trainer/Policy log std Mean                              -2.37869
trainer/Policy log std Std                                0.49231
trainer/Policy log std Max                               -0.165252
trainer/Policy log std Min                               -3.24494
trainer/Alpha                                             0.0206982
trainer/Alpha Loss                                        0.456589
exploration/num steps total                           18600
exploration/num paths total                             930
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.171605
exploration/Rewards Std                                   0.243917
exploration/Rewards Max                                   0.0735185
exploration/Rewards Min                                  -0.940127
exploration/Returns Mean                                 -3.43211
exploration/Returns Std                                   4.55575
exploration/Returns Max                                   0.0655828
exploration/Returns Min                                 -12.4222
exploration/Actions Mean                                  0.00152869
exploration/Actions Std                                   0.133579
exploration/Actions Max                                   0.662514
exploration/Actions Min                                  -0.719412
exploration/Num Paths                                     5
exploration/Average Returns                              -3.43211
exploration/env_infos/final/reward_energy Mean           -0.0457674
exploration/env_infos/final/reward_energy Std             0.0210015
exploration/env_infos/final/reward_energy Max            -0.018167
exploration/env_infos/final/reward_energy Min            -0.0749773
exploration/env_infos/initial/reward_energy Mean         -0.31884
exploration/env_infos/initial/reward_energy Std           0.285896
exploration/env_infos/initial/reward_energy Max          -0.0620097
exploration/env_infos/initial/reward_energy Min          -0.7999
exploration/env_infos/reward_energy Mean                 -0.130502
exploration/env_infos/reward_energy Std                   0.136605
exploration/env_infos/reward_energy Max                  -0.0112107
exploration/env_infos/reward_energy Min                  -0.7999
exploration/env_infos/final/end_effector_loc Mean        -0.00515006
exploration/env_infos/final/end_effector_loc Std          0.487799
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00266107
exploration/env_infos/initial/end_effector_loc Std        0.0149051
exploration/env_infos/initial/end_effector_loc Max        0.0174847
exploration/env_infos/initial/end_effector_loc Min       -0.0359706
exploration/env_infos/end_effector_loc Mean              -0.0226544
exploration/env_infos/end_effector_loc Std                0.365714
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.11263
exploration/env_infos/final/reward_dist Std               0.203335
exploration/env_infos/final/reward_dist Max               0.517956
exploration/env_infos/final/reward_dist Min               9.42646e-140
exploration/env_infos/initial/reward_dist Mean            0.00766876
exploration/env_infos/initial/reward_dist Std             0.012165
exploration/env_infos/initial/reward_dist Max             0.0314617
exploration/env_infos/initial/reward_dist Min             1.93036e-05
exploration/env_infos/reward_dist Mean                    0.213144
exploration/env_infos/reward_dist Std                     0.301302
exploration/env_infos/reward_dist Max                     0.941738
exploration/env_infos/reward_dist Min                     9.42646e-140
evaluation/num steps total                           176000
evaluation/num paths total                             8800
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.114763
evaluation/Rewards Std                                    0.173829
evaluation/Rewards Max                                    0.142465
evaluation/Rewards Min                                   -1.05468
evaluation/Returns Mean                                  -2.29525
evaluation/Returns Std                                    3.0681
evaluation/Returns Max                                    2.17489
evaluation/Returns Min                                  -14.0024
evaluation/Actions Mean                                   0.00168798
evaluation/Actions Std                                    0.157019
evaluation/Actions Max                                    0.991879
evaluation/Actions Min                                   -0.98949
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.29525
evaluation/env_infos/final/reward_energy Mean            -0.0832572
evaluation/env_infos/final/reward_energy Std              0.176937
evaluation/env_infos/final/reward_energy Max             -0.00415656
evaluation/env_infos/final/reward_energy Min             -1.21416
evaluation/env_infos/initial/reward_energy Mean          -0.3424
evaluation/env_infos/initial/reward_energy Std            0.320117
evaluation/env_infos/initial/reward_energy Max           -0.0103275
evaluation/env_infos/initial/reward_energy Min           -1.29885
evaluation/env_infos/reward_energy Mean                  -0.125497
evaluation/env_infos/reward_energy Std                    0.183211
evaluation/env_infos/reward_energy Max                   -0.0011361
evaluation/env_infos/reward_energy Min                   -1.29885
evaluation/env_infos/final/end_effector_loc Mean         -0.0094956
evaluation/env_infos/final/end_effector_loc Std           0.445265
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00367219
evaluation/env_infos/initial/end_effector_loc Std         0.0161603
evaluation/env_infos/initial/end_effector_loc Max         0.0420686
evaluation/env_infos/initial/end_effector_loc Min        -0.0494745
evaluation/env_infos/end_effector_loc Mean               -0.0211529
evaluation/env_infos/end_effector_loc Std                 0.305906
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.114548
evaluation/env_infos/final/reward_dist Std                0.206768
evaluation/env_infos/final/reward_dist Max                0.965246
evaluation/env_infos/final/reward_dist Min                1.84055e-190
evaluation/env_infos/initial/reward_dist Mean             0.00417476
evaluation/env_infos/initial/reward_dist Std              0.00843154
evaluation/env_infos/initial/reward_dist Max              0.0402392
evaluation/env_infos/initial/reward_dist Min              7.4602e-07
evaluation/env_infos/reward_dist Mean                     0.1237
evaluation/env_infos/reward_dist Std                      0.225986
evaluation/env_infos/reward_dist Max                      0.986032
evaluation/env_infos/reward_dist Min                      1.84055e-190
time/data storing (s)                                    38.2938
time/evaluation sampling (s)                              0.634159
time/exploration sampling (s)                             0.0842452
time/logging (s)                                          0.0156124
time/saving (s)                                           0.799044
time/training (s)                                        39.3335
time/epoch (s)                                           79.1604
time/total (s)                                        12490.5
Epoch                                                   175
---------------------------------------------------  -----------------
2021-05-29 03:25:24.910067 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 176 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00502963
trainer/QF2 Loss                                          0.0056465
trainer/Policy Loss                                       2.87965
trainer/Q1 Predictions Mean                              -1.11018
trainer/Q1 Predictions Std                                0.98561
trainer/Q1 Predictions Max                                0.958099
trainer/Q1 Predictions Min                               -4.61669
trainer/Q2 Predictions Mean                              -1.10545
trainer/Q2 Predictions Std                                0.979152
trainer/Q2 Predictions Max                                0.899014
trainer/Q2 Predictions Min                               -4.81104
trainer/Q Targets Mean                                   -1.105
trainer/Q Targets Std                                     0.98185
trainer/Q Targets Max                                     1.00684
trainer/Q Targets Min                                    -4.57951
trainer/Log Pis Mean                                      1.78309
trainer/Log Pis Std                                       1.28092
trainer/Log Pis Max                                       3.92312
trainer/Log Pis Min                                      -5.48933
trainer/Policy mu Mean                                    0.00167596
trainer/Policy mu Std                                     0.344932
trainer/Policy mu Max                                     1.92346
trainer/Policy mu Min                                    -1.80348
trainer/Policy log std Mean                              -2.23219
trainer/Policy log std Std                                0.499401
trainer/Policy log std Max                                0.797073
trainer/Policy log std Min                               -3.11096
trainer/Alpha                                             0.0227034
trainer/Alpha Loss                                       -0.82111
exploration/num steps total                           18700
exploration/num paths total                             935
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0881799
exploration/Rewards Std                                   0.0955054
exploration/Rewards Max                                   0.123105
exploration/Rewards Min                                  -0.514799
exploration/Returns Mean                                 -1.7636
exploration/Returns Std                                   1.24834
exploration/Returns Max                                   0.0445659
exploration/Returns Min                                  -3.61824
exploration/Actions Mean                                 -0.00826915
exploration/Actions Std                                   0.188561
exploration/Actions Max                                   0.636405
exploration/Actions Min                                  -0.751626
exploration/Num Paths                                     5
exploration/Average Returns                              -1.7636
exploration/env_infos/final/reward_energy Mean           -0.156672
exploration/env_infos/final/reward_energy Std             0.0499398
exploration/env_infos/final/reward_energy Max            -0.0736967
exploration/env_infos/final/reward_energy Min            -0.212683
exploration/env_infos/initial/reward_energy Mean         -0.466494
exploration/env_infos/initial/reward_energy Std           0.207066
exploration/env_infos/initial/reward_energy Max          -0.242726
exploration/env_infos/initial/reward_energy Min          -0.828483
exploration/env_infos/reward_energy Mean                 -0.219998
exploration/env_infos/reward_energy Std                   0.151157
exploration/env_infos/reward_energy Max                  -0.0170518
exploration/env_infos/reward_energy Min                  -0.828483
exploration/env_infos/final/end_effector_loc Mean        -0.148544
exploration/env_infos/final/end_effector_loc Std          0.214066
exploration/env_infos/final/end_effector_loc Max          0.154294
exploration/env_infos/final/end_effector_loc Min         -0.61097
exploration/env_infos/initial/end_effector_loc Mean      -0.002263
exploration/env_infos/initial/end_effector_loc Std        0.0179024
exploration/env_infos/initial/end_effector_loc Max        0.0225251
exploration/env_infos/initial/end_effector_loc Min       -0.0375813
exploration/env_infos/end_effector_loc Mean              -0.082082
exploration/env_infos/end_effector_loc Std                0.199982
exploration/env_infos/end_effector_loc Max                0.253699
exploration/env_infos/end_effector_loc Min               -0.61097
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.269326
exploration/env_infos/final/reward_dist Std               0.339695
exploration/env_infos/final/reward_dist Max               0.908421
exploration/env_infos/final/reward_dist Min               2.06823e-20
exploration/env_infos/initial/reward_dist Mean            0.00503777
exploration/env_infos/initial/reward_dist Std             0.00805488
exploration/env_infos/initial/reward_dist Max             0.0209579
exploration/env_infos/initial/reward_dist Min             9.79332e-06
exploration/env_infos/reward_dist Mean                    0.155788
exploration/env_infos/reward_dist Std                     0.25434
exploration/env_infos/reward_dist Max                     0.934674
exploration/env_infos/reward_dist Min                     5.43081e-30
evaluation/num steps total                           177000
evaluation/num paths total                             8850
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0889694
evaluation/Rewards Std                                    0.125987
evaluation/Rewards Max                                    0.149514
evaluation/Rewards Min                                   -0.773011
evaluation/Returns Mean                                  -1.77939
evaluation/Returns Std                                    1.99225
evaluation/Returns Max                                    2.14342
evaluation/Returns Min                                   -8.49127
evaluation/Actions Mean                                  -0.00335253
evaluation/Actions Std                                    0.107506
evaluation/Actions Max                                    0.829198
evaluation/Actions Min                                   -0.844754
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.77939
evaluation/env_infos/final/reward_energy Mean            -0.0824286
evaluation/env_infos/final/reward_energy Std              0.0742885
evaluation/env_infos/final/reward_energy Max             -0.0149375
evaluation/env_infos/final/reward_energy Min             -0.32611
evaluation/env_infos/initial/reward_energy Mean          -0.255026
evaluation/env_infos/initial/reward_energy Std            0.238027
evaluation/env_infos/initial/reward_energy Max           -0.00353255
evaluation/env_infos/initial/reward_energy Min           -0.890099
evaluation/env_infos/reward_energy Mean                  -0.0988073
evaluation/env_infos/reward_energy Std                    0.115649
evaluation/env_infos/reward_energy Max                   -0.00351497
evaluation/env_infos/reward_energy Min                   -0.950118
evaluation/env_infos/final/end_effector_loc Mean         -0.0664946
evaluation/env_infos/final/end_effector_loc Std           0.401019
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000259291
evaluation/env_infos/initial/end_effector_loc Std         0.0123309
evaluation/env_infos/initial/end_effector_loc Max         0.0414599
evaluation/env_infos/initial/end_effector_loc Min        -0.0422377
evaluation/env_infos/end_effector_loc Mean               -0.023964
evaluation/env_infos/end_effector_loc Std                 0.251862
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0806519
evaluation/env_infos/final/reward_dist Std                0.185366
evaluation/env_infos/final/reward_dist Max                0.762319
evaluation/env_infos/final/reward_dist Min                1.07802e-174
evaluation/env_infos/initial/reward_dist Mean             0.00554665
evaluation/env_infos/initial/reward_dist Std              0.00881592
evaluation/env_infos/initial/reward_dist Max              0.0351862
evaluation/env_infos/initial/reward_dist Min              4.89998e-07
evaluation/env_infos/reward_dist Mean                     0.140133
evaluation/env_infos/reward_dist Std                      0.252527
evaluation/env_infos/reward_dist Max                      0.996029
evaluation/env_infos/reward_dist Min                      1.07802e-174
time/data storing (s)                                    38.4426
time/evaluation sampling (s)                              0.657367
time/exploration sampling (s)                             0.0861847
time/logging (s)                                          0.014262
time/saving (s)                                           0.779386
time/training (s)                                        39.1443
time/epoch (s)                                           79.124
time/total (s)                                        12571.6
Epoch                                                   176
---------------------------------------------------  -----------------
2021-05-29 03:26:46.352643 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 177 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00515358
trainer/QF2 Loss                                          0.00536279
trainer/Policy Loss                                       3.23857
trainer/Q1 Predictions Mean                              -1.18023
trainer/Q1 Predictions Std                                1.0371
trainer/Q1 Predictions Max                                0.968478
trainer/Q1 Predictions Min                               -5.50116
trainer/Q2 Predictions Mean                              -1.1732
trainer/Q2 Predictions Std                                1.03598
trainer/Q2 Predictions Max                                1.02172
trainer/Q2 Predictions Min                               -5.41757
trainer/Q Targets Mean                                   -1.17092
trainer/Q Targets Std                                     1.01965
trainer/Q Targets Max                                     0.948351
trainer/Q Targets Min                                    -5.31639
trainer/Log Pis Mean                                      2.08186
trainer/Log Pis Std                                       1.21097
trainer/Log Pis Max                                       4.47421
trainer/Log Pis Min                                      -2.9479
trainer/Policy mu Mean                                    0.0123119
trainer/Policy mu Std                                     0.336203
trainer/Policy mu Max                                     2.22228
trainer/Policy mu Min                                    -2.22128
trainer/Policy log std Mean                              -2.35117
trainer/Policy log std Std                                0.519938
trainer/Policy log std Max                               -0.55637
trainer/Policy log std Min                               -3.30606
trainer/Alpha                                             0.0221172
trainer/Alpha Loss                                        0.31209
exploration/num steps total                           18800
exploration/num paths total                             940
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.144878
exploration/Rewards Std                                   0.104347
exploration/Rewards Max                                  -0.0141559
exploration/Rewards Min                                  -0.508373
exploration/Returns Mean                                 -2.89756
exploration/Returns Std                                   1.34835
exploration/Returns Max                                  -1.14938
exploration/Returns Min                                  -4.54697
exploration/Actions Mean                                  0.0228985
exploration/Actions Std                                   0.170069
exploration/Actions Max                                   0.650828
exploration/Actions Min                                  -0.864996
exploration/Num Paths                                     5
exploration/Average Returns                              -2.89756
exploration/env_infos/final/reward_energy Mean           -0.20322
exploration/env_infos/final/reward_energy Std             0.177025
exploration/env_infos/final/reward_energy Max            -0.0551129
exploration/env_infos/final/reward_energy Min            -0.49156
exploration/env_infos/initial/reward_energy Mean         -0.44646
exploration/env_infos/initial/reward_energy Std           0.495836
exploration/env_infos/initial/reward_energy Max          -0.0253886
exploration/env_infos/initial/reward_energy Min          -1.0825
exploration/env_infos/reward_energy Mean                 -0.151209
exploration/env_infos/reward_energy Std                   0.189819
exploration/env_infos/reward_energy Max                  -0.00522586
exploration/env_infos/reward_energy Min                  -1.0825
exploration/env_infos/final/end_effector_loc Mean         0.014234
exploration/env_infos/final/end_effector_loc Std          0.395271
exploration/env_infos/final/end_effector_loc Max          0.46394
exploration/env_infos/final/end_effector_loc Min         -0.820475
exploration/env_infos/initial/end_effector_loc Mean      -0.00753661
exploration/env_infos/initial/end_effector_loc Std        0.0223534
exploration/env_infos/initial/end_effector_loc Max        0.0325414
exploration/env_infos/initial/end_effector_loc Min       -0.0432498
exploration/env_infos/end_effector_loc Mean              -0.0252535
exploration/env_infos/end_effector_loc Std                0.227032
exploration/env_infos/end_effector_loc Max                0.46394
exploration/env_infos/end_effector_loc Min               -0.820475
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              1.62895e-05
exploration/env_infos/final/reward_dist Std               2.90737e-05
exploration/env_infos/final/reward_dist Max               7.41624e-05
exploration/env_infos/final/reward_dist Min               5.11353e-57
exploration/env_infos/initial/reward_dist Mean            0.0133652
exploration/env_infos/initial/reward_dist Std             0.0250718
exploration/env_infos/initial/reward_dist Max             0.0634432
exploration/env_infos/initial/reward_dist Min             1.36406e-06
exploration/env_infos/reward_dist Mean                    0.0133875
exploration/env_infos/reward_dist Std                     0.0637051
exploration/env_infos/reward_dist Max                     0.505295
exploration/env_infos/reward_dist Min                     5.11353e-57
evaluation/num steps total                           178000
evaluation/num paths total                             8900
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0660709
evaluation/Rewards Std                                    0.0974107
evaluation/Rewards Max                                    0.134801
evaluation/Rewards Min                                   -0.546506
evaluation/Returns Mean                                  -1.32142
evaluation/Returns Std                                    1.62623
evaluation/Returns Max                                    1.80536
evaluation/Returns Min                                   -7.03906
evaluation/Actions Mean                                  -0.000572964
evaluation/Actions Std                                    0.100091
evaluation/Actions Max                                    0.691057
evaluation/Actions Min                                   -0.765047
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.32142
evaluation/env_infos/final/reward_energy Mean            -0.071972
evaluation/env_infos/final/reward_energy Std              0.0589125
evaluation/env_infos/final/reward_energy Max             -0.00433052
evaluation/env_infos/final/reward_energy Min             -0.23863
evaluation/env_infos/initial/reward_energy Mean          -0.229693
evaluation/env_infos/initial/reward_energy Std            0.257709
evaluation/env_infos/initial/reward_energy Max           -0.00218469
evaluation/env_infos/initial/reward_energy Min           -0.99448
evaluation/env_infos/reward_energy Mean                  -0.0891355
evaluation/env_infos/reward_energy Std                    0.109964
evaluation/env_infos/reward_energy Max                   -0.00067739
evaluation/env_infos/reward_energy Min                   -0.99448
evaluation/env_infos/final/end_effector_loc Mean         -0.0638566
evaluation/env_infos/final/end_effector_loc Std           0.336424
evaluation/env_infos/final/end_effector_loc Max           0.997225
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00086639
evaluation/env_infos/initial/end_effector_loc Std         0.0121744
evaluation/env_infos/initial/end_effector_loc Max         0.0345529
evaluation/env_infos/initial/end_effector_loc Min        -0.0382523
evaluation/env_infos/end_effector_loc Mean               -0.0365809
evaluation/env_infos/end_effector_loc Std                 0.203743
evaluation/env_infos/end_effector_loc Max                 0.997225
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0967535
evaluation/env_infos/final/reward_dist Std                0.195611
evaluation/env_infos/final/reward_dist Max                0.872799
evaluation/env_infos/final/reward_dist Min                2.62316e-116
evaluation/env_infos/initial/reward_dist Mean             0.0066538
evaluation/env_infos/initial/reward_dist Std              0.0203377
evaluation/env_infos/initial/reward_dist Max              0.140295
evaluation/env_infos/initial/reward_dist Min              1.41777e-06
evaluation/env_infos/reward_dist Mean                     0.142145
evaluation/env_infos/reward_dist Std                      0.252202
evaluation/env_infos/reward_dist Max                      0.992573
evaluation/env_infos/reward_dist Min                      2.62316e-116
time/data storing (s)                                    38.5028
time/evaluation sampling (s)                              0.630076
time/exploration sampling (s)                             0.0858096
time/logging (s)                                          0.0159142
time/saving (s)                                           0.818972
time/training (s)                                        39.507
time/epoch (s)                                           79.5606
time/total (s)                                        12653
Epoch                                                   177
---------------------------------------------------  -----------------
2021-05-29 03:28:07.242547 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 178 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00568415
trainer/QF2 Loss                                          0.00514576
trainer/Policy Loss                                       3.16149
trainer/Q1 Predictions Mean                              -1.08494
trainer/Q1 Predictions Std                                0.94209
trainer/Q1 Predictions Max                                0.718326
trainer/Q1 Predictions Min                               -6.03633
trainer/Q2 Predictions Mean                              -1.0801
trainer/Q2 Predictions Std                                0.938411
trainer/Q2 Predictions Max                                0.758826
trainer/Q2 Predictions Min                               -6.17606
trainer/Q Targets Mean                                   -1.06783
trainer/Q Targets Std                                     0.949576
trainer/Q Targets Max                                     0.803164
trainer/Q Targets Min                                    -6.17292
trainer/Log Pis Mean                                      2.08747
trainer/Log Pis Std                                       1.10439
trainer/Log Pis Max                                       4.24787
trainer/Log Pis Min                                      -2.66921
trainer/Policy mu Mean                                    0.0275443
trainer/Policy mu Std                                     0.359977
trainer/Policy mu Max                                     2.38926
trainer/Policy mu Min                                    -2.28067
trainer/Policy log std Mean                              -2.31936
trainer/Policy log std Std                                0.481497
trainer/Policy log std Max                               -0.586078
trainer/Policy log std Min                               -3.37073
trainer/Alpha                                             0.0215362
trainer/Alpha Loss                                        0.335822
exploration/num steps total                           18900
exploration/num paths total                             945
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0896766
exploration/Rewards Std                                   0.0747999
exploration/Rewards Max                                   0.049493
exploration/Rewards Min                                  -0.273871
exploration/Returns Mean                                 -1.79353
exploration/Returns Std                                   1.19903
exploration/Returns Max                                   0.0880395
exploration/Returns Min                                  -3.29573
exploration/Actions Mean                                  0.00421311
exploration/Actions Std                                   0.169366
exploration/Actions Max                                   0.797535
exploration/Actions Min                                  -0.844682
exploration/Num Paths                                     5
exploration/Average Returns                              -1.79353
exploration/env_infos/final/reward_energy Mean           -0.145474
exploration/env_infos/final/reward_energy Std             0.1489
exploration/env_infos/final/reward_energy Max            -0.0204611
exploration/env_infos/final/reward_energy Min            -0.437472
exploration/env_infos/initial/reward_energy Mean         -0.327362
exploration/env_infos/initial/reward_energy Std           0.278738
exploration/env_infos/initial/reward_energy Max          -0.145991
exploration/env_infos/initial/reward_energy Min          -0.880437
exploration/env_infos/reward_energy Mean                 -0.182109
exploration/env_infos/reward_energy Std                   0.155698
exploration/env_infos/reward_energy Max                  -0.0204611
exploration/env_infos/reward_energy Min                  -1.1042
exploration/env_infos/final/end_effector_loc Mean        -0.0474656
exploration/env_infos/final/end_effector_loc Std          0.287515
exploration/env_infos/final/end_effector_loc Max          0.454273
exploration/env_infos/final/end_effector_loc Min         -0.491245
exploration/env_infos/initial/end_effector_loc Mean      -0.00282726
exploration/env_infos/initial/end_effector_loc Std        0.014936
exploration/env_infos/initial/end_effector_loc Max        0.012418
exploration/env_infos/initial/end_effector_loc Min       -0.0422341
exploration/env_infos/end_effector_loc Mean              -0.0380653
exploration/env_infos/end_effector_loc Std                0.200495
exploration/env_infos/end_effector_loc Max                0.454273
exploration/env_infos/end_effector_loc Min               -0.491245
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.141083
exploration/env_infos/final/reward_dist Std               0.278406
exploration/env_infos/final/reward_dist Max               0.697866
exploration/env_infos/final/reward_dist Min               2.91769e-11
exploration/env_infos/initial/reward_dist Mean            0.0155545
exploration/env_infos/initial/reward_dist Std             0.0264043
exploration/env_infos/initial/reward_dist Max             0.0678257
exploration/env_infos/initial/reward_dist Min             5.59533e-06
exploration/env_infos/reward_dist Mean                    0.142153
exploration/env_infos/reward_dist Std                     0.236865
exploration/env_infos/reward_dist Max                     0.910108
exploration/env_infos/reward_dist Min                     9.0454e-12
evaluation/num steps total                           179000
evaluation/num paths total                             8950
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0656316
evaluation/Rewards Std                                    0.105685
evaluation/Rewards Max                                    0.181103
evaluation/Rewards Min                                   -0.620343
evaluation/Returns Mean                                  -1.31263
evaluation/Returns Std                                    1.68687
evaluation/Returns Max                                    2.19575
evaluation/Returns Min                                   -5.92741
evaluation/Actions Mean                                  -0.000633212
evaluation/Actions Std                                    0.104975
evaluation/Actions Max                                    0.905097
evaluation/Actions Min                                   -0.948044
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.31263
evaluation/env_infos/final/reward_energy Mean            -0.0917719
evaluation/env_infos/final/reward_energy Std              0.131853
evaluation/env_infos/final/reward_energy Max             -0.0102363
evaluation/env_infos/final/reward_energy Min             -0.641988
evaluation/env_infos/initial/reward_energy Mean          -0.209694
evaluation/env_infos/initial/reward_energy Std            0.220824
evaluation/env_infos/initial/reward_energy Max           -0.00353462
evaluation/env_infos/initial/reward_energy Min           -0.984069
evaluation/env_infos/reward_energy Mean                  -0.0922676
evaluation/env_infos/reward_energy Std                    0.116305
evaluation/env_infos/reward_energy Max                   -0.00121476
evaluation/env_infos/reward_energy Min                   -0.984069
evaluation/env_infos/final/end_effector_loc Mean         -0.0181516
evaluation/env_infos/final/end_effector_loc Std           0.388883
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -5.25969e-05
evaluation/env_infos/initial/end_effector_loc Std         0.0107664
evaluation/env_infos/initial/end_effector_loc Max         0.0268959
evaluation/env_infos/initial/end_effector_loc Min        -0.0474022
evaluation/env_infos/end_effector_loc Mean               -0.00355932
evaluation/env_infos/end_effector_loc Std                 0.246198
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.161185
evaluation/env_infos/final/reward_dist Std                0.237762
evaluation/env_infos/final/reward_dist Max                0.801014
evaluation/env_infos/final/reward_dist Min                2.5798e-174
evaluation/env_infos/initial/reward_dist Mean             0.00575359
evaluation/env_infos/initial/reward_dist Std              0.0108678
evaluation/env_infos/initial/reward_dist Max              0.0548799
evaluation/env_infos/initial/reward_dist Min              1.11058e-06
evaluation/env_infos/reward_dist Mean                     0.166437
evaluation/env_infos/reward_dist Std                      0.250269
evaluation/env_infos/reward_dist Max                      0.993575
evaluation/env_infos/reward_dist Min                      2.5798e-174
time/data storing (s)                                    38.358
time/evaluation sampling (s)                              0.647778
time/exploration sampling (s)                             0.0900535
time/logging (s)                                          0.0139596
time/saving (s)                                           0.795723
time/training (s)                                        38.9724
time/epoch (s)                                           78.8779
time/total (s)                                        12733.9
Epoch                                                   178
---------------------------------------------------  ----------------
2021-05-29 03:29:28.405627 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 179 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00253205
trainer/QF2 Loss                                          0.0025176
trainer/Policy Loss                                       3.02036
trainer/Q1 Predictions Mean                              -1.05829
trainer/Q1 Predictions Std                                0.99016
trainer/Q1 Predictions Max                                0.849818
trainer/Q1 Predictions Min                               -6.62084
trainer/Q2 Predictions Mean                              -1.06744
trainer/Q2 Predictions Std                                0.995545
trainer/Q2 Predictions Max                                0.830634
trainer/Q2 Predictions Min                               -6.65236
trainer/Q Targets Mean                                   -1.06696
trainer/Q Targets Std                                     0.996693
trainer/Q Targets Max                                     0.682023
trainer/Q Targets Min                                    -6.6702
trainer/Log Pis Mean                                      1.97232
trainer/Log Pis Std                                       1.24125
trainer/Log Pis Max                                       4.45636
trainer/Log Pis Min                                      -2.83017
trainer/Policy mu Mean                                    0.0132479
trainer/Policy mu Std                                     0.361137
trainer/Policy mu Max                                     2.1894
trainer/Policy mu Min                                    -1.58624
trainer/Policy log std Mean                              -2.34171
trainer/Policy log std Std                                0.481152
trainer/Policy log std Max                               -0.435594
trainer/Policy log std Min                               -3.27761
trainer/Alpha                                             0.0204802
trainer/Alpha Loss                                       -0.107671
exploration/num steps total                           19000
exploration/num paths total                             950
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0678851
exploration/Rewards Std                                   0.0591795
exploration/Rewards Max                                   0.0434564
exploration/Rewards Min                                  -0.252226
exploration/Returns Mean                                 -1.3577
exploration/Returns Std                                   0.257994
exploration/Returns Max                                  -0.95802
exploration/Returns Min                                  -1.77294
exploration/Actions Mean                                 -0.00630434
exploration/Actions Std                                   0.0765189
exploration/Actions Max                                   0.239334
exploration/Actions Min                                  -0.205933
exploration/Num Paths                                     5
exploration/Average Returns                              -1.3577
exploration/env_infos/final/reward_energy Mean           -0.107366
exploration/env_infos/final/reward_energy Std             0.0452988
exploration/env_infos/final/reward_energy Max            -0.0397658
exploration/env_infos/final/reward_energy Min            -0.167986
exploration/env_infos/initial/reward_energy Mean         -0.138078
exploration/env_infos/initial/reward_energy Std           0.0539267
exploration/env_infos/initial/reward_energy Max          -0.0527498
exploration/env_infos/initial/reward_energy Min          -0.219819
exploration/env_infos/reward_energy Mean                 -0.0921126
exploration/env_infos/reward_energy Std                   0.0574893
exploration/env_infos/reward_energy Max                  -0.0032341
exploration/env_infos/reward_energy Min                  -0.272017
exploration/env_infos/final/end_effector_loc Mean        -0.00332343
exploration/env_infos/final/end_effector_loc Std          0.252185
exploration/env_infos/final/end_effector_loc Max          0.353356
exploration/env_infos/final/end_effector_loc Min         -0.461234
exploration/env_infos/initial/end_effector_loc Mean       2.24396e-05
exploration/env_infos/initial/end_effector_loc Std        0.00524086
exploration/env_infos/initial/end_effector_loc Max        0.00678277
exploration/env_infos/initial/end_effector_loc Min       -0.0102725
exploration/env_infos/end_effector_loc Mean               0.00790123
exploration/env_infos/end_effector_loc Std                0.155037
exploration/env_infos/end_effector_loc Max                0.353356
exploration/env_infos/end_effector_loc Min               -0.461234
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.205227
exploration/env_infos/final/reward_dist Std               0.342665
exploration/env_infos/final/reward_dist Max               0.888274
exploration/env_infos/final/reward_dist Min               0.000288501
exploration/env_infos/initial/reward_dist Mean            0.00427073
exploration/env_infos/initial/reward_dist Std             0.00839812
exploration/env_infos/initial/reward_dist Max             0.0210664
exploration/env_infos/initial/reward_dist Min             1.08206e-06
exploration/env_infos/reward_dist Mean                    0.113211
exploration/env_infos/reward_dist Std                     0.161142
exploration/env_infos/reward_dist Max                     0.888274
exploration/env_infos/reward_dist Min                     1.08206e-06
evaluation/num steps total                           180000
evaluation/num paths total                             9000
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0932512
evaluation/Rewards Std                                    0.15624
evaluation/Rewards Max                                    0.142789
evaluation/Rewards Min                                   -1.07278
evaluation/Returns Mean                                  -1.86502
evaluation/Returns Std                                    2.58901
evaluation/Returns Max                                    1.95352
evaluation/Returns Min                                  -10.7535
evaluation/Actions Mean                                  -0.00655268
evaluation/Actions Std                                    0.165118
evaluation/Actions Max                                    0.980781
evaluation/Actions Min                                   -0.982078
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.86502
evaluation/env_infos/final/reward_energy Mean            -0.129178
evaluation/env_infos/final/reward_energy Std              0.198349
evaluation/env_infos/final/reward_energy Max             -0.0104515
evaluation/env_infos/final/reward_energy Min             -0.960308
evaluation/env_infos/initial/reward_energy Mean          -0.302534
evaluation/env_infos/initial/reward_energy Std            0.273905
evaluation/env_infos/initial/reward_energy Max           -0.00987111
evaluation/env_infos/initial/reward_energy Min           -0.970072
evaluation/env_infos/reward_energy Mean                  -0.131571
evaluation/env_infos/reward_energy Std                    0.193139
evaluation/env_infos/reward_energy Max                   -0.00465945
evaluation/env_infos/reward_energy Min                   -1.35236
evaluation/env_infos/final/end_effector_loc Mean         -0.0772276
evaluation/env_infos/final/end_effector_loc Std           0.36055
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000406603
evaluation/env_infos/initial/end_effector_loc Std         0.014423
evaluation/env_infos/initial/end_effector_loc Max         0.0430327
evaluation/env_infos/initial/end_effector_loc Min        -0.0472805
evaluation/env_infos/end_effector_loc Mean               -0.0219375
evaluation/env_infos/end_effector_loc Std                 0.237392
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.135247
evaluation/env_infos/final/reward_dist Std                0.256081
evaluation/env_infos/final/reward_dist Max                0.945592
evaluation/env_infos/final/reward_dist Min                6.42342e-155
evaluation/env_infos/initial/reward_dist Mean             0.0104494
evaluation/env_infos/initial/reward_dist Std              0.0278289
evaluation/env_infos/initial/reward_dist Max              0.183988
evaluation/env_infos/initial/reward_dist Min              1.25289e-06
evaluation/env_infos/reward_dist Mean                     0.156105
evaluation/env_infos/reward_dist Std                      0.252082
evaluation/env_infos/reward_dist Max                      0.999756
evaluation/env_infos/reward_dist Min                      6.42342e-155
time/data storing (s)                                    38.3319
time/evaluation sampling (s)                              0.653803
time/exploration sampling (s)                             0.085568
time/logging (s)                                          0.0142966
time/saving (s)                                           1.07797
time/training (s)                                        39.0682
time/epoch (s)                                           79.2318
time/total (s)                                        12815
Epoch                                                   179
---------------------------------------------------  -----------------
2021-05-29 03:30:49.593981 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 180 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00337615
trainer/QF2 Loss                                          0.00343357
trainer/Policy Loss                                       3.19291
trainer/Q1 Predictions Mean                              -1.05719
trainer/Q1 Predictions Std                                0.954373
trainer/Q1 Predictions Max                                1.10727
trainer/Q1 Predictions Min                               -6.6381
trainer/Q2 Predictions Mean                              -1.0534
trainer/Q2 Predictions Std                                0.960885
trainer/Q2 Predictions Max                                1.11759
trainer/Q2 Predictions Min                               -6.42767
trainer/Q Targets Mean                                   -1.06407
trainer/Q Targets Std                                     0.959596
trainer/Q Targets Max                                     1.15764
trainer/Q Targets Min                                    -6.53475
trainer/Log Pis Mean                                      2.14802
trainer/Log Pis Std                                       1.01132
trainer/Log Pis Max                                       5.59052
trainer/Log Pis Min                                      -3.08313
trainer/Policy mu Mean                                    0.0629962
trainer/Policy mu Std                                     0.391248
trainer/Policy mu Max                                     2.42302
trainer/Policy mu Min                                    -2.97064
trainer/Policy log std Mean                              -2.28522
trainer/Policy log std Std                                0.507959
trainer/Policy log std Max                               -0.514138
trainer/Policy log std Min                               -3.40434
trainer/Alpha                                             0.021084
trainer/Alpha Loss                                        0.571229
exploration/num steps total                           19100
exploration/num paths total                             955
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.148314
exploration/Rewards Std                                   0.103384
exploration/Rewards Max                                   0.0595417
exploration/Rewards Min                                  -0.422332
exploration/Returns Mean                                 -2.96628
exploration/Returns Std                                   1.73478
exploration/Returns Max                                  -0.881534
exploration/Returns Min                                  -5.881
exploration/Actions Mean                                  0.00303665
exploration/Actions Std                                   0.1139
exploration/Actions Max                                   0.367674
exploration/Actions Min                                  -0.317277
exploration/Num Paths                                     5
exploration/Average Returns                              -2.96628
exploration/env_infos/final/reward_energy Mean           -0.0818001
exploration/env_infos/final/reward_energy Std             0.0364936
exploration/env_infos/final/reward_energy Max            -0.035275
exploration/env_infos/final/reward_energy Min            -0.131692
exploration/env_infos/initial/reward_energy Mean         -0.189216
exploration/env_infos/initial/reward_energy Std           0.137292
exploration/env_infos/initial/reward_energy Max          -0.0457738
exploration/env_infos/initial/reward_energy Min          -0.450166
exploration/env_infos/reward_energy Mean                 -0.136518
exploration/env_infos/reward_energy Std                   0.0856029
exploration/env_infos/reward_energy Max                  -0.0177056
exploration/env_infos/reward_energy Min                  -0.450166
exploration/env_infos/final/end_effector_loc Mean         0.0698183
exploration/env_infos/final/end_effector_loc Std          0.317878
exploration/env_infos/final/end_effector_loc Max          0.605192
exploration/env_infos/final/end_effector_loc Min         -0.566684
exploration/env_infos/initial/end_effector_loc Mean       0.00272958
exploration/env_infos/initial/end_effector_loc Std        0.00780157
exploration/env_infos/initial/end_effector_loc Max        0.0159675
exploration/env_infos/initial/end_effector_loc Min       -0.0158638
exploration/env_infos/end_effector_loc Mean               0.0427684
exploration/env_infos/end_effector_loc Std                0.207338
exploration/env_infos/end_effector_loc Max                0.605192
exploration/env_infos/end_effector_loc Min               -0.582724
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.226086
exploration/env_infos/final/reward_dist Std               0.318751
exploration/env_infos/final/reward_dist Max               0.814865
exploration/env_infos/final/reward_dist Min               1.34362e-38
exploration/env_infos/initial/reward_dist Mean            0.00168686
exploration/env_infos/initial/reward_dist Std             0.00242433
exploration/env_infos/initial/reward_dist Max             0.00632077
exploration/env_infos/initial/reward_dist Min             1.9539e-06
exploration/env_infos/reward_dist Mean                    0.150308
exploration/env_infos/reward_dist Std                     0.280011
exploration/env_infos/reward_dist Max                     0.975301
exploration/env_infos/reward_dist Min                     1.34362e-38
evaluation/num steps total                           181000
evaluation/num paths total                             9050
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0868748
evaluation/Rewards Std                                    0.159988
evaluation/Rewards Max                                    0.126627
evaluation/Rewards Min                                   -1.25323
evaluation/Returns Mean                                  -1.7375
evaluation/Returns Std                                    2.71187
evaluation/Returns Max                                    1.53739
evaluation/Returns Min                                  -15.1219
evaluation/Actions Mean                                  -0.00548547
evaluation/Actions Std                                    0.135392
evaluation/Actions Max                                    0.755808
evaluation/Actions Min                                   -0.995108
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.7375
evaluation/env_infos/final/reward_energy Mean            -0.107386
evaluation/env_infos/final/reward_energy Std              0.200748
evaluation/env_infos/final/reward_energy Max             -0.0107241
evaluation/env_infos/final/reward_energy Min             -1.08309
evaluation/env_infos/initial/reward_energy Mean          -0.27178
evaluation/env_infos/initial/reward_energy Std            0.22387
evaluation/env_infos/initial/reward_energy Max           -0.0223203
evaluation/env_infos/initial/reward_energy Min           -0.921362
evaluation/env_infos/reward_energy Mean                  -0.110655
evaluation/env_infos/reward_energy Std                    0.156454
evaluation/env_infos/reward_energy Max                   -0.000731549
evaluation/env_infos/reward_energy Min                   -1.08309
evaluation/env_infos/final/end_effector_loc Mean         -0.0101818
evaluation/env_infos/final/end_effector_loc Std           0.444839
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00109178
evaluation/env_infos/initial/end_effector_loc Std         0.012401
evaluation/env_infos/initial/end_effector_loc Max         0.0328156
evaluation/env_infos/initial/end_effector_loc Min        -0.0429459
evaluation/env_infos/end_effector_loc Mean               -0.00544466
evaluation/env_infos/end_effector_loc Std                 0.304624
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.13207
evaluation/env_infos/final/reward_dist Std                0.218954
evaluation/env_infos/final/reward_dist Max                0.854048
evaluation/env_infos/final/reward_dist Min                6.62626e-176
evaluation/env_infos/initial/reward_dist Mean             0.00419637
evaluation/env_infos/initial/reward_dist Std              0.00679492
evaluation/env_infos/initial/reward_dist Max              0.0278986
evaluation/env_infos/initial/reward_dist Min              6.71109e-07
evaluation/env_infos/reward_dist Mean                     0.14963
evaluation/env_infos/reward_dist Std                      0.249337
evaluation/env_infos/reward_dist Max                      0.998606
evaluation/env_infos/reward_dist Min                      7.756e-182
time/data storing (s)                                    38.2726
time/evaluation sampling (s)                              0.65555
time/exploration sampling (s)                             0.0879911
time/logging (s)                                          0.0146291
time/saving (s)                                           0.793957
time/training (s)                                        39.4328
time/epoch (s)                                           79.2575
time/total (s)                                        12896.2
Epoch                                                   180
---------------------------------------------------  -----------------
2021-05-29 03:32:11.481157 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 181 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00360595
trainer/QF2 Loss                                          0.00347236
trainer/Policy Loss                                       2.94205
trainer/Q1 Predictions Mean                              -1.02331
trainer/Q1 Predictions Std                                0.842244
trainer/Q1 Predictions Max                                0.818588
trainer/Q1 Predictions Min                               -3.16879
trainer/Q2 Predictions Mean                              -1.03534
trainer/Q2 Predictions Std                                0.837839
trainer/Q2 Predictions Max                                0.834051
trainer/Q2 Predictions Min                               -3.19544
trainer/Q Targets Mean                                   -1.04061
trainer/Q Targets Std                                     0.841035
trainer/Q Targets Max                                     0.8886
trainer/Q Targets Min                                    -3.19572
trainer/Log Pis Mean                                      1.92292
trainer/Log Pis Std                                       1.20404
trainer/Log Pis Max                                       3.99289
trainer/Log Pis Min                                      -2.39791
trainer/Policy mu Mean                                    0.0291983
trainer/Policy mu Std                                     0.37237
trainer/Policy mu Max                                     1.95621
trainer/Policy mu Min                                    -2.13789
trainer/Policy log std Mean                              -2.27175
trainer/Policy log std Std                                0.492637
trainer/Policy log std Max                               -0.538896
trainer/Policy log std Min                               -3.23249
trainer/Alpha                                             0.0214199
trainer/Alpha Loss                                       -0.296202
exploration/num steps total                           19200
exploration/num paths total                             960
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.138925
exploration/Rewards Std                                   0.129573
exploration/Rewards Max                                   0.0213753
exploration/Rewards Min                                  -0.684244
exploration/Returns Mean                                 -2.7785
exploration/Returns Std                                   1.71002
exploration/Returns Max                                  -0.362943
exploration/Returns Min                                  -5.36632
exploration/Actions Mean                                 -0.00308743
exploration/Actions Std                                   0.195974
exploration/Actions Max                                   0.879575
exploration/Actions Min                                  -0.705903
exploration/Num Paths                                     5
exploration/Average Returns                              -2.7785
exploration/env_infos/final/reward_energy Mean           -0.0992764
exploration/env_infos/final/reward_energy Std             0.0554976
exploration/env_infos/final/reward_energy Max            -0.0200203
exploration/env_infos/final/reward_energy Min            -0.184037
exploration/env_infos/initial/reward_energy Mean         -0.543885
exploration/env_infos/initial/reward_energy Std           0.339134
exploration/env_infos/initial/reward_energy Max          -0.0499367
exploration/env_infos/initial/reward_energy Min          -1.01587
exploration/env_infos/reward_energy Mean                 -0.198637
exploration/env_infos/reward_energy Std                   0.193325
exploration/env_infos/reward_energy Max                  -0.0125203
exploration/env_infos/reward_energy Min                  -1.07184
exploration/env_infos/final/end_effector_loc Mean        -0.17623
exploration/env_infos/final/end_effector_loc Std          0.502097
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00120735
exploration/env_infos/initial/end_effector_loc Std        0.022629
exploration/env_infos/initial/end_effector_loc Max        0.0377417
exploration/env_infos/initial/end_effector_loc Min       -0.0352952
exploration/env_infos/end_effector_loc Mean              -0.0720951
exploration/env_infos/end_effector_loc Std                0.404507
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0466655
exploration/env_infos/final/reward_dist Std               0.0798479
exploration/env_infos/final/reward_dist Max               0.204828
exploration/env_infos/final/reward_dist Min               2.5607e-131
exploration/env_infos/initial/reward_dist Mean            0.00196893
exploration/env_infos/initial/reward_dist Std             0.00202833
exploration/env_infos/initial/reward_dist Max             0.00560696
exploration/env_infos/initial/reward_dist Min             6.23374e-05
exploration/env_infos/reward_dist Mean                    0.0933599
exploration/env_infos/reward_dist Std                     0.207318
exploration/env_infos/reward_dist Max                     0.939696
exploration/env_infos/reward_dist Min                     2.5607e-131
evaluation/num steps total                           182000
evaluation/num paths total                             9100
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.111556
evaluation/Rewards Std                                    0.173935
evaluation/Rewards Max                                    0.129535
evaluation/Rewards Min                                   -1.28094
evaluation/Returns Mean                                  -2.23113
evaluation/Returns Std                                    2.99902
evaluation/Returns Max                                    1.31793
evaluation/Returns Min                                  -17.8273
evaluation/Actions Mean                                  -0.0154027
evaluation/Actions Std                                    0.198614
evaluation/Actions Max                                    0.967618
evaluation/Actions Min                                   -0.986702
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.23113
evaluation/env_infos/final/reward_energy Mean            -0.131454
evaluation/env_infos/final/reward_energy Std              0.19998
evaluation/env_infos/final/reward_energy Max             -0.00594066
evaluation/env_infos/final/reward_energy Min             -1.01167
evaluation/env_infos/initial/reward_energy Mean          -0.395552
evaluation/env_infos/initial/reward_energy Std            0.326674
evaluation/env_infos/initial/reward_energy Max           -0.0280928
evaluation/env_infos/initial/reward_energy Min           -1.20015
evaluation/env_infos/reward_energy Mean                  -0.164187
evaluation/env_infos/reward_energy Std                    0.228937
evaluation/env_infos/reward_energy Max                   -0.000883278
evaluation/env_infos/reward_energy Min                   -1.26204
evaluation/env_infos/final/end_effector_loc Mean         -0.149785
evaluation/env_infos/final/end_effector_loc Std           0.471363
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00147213
evaluation/env_infos/initial/end_effector_loc Std         0.0180777
evaluation/env_infos/initial/end_effector_loc Max         0.0483809
evaluation/env_infos/initial/end_effector_loc Min        -0.045946
evaluation/env_infos/end_effector_loc Mean               -0.0738789
evaluation/env_infos/end_effector_loc Std                 0.320267
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0890265
evaluation/env_infos/final/reward_dist Std                0.178133
evaluation/env_infos/final/reward_dist Max                0.714774
evaluation/env_infos/final/reward_dist Min                1.0872e-188
evaluation/env_infos/initial/reward_dist Mean             0.012204
evaluation/env_infos/initial/reward_dist Std              0.0235229
evaluation/env_infos/initial/reward_dist Max              0.0932295
evaluation/env_infos/initial/reward_dist Min              2.60878e-07
evaluation/env_infos/reward_dist Mean                     0.155515
evaluation/env_infos/reward_dist Std                      0.269696
evaluation/env_infos/reward_dist Max                      0.985657
evaluation/env_infos/reward_dist Min                      3.66816e-189
time/data storing (s)                                    38.6427
time/evaluation sampling (s)                              0.653635
time/exploration sampling (s)                             0.0876937
time/logging (s)                                          0.0151929
time/saving (s)                                           0.794699
time/training (s)                                        39.7142
time/epoch (s)                                           79.9082
time/total (s)                                        12978.1
Epoch                                                   181
---------------------------------------------------  -----------------
2021-05-29 03:33:36.420596 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 182 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00350064
trainer/QF2 Loss                                          0.00314211
trainer/Policy Loss                                       3.01024
trainer/Q1 Predictions Mean                              -1.08291
trainer/Q1 Predictions Std                                0.91577
trainer/Q1 Predictions Max                                0.692868
trainer/Q1 Predictions Min                               -7.52008
trainer/Q2 Predictions Mean                              -1.09177
trainer/Q2 Predictions Std                                0.911632
trainer/Q2 Predictions Max                                0.664978
trainer/Q2 Predictions Min                               -7.41924
trainer/Q Targets Mean                                   -1.07587
trainer/Q Targets Std                                     0.911178
trainer/Q Targets Max                                     0.719714
trainer/Q Targets Min                                    -7.52708
trainer/Log Pis Mean                                      1.95589
trainer/Log Pis Std                                       1.09152
trainer/Log Pis Max                                       3.90064
trainer/Log Pis Min                                      -2.7178
trainer/Policy mu Mean                                    0.0444078
trainer/Policy mu Std                                     0.345567
trainer/Policy mu Max                                     2.01225
trainer/Policy mu Min                                    -1.95143
trainer/Policy log std Mean                              -2.27843
trainer/Policy log std Std                                0.429564
trainer/Policy log std Max                               -0.563359
trainer/Policy log std Min                               -3.06115
trainer/Alpha                                             0.0193525
trainer/Alpha Loss                                       -0.173987
exploration/num steps total                           19300
exploration/num paths total                             965
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.104213
exploration/Rewards Std                                   0.0872767
exploration/Rewards Max                                   0.0800246
exploration/Rewards Min                                  -0.419821
exploration/Returns Mean                                 -2.08426
exploration/Returns Std                                   1.33194
exploration/Returns Max                                   0.0570281
exploration/Returns Min                                  -4.01585
exploration/Actions Mean                                  0.00388873
exploration/Actions Std                                   0.130426
exploration/Actions Max                                   0.713888
exploration/Actions Min                                  -0.486692
exploration/Num Paths                                     5
exploration/Average Returns                              -2.08426
exploration/env_infos/final/reward_energy Mean           -0.132025
exploration/env_infos/final/reward_energy Std             0.0224618
exploration/env_infos/final/reward_energy Max            -0.0909087
exploration/env_infos/final/reward_energy Min            -0.152356
exploration/env_infos/initial/reward_energy Mean         -0.357526
exploration/env_infos/initial/reward_energy Std           0.224835
exploration/env_infos/initial/reward_energy Max          -0.128228
exploration/env_infos/initial/reward_energy Min          -0.763509
exploration/env_infos/reward_energy Mean                 -0.143721
exploration/env_infos/reward_energy Std                   0.115742
exploration/env_infos/reward_energy Max                  -0.00979235
exploration/env_infos/reward_energy Min                  -0.763509
exploration/env_infos/final/end_effector_loc Mean        -0.0462154
exploration/env_infos/final/end_effector_loc Std          0.249026
exploration/env_infos/final/end_effector_loc Max          0.42186
exploration/env_infos/final/end_effector_loc Min         -0.378696
exploration/env_infos/initial/end_effector_loc Mean      -0.00178305
exploration/env_infos/initial/end_effector_loc Std        0.0148253
exploration/env_infos/initial/end_effector_loc Max        0.0356944
exploration/env_infos/initial/end_effector_loc Min       -0.0195712
exploration/env_infos/end_effector_loc Mean              -0.0421494
exploration/env_infos/end_effector_loc Std                0.170867
exploration/env_infos/end_effector_loc Max                0.42186
exploration/env_infos/end_effector_loc Min               -0.378696
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0855726
exploration/env_infos/final/reward_dist Std               0.167293
exploration/env_infos/final/reward_dist Max               0.420105
exploration/env_infos/final/reward_dist Min               4.4935e-13
exploration/env_infos/initial/reward_dist Mean            0.015662
exploration/env_infos/initial/reward_dist Std             0.0173037
exploration/env_infos/initial/reward_dist Max             0.0416408
exploration/env_infos/initial/reward_dist Min             4.09853e-06
exploration/env_infos/reward_dist Mean                    0.167063
exploration/env_infos/reward_dist Std                     0.25196
exploration/env_infos/reward_dist Max                     0.827855
exploration/env_infos/reward_dist Min                     5.49777e-25
evaluation/num steps total                           183000
evaluation/num paths total                             9150
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.100046
evaluation/Rewards Std                                    0.127361
evaluation/Rewards Max                                    0.110009
evaluation/Rewards Min                                   -0.815178
evaluation/Returns Mean                                  -2.00093
evaluation/Returns Std                                    1.97221
evaluation/Returns Max                                    0.729956
evaluation/Returns Min                                   -9.39061
evaluation/Actions Mean                                  -0.000630881
evaluation/Actions Std                                    0.150922
evaluation/Actions Max                                    0.849742
evaluation/Actions Min                                   -0.954071
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.00093
evaluation/env_infos/final/reward_energy Mean            -0.0658335
evaluation/env_infos/final/reward_energy Std              0.062777
evaluation/env_infos/final/reward_energy Max             -0.00867751
evaluation/env_infos/final/reward_energy Min             -0.320287
evaluation/env_infos/initial/reward_energy Mean          -0.375151
evaluation/env_infos/initial/reward_energy Std            0.231788
evaluation/env_infos/initial/reward_energy Max           -0.0364063
evaluation/env_infos/initial/reward_energy Min           -1.13116
evaluation/env_infos/reward_energy Mean                  -0.134122
evaluation/env_infos/reward_energy Std                    0.166032
evaluation/env_infos/reward_energy Max                   -0.000567511
evaluation/env_infos/reward_energy Min                   -1.13116
evaluation/env_infos/final/end_effector_loc Mean         -0.0504977
evaluation/env_infos/final/end_effector_loc Std           0.455051
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000936974
evaluation/env_infos/initial/end_effector_loc Std         0.0155628
evaluation/env_infos/initial/end_effector_loc Max         0.0332942
evaluation/env_infos/initial/end_effector_loc Min        -0.0477035
evaluation/env_infos/end_effector_loc Mean               -0.0288754
evaluation/env_infos/end_effector_loc Std                 0.311131
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0875537
evaluation/env_infos/final/reward_dist Std                0.184596
evaluation/env_infos/final/reward_dist Max                0.87166
evaluation/env_infos/final/reward_dist Min                9.45941e-169
evaluation/env_infos/initial/reward_dist Mean             0.00738039
evaluation/env_infos/initial/reward_dist Std              0.0128507
evaluation/env_infos/initial/reward_dist Max              0.0499734
evaluation/env_infos/initial/reward_dist Min              1.29066e-06
evaluation/env_infos/reward_dist Mean                     0.140924
evaluation/env_infos/reward_dist Std                      0.243736
evaluation/env_infos/reward_dist Max                      0.999856
evaluation/env_infos/reward_dist Min                      9.45941e-169
time/data storing (s)                                    39.0301
time/evaluation sampling (s)                              0.547497
time/exploration sampling (s)                             0.0855906
time/logging (s)                                          0.0162115
time/saving (s)                                           0.783048
time/training (s)                                        42.5267
time/epoch (s)                                           82.9892
time/total (s)                                        13063
Epoch                                                   182
---------------------------------------------------  -----------------
2021-05-29 03:34:58.473478 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 183 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00448892
trainer/QF2 Loss                                          0.00442941
trainer/Policy Loss                                       2.94285
trainer/Q1 Predictions Mean                              -0.975456
trainer/Q1 Predictions Std                                0.820075
trainer/Q1 Predictions Max                                0.754265
trainer/Q1 Predictions Min                               -4.70225
trainer/Q2 Predictions Mean                              -0.965494
trainer/Q2 Predictions Std                                0.829384
trainer/Q2 Predictions Max                                0.803357
trainer/Q2 Predictions Min                               -4.71865
trainer/Q Targets Mean                                   -0.968881
trainer/Q Targets Std                                     0.827596
trainer/Q Targets Max                                     0.797562
trainer/Q Targets Min                                    -4.71709
trainer/Log Pis Mean                                      1.97773
trainer/Log Pis Std                                       1.20813
trainer/Log Pis Max                                       4.22489
trainer/Log Pis Min                                      -2.88266
trainer/Policy mu Mean                                    0.0729787
trainer/Policy mu Std                                     0.419631
trainer/Policy mu Max                                     2.40613
trainer/Policy mu Min                                    -2.61291
trainer/Policy log std Mean                              -2.25894
trainer/Policy log std Std                                0.458323
trainer/Policy log std Max                                0.0599553
trainer/Policy log std Min                               -3.22952
trainer/Alpha                                             0.0201322
trainer/Alpha Loss                                       -0.0870162
exploration/num steps total                           19400
exploration/num paths total                             970
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.153419
exploration/Rewards Std                                   0.147068
exploration/Rewards Max                                   0.0371733
exploration/Rewards Min                                  -0.657041
exploration/Returns Mean                                 -3.06838
exploration/Returns Std                                   2.47968
exploration/Returns Max                                  -0.616909
exploration/Returns Min                                  -7.04737
exploration/Actions Mean                                 -0.000962925
exploration/Actions Std                                   0.170806
exploration/Actions Max                                   0.617319
exploration/Actions Min                                  -0.630511
exploration/Num Paths                                     5
exploration/Average Returns                              -3.06838
exploration/env_infos/final/reward_energy Mean           -0.137576
exploration/env_infos/final/reward_energy Std             0.112969
exploration/env_infos/final/reward_energy Max            -0.0255041
exploration/env_infos/final/reward_energy Min            -0.34968
exploration/env_infos/initial/reward_energy Mean         -0.341796
exploration/env_infos/initial/reward_energy Std           0.162956
exploration/env_infos/initial/reward_energy Max          -0.201893
exploration/env_infos/initial/reward_energy Min          -0.57807
exploration/env_infos/reward_energy Mean                 -0.179865
exploration/env_infos/reward_energy Std                   0.161243
exploration/env_infos/reward_energy Max                  -0.0133722
exploration/env_infos/reward_energy Min                  -0.839095
exploration/env_infos/final/end_effector_loc Mean         0.0751216
exploration/env_infos/final/end_effector_loc Std          0.301263
exploration/env_infos/final/end_effector_loc Max          0.567923
exploration/env_infos/final/end_effector_loc Min         -0.294198
exploration/env_infos/initial/end_effector_loc Mean      -0.00546694
exploration/env_infos/initial/end_effector_loc Std        0.0122203
exploration/env_infos/initial/end_effector_loc Max        0.010875
exploration/env_infos/initial/end_effector_loc Min       -0.0288279
exploration/env_infos/end_effector_loc Mean               0.0303884
exploration/env_infos/end_effector_loc Std                0.183576
exploration/env_infos/end_effector_loc Max                0.567923
exploration/env_infos/end_effector_loc Min               -0.294198
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0432735
exploration/env_infos/final/reward_dist Std               0.0732804
exploration/env_infos/final/reward_dist Max               0.188201
exploration/env_infos/final/reward_dist Min               5.17326e-25
exploration/env_infos/initial/reward_dist Mean            0.00921074
exploration/env_infos/initial/reward_dist Std             0.0162728
exploration/env_infos/initial/reward_dist Max             0.0417371
exploration/env_infos/initial/reward_dist Min             2.88151e-05
exploration/env_infos/reward_dist Mean                    0.148854
exploration/env_infos/reward_dist Std                     0.231564
exploration/env_infos/reward_dist Max                     0.973929
exploration/env_infos/reward_dist Min                     5.42761e-27
evaluation/num steps total                           184000
evaluation/num paths total                             9200
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.082068
evaluation/Rewards Std                                    0.106073
evaluation/Rewards Max                                    0.151054
evaluation/Rewards Min                                   -0.704717
evaluation/Returns Mean                                  -1.64136
evaluation/Returns Std                                    1.74621
evaluation/Returns Max                                    1.22939
evaluation/Returns Min                                   -6.30093
evaluation/Actions Mean                                   0.00237059
evaluation/Actions Std                                    0.124863
evaluation/Actions Max                                    0.822431
evaluation/Actions Min                                   -0.809585
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.64136
evaluation/env_infos/final/reward_energy Mean            -0.0736957
evaluation/env_infos/final/reward_energy Std              0.0781191
evaluation/env_infos/final/reward_energy Max             -0.0138672
evaluation/env_infos/final/reward_energy Min             -0.451578
evaluation/env_infos/initial/reward_energy Mean          -0.293737
evaluation/env_infos/initial/reward_energy Std            0.239242
evaluation/env_infos/initial/reward_energy Max           -0.0317291
evaluation/env_infos/initial/reward_energy Min           -0.866785
evaluation/env_infos/reward_energy Mean                  -0.114025
evaluation/env_infos/reward_energy Std                    0.134874
evaluation/env_infos/reward_energy Max                   -0.00232123
evaluation/env_infos/reward_energy Min                   -0.874821
evaluation/env_infos/final/end_effector_loc Mean          0.00771392
evaluation/env_infos/final/end_effector_loc Std           0.380285
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000162793
evaluation/env_infos/initial/end_effector_loc Std         0.013393
evaluation/env_infos/initial/end_effector_loc Max         0.037298
evaluation/env_infos/initial/end_effector_loc Min        -0.0387566
evaluation/env_infos/end_effector_loc Mean                0.0118908
evaluation/env_infos/end_effector_loc Std                 0.268762
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.131839
evaluation/env_infos/final/reward_dist Std                0.242717
evaluation/env_infos/final/reward_dist Max                0.882896
evaluation/env_infos/final/reward_dist Min                4.04961e-195
evaluation/env_infos/initial/reward_dist Mean             0.00525343
evaluation/env_infos/initial/reward_dist Std              0.0102244
evaluation/env_infos/initial/reward_dist Max              0.0498663
evaluation/env_infos/initial/reward_dist Min              8.18116e-08
evaluation/env_infos/reward_dist Mean                     0.146455
evaluation/env_infos/reward_dist Std                      0.248429
evaluation/env_infos/reward_dist Max                      0.961087
evaluation/env_infos/reward_dist Min                      4.04961e-195
time/data storing (s)                                    38.5585
time/evaluation sampling (s)                              0.647109
time/exploration sampling (s)                             0.0893912
time/logging (s)                                          0.0160557
time/saving (s)                                           0.819987
time/training (s)                                        39.9203
time/epoch (s)                                           80.0513
time/total (s)                                        13145.1
Epoch                                                   183
---------------------------------------------------  -----------------
2021-05-29 03:36:20.466419 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 184 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0030779
trainer/QF2 Loss                                          0.00428358
trainer/Policy Loss                                       3.03767
trainer/Q1 Predictions Mean                              -1.0334
trainer/Q1 Predictions Std                                0.925794
trainer/Q1 Predictions Max                                0.323478
trainer/Q1 Predictions Min                               -6.92872
trainer/Q2 Predictions Mean                              -1.02498
trainer/Q2 Predictions Std                                0.935769
trainer/Q2 Predictions Max                                0.360739
trainer/Q2 Predictions Min                               -6.97365
trainer/Q Targets Mean                                   -1.03191
trainer/Q Targets Std                                     0.932092
trainer/Q Targets Max                                     0.313973
trainer/Q Targets Min                                    -6.96449
trainer/Log Pis Mean                                      2.01789
trainer/Log Pis Std                                       1.15746
trainer/Log Pis Max                                       4.34131
trainer/Log Pis Min                                      -2.90768
trainer/Policy mu Mean                                   -0.0268758
trainer/Policy mu Std                                     0.393414
trainer/Policy mu Max                                     1.71183
trainer/Policy mu Min                                    -2.61264
trainer/Policy log std Mean                              -2.2744
trainer/Policy log std Std                                0.455496
trainer/Policy log std Max                                0.0373168
trainer/Policy log std Min                               -3.16854
trainer/Alpha                                             0.0213826
trainer/Alpha Loss                                        0.0687938
exploration/num steps total                           19500
exploration/num paths total                             975
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.25839
exploration/Rewards Std                                   0.213089
exploration/Rewards Max                                  -0.0513382
exploration/Rewards Min                                  -0.868948
exploration/Returns Mean                                 -5.16779
exploration/Returns Std                                   3.77281
exploration/Returns Max                                  -1.48012
exploration/Returns Min                                 -11.8211
exploration/Actions Mean                                  0.0175688
exploration/Actions Std                                   0.329699
exploration/Actions Max                                   0.99661
exploration/Actions Min                                  -0.899669
exploration/Num Paths                                     5
exploration/Average Returns                              -5.16779
exploration/env_infos/final/reward_energy Mean           -0.287163
exploration/env_infos/final/reward_energy Std             0.198402
exploration/env_infos/final/reward_energy Max            -0.0535757
exploration/env_infos/final/reward_energy Min            -0.651381
exploration/env_infos/initial/reward_energy Mean         -0.552399
exploration/env_infos/initial/reward_energy Std           0.201324
exploration/env_infos/initial/reward_energy Max          -0.2777
exploration/env_infos/initial/reward_energy Min          -0.872306
exploration/env_infos/reward_energy Mean                 -0.379573
exploration/env_infos/reward_energy Std                   0.271927
exploration/env_infos/reward_energy Max                  -0.0434746
exploration/env_infos/reward_energy Min                  -1.09522
exploration/env_infos/final/end_effector_loc Mean        -0.0772752
exploration/env_infos/final/end_effector_loc Std          0.581484
exploration/env_infos/final/end_effector_loc Max          0.891638
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00470561
exploration/env_infos/initial/end_effector_loc Std        0.0202473
exploration/env_infos/initial/end_effector_loc Max        0.0230342
exploration/env_infos/initial/end_effector_loc Min       -0.0411606
exploration/env_infos/end_effector_loc Mean              -0.115793
exploration/env_infos/end_effector_loc Std                0.431908
exploration/env_infos/end_effector_loc Max                0.919614
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.179978
exploration/env_infos/final/reward_dist Std               0.358647
exploration/env_infos/final/reward_dist Max               0.897269
exploration/env_infos/final/reward_dist Min               5.27878e-116
exploration/env_infos/initial/reward_dist Mean            0.00738459
exploration/env_infos/initial/reward_dist Std             0.00897781
exploration/env_infos/initial/reward_dist Max             0.0225223
exploration/env_infos/initial/reward_dist Min             3.18025e-06
exploration/env_infos/reward_dist Mean                    0.115028
exploration/env_infos/reward_dist Std                     0.23102
exploration/env_infos/reward_dist Max                     0.994008
exploration/env_infos/reward_dist Min                     5.49531e-139
evaluation/num steps total                           185000
evaluation/num paths total                             9250
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.133782
evaluation/Rewards Std                                    0.177065
evaluation/Rewards Max                                    0.150869
evaluation/Rewards Min                                   -0.843232
evaluation/Returns Mean                                  -2.67564
evaluation/Returns Std                                    3.20211
evaluation/Returns Max                                    1.19728
evaluation/Returns Min                                  -10.7076
evaluation/Actions Mean                                   0.00732944
evaluation/Actions Std                                    0.185508
evaluation/Actions Max                                    0.830367
evaluation/Actions Min                                   -0.976519
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.67564
evaluation/env_infos/final/reward_energy Mean            -0.0811171
evaluation/env_infos/final/reward_energy Std              0.0904753
evaluation/env_infos/final/reward_energy Max             -0.00657943
evaluation/env_infos/final/reward_energy Min             -0.499673
evaluation/env_infos/initial/reward_energy Mean          -0.386247
evaluation/env_infos/initial/reward_energy Std            0.311846
evaluation/env_infos/initial/reward_energy Max           -0.0387898
evaluation/env_infos/initial/reward_energy Min           -1.14278
evaluation/env_infos/reward_energy Mean                  -0.168131
evaluation/env_infos/reward_energy Std                    0.201658
evaluation/env_infos/reward_energy Max                   -0.000891911
evaluation/env_infos/reward_energy Min                   -1.14278
evaluation/env_infos/final/end_effector_loc Mean         -0.0232602
evaluation/env_infos/final/end_effector_loc Std           0.415897
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00276041
evaluation/env_infos/initial/end_effector_loc Std         0.0173327
evaluation/env_infos/initial/end_effector_loc Max         0.0363466
evaluation/env_infos/initial/end_effector_loc Min        -0.048826
evaluation/env_infos/end_effector_loc Mean               -0.0308099
evaluation/env_infos/end_effector_loc Std                 0.308688
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0794347
evaluation/env_infos/final/reward_dist Std                0.173729
evaluation/env_infos/final/reward_dist Max                0.623897
evaluation/env_infos/final/reward_dist Min                3.82292e-168
evaluation/env_infos/initial/reward_dist Mean             0.00623412
evaluation/env_infos/initial/reward_dist Std              0.0129815
evaluation/env_infos/initial/reward_dist Max              0.0738548
evaluation/env_infos/initial/reward_dist Min              1.16594e-06
evaluation/env_infos/reward_dist Mean                     0.115413
evaluation/env_infos/reward_dist Std                      0.220602
evaluation/env_infos/reward_dist Max                      0.955978
evaluation/env_infos/reward_dist Min                      3.82292e-168
time/data storing (s)                                    38.5064
time/evaluation sampling (s)                              0.566365
time/exploration sampling (s)                             0.0864581
time/logging (s)                                          0.0160164
time/saving (s)                                           0.771583
time/training (s)                                        39.7962
time/epoch (s)                                           79.743
time/total (s)                                        13227.1
Epoch                                                   184
---------------------------------------------------  -----------------
2021-05-29 03:37:42.398050 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 185 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00425402
trainer/QF2 Loss                                          0.00538751
trainer/Policy Loss                                       2.80541
trainer/Q1 Predictions Mean                              -0.844712
trainer/Q1 Predictions Std                                0.715493
trainer/Q1 Predictions Max                                0.376438
trainer/Q1 Predictions Min                               -3.20744
trainer/Q2 Predictions Mean                              -0.849222
trainer/Q2 Predictions Std                                0.702356
trainer/Q2 Predictions Max                                0.38477
trainer/Q2 Predictions Min                               -3.20843
trainer/Q Targets Mean                                   -0.85199
trainer/Q Targets Std                                     0.718067
trainer/Q Targets Max                                     0.377135
trainer/Q Targets Min                                    -3.1838
trainer/Log Pis Mean                                      1.94406
trainer/Log Pis Std                                       1.14064
trainer/Log Pis Max                                       5.71661
trainer/Log Pis Min                                      -2.55175
trainer/Policy mu Mean                                   -0.0194223
trainer/Policy mu Std                                     0.34379
trainer/Policy mu Max                                     1.39693
trainer/Policy mu Min                                    -2.55047
trainer/Policy log std Mean                              -2.28192
trainer/Policy log std Std                                0.428052
trainer/Policy log std Max                               -0.669678
trainer/Policy log std Min                               -3.19195
trainer/Alpha                                             0.0183889
trainer/Alpha Loss                                       -0.223485
exploration/num steps total                           19600
exploration/num paths total                             980
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.163262
exploration/Rewards Std                                   0.0591711
exploration/Rewards Max                                  -0.0501048
exploration/Rewards Min                                  -0.373722
exploration/Returns Mean                                 -3.26525
exploration/Returns Std                                   0.603105
exploration/Returns Max                                  -2.61833
exploration/Returns Min                                  -4.33462
exploration/Actions Mean                                 -0.00572709
exploration/Actions Std                                   0.125691
exploration/Actions Max                                   0.401147
exploration/Actions Min                                  -0.452049
exploration/Num Paths                                     5
exploration/Average Returns                              -3.26525
exploration/env_infos/final/reward_energy Mean           -0.131893
exploration/env_infos/final/reward_energy Std             0.0970325
exploration/env_infos/final/reward_energy Max            -0.033643
exploration/env_infos/final/reward_energy Min            -0.302144
exploration/env_infos/initial/reward_energy Mean         -0.293939
exploration/env_infos/initial/reward_energy Std           0.0975429
exploration/env_infos/initial/reward_energy Max          -0.165114
exploration/env_infos/initial/reward_energy Min          -0.453298
exploration/env_infos/reward_energy Mean                 -0.150488
exploration/env_infos/reward_energy Std                   0.0949501
exploration/env_infos/reward_energy Max                  -0.018101
exploration/env_infos/reward_energy Min                  -0.551473
exploration/env_infos/final/end_effector_loc Mean        -0.0793818
exploration/env_infos/final/end_effector_loc Std          0.464992
exploration/env_infos/final/end_effector_loc Max          0.638022
exploration/env_infos/final/end_effector_loc Min         -0.794516
exploration/env_infos/initial/end_effector_loc Mean      -0.00368388
exploration/env_infos/initial/end_effector_loc Std        0.0103113
exploration/env_infos/initial/end_effector_loc Max        0.00968969
exploration/env_infos/initial/end_effector_loc Min       -0.0226024
exploration/env_infos/end_effector_loc Mean              -0.0366202
exploration/env_infos/end_effector_loc Std                0.256999
exploration/env_infos/end_effector_loc Max                0.638022
exploration/env_infos/end_effector_loc Min               -0.794516
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0163674
exploration/env_infos/final/reward_dist Std               0.032732
exploration/env_infos/final/reward_dist Max               0.0818313
exploration/env_infos/final/reward_dist Min               5.82508e-86
exploration/env_infos/initial/reward_dist Mean            0.0121141
exploration/env_infos/initial/reward_dist Std             0.0212539
exploration/env_infos/initial/reward_dist Max             0.0543752
exploration/env_infos/initial/reward_dist Min             4.43913e-06
exploration/env_infos/reward_dist Mean                    0.0431572
exploration/env_infos/reward_dist Std                     0.15954
exploration/env_infos/reward_dist Max                     0.994477
exploration/env_infos/reward_dist Min                     5.82508e-86
evaluation/num steps total                           186000
evaluation/num paths total                             9300
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0813344
evaluation/Rewards Std                                    0.121272
evaluation/Rewards Max                                    0.145827
evaluation/Rewards Min                                   -0.790255
evaluation/Returns Mean                                  -1.62669
evaluation/Returns Std                                    1.99657
evaluation/Returns Max                                    2.06255
evaluation/Returns Min                                   -9.42367
evaluation/Actions Mean                                  -0.00720018
evaluation/Actions Std                                    0.112777
evaluation/Actions Max                                    0.945917
evaluation/Actions Min                                   -0.684258
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.62669
evaluation/env_infos/final/reward_energy Mean            -0.0768477
evaluation/env_infos/final/reward_energy Std              0.0705206
evaluation/env_infos/final/reward_energy Max             -0.00820238
evaluation/env_infos/final/reward_energy Min             -0.4195
evaluation/env_infos/initial/reward_energy Mean          -0.262689
evaluation/env_infos/initial/reward_energy Std            0.21575
evaluation/env_infos/initial/reward_energy Max           -0.014807
evaluation/env_infos/initial/reward_energy Min           -0.975609
evaluation/env_infos/reward_energy Mean                  -0.10551
evaluation/env_infos/reward_energy Std                    0.120035
evaluation/env_infos/reward_energy Max                   -0.00102642
evaluation/env_infos/reward_energy Min                   -0.975609
evaluation/env_infos/final/end_effector_loc Mean         -0.053832
evaluation/env_infos/final/end_effector_loc Std           0.318292
evaluation/env_infos/final/end_effector_loc Max           0.945808
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000628112
evaluation/env_infos/initial/end_effector_loc Std         0.012002
evaluation/env_infos/initial/end_effector_loc Max         0.0472959
evaluation/env_infos/initial/end_effector_loc Min        -0.0322902
evaluation/env_infos/end_effector_loc Mean               -0.0219859
evaluation/env_infos/end_effector_loc Std                 0.210512
evaluation/env_infos/end_effector_loc Max                 0.945808
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.150406
evaluation/env_infos/final/reward_dist Std                0.246967
evaluation/env_infos/final/reward_dist Max                0.972369
evaluation/env_infos/final/reward_dist Min                3.49192e-82
evaluation/env_infos/initial/reward_dist Mean             0.00579657
evaluation/env_infos/initial/reward_dist Std              0.00948891
evaluation/env_infos/initial/reward_dist Max              0.0418453
evaluation/env_infos/initial/reward_dist Min              1.13048e-06
evaluation/env_infos/reward_dist Mean                     0.165693
evaluation/env_infos/reward_dist Std                      0.261059
evaluation/env_infos/reward_dist Max                      0.996272
evaluation/env_infos/reward_dist Min                      3.49192e-82
time/data storing (s)                                    38.1823
time/evaluation sampling (s)                              0.636102
time/exploration sampling (s)                             0.0867413
time/logging (s)                                          0.0174955
time/saving (s)                                           0.786036
time/training (s)                                        40.259
time/epoch (s)                                           79.9677
time/total (s)                                        13309
Epoch                                                   185
---------------------------------------------------  ----------------
2021-05-29 03:39:02.817631 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 186 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00335836
trainer/QF2 Loss                                          0.00370887
trainer/Policy Loss                                       2.85753
trainer/Q1 Predictions Mean                              -0.902079
trainer/Q1 Predictions Std                                0.766201
trainer/Q1 Predictions Max                                0.375165
trainer/Q1 Predictions Min                               -3.11799
trainer/Q2 Predictions Mean                              -0.925319
trainer/Q2 Predictions Std                                0.757333
trainer/Q2 Predictions Max                                0.386594
trainer/Q2 Predictions Min                               -3.13697
trainer/Q Targets Mean                                   -0.913229
trainer/Q Targets Std                                     0.765232
trainer/Q Targets Max                                     0.425333
trainer/Q Targets Min                                    -3.11808
trainer/Log Pis Mean                                      1.96026
trainer/Log Pis Std                                       1.19257
trainer/Log Pis Max                                       4.41743
trainer/Log Pis Min                                      -4.69018
trainer/Policy mu Mean                                   -0.00704605
trainer/Policy mu Std                                     0.330286
trainer/Policy mu Max                                     2.02915
trainer/Policy mu Min                                    -2.32829
trainer/Policy log std Mean                              -2.30144
trainer/Policy log std Std                                0.40986
trainer/Policy log std Max                               -0.624568
trainer/Policy log std Min                               -3.2477
trainer/Alpha                                             0.0183207
trainer/Alpha Loss                                       -0.159024
exploration/num steps total                           19700
exploration/num paths total                             985
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0931351
exploration/Rewards Std                                   0.0924221
exploration/Rewards Max                                   0.0950671
exploration/Rewards Min                                  -0.379647
exploration/Returns Mean                                 -1.8627
exploration/Returns Std                                   1.19498
exploration/Returns Max                                   0.331312
exploration/Returns Min                                  -3.08903
exploration/Actions Mean                                 -0.0165218
exploration/Actions Std                                   0.176994
exploration/Actions Max                                   0.765872
exploration/Actions Min                                  -0.78458
exploration/Num Paths                                     5
exploration/Average Returns                              -1.8627
exploration/env_infos/final/reward_energy Mean           -0.0729763
exploration/env_infos/final/reward_energy Std             0.0243157
exploration/env_infos/final/reward_energy Max            -0.037729
exploration/env_infos/final/reward_energy Min            -0.101905
exploration/env_infos/initial/reward_energy Mean         -0.356554
exploration/env_infos/initial/reward_energy Std           0.244875
exploration/env_infos/initial/reward_energy Max          -0.0337202
exploration/env_infos/initial/reward_energy Min          -0.635286
exploration/env_infos/reward_energy Mean                 -0.181385
exploration/env_infos/reward_energy Std                   0.174067
exploration/env_infos/reward_energy Max                  -0.00954706
exploration/env_infos/reward_energy Min                  -0.998648
exploration/env_infos/final/end_effector_loc Mean        -0.0349552
exploration/env_infos/final/end_effector_loc Std          0.469472
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00568919
exploration/env_infos/initial/end_effector_loc Std        0.0141951
exploration/env_infos/initial/end_effector_loc Max        0.0296913
exploration/env_infos/initial/end_effector_loc Min       -0.013015
exploration/env_infos/end_effector_loc Mean               0.0225311
exploration/env_infos/end_effector_loc Std                0.378954
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000115499
exploration/env_infos/final/reward_dist Std               0.000220286
exploration/env_infos/final/reward_dist Max               0.000555751
exploration/env_infos/final/reward_dist Min               1.64472e-163
exploration/env_infos/initial/reward_dist Mean            0.00352772
exploration/env_infos/initial/reward_dist Std             0.0053514
exploration/env_infos/initial/reward_dist Max             0.0138269
exploration/env_infos/initial/reward_dist Min             8.02203e-06
exploration/env_infos/reward_dist Mean                    0.0209094
exploration/env_infos/reward_dist Std                     0.0718942
exploration/env_infos/reward_dist Max                     0.390635
exploration/env_infos/reward_dist Min                     1.64472e-163
evaluation/num steps total                           187000
evaluation/num paths total                             9350
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0965995
evaluation/Rewards Std                                    0.121977
evaluation/Rewards Max                                    0.138939
evaluation/Rewards Min                                   -0.81331
evaluation/Returns Mean                                  -1.93199
evaluation/Returns Std                                    2.07101
evaluation/Returns Max                                    0.689399
evaluation/Returns Min                                   -9.09396
evaluation/Actions Mean                                  -0.00186059
evaluation/Actions Std                                    0.105939
evaluation/Actions Max                                    0.787507
evaluation/Actions Min                                   -0.729598
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.93199
evaluation/env_infos/final/reward_energy Mean            -0.0776269
evaluation/env_infos/final/reward_energy Std              0.0590096
evaluation/env_infos/final/reward_energy Max             -0.0163094
evaluation/env_infos/final/reward_energy Min             -0.322715
evaluation/env_infos/initial/reward_energy Mean          -0.281604
evaluation/env_infos/initial/reward_energy Std            0.235488
evaluation/env_infos/initial/reward_energy Max           -0.0180054
evaluation/env_infos/initial/reward_energy Min           -1.01013
evaluation/env_infos/reward_energy Mean                  -0.0975905
evaluation/env_infos/reward_energy Std                    0.113706
evaluation/env_infos/reward_energy Max                   -0.00329469
evaluation/env_infos/reward_energy Min                   -1.01013
evaluation/env_infos/final/end_effector_loc Mean         -0.0278668
evaluation/env_infos/final/end_effector_loc Std           0.351478
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00107069
evaluation/env_infos/initial/end_effector_loc Std         0.0129344
evaluation/env_infos/initial/end_effector_loc Max         0.0393753
evaluation/env_infos/initial/end_effector_loc Min        -0.0364799
evaluation/env_infos/end_effector_loc Mean               -0.00592323
evaluation/env_infos/end_effector_loc Std                 0.241911
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0982424
evaluation/env_infos/final/reward_dist Std                0.211021
evaluation/env_infos/final/reward_dist Max                0.990754
evaluation/env_infos/final/reward_dist Min                6.22103e-152
evaluation/env_infos/initial/reward_dist Mean             0.00584205
evaluation/env_infos/initial/reward_dist Std              0.0120605
evaluation/env_infos/initial/reward_dist Max              0.0668865
evaluation/env_infos/initial/reward_dist Min              1.54956e-07
evaluation/env_infos/reward_dist Mean                     0.138229
evaluation/env_infos/reward_dist Std                      0.239233
evaluation/env_infos/reward_dist Max                      0.990754
evaluation/env_infos/reward_dist Min                      6.22103e-152
time/data storing (s)                                    37.9162
time/evaluation sampling (s)                              0.636302
time/exploration sampling (s)                             0.0844811
time/logging (s)                                          0.0154257
time/saving (s)                                           0.796408
time/training (s)                                        38.967
time/epoch (s)                                           78.4157
time/total (s)                                        13389.4
Epoch                                                   186
---------------------------------------------------  -----------------
2021-05-29 03:40:23.225529 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 187 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00204051
trainer/QF2 Loss                                          0.00249679
trainer/Policy Loss                                       3.11292
trainer/Q1 Predictions Mean                              -1.04474
trainer/Q1 Predictions Std                                0.836686
trainer/Q1 Predictions Max                                1.0761
trainer/Q1 Predictions Min                               -3.64979
trainer/Q2 Predictions Mean                              -1.04961
trainer/Q2 Predictions Std                                0.838662
trainer/Q2 Predictions Max                                1.03172
trainer/Q2 Predictions Min                               -3.74517
trainer/Q Targets Mean                                   -1.04255
trainer/Q Targets Std                                     0.83615
trainer/Q Targets Max                                     1.00667
trainer/Q Targets Min                                    -3.60773
trainer/Log Pis Mean                                      2.08561
trainer/Log Pis Std                                       1.12018
trainer/Log Pis Max                                       8.67192
trainer/Log Pis Min                                      -3.77925
trainer/Policy mu Mean                                    0.0189232
trainer/Policy mu Std                                     0.433482
trainer/Policy mu Max                                     3.28621
trainer/Policy mu Min                                    -2.62266
trainer/Policy log std Mean                              -2.25022
trainer/Policy log std Std                                0.453009
trainer/Policy log std Max                                0.0853586
trainer/Policy log std Min                               -3.26732
trainer/Alpha                                             0.0198567
trainer/Alpha Loss                                        0.335527
exploration/num steps total                           19800
exploration/num paths total                             990
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0623413
exploration/Rewards Std                                   0.058141
exploration/Rewards Max                                   0.0692693
exploration/Rewards Min                                  -0.297793
exploration/Returns Mean                                 -1.24683
exploration/Returns Std                                   0.678758
exploration/Returns Max                                  -0.233614
exploration/Returns Min                                  -1.89124
exploration/Actions Mean                                  0.00389114
exploration/Actions Std                                   0.140745
exploration/Actions Max                                   0.610975
exploration/Actions Min                                  -0.495113
exploration/Num Paths                                     5
exploration/Average Returns                              -1.24683
exploration/env_infos/final/reward_energy Mean           -0.102623
exploration/env_infos/final/reward_energy Std             0.0812494
exploration/env_infos/final/reward_energy Max            -0.0301371
exploration/env_infos/final/reward_energy Min            -0.254921
exploration/env_infos/initial/reward_energy Mean         -0.251142
exploration/env_infos/initial/reward_energy Std           0.205625
exploration/env_infos/initial/reward_energy Max          -0.120246
exploration/env_infos/initial/reward_energy Min          -0.65935
exploration/env_infos/reward_energy Mean                 -0.155392
exploration/env_infos/reward_energy Std                   0.124506
exploration/env_infos/reward_energy Max                  -0.0194076
exploration/env_infos/reward_energy Min                  -0.65935
exploration/env_infos/final/end_effector_loc Mean         0.155375
exploration/env_infos/final/end_effector_loc Std          0.21063
exploration/env_infos/final/end_effector_loc Max          0.445266
exploration/env_infos/final/end_effector_loc Min         -0.140002
exploration/env_infos/initial/end_effector_loc Mean       0.00637431
exploration/env_infos/initial/end_effector_loc Std        0.00954257
exploration/env_infos/initial/end_effector_loc Max        0.0305488
exploration/env_infos/initial/end_effector_loc Min       -0.00600103
exploration/env_infos/end_effector_loc Mean               0.0881842
exploration/env_infos/end_effector_loc Std                0.138906
exploration/env_infos/end_effector_loc Max                0.445266
exploration/env_infos/end_effector_loc Min               -0.189468
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00421046
exploration/env_infos/final/reward_dist Std               0.00571825
exploration/env_infos/final/reward_dist Max               0.0152153
exploration/env_infos/final/reward_dist Min               1.73605e-13
exploration/env_infos/initial/reward_dist Mean            0.00605817
exploration/env_infos/initial/reward_dist Std             0.0120209
exploration/env_infos/initial/reward_dist Max             0.0300997
exploration/env_infos/initial/reward_dist Min             2.27336e-06
exploration/env_infos/reward_dist Mean                    0.112939
exploration/env_infos/reward_dist Std                     0.182626
exploration/env_infos/reward_dist Max                     0.948935
exploration/env_infos/reward_dist Min                     1.73605e-13
evaluation/num steps total                           188000
evaluation/num paths total                             9400
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0716126
evaluation/Rewards Std                                    0.103434
evaluation/Rewards Max                                    0.157773
evaluation/Rewards Min                                   -0.856142
evaluation/Returns Mean                                  -1.43225
evaluation/Returns Std                                    1.64994
evaluation/Returns Max                                    1.37877
evaluation/Returns Min                                  -10.2059
evaluation/Actions Mean                                  -0.00652725
evaluation/Actions Std                                    0.110571
evaluation/Actions Max                                    0.807022
evaluation/Actions Min                                   -0.898907
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.43225
evaluation/env_infos/final/reward_energy Mean            -0.0649193
evaluation/env_infos/final/reward_energy Std              0.0852016
evaluation/env_infos/final/reward_energy Max             -0.00907874
evaluation/env_infos/final/reward_energy Min             -0.549496
evaluation/env_infos/initial/reward_energy Mean          -0.316501
evaluation/env_infos/initial/reward_energy Std            0.276511
evaluation/env_infos/initial/reward_energy Max           -0.0101296
evaluation/env_infos/initial/reward_energy Min           -1.1306
evaluation/env_infos/reward_energy Mean                  -0.0963549
evaluation/env_infos/reward_energy Std                    0.123502
evaluation/env_infos/reward_energy Max                   -0.00277674
evaluation/env_infos/reward_energy Min                   -1.1306
evaluation/env_infos/final/end_effector_loc Mean         -0.0520595
evaluation/env_infos/final/end_effector_loc Std           0.304456
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -4.24659e-05
evaluation/env_infos/initial/end_effector_loc Std         0.0148589
evaluation/env_infos/initial/end_effector_loc Max         0.0403511
evaluation/env_infos/initial/end_effector_loc Min        -0.0449454
evaluation/env_infos/end_effector_loc Mean               -0.0149745
evaluation/env_infos/end_effector_loc Std                 0.207505
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.12877
evaluation/env_infos/final/reward_dist Std                0.229723
evaluation/env_infos/final/reward_dist Max                0.809315
evaluation/env_infos/final/reward_dist Min                5.74155e-172
evaluation/env_infos/initial/reward_dist Mean             0.00469069
evaluation/env_infos/initial/reward_dist Std              0.00977651
evaluation/env_infos/initial/reward_dist Max              0.0465737
evaluation/env_infos/initial/reward_dist Min              1.29978e-06
evaluation/env_infos/reward_dist Mean                     0.159498
evaluation/env_infos/reward_dist Std                      0.255328
evaluation/env_infos/reward_dist Max                      0.999874
evaluation/env_infos/reward_dist Min                      5.74155e-172
time/data storing (s)                                    37.9373
time/evaluation sampling (s)                              0.645441
time/exploration sampling (s)                             0.0894754
time/logging (s)                                          0.0169403
time/saving (s)                                           0.774361
time/training (s)                                        38.9228
time/epoch (s)                                           78.3863
time/total (s)                                        13469.8
Epoch                                                   187
---------------------------------------------------  -----------------
2021-05-29 03:41:44.087215 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 188 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00435225
trainer/QF2 Loss                                          0.00348851
trainer/Policy Loss                                       2.91055
trainer/Q1 Predictions Mean                              -0.940946
trainer/Q1 Predictions Std                                0.812212
trainer/Q1 Predictions Max                                0.534432
trainer/Q1 Predictions Min                               -4.53083
trainer/Q2 Predictions Mean                              -0.923774
trainer/Q2 Predictions Std                                0.817431
trainer/Q2 Predictions Max                                0.613104
trainer/Q2 Predictions Min                               -4.51053
trainer/Q Targets Mean                                   -0.945315
trainer/Q Targets Std                                     0.823471
trainer/Q Targets Max                                     0.580853
trainer/Q Targets Min                                    -4.55597
trainer/Log Pis Mean                                      2.00189
trainer/Log Pis Std                                       1.17986
trainer/Log Pis Max                                       6.589
trainer/Log Pis Min                                      -3.48278
trainer/Policy mu Mean                                   -0.0240638
trainer/Policy mu Std                                     0.391529
trainer/Policy mu Max                                     2.52633
trainer/Policy mu Min                                    -2.38451
trainer/Policy log std Mean                              -2.2671
trainer/Policy log std Std                                0.37398
trainer/Policy log std Max                               -0.360889
trainer/Policy log std Min                               -2.99565
trainer/Alpha                                             0.0181559
trainer/Alpha Loss                                        0.00759066
exploration/num steps total                           19900
exploration/num paths total                             995
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0958789
exploration/Rewards Std                                   0.134977
exploration/Rewards Max                                   0.127936
exploration/Rewards Min                                  -0.39534
exploration/Returns Mean                                 -1.91758
exploration/Returns Std                                   2.51918
exploration/Returns Max                                   1.19375
exploration/Returns Min                                  -6.14117
exploration/Actions Mean                                 -0.00288268
exploration/Actions Std                                   0.178994
exploration/Actions Max                                   0.729403
exploration/Actions Min                                  -0.585245
exploration/Num Paths                                     5
exploration/Average Returns                              -1.91758
exploration/env_infos/final/reward_energy Mean           -0.163439
exploration/env_infos/final/reward_energy Std             0.0554523
exploration/env_infos/final/reward_energy Max            -0.096084
exploration/env_infos/final/reward_energy Min            -0.216403
exploration/env_infos/initial/reward_energy Mean         -0.318835
exploration/env_infos/initial/reward_energy Std           0.200404
exploration/env_infos/initial/reward_energy Max          -0.0229727
exploration/env_infos/initial/reward_energy Min          -0.638499
exploration/env_infos/reward_energy Mean                 -0.209923
exploration/env_infos/reward_energy Std                   0.141515
exploration/env_infos/reward_energy Max                  -0.00720372
exploration/env_infos/reward_energy Min                  -0.734164
exploration/env_infos/final/end_effector_loc Mean         0.128765
exploration/env_infos/final/end_effector_loc Std          0.388608
exploration/env_infos/final/end_effector_loc Max          0.931643
exploration/env_infos/final/end_effector_loc Min         -0.655974
exploration/env_infos/initial/end_effector_loc Mean       0.00620833
exploration/env_infos/initial/end_effector_loc Std        0.0117783
exploration/env_infos/initial/end_effector_loc Max        0.0244177
exploration/env_infos/initial/end_effector_loc Min       -0.00877318
exploration/env_infos/end_effector_loc Mean               0.101601
exploration/env_infos/end_effector_loc Std                0.240659
exploration/env_infos/end_effector_loc Max                0.931643
exploration/env_infos/end_effector_loc Min               -0.655974
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.181968
exploration/env_infos/final/reward_dist Std               0.260508
exploration/env_infos/final/reward_dist Max               0.671258
exploration/env_infos/final/reward_dist Min               2.75971e-112
exploration/env_infos/initial/reward_dist Mean            0.00288033
exploration/env_infos/initial/reward_dist Std             0.00410907
exploration/env_infos/initial/reward_dist Max             0.0109946
exploration/env_infos/initial/reward_dist Min             3.16636e-05
exploration/env_infos/reward_dist Mean                    0.109946
exploration/env_infos/reward_dist Std                     0.202518
exploration/env_infos/reward_dist Max                     0.925019
exploration/env_infos/reward_dist Min                     2.75971e-112
evaluation/num steps total                           189000
evaluation/num paths total                             9450
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0706993
evaluation/Rewards Std                                    0.098128
evaluation/Rewards Max                                    0.130876
evaluation/Rewards Min                                   -0.591179
evaluation/Returns Mean                                  -1.41399
evaluation/Returns Std                                    1.63095
evaluation/Returns Max                                    1.2558
evaluation/Returns Min                                   -6.26589
evaluation/Actions Mean                                  -0.00286556
evaluation/Actions Std                                    0.101634
evaluation/Actions Max                                    0.75083
evaluation/Actions Min                                   -0.92891
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.41399
evaluation/env_infos/final/reward_energy Mean            -0.0932801
evaluation/env_infos/final/reward_energy Std              0.0987105
evaluation/env_infos/final/reward_energy Max             -0.00480174
evaluation/env_infos/final/reward_energy Min             -0.599095
evaluation/env_infos/initial/reward_energy Mean          -0.254378
evaluation/env_infos/initial/reward_energy Std            0.199735
evaluation/env_infos/initial/reward_energy Max           -0.01763
evaluation/env_infos/initial/reward_energy Min           -0.962564
evaluation/env_infos/reward_energy Mean                  -0.0937272
evaluation/env_infos/reward_energy Std                    0.109044
evaluation/env_infos/reward_energy Max                   -0.00369278
evaluation/env_infos/reward_energy Min                   -0.962564
evaluation/env_infos/final/end_effector_loc Mean         -0.0324089
evaluation/env_infos/final/end_effector_loc Std           0.330862
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.0011658
evaluation/env_infos/initial/end_effector_loc Std         0.0113751
evaluation/env_infos/initial/end_effector_loc Max         0.0229872
evaluation/env_infos/initial/end_effector_loc Min        -0.0464455
evaluation/env_infos/end_effector_loc Mean               -0.015821
evaluation/env_infos/end_effector_loc Std                 0.211722
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.15933
evaluation/env_infos/final/reward_dist Std                0.264187
evaluation/env_infos/final/reward_dist Max                0.945082
evaluation/env_infos/final/reward_dist Min                4.4645e-172
evaluation/env_infos/initial/reward_dist Mean             0.00529563
evaluation/env_infos/initial/reward_dist Std              0.0107646
evaluation/env_infos/initial/reward_dist Max              0.0637729
evaluation/env_infos/initial/reward_dist Min              2.72224e-06
evaluation/env_infos/reward_dist Mean                     0.139937
evaluation/env_infos/reward_dist Std                      0.245951
evaluation/env_infos/reward_dist Max                      0.996323
evaluation/env_infos/reward_dist Min                      4.4645e-172
time/data storing (s)                                    38.3244
time/evaluation sampling (s)                              0.638956
time/exploration sampling (s)                             0.0838297
time/logging (s)                                          0.0172558
time/saving (s)                                           0.796035
time/training (s)                                        39.01
time/epoch (s)                                           78.8704
time/total (s)                                        13550.7
Epoch                                                   188
---------------------------------------------------  -----------------
2021-05-29 03:43:04.772800 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 189 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0018002
trainer/QF2 Loss                                          0.00197467
trainer/Policy Loss                                       2.99762
trainer/Q1 Predictions Mean                              -0.928768
trainer/Q1 Predictions Std                                0.889722
trainer/Q1 Predictions Max                                1.69141
trainer/Q1 Predictions Min                               -4.36947
trainer/Q2 Predictions Mean                              -0.922176
trainer/Q2 Predictions Std                                0.892946
trainer/Q2 Predictions Max                                1.57733
trainer/Q2 Predictions Min                               -4.40734
trainer/Q Targets Mean                                   -0.920254
trainer/Q Targets Std                                     0.891998
trainer/Q Targets Max                                     1.69173
trainer/Q Targets Min                                    -4.51325
trainer/Log Pis Mean                                      2.08696
trainer/Log Pis Std                                       0.95774
trainer/Log Pis Max                                       4.00907
trainer/Log Pis Min                                      -1.37482
trainer/Policy mu Mean                                   -0.0333159
trainer/Policy mu Std                                     0.316139
trainer/Policy mu Max                                     2.11297
trainer/Policy mu Min                                    -2.35531
trainer/Policy log std Mean                              -2.30409
trainer/Policy log std Std                                0.384004
trainer/Policy log std Max                               -0.502166
trainer/Policy log std Min                               -3.24941
trainer/Alpha                                             0.0187085
trainer/Alpha Loss                                        0.346037
exploration/num steps total                           20000
exploration/num paths total                            1000
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.092146
exploration/Rewards Std                                   0.0931483
exploration/Rewards Max                                   0.108988
exploration/Rewards Min                                  -0.353995
exploration/Returns Mean                                 -1.84292
exploration/Returns Std                                   1.47789
exploration/Returns Max                                   0.507491
exploration/Returns Min                                  -4.09854
exploration/Actions Mean                                  0.000449541
exploration/Actions Std                                   0.15727
exploration/Actions Max                                   0.473908
exploration/Actions Min                                  -0.470114
exploration/Num Paths                                     5
exploration/Average Returns                              -1.84292
exploration/env_infos/final/reward_energy Mean           -0.215378
exploration/env_infos/final/reward_energy Std             0.0679716
exploration/env_infos/final/reward_energy Max            -0.113476
exploration/env_infos/final/reward_energy Min            -0.306798
exploration/env_infos/initial/reward_energy Mean         -0.320686
exploration/env_infos/initial/reward_energy Std           0.151438
exploration/env_infos/initial/reward_energy Max          -0.076775
exploration/env_infos/initial/reward_energy Min          -0.508769
exploration/env_infos/reward_energy Mean                 -0.186812
exploration/env_infos/reward_energy Std                   0.120705
exploration/env_infos/reward_energy Max                  -0.0192385
exploration/env_infos/reward_energy Min                  -0.586728
exploration/env_infos/final/end_effector_loc Mean         0.0920085
exploration/env_infos/final/end_effector_loc Std          0.259681
exploration/env_infos/final/end_effector_loc Max          0.637401
exploration/env_infos/final/end_effector_loc Min         -0.360731
exploration/env_infos/initial/end_effector_loc Mean       0.00612729
exploration/env_infos/initial/end_effector_loc Std        0.0109395
exploration/env_infos/initial/end_effector_loc Max        0.0220894
exploration/env_infos/initial/end_effector_loc Min       -0.0154535
exploration/env_infos/end_effector_loc Mean               0.075895
exploration/env_infos/end_effector_loc Std                0.174507
exploration/env_infos/end_effector_loc Max                0.637401
exploration/env_infos/end_effector_loc Min               -0.374841
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.151028
exploration/env_infos/final/reward_dist Std               0.264355
exploration/env_infos/final/reward_dist Max               0.678011
exploration/env_infos/final/reward_dist Min               1.0251e-20
exploration/env_infos/initial/reward_dist Mean            0.0136677
exploration/env_infos/initial/reward_dist Std             0.0242869
exploration/env_infos/initial/reward_dist Max             0.0621518
exploration/env_infos/initial/reward_dist Min             5.48142e-05
exploration/env_infos/reward_dist Mean                    0.17642
exploration/env_infos/reward_dist Std                     0.264005
exploration/env_infos/reward_dist Max                     0.940515
exploration/env_infos/reward_dist Min                     1.0251e-20
evaluation/num steps total                           190000
evaluation/num paths total                             9500
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.06882
evaluation/Rewards Std                                    0.0860569
evaluation/Rewards Max                                    0.140576
evaluation/Rewards Min                                   -0.503661
evaluation/Returns Mean                                  -1.3764
evaluation/Returns Std                                    1.29549
evaluation/Returns Max                                    0.86128
evaluation/Returns Min                                   -6.98905
evaluation/Actions Mean                                  -0.00793928
evaluation/Actions Std                                    0.100926
evaluation/Actions Max                                    0.541672
evaluation/Actions Min                                   -0.912427
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.3764
evaluation/env_infos/final/reward_energy Mean            -0.0762147
evaluation/env_infos/final/reward_energy Std              0.0866792
evaluation/env_infos/final/reward_energy Max             -0.00212559
evaluation/env_infos/final/reward_energy Min             -0.427701
evaluation/env_infos/initial/reward_energy Mean          -0.280867
evaluation/env_infos/initial/reward_energy Std            0.253543
evaluation/env_infos/initial/reward_energy Max           -0.00394526
evaluation/env_infos/initial/reward_energy Min           -0.959505
evaluation/env_infos/reward_energy Mean                  -0.0887912
evaluation/env_infos/reward_energy Std                    0.112314
evaluation/env_infos/reward_energy Max                   -0.00126783
evaluation/env_infos/reward_energy Min                   -0.959505
evaluation/env_infos/final/end_effector_loc Mean         -0.0467889
evaluation/env_infos/final/end_effector_loc Std           0.329789
evaluation/env_infos/final/end_effector_loc Max           0.968084
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00302708
evaluation/env_infos/initial/end_effector_loc Std         0.0130307
evaluation/env_infos/initial/end_effector_loc Max         0.0248625
evaluation/env_infos/initial/end_effector_loc Min        -0.0456214
evaluation/env_infos/end_effector_loc Mean               -0.0255259
evaluation/env_infos/end_effector_loc Std                 0.217977
evaluation/env_infos/end_effector_loc Max                 0.968084
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0654078
evaluation/env_infos/final/reward_dist Std                0.155398
evaluation/env_infos/final/reward_dist Max                0.843595
evaluation/env_infos/final/reward_dist Min                2.24403e-164
evaluation/env_infos/initial/reward_dist Mean             0.00987289
evaluation/env_infos/initial/reward_dist Std              0.0213178
evaluation/env_infos/initial/reward_dist Max              0.102545
evaluation/env_infos/initial/reward_dist Min              2.01029e-06
evaluation/env_infos/reward_dist Mean                     0.128163
evaluation/env_infos/reward_dist Std                      0.224689
evaluation/env_infos/reward_dist Max                      0.994102
evaluation/env_infos/reward_dist Min                      2.24403e-164
time/data storing (s)                                    37.7677
time/evaluation sampling (s)                              0.624669
time/exploration sampling (s)                             0.0864379
time/logging (s)                                          0.0159299
time/saving (s)                                           0.782038
time/training (s)                                        39.0884
time/epoch (s)                                           78.3652
time/total (s)                                        13631.3
Epoch                                                   189
---------------------------------------------------  -----------------
2021-05-29 03:44:25.495585 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 190 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00270052
trainer/QF2 Loss                                          0.00467074
trainer/Policy Loss                                       2.92869
trainer/Q1 Predictions Mean                              -0.914714
trainer/Q1 Predictions Std                                0.83633
trainer/Q1 Predictions Max                                1.95023
trainer/Q1 Predictions Min                               -3.36447
trainer/Q2 Predictions Mean                              -0.899768
trainer/Q2 Predictions Std                                0.845825
trainer/Q2 Predictions Max                                1.78128
trainer/Q2 Predictions Min                               -3.53786
trainer/Q Targets Mean                                   -0.905793
trainer/Q Targets Std                                     0.835534
trainer/Q Targets Max                                     1.90723
trainer/Q Targets Min                                    -3.31913
trainer/Log Pis Mean                                      2.04415
trainer/Log Pis Std                                       1.06629
trainer/Log Pis Max                                       5.10879
trainer/Log Pis Min                                      -2.35945
trainer/Policy mu Mean                                   -0.039033
trainer/Policy mu Std                                     0.391505
trainer/Policy mu Max                                     1.72243
trainer/Policy mu Min                                    -2.71742
trainer/Policy log std Mean                              -2.25914
trainer/Policy log std Std                                0.428008
trainer/Policy log std Max                               -0.327296
trainer/Policy log std Min                               -3.13145
trainer/Alpha                                             0.0185522
trainer/Alpha Loss                                        0.176092
exploration/num steps total                           20100
exploration/num paths total                            1005
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0990119
exploration/Rewards Std                                   0.077121
exploration/Rewards Max                                   0.0710411
exploration/Rewards Min                                  -0.292236
exploration/Returns Mean                                 -1.98024
exploration/Returns Std                                   1.14723
exploration/Returns Max                                  -0.68452
exploration/Returns Min                                  -3.95482
exploration/Actions Mean                                 -0.0138997
exploration/Actions Std                                   0.140147
exploration/Actions Max                                   0.55067
exploration/Actions Min                                  -0.613151
exploration/Num Paths                                     5
exploration/Average Returns                              -1.98024
exploration/env_infos/final/reward_energy Mean           -0.206225
exploration/env_infos/final/reward_energy Std             0.139883
exploration/env_infos/final/reward_energy Max            -0.0479693
exploration/env_infos/final/reward_energy Min            -0.443271
exploration/env_infos/initial/reward_energy Mean         -0.271816
exploration/env_infos/initial/reward_energy Std           0.156091
exploration/env_infos/initial/reward_energy Max          -0.0334563
exploration/env_infos/initial/reward_energy Min          -0.471131
exploration/env_infos/reward_energy Mean                 -0.155792
exploration/env_infos/reward_energy Std                   0.124086
exploration/env_infos/reward_energy Max                  -0.00519585
exploration/env_infos/reward_energy Min                  -0.642133
exploration/env_infos/final/end_effector_loc Mean        -0.00561649
exploration/env_infos/final/end_effector_loc Std          0.243865
exploration/env_infos/final/end_effector_loc Max          0.394592
exploration/env_infos/final/end_effector_loc Min         -0.51788
exploration/env_infos/initial/end_effector_loc Mean       0.00448917
exploration/env_infos/initial/end_effector_loc Std        0.010132
exploration/env_infos/initial/end_effector_loc Max        0.0174802
exploration/env_infos/initial/end_effector_loc Min       -0.0176065
exploration/env_infos/end_effector_loc Mean               0.0247545
exploration/env_infos/end_effector_loc Std                0.172265
exploration/env_infos/end_effector_loc Max                0.394592
exploration/env_infos/end_effector_loc Min               -0.51788
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.156351
exploration/env_infos/final/reward_dist Std               0.312257
exploration/env_infos/final/reward_dist Max               0.780864
exploration/env_infos/final/reward_dist Min               2.02183e-08
exploration/env_infos/initial/reward_dist Mean            0.00274661
exploration/env_infos/initial/reward_dist Std             0.00365935
exploration/env_infos/initial/reward_dist Max             0.00993123
exploration/env_infos/initial/reward_dist Min             4.36667e-06
exploration/env_infos/reward_dist Mean                    0.057777
exploration/env_infos/reward_dist Std                     0.124986
exploration/env_infos/reward_dist Max                     0.780864
exploration/env_infos/reward_dist Min                     2.02183e-08
evaluation/num steps total                           191000
evaluation/num paths total                             9550
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.056086
evaluation/Rewards Std                                    0.0868989
evaluation/Rewards Max                                    0.144308
evaluation/Rewards Min                                   -0.633063
evaluation/Returns Mean                                  -1.12172
evaluation/Returns Std                                    1.33557
evaluation/Returns Max                                    1.03639
evaluation/Returns Min                                   -5.65913
evaluation/Actions Mean                                  -0.00629441
evaluation/Actions Std                                    0.0857989
evaluation/Actions Max                                    0.666201
evaluation/Actions Min                                   -0.705973
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.12172
evaluation/env_infos/final/reward_energy Mean            -0.0771829
evaluation/env_infos/final/reward_energy Std              0.0903274
evaluation/env_infos/final/reward_energy Max             -0.00402808
evaluation/env_infos/final/reward_energy Min             -0.597325
evaluation/env_infos/initial/reward_energy Mean          -0.260049
evaluation/env_infos/initial/reward_energy Std            0.197163
evaluation/env_infos/initial/reward_energy Max           -0.0124838
evaluation/env_infos/initial/reward_energy Min           -0.803045
evaluation/env_infos/reward_energy Mean                  -0.0798472
evaluation/env_infos/reward_energy Std                    0.0917962
evaluation/env_infos/reward_energy Max                   -0.00194984
evaluation/env_infos/reward_energy Min                   -0.803045
evaluation/env_infos/final/end_effector_loc Mean         -0.017671
evaluation/env_infos/final/end_effector_loc Std           0.256118
evaluation/env_infos/final/end_effector_loc Max           0.562806
evaluation/env_infos/final/end_effector_loc Min          -0.737717
evaluation/env_infos/initial/end_effector_loc Mean        0.000751735
evaluation/env_infos/initial/end_effector_loc Std         0.0115134
evaluation/env_infos/initial/end_effector_loc Max         0.0333101
evaluation/env_infos/initial/end_effector_loc Min        -0.0352987
evaluation/env_infos/end_effector_loc Mean                0.000111857
evaluation/env_infos/end_effector_loc Std                 0.164926
evaluation/env_infos/end_effector_loc Max                 0.562806
evaluation/env_infos/end_effector_loc Min                -0.737717
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.110148
evaluation/env_infos/final/reward_dist Std                0.234725
evaluation/env_infos/final/reward_dist Max                0.920871
evaluation/env_infos/final/reward_dist Min                5.35595e-54
evaluation/env_infos/initial/reward_dist Mean             0.00517796
evaluation/env_infos/initial/reward_dist Std              0.0089494
evaluation/env_infos/initial/reward_dist Max              0.0374095
evaluation/env_infos/initial/reward_dist Min              1.53735e-06
evaluation/env_infos/reward_dist Mean                     0.155799
evaluation/env_infos/reward_dist Std                      0.248732
evaluation/env_infos/reward_dist Max                      0.996304
evaluation/env_infos/reward_dist Min                      5.35595e-54
time/data storing (s)                                    38.1105
time/evaluation sampling (s)                              0.642823
time/exploration sampling (s)                             0.0873175
time/logging (s)                                          0.0141167
time/saving (s)                                           0.781541
time/training (s)                                        39.0384
time/epoch (s)                                           78.6747
time/total (s)                                        13712
Epoch                                                   190
---------------------------------------------------  ----------------
2021-05-29 03:45:45.316166 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 191 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0045309
trainer/QF2 Loss                                          0.00247416
trainer/Policy Loss                                       2.87829
trainer/Q1 Predictions Mean                              -0.871018
trainer/Q1 Predictions Std                                0.873562
trainer/Q1 Predictions Max                                1.97568
trainer/Q1 Predictions Min                               -3.97602
trainer/Q2 Predictions Mean                              -0.860741
trainer/Q2 Predictions Std                                0.868718
trainer/Q2 Predictions Max                                2.04522
trainer/Q2 Predictions Min                               -4.00815
trainer/Q Targets Mean                                   -0.878143
trainer/Q Targets Std                                     0.865099
trainer/Q Targets Max                                     1.96745
trainer/Q Targets Min                                    -3.94157
trainer/Log Pis Mean                                      2.04145
trainer/Log Pis Std                                       1.07109
trainer/Log Pis Max                                       3.96967
trainer/Log Pis Min                                      -3.06192
trainer/Policy mu Mean                                    0.0268493
trainer/Policy mu Std                                     0.387549
trainer/Policy mu Max                                     2.68592
trainer/Policy mu Min                                    -3.63225
trainer/Policy log std Mean                              -2.31985
trainer/Policy log std Std                                0.400758
trainer/Policy log std Max                                0.0336431
trainer/Policy log std Min                               -3.03877
trainer/Alpha                                             0.018755
trainer/Alpha Loss                                        0.164775
exploration/num steps total                           20200
exploration/num paths total                            1010
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0228975
exploration/Rewards Std                                   0.111791
exploration/Rewards Max                                   0.154261
exploration/Rewards Min                                  -0.40518
exploration/Returns Mean                                 -0.457951
exploration/Returns Std                                   1.93371
exploration/Returns Max                                   1.76342
exploration/Returns Min                                  -3.732
exploration/Actions Mean                                 -0.00333281
exploration/Actions Std                                   0.141331
exploration/Actions Max                                   0.436627
exploration/Actions Min                                  -0.432821
exploration/Num Paths                                     5
exploration/Average Returns                              -0.457951
exploration/env_infos/final/reward_energy Mean           -0.245715
exploration/env_infos/final/reward_energy Std             0.145814
exploration/env_infos/final/reward_energy Max            -0.0759543
exploration/env_infos/final/reward_energy Min            -0.466491
exploration/env_infos/initial/reward_energy Mean         -0.270415
exploration/env_infos/initial/reward_energy Std           0.153488
exploration/env_infos/initial/reward_energy Max          -0.039515
exploration/env_infos/initial/reward_energy Min          -0.445692
exploration/env_infos/reward_energy Mean                 -0.174146
exploration/env_infos/reward_energy Std                   0.098204
exploration/env_infos/reward_energy Max                  -0.00544176
exploration/env_infos/reward_energy Min                  -0.466491
exploration/env_infos/final/end_effector_loc Mean        -0.041376
exploration/env_infos/final/end_effector_loc Std          0.387477
exploration/env_infos/final/end_effector_loc Max          0.470751
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.000959533
exploration/env_infos/initial/end_effector_loc Std        0.0109514
exploration/env_infos/initial/end_effector_loc Max        0.0218313
exploration/env_infos/initial/end_effector_loc Min       -0.021641
exploration/env_infos/end_effector_loc Mean              -0.0281492
exploration/env_infos/end_effector_loc Std                0.263467
exploration/env_infos/end_effector_loc Max                0.470751
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.124528
exploration/env_infos/final/reward_dist Std               0.243173
exploration/env_infos/final/reward_dist Max               0.610842
exploration/env_infos/final/reward_dist Min               3.31499e-48
exploration/env_infos/initial/reward_dist Mean            0.00238909
exploration/env_infos/initial/reward_dist Std             0.00328954
exploration/env_infos/initial/reward_dist Max             0.00883883
exploration/env_infos/initial/reward_dist Min             8.03948e-06
exploration/env_infos/reward_dist Mean                    0.209968
exploration/env_infos/reward_dist Std                     0.270654
exploration/env_infos/reward_dist Max                     0.898178
exploration/env_infos/reward_dist Min                     3.31499e-48
evaluation/num steps total                           192000
evaluation/num paths total                             9600
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0559248
evaluation/Rewards Std                                    0.0879116
evaluation/Rewards Max                                    0.1161
evaluation/Rewards Min                                   -0.44981
evaluation/Returns Mean                                  -1.1185
evaluation/Returns Std                                    1.43889
evaluation/Returns Max                                    1.4155
evaluation/Returns Min                                   -5.75622
evaluation/Actions Mean                                   0.00477479
evaluation/Actions Std                                    0.0985714
evaluation/Actions Max                                    0.890593
evaluation/Actions Min                                   -0.903923
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.1185
evaluation/env_infos/final/reward_energy Mean            -0.067509
evaluation/env_infos/final/reward_energy Std              0.0722858
evaluation/env_infos/final/reward_energy Max             -0.00639749
evaluation/env_infos/final/reward_energy Min             -0.363624
evaluation/env_infos/initial/reward_energy Mean          -0.293599
evaluation/env_infos/initial/reward_energy Std            0.210494
evaluation/env_infos/initial/reward_energy Max           -0.0396134
evaluation/env_infos/initial/reward_energy Min           -0.915355
evaluation/env_infos/reward_energy Mean                  -0.0907631
evaluation/env_infos/reward_energy Std                    0.10602
evaluation/env_infos/reward_energy Max                   -0.00115841
evaluation/env_infos/reward_energy Min                   -1.06461
evaluation/env_infos/final/end_effector_loc Mean          0.100399
evaluation/env_infos/final/end_effector_loc Std           0.324243
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00183026
evaluation/env_infos/initial/end_effector_loc Std         0.0126406
evaluation/env_infos/initial/end_effector_loc Max         0.0381426
evaluation/env_infos/initial/end_effector_loc Min        -0.0451961
evaluation/env_infos/end_effector_loc Mean                0.0572161
evaluation/env_infos/end_effector_loc Std                 0.221843
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.111232
evaluation/env_infos/final/reward_dist Std                0.202989
evaluation/env_infos/final/reward_dist Max                0.772903
evaluation/env_infos/final/reward_dist Min                1.63167e-166
evaluation/env_infos/initial/reward_dist Mean             0.0106224
evaluation/env_infos/initial/reward_dist Std              0.0185547
evaluation/env_infos/initial/reward_dist Max              0.0852475
evaluation/env_infos/initial/reward_dist Min              2.50383e-06
evaluation/env_infos/reward_dist Mean                     0.152794
evaluation/env_infos/reward_dist Std                      0.242505
evaluation/env_infos/reward_dist Max                      0.978448
evaluation/env_infos/reward_dist Min                      1.63167e-166
time/data storing (s)                                    37.8385
time/evaluation sampling (s)                              0.567849
time/exploration sampling (s)                             0.0831546
time/logging (s)                                          0.0144434
time/saving (s)                                           0.775836
time/training (s)                                        38.5525
time/epoch (s)                                           77.8323
time/total (s)                                        13791.9
Epoch                                                   191
---------------------------------------------------  -----------------
2021-05-29 03:47:06.562678 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 192 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00350701
trainer/QF2 Loss                                          0.00270971
trainer/Policy Loss                                       2.87966
trainer/Q1 Predictions Mean                              -0.840023
trainer/Q1 Predictions Std                                0.837071
trainer/Q1 Predictions Max                                0.935823
trainer/Q1 Predictions Min                               -4.14265
trainer/Q2 Predictions Mean                              -0.867631
trainer/Q2 Predictions Std                                0.845096
trainer/Q2 Predictions Max                                0.921716
trainer/Q2 Predictions Min                               -4.22539
trainer/Q Targets Mean                                   -0.859194
trainer/Q Targets Std                                     0.847344
trainer/Q Targets Max                                     0.911791
trainer/Q Targets Min                                    -4.19063
trainer/Log Pis Mean                                      2.03488
trainer/Log Pis Std                                       1.16331
trainer/Log Pis Max                                       4.18599
trainer/Log Pis Min                                      -3.49901
trainer/Policy mu Mean                                   -0.00506421
trainer/Policy mu Std                                     0.355586
trainer/Policy mu Max                                     2.37968
trainer/Policy mu Min                                    -3.48967
trainer/Policy log std Mean                              -2.32397
trainer/Policy log std Std                                0.373685
trainer/Policy log std Max                                0.0361127
trainer/Policy log std Min                               -3.21545
trainer/Alpha                                             0.0181842
trainer/Alpha Loss                                        0.139757
exploration/num steps total                           20300
exploration/num paths total                            1015
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0707342
exploration/Rewards Std                                   0.113225
exploration/Rewards Max                                   0.117155
exploration/Rewards Min                                  -0.479334
exploration/Returns Mean                                 -1.41468
exploration/Returns Std                                   1.60278
exploration/Returns Max                                   0.457169
exploration/Returns Min                                  -3.8182
exploration/Actions Mean                                 -0.0275025
exploration/Actions Std                                   0.12891
exploration/Actions Max                                   0.394187
exploration/Actions Min                                  -0.391321
exploration/Num Paths                                     5
exploration/Average Returns                              -1.41468
exploration/env_infos/final/reward_energy Mean           -0.132898
exploration/env_infos/final/reward_energy Std             0.0732035
exploration/env_infos/final/reward_energy Max            -0.0433202
exploration/env_infos/final/reward_energy Min            -0.263417
exploration/env_infos/initial/reward_energy Mean         -0.225721
exploration/env_infos/initial/reward_energy Std           0.146664
exploration/env_infos/initial/reward_energy Max          -0.0811712
exploration/env_infos/initial/reward_energy Min          -0.464541
exploration/env_infos/reward_energy Mean                 -0.1521
exploration/env_infos/reward_energy Std                   0.107767
exploration/env_infos/reward_energy Max                  -0.00869325
exploration/env_infos/reward_energy Min                  -0.464541
exploration/env_infos/final/end_effector_loc Mean        -0.0808395
exploration/env_infos/final/end_effector_loc Std          0.255247
exploration/env_infos/final/end_effector_loc Max          0.254683
exploration/env_infos/final/end_effector_loc Min         -0.689415
exploration/env_infos/initial/end_effector_loc Mean       0.00462359
exploration/env_infos/initial/end_effector_loc Std        0.00831854
exploration/env_infos/initial/end_effector_loc Max        0.0197093
exploration/env_infos/initial/end_effector_loc Min       -0.0077736
exploration/env_infos/end_effector_loc Mean               0.0276868
exploration/env_infos/end_effector_loc Std                0.137422
exploration/env_infos/end_effector_loc Max                0.273367
exploration/env_infos/end_effector_loc Min               -0.689415
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.173448
exploration/env_infos/final/reward_dist Std               0.300271
exploration/env_infos/final/reward_dist Max               0.771098
exploration/env_infos/final/reward_dist Min               2.23551e-27
exploration/env_infos/initial/reward_dist Mean            0.0182482
exploration/env_infos/initial/reward_dist Std             0.0173559
exploration/env_infos/initial/reward_dist Max             0.0435414
exploration/env_infos/initial/reward_dist Min             4.31367e-05
exploration/env_infos/reward_dist Mean                    0.173757
exploration/env_infos/reward_dist Std                     0.277086
exploration/env_infos/reward_dist Max                     0.962498
exploration/env_infos/reward_dist Min                     2.23551e-27
evaluation/num steps total                           193000
evaluation/num paths total                             9650
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0574096
evaluation/Rewards Std                                    0.0789422
evaluation/Rewards Max                                    0.15971
evaluation/Rewards Min                                   -0.446997
evaluation/Returns Mean                                  -1.14819
evaluation/Returns Std                                    1.19216
evaluation/Returns Max                                    1.3048
evaluation/Returns Min                                   -4.79066
evaluation/Actions Mean                                  -0.00787062
evaluation/Actions Std                                    0.0989172
evaluation/Actions Max                                    0.600497
evaluation/Actions Min                                   -0.727346
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.14819
evaluation/env_infos/final/reward_energy Mean            -0.0626541
evaluation/env_infos/final/reward_energy Std              0.0915238
evaluation/env_infos/final/reward_energy Max             -0.00141682
evaluation/env_infos/final/reward_energy Min             -0.595338
evaluation/env_infos/initial/reward_energy Mean          -0.321336
evaluation/env_infos/initial/reward_energy Std            0.21038
evaluation/env_infos/initial/reward_energy Max           -0.0210131
evaluation/env_infos/initial/reward_energy Min           -0.925867
evaluation/env_infos/reward_energy Mean                  -0.0930652
evaluation/env_infos/reward_energy Std                    0.105033
evaluation/env_infos/reward_energy Max                   -0.00141682
evaluation/env_infos/reward_energy Min                   -0.925867
evaluation/env_infos/final/end_effector_loc Mean         -0.0189186
evaluation/env_infos/final/end_effector_loc Std           0.279852
evaluation/env_infos/final/end_effector_loc Max           0.536253
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000445858
evaluation/env_infos/initial/end_effector_loc Std         0.0135719
evaluation/env_infos/initial/end_effector_loc Max         0.0300248
evaluation/env_infos/initial/end_effector_loc Min        -0.0334239
evaluation/env_infos/end_effector_loc Mean                0.00590489
evaluation/env_infos/end_effector_loc Std                 0.18796
evaluation/env_infos/end_effector_loc Max                 0.536253
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.136527
evaluation/env_infos/final/reward_dist Std                0.25411
evaluation/env_infos/final/reward_dist Max                0.963483
evaluation/env_infos/final/reward_dist Min                5.73082e-71
evaluation/env_infos/initial/reward_dist Mean             0.00520441
evaluation/env_infos/initial/reward_dist Std              0.00960919
evaluation/env_infos/initial/reward_dist Max              0.0473697
evaluation/env_infos/initial/reward_dist Min              1.59743e-06
evaluation/env_infos/reward_dist Mean                     0.170557
evaluation/env_infos/reward_dist Std                      0.264335
evaluation/env_infos/reward_dist Max                      0.996623
evaluation/env_infos/reward_dist Min                      5.73082e-71
time/data storing (s)                                    38.0989
time/evaluation sampling (s)                              0.634171
time/exploration sampling (s)                             0.0871787
time/logging (s)                                          0.0160714
time/saving (s)                                           0.788169
time/training (s)                                        39.5942
time/epoch (s)                                           79.2186
time/total (s)                                        13873.1
Epoch                                                   192
---------------------------------------------------  ----------------
2021-05-29 03:48:27.331943 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 193 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00242515
trainer/QF2 Loss                                          0.00304872
trainer/Policy Loss                                       2.66004
trainer/Q1 Predictions Mean                              -0.727336
trainer/Q1 Predictions Std                                0.788241
trainer/Q1 Predictions Max                                0.686392
trainer/Q1 Predictions Min                               -4.45973
trainer/Q2 Predictions Mean                              -0.738425
trainer/Q2 Predictions Std                                0.790244
trainer/Q2 Predictions Max                                0.662643
trainer/Q2 Predictions Min                               -4.50433
trainer/Q Targets Mean                                   -0.724489
trainer/Q Targets Std                                     0.794484
trainer/Q Targets Max                                     0.673483
trainer/Q Targets Min                                    -4.50084
trainer/Log Pis Mean                                      1.95528
trainer/Log Pis Std                                       1.28899
trainer/Log Pis Max                                       8.03664
trainer/Log Pis Min                                      -2.519
trainer/Policy mu Mean                                   -0.0554913
trainer/Policy mu Std                                     0.527455
trainer/Policy mu Max                                     2.63717
trainer/Policy mu Min                                    -3.28859
trainer/Policy log std Mean                              -2.24709
trainer/Policy log std Std                                0.480306
trainer/Policy log std Max                               -0.0259352
trainer/Policy log std Min                               -3.29817
trainer/Alpha                                             0.0177127
trainer/Alpha Loss                                       -0.180409
exploration/num steps total                           20400
exploration/num paths total                            1020
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.221667
exploration/Rewards Std                                   0.279313
exploration/Rewards Max                                   0.0467671
exploration/Rewards Min                                  -0.986466
exploration/Returns Mean                                 -4.43334
exploration/Returns Std                                   5.25159
exploration/Returns Max                                  -0.467802
exploration/Returns Min                                 -14.5074
exploration/Actions Mean                                 -0.102929
exploration/Actions Std                                   0.330916
exploration/Actions Max                                   0.908994
exploration/Actions Min                                  -0.999846
exploration/Num Paths                                     5
exploration/Average Returns                              -4.43334
exploration/env_infos/final/reward_energy Mean           -0.324103
exploration/env_infos/final/reward_energy Std             0.391197
exploration/env_infos/final/reward_energy Max            -0.0253306
exploration/env_infos/final/reward_energy Min            -1.06581
exploration/env_infos/initial/reward_energy Mean         -0.629714
exploration/env_infos/initial/reward_energy Std           0.393083
exploration/env_infos/initial/reward_energy Max          -0.0873165
exploration/env_infos/initial/reward_energy Min          -1.23152
exploration/env_infos/reward_energy Mean                 -0.349072
exploration/env_infos/reward_energy Std                   0.344019
exploration/env_infos/reward_energy Max                  -0.0188617
exploration/env_infos/reward_energy Min                  -1.23152
exploration/env_infos/final/end_effector_loc Mean        -0.219621
exploration/env_infos/final/end_effector_loc Std          0.449667
exploration/env_infos/final/end_effector_loc Max          0.315769
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00567795
exploration/env_infos/initial/end_effector_loc Std        0.0256238
exploration/env_infos/initial/end_effector_loc Max        0.0454497
exploration/env_infos/initial/end_effector_loc Min       -0.041544
exploration/env_infos/end_effector_loc Mean              -0.133199
exploration/env_infos/end_effector_loc Std                0.347966
exploration/env_infos/end_effector_loc Max                0.315769
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.180436
exploration/env_infos/final/reward_dist Std               0.319981
exploration/env_infos/final/reward_dist Max               0.816987
exploration/env_infos/final/reward_dist Min               3.43625e-68
exploration/env_infos/initial/reward_dist Mean            0.027981
exploration/env_infos/initial/reward_dist Std             0.0444768
exploration/env_infos/initial/reward_dist Max             0.116274
exploration/env_infos/initial/reward_dist Min             9.4425e-05
exploration/env_infos/reward_dist Mean                    0.142237
exploration/env_infos/reward_dist Std                     0.250259
exploration/env_infos/reward_dist Max                     0.982701
exploration/env_infos/reward_dist Min                     3.43625e-68
evaluation/num steps total                           194000
evaluation/num paths total                             9700
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.11
evaluation/Rewards Std                                    0.135601
evaluation/Rewards Max                                    0.123536
evaluation/Rewards Min                                   -0.890186
evaluation/Returns Mean                                  -2.2
evaluation/Returns Std                                    2.27614
evaluation/Returns Max                                    1.10217
evaluation/Returns Min                                  -10.2169
evaluation/Actions Mean                                  -0.00336381
evaluation/Actions Std                                    0.143497
evaluation/Actions Max                                    0.966078
evaluation/Actions Min                                   -0.816813
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.2
evaluation/env_infos/final/reward_energy Mean            -0.0992141
evaluation/env_infos/final/reward_energy Std              0.140383
evaluation/env_infos/final/reward_energy Max             -0.00485765
evaluation/env_infos/final/reward_energy Min             -0.671456
evaluation/env_infos/initial/reward_energy Mean          -0.34843
evaluation/env_infos/initial/reward_energy Std            0.272676
evaluation/env_infos/initial/reward_energy Max           -0.0118991
evaluation/env_infos/initial/reward_energy Min           -1.01533
evaluation/env_infos/reward_energy Mean                  -0.125301
evaluation/env_infos/reward_energy Std                    0.159702
evaluation/env_infos/reward_energy Max                   -0.0004962
evaluation/env_infos/reward_energy Min                   -1.08217
evaluation/env_infos/final/end_effector_loc Mean          0.0733817
evaluation/env_infos/final/end_effector_loc Std           0.42591
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000948918
evaluation/env_infos/initial/end_effector_loc Std         0.0156139
evaluation/env_infos/initial/end_effector_loc Max         0.0483039
evaluation/env_infos/initial/end_effector_loc Min        -0.0349906
evaluation/env_infos/end_effector_loc Mean                0.0304728
evaluation/env_infos/end_effector_loc Std                 0.305168
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.111678
evaluation/env_infos/final/reward_dist Std                0.225148
evaluation/env_infos/final/reward_dist Max                0.886604
evaluation/env_infos/final/reward_dist Min                5.08692e-187
evaluation/env_infos/initial/reward_dist Mean             0.00685229
evaluation/env_infos/initial/reward_dist Std              0.0143671
evaluation/env_infos/initial/reward_dist Max              0.0737589
evaluation/env_infos/initial/reward_dist Min              1.93665e-07
evaluation/env_infos/reward_dist Mean                     0.131942
evaluation/env_infos/reward_dist Std                      0.237001
evaluation/env_infos/reward_dist Max                      0.983841
evaluation/env_infos/reward_dist Min                      5.08692e-187
time/data storing (s)                                    37.981
time/evaluation sampling (s)                              0.640674
time/exploration sampling (s)                             0.0897563
time/logging (s)                                          0.0143525
time/saving (s)                                           0.772739
time/training (s)                                        39.163
time/epoch (s)                                           78.6615
time/total (s)                                        13953.9
Epoch                                                   193
---------------------------------------------------  -----------------
2021-05-29 03:49:47.226120 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 194 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0036476
trainer/QF2 Loss                                          0.00228879
trainer/Policy Loss                                       2.84503
trainer/Q1 Predictions Mean                              -0.698324
trainer/Q1 Predictions Std                                0.777628
trainer/Q1 Predictions Max                                0.7613
trainer/Q1 Predictions Min                               -4.28753
trainer/Q2 Predictions Mean                              -0.705158
trainer/Q2 Predictions Std                                0.77944
trainer/Q2 Predictions Max                                0.727745
trainer/Q2 Predictions Min                               -4.34985
trainer/Q Targets Mean                                   -0.697695
trainer/Q Targets Std                                     0.786166
trainer/Q Targets Max                                     0.737017
trainer/Q Targets Min                                    -4.32415
trainer/Log Pis Mean                                      2.17379
trainer/Log Pis Std                                       1.13128
trainer/Log Pis Max                                       7.7072
trainer/Log Pis Min                                      -2.39581
trainer/Policy mu Mean                                    0.0267548
trainer/Policy mu Std                                     0.407638
trainer/Policy mu Max                                     3.53119
trainer/Policy mu Min                                    -1.91378
trainer/Policy log std Mean                              -2.35988
trainer/Policy log std Std                                0.396714
trainer/Policy log std Max                               -0.638622
trainer/Policy log std Min                               -3.22142
trainer/Alpha                                             0.0164233
trainer/Alpha Loss                                        0.714548
exploration/num steps total                           20500
exploration/num paths total                            1025
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0845696
exploration/Rewards Std                                   0.0631569
exploration/Rewards Max                                   0.0746417
exploration/Rewards Min                                  -0.258434
exploration/Returns Mean                                 -1.69139
exploration/Returns Std                                   0.937991
exploration/Returns Max                                   0.055859
exploration/Returns Min                                  -2.56535
exploration/Actions Mean                                 -0.00287871
exploration/Actions Std                                   0.114607
exploration/Actions Max                                   0.489625
exploration/Actions Min                                  -0.499618
exploration/Num Paths                                     5
exploration/Average Returns                              -1.69139
exploration/env_infos/final/reward_energy Mean           -0.109597
exploration/env_infos/final/reward_energy Std             0.0938612
exploration/env_infos/final/reward_energy Max            -0.0200383
exploration/env_infos/final/reward_energy Min            -0.25235
exploration/env_infos/initial/reward_energy Mean         -0.22937
exploration/env_infos/initial/reward_energy Std           0.167735
exploration/env_infos/initial/reward_energy Max          -0.0539548
exploration/env_infos/initial/reward_energy Min          -0.533284
exploration/env_infos/reward_energy Mean                 -0.123151
exploration/env_infos/reward_energy Std                   0.10545
exploration/env_infos/reward_energy Max                  -0.0194658
exploration/env_infos/reward_energy Min                  -0.570515
exploration/env_infos/final/end_effector_loc Mean         0.0314893
exploration/env_infos/final/end_effector_loc Std          0.245682
exploration/env_infos/final/end_effector_loc Max          0.441862
exploration/env_infos/final/end_effector_loc Min         -0.39817
exploration/env_infos/initial/end_effector_loc Mean      -0.000257852
exploration/env_infos/initial/end_effector_loc Std        0.0100432
exploration/env_infos/initial/end_effector_loc Max        0.0244813
exploration/env_infos/initial/end_effector_loc Min       -0.0125194
exploration/env_infos/end_effector_loc Mean               0.0262061
exploration/env_infos/end_effector_loc Std                0.148354
exploration/env_infos/end_effector_loc Max                0.441862
exploration/env_infos/end_effector_loc Min               -0.39817
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.136885
exploration/env_infos/final/reward_dist Std               0.262221
exploration/env_infos/final/reward_dist Max               0.661039
exploration/env_infos/final/reward_dist Min               1.04941e-52
exploration/env_infos/initial/reward_dist Mean            0.0155006
exploration/env_infos/initial/reward_dist Std             0.0248068
exploration/env_infos/initial/reward_dist Max             0.0642499
exploration/env_infos/initial/reward_dist Min             2.63969e-06
exploration/env_infos/reward_dist Mean                    0.129616
exploration/env_infos/reward_dist Std                     0.273665
exploration/env_infos/reward_dist Max                     0.954223
exploration/env_infos/reward_dist Min                     1.04941e-52
evaluation/num steps total                           195000
evaluation/num paths total                             9750
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0779887
evaluation/Rewards Std                                    0.0992231
evaluation/Rewards Max                                    0.118975
evaluation/Rewards Min                                   -0.564239
evaluation/Returns Mean                                  -1.55977
evaluation/Returns Std                                    1.62533
evaluation/Returns Max                                    1.18297
evaluation/Returns Min                                   -5.83382
evaluation/Actions Mean                                  -0.00522246
evaluation/Actions Std                                    0.107291
evaluation/Actions Max                                    0.802604
evaluation/Actions Min                                   -0.898975
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.55977
evaluation/env_infos/final/reward_energy Mean            -0.0645691
evaluation/env_infos/final/reward_energy Std              0.109442
evaluation/env_infos/final/reward_energy Max             -0.0021367
evaluation/env_infos/final/reward_energy Min             -0.75192
evaluation/env_infos/initial/reward_energy Mean          -0.269496
evaluation/env_infos/initial/reward_energy Std            0.199844
evaluation/env_infos/initial/reward_energy Max           -0.0210133
evaluation/env_infos/initial/reward_energy Min           -1.06569
evaluation/env_infos/reward_energy Mean                  -0.101483
evaluation/env_infos/reward_energy Std                    0.113041
evaluation/env_infos/reward_energy Max                   -0.000947325
evaluation/env_infos/reward_energy Min                   -1.06569
evaluation/env_infos/final/end_effector_loc Mean          0.000317001
evaluation/env_infos/final/end_effector_loc Std           0.301978
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000876175
evaluation/env_infos/initial/end_effector_loc Std         0.0118296
evaluation/env_infos/initial/end_effector_loc Max         0.0333005
evaluation/env_infos/initial/end_effector_loc Min        -0.0449487
evaluation/env_infos/end_effector_loc Mean                0.013987
evaluation/env_infos/end_effector_loc Std                 0.204108
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.123435
evaluation/env_infos/final/reward_dist Std                0.241607
evaluation/env_infos/final/reward_dist Max                0.889845
evaluation/env_infos/final/reward_dist Min                1.81734e-102
evaluation/env_infos/initial/reward_dist Mean             0.00413243
evaluation/env_infos/initial/reward_dist Std              0.0102839
evaluation/env_infos/initial/reward_dist Max              0.0625049
evaluation/env_infos/initial/reward_dist Min              1.01349e-07
evaluation/env_infos/reward_dist Mean                     0.142318
evaluation/env_infos/reward_dist Std                      0.240054
evaluation/env_infos/reward_dist Max                      0.998582
evaluation/env_infos/reward_dist Min                      1.81734e-102
time/data storing (s)                                    37.6427
time/evaluation sampling (s)                              0.520788
time/exploration sampling (s)                             0.0867998
time/logging (s)                                          0.0162552
time/saving (s)                                           0.797014
time/training (s)                                        38.8135
time/epoch (s)                                           77.8771
time/total (s)                                        14033.7
Epoch                                                   194
---------------------------------------------------  -----------------
2021-05-29 03:51:32.223962 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 195 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00258124
trainer/QF2 Loss                                          0.00283321
trainer/Policy Loss                                       2.65395
trainer/Q1 Predictions Mean                              -0.658473
trainer/Q1 Predictions Std                                0.716559
trainer/Q1 Predictions Max                                0.956936
trainer/Q1 Predictions Min                               -2.97911
trainer/Q2 Predictions Mean                              -0.672318
trainer/Q2 Predictions Std                                0.717212
trainer/Q2 Predictions Max                                0.943517
trainer/Q2 Predictions Min                               -3.02774
trainer/Q Targets Mean                                   -0.666724
trainer/Q Targets Std                                     0.716443
trainer/Q Targets Max                                     0.926591
trainer/Q Targets Min                                    -3.03655
trainer/Log Pis Mean                                      1.99996
trainer/Log Pis Std                                       1.28967
trainer/Log Pis Max                                       4.16531
trainer/Log Pis Min                                      -4.50487
trainer/Policy mu Mean                                   -0.00186325
trainer/Policy mu Std                                     0.281072
trainer/Policy mu Max                                     2.04807
trainer/Policy mu Min                                    -2.05118
trainer/Policy log std Mean                              -2.35067
trainer/Policy log std Std                                0.386778
trainer/Policy log std Max                               -0.844743
trainer/Policy log std Min                               -3.21645
trainer/Alpha                                             0.0180359
trainer/Alpha Loss                                       -0.000178035
exploration/num steps total                           20600
exploration/num paths total                            1030
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.082182
exploration/Rewards Std                                   0.0854953
exploration/Rewards Max                                   0.0770301
exploration/Rewards Min                                  -0.328941
exploration/Returns Mean                                 -1.64364
exploration/Returns Std                                   1.16185
exploration/Returns Max                                  -0.394616
exploration/Returns Min                                  -3.80748
exploration/Actions Mean                                 -0.00190654
exploration/Actions Std                                   0.224347
exploration/Actions Max                                   0.873619
exploration/Actions Min                                  -0.999948
exploration/Num Paths                                     5
exploration/Average Returns                              -1.64364
exploration/env_infos/final/reward_energy Mean           -0.173764
exploration/env_infos/final/reward_energy Std             0.139067
exploration/env_infos/final/reward_energy Max            -0.0574742
exploration/env_infos/final/reward_energy Min            -0.436633
exploration/env_infos/initial/reward_energy Mean         -0.352905
exploration/env_infos/initial/reward_energy Std           0.340158
exploration/env_infos/initial/reward_energy Max          -0.0700974
exploration/env_infos/initial/reward_energy Min          -1.01347
exploration/env_infos/reward_energy Mean                 -0.214192
exploration/env_infos/reward_energy Std                   0.234076
exploration/env_infos/reward_energy Max                  -0.00937637
exploration/env_infos/reward_energy Min                  -1.03673
exploration/env_infos/final/end_effector_loc Mean        -0.0831348
exploration/env_infos/final/end_effector_loc Std          0.294823
exploration/env_infos/final/end_effector_loc Max          0.248561
exploration/env_infos/final/end_effector_loc Min         -0.701066
exploration/env_infos/initial/end_effector_loc Mean      -0.00522863
exploration/env_infos/initial/end_effector_loc Std        0.0165219
exploration/env_infos/initial/end_effector_loc Max        0.00921791
exploration/env_infos/initial/end_effector_loc Min       -0.0499974
exploration/env_infos/end_effector_loc Mean              -0.0742706
exploration/env_infos/end_effector_loc Std                0.246699
exploration/env_infos/end_effector_loc Max                0.254713
exploration/env_infos/end_effector_loc Min               -0.849476
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.127506
exploration/env_infos/final/reward_dist Std               0.211311
exploration/env_infos/final/reward_dist Max               0.544603
exploration/env_infos/final/reward_dist Min               8.20031e-63
exploration/env_infos/initial/reward_dist Mean            0.000629432
exploration/env_infos/initial/reward_dist Std             0.000688764
exploration/env_infos/initial/reward_dist Max             0.00150122
exploration/env_infos/initial/reward_dist Min             3.77201e-08
exploration/env_infos/reward_dist Mean                    0.130315
exploration/env_infos/reward_dist Std                     0.214333
exploration/env_infos/reward_dist Max                     0.801938
exploration/env_infos/reward_dist Min                     2.22525e-85
evaluation/num steps total                           196000
evaluation/num paths total                             9800
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0876972
evaluation/Rewards Std                                    0.122582
evaluation/Rewards Max                                    0.138042
evaluation/Rewards Min                                   -0.742193
evaluation/Returns Mean                                  -1.75394
evaluation/Returns Std                                    1.98698
evaluation/Returns Max                                    1.72507
evaluation/Returns Min                                   -8.26767
evaluation/Actions Mean                                  -0.0123868
evaluation/Actions Std                                    0.139828
evaluation/Actions Max                                    0.893951
evaluation/Actions Min                                   -0.980184
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.75394
evaluation/env_infos/final/reward_energy Mean            -0.0942559
evaluation/env_infos/final/reward_energy Std              0.0998798
evaluation/env_infos/final/reward_energy Max             -0.00862631
evaluation/env_infos/final/reward_energy Min             -0.489787
evaluation/env_infos/initial/reward_energy Mean          -0.318685
evaluation/env_infos/initial/reward_energy Std            0.25725
evaluation/env_infos/initial/reward_energy Max           -0.0169863
evaluation/env_infos/initial/reward_energy Min           -0.991001
evaluation/env_infos/reward_energy Mean                  -0.124756
evaluation/env_infos/reward_energy Std                    0.154424
evaluation/env_infos/reward_energy Max                   -0.00686737
evaluation/env_infos/reward_energy Min                   -1.07651
evaluation/env_infos/final/end_effector_loc Mean         -0.165917
evaluation/env_infos/final/end_effector_loc Std           0.436407
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00268738
evaluation/env_infos/initial/end_effector_loc Std         0.0142285
evaluation/env_infos/initial/end_effector_loc Max         0.0332184
evaluation/env_infos/initial/end_effector_loc Min        -0.0490092
evaluation/env_infos/end_effector_loc Mean               -0.0771869
evaluation/env_infos/end_effector_loc Std                 0.29603
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0914334
evaluation/env_infos/final/reward_dist Std                0.213603
evaluation/env_infos/final/reward_dist Max                0.953488
evaluation/env_infos/final/reward_dist Min                1.46187e-151
evaluation/env_infos/initial/reward_dist Mean             0.00439346
evaluation/env_infos/initial/reward_dist Std              0.0104064
evaluation/env_infos/initial/reward_dist Max              0.0535889
evaluation/env_infos/initial/reward_dist Min              2.56139e-06
evaluation/env_infos/reward_dist Mean                     0.127554
evaluation/env_infos/reward_dist Std                      0.227978
evaluation/env_infos/reward_dist Max                      0.987689
evaluation/env_infos/reward_dist Min                      1.46187e-151
time/data storing (s)                                    49.3692
time/evaluation sampling (s)                              0.642185
time/exploration sampling (s)                             0.0976062
time/logging (s)                                          0.0299453
time/saving (s)                                           1.46813
time/training (s)                                        51.3051
time/epoch (s)                                          102.912
time/total (s)                                        14138.8
Epoch                                                   195
---------------------------------------------------  -----------------
2021-05-29 03:53:56.295873 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 196 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00362619
trainer/QF2 Loss                                          0.00245516
trainer/Policy Loss                                       2.50841
trainer/Q1 Predictions Mean                              -0.606306
trainer/Q1 Predictions Std                                0.767707
trainer/Q1 Predictions Max                                1.06409
trainer/Q1 Predictions Min                               -3.15139
trainer/Q2 Predictions Mean                              -0.60306
trainer/Q2 Predictions Std                                0.778936
trainer/Q2 Predictions Max                                1.0745
trainer/Q2 Predictions Min                               -3.16821
trainer/Q Targets Mean                                   -0.603763
trainer/Q Targets Std                                     0.775984
trainer/Q Targets Max                                     1.04332
trainer/Q Targets Min                                    -3.23499
trainer/Log Pis Mean                                      1.91826
trainer/Log Pis Std                                       1.08857
trainer/Log Pis Max                                       4.26592
trainer/Log Pis Min                                      -2.01126
trainer/Policy mu Mean                                    0.0682642
trainer/Policy mu Std                                     0.384194
trainer/Policy mu Max                                     2.69378
trainer/Policy mu Min                                    -1.03335
trainer/Policy log std Mean                              -2.26867
trainer/Policy log std Std                                0.443782
trainer/Policy log std Max                               -0.392547
trainer/Policy log std Min                               -3.1699
trainer/Alpha                                             0.0182306
trainer/Alpha Loss                                       -0.327338
exploration/num steps total                           20700
exploration/num paths total                            1035
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.116217
exploration/Rewards Std                                   0.0624943
exploration/Rewards Max                                   0.0285776
exploration/Rewards Min                                  -0.288455
exploration/Returns Mean                                 -2.32435
exploration/Returns Std                                   0.505904
exploration/Returns Max                                  -1.42735
exploration/Returns Min                                  -2.98396
exploration/Actions Mean                                 -0.00294
exploration/Actions Std                                   0.136015
exploration/Actions Max                                   0.473391
exploration/Actions Min                                  -0.7672
exploration/Num Paths                                     5
exploration/Average Returns                              -2.32435
exploration/env_infos/final/reward_energy Mean           -0.0955552
exploration/env_infos/final/reward_energy Std             0.0715346
exploration/env_infos/final/reward_energy Max            -0.0108828
exploration/env_infos/final/reward_energy Min            -0.217049
exploration/env_infos/initial/reward_energy Mean         -0.233274
exploration/env_infos/initial/reward_energy Std           0.321857
exploration/env_infos/initial/reward_energy Max          -0.0483967
exploration/env_infos/initial/reward_energy Min          -0.875599
exploration/env_infos/reward_energy Mean                 -0.138802
exploration/env_infos/reward_energy Std                   0.133234
exploration/env_infos/reward_energy Max                  -0.00655328
exploration/env_infos/reward_energy Min                  -0.875599
exploration/env_infos/final/end_effector_loc Mean         0.077381
exploration/env_infos/final/end_effector_loc Std          0.27818
exploration/env_infos/final/end_effector_loc Max          0.431695
exploration/env_infos/final/end_effector_loc Min         -0.522075
exploration/env_infos/initial/end_effector_loc Mean      -0.0018563
exploration/env_infos/initial/end_effector_loc Std        0.0139307
exploration/env_infos/initial/end_effector_loc Max        0.0210997
exploration/env_infos/initial/end_effector_loc Min       -0.03836
exploration/env_infos/end_effector_loc Mean               0.0495873
exploration/env_infos/end_effector_loc Std                0.154973
exploration/env_infos/end_effector_loc Max                0.431695
exploration/env_infos/end_effector_loc Min               -0.522075
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0185771
exploration/env_infos/final/reward_dist Std               0.0371479
exploration/env_infos/final/reward_dist Max               0.0928728
exploration/env_infos/final/reward_dist Min               2.01091e-12
exploration/env_infos/initial/reward_dist Mean            0.0113394
exploration/env_infos/initial/reward_dist Std             0.0222959
exploration/env_infos/initial/reward_dist Max             0.0559301
exploration/env_infos/initial/reward_dist Min             9.44568e-07
exploration/env_infos/reward_dist Mean                    0.071806
exploration/env_infos/reward_dist Std                     0.173058
exploration/env_infos/reward_dist Max                     0.947691
exploration/env_infos/reward_dist Min                     2.01091e-12
evaluation/num steps total                           197000
evaluation/num paths total                             9850
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0992484
evaluation/Rewards Std                                    0.134818
evaluation/Rewards Max                                    0.161004
evaluation/Rewards Min                                   -0.84737
evaluation/Returns Mean                                  -1.98497
evaluation/Returns Std                                    2.29566
evaluation/Returns Max                                    1.82686
evaluation/Returns Min                                  -12.359
evaluation/Actions Mean                                  -0.00395433
evaluation/Actions Std                                    0.152297
evaluation/Actions Max                                    0.82528
evaluation/Actions Min                                   -0.963095
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.98497
evaluation/env_infos/final/reward_energy Mean            -0.0843466
evaluation/env_infos/final/reward_energy Std              0.108269
evaluation/env_infos/final/reward_energy Max             -0.00977585
evaluation/env_infos/final/reward_energy Min             -0.550979
evaluation/env_infos/initial/reward_energy Mean          -0.416029
evaluation/env_infos/initial/reward_energy Std            0.298734
evaluation/env_infos/initial/reward_energy Max           -0.0165901
evaluation/env_infos/initial/reward_energy Min           -1.08883
evaluation/env_infos/reward_energy Mean                  -0.134438
evaluation/env_infos/reward_energy Std                    0.168365
evaluation/env_infos/reward_energy Max                   -0.00111459
evaluation/env_infos/reward_energy Min                   -1.35881
evaluation/env_infos/final/end_effector_loc Mean         -0.0871787
evaluation/env_infos/final/end_effector_loc Std           0.390551
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00356267
evaluation/env_infos/initial/end_effector_loc Std         0.0177542
evaluation/env_infos/initial/end_effector_loc Max         0.041264
evaluation/env_infos/initial/end_effector_loc Min        -0.0479367
evaluation/env_infos/end_effector_loc Mean               -0.046514
evaluation/env_infos/end_effector_loc Std                 0.271782
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.13825
evaluation/env_infos/final/reward_dist Std                0.271475
evaluation/env_infos/final/reward_dist Max                0.980508
evaluation/env_infos/final/reward_dist Min                3.79689e-117
evaluation/env_infos/initial/reward_dist Mean             0.0115266
evaluation/env_infos/initial/reward_dist Std              0.0188888
evaluation/env_infos/initial/reward_dist Max              0.0780237
evaluation/env_infos/initial/reward_dist Min              2.82291e-06
evaluation/env_infos/reward_dist Mean                     0.136503
evaluation/env_infos/reward_dist Std                      0.248765
evaluation/env_infos/reward_dist Max                      0.995563
evaluation/env_infos/reward_dist Min                      3.79689e-117
time/data storing (s)                                    71.3812
time/evaluation sampling (s)                              1.1941
time/exploration sampling (s)                             0.142141
time/logging (s)                                          0.0275983
time/saving (s)                                           1.42169
time/training (s)                                        65.9698
time/epoch (s)                                          140.137
time/total (s)                                        14282.8
Epoch                                                   196
---------------------------------------------------  -----------------
2021-05-29 03:56:27.997331 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 197 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00461969
trainer/QF2 Loss                                          0.00526767
trainer/Policy Loss                                       2.71152
trainer/Q1 Predictions Mean                              -0.774968
trainer/Q1 Predictions Std                                0.736114
trainer/Q1 Predictions Max                                0.873715
trainer/Q1 Predictions Min                               -3.01212
trainer/Q2 Predictions Mean                              -0.761676
trainer/Q2 Predictions Std                                0.735802
trainer/Q2 Predictions Max                                0.873302
trainer/Q2 Predictions Min                               -3.06092
trainer/Q Targets Mean                                   -0.778937
trainer/Q Targets Std                                     0.744046
trainer/Q Targets Max                                     0.8425
trainer/Q Targets Min                                    -3.072
trainer/Log Pis Mean                                      1.95832
trainer/Log Pis Std                                       1.30067
trainer/Log Pis Max                                       7.07407
trainer/Log Pis Min                                      -6.32545
trainer/Policy mu Mean                                    0.0317132
trainer/Policy mu Std                                     0.472384
trainer/Policy mu Max                                     3.00471
trainer/Policy mu Min                                    -2.44057
trainer/Policy log std Mean                              -2.25964
trainer/Policy log std Std                                0.514709
trainer/Policy log std Max                               -0.367976
trainer/Policy log std Min                               -3.24818
trainer/Alpha                                             0.0198054
trainer/Alpha Loss                                       -0.163538
exploration/num steps total                           20800
exploration/num paths total                            1040
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.175836
exploration/Rewards Std                                   0.222311
exploration/Rewards Max                                   0.116471
exploration/Rewards Min                                  -0.828853
exploration/Returns Mean                                 -3.51671
exploration/Returns Std                                   4.15894
exploration/Returns Max                                   0.888069
exploration/Returns Min                                 -11.3458
exploration/Actions Mean                                 -0.00459765
exploration/Actions Std                                   0.219555
exploration/Actions Max                                   0.661679
exploration/Actions Min                                  -0.938241
exploration/Num Paths                                     5
exploration/Average Returns                              -3.51671
exploration/env_infos/final/reward_energy Mean           -0.210682
exploration/env_infos/final/reward_energy Std             0.0740137
exploration/env_infos/final/reward_energy Max            -0.0906775
exploration/env_infos/final/reward_energy Min            -0.296003
exploration/env_infos/initial/reward_energy Mean         -0.569851
exploration/env_infos/initial/reward_energy Std           0.255913
exploration/env_infos/initial/reward_energy Max          -0.228902
exploration/env_infos/initial/reward_energy Min          -0.946968
exploration/env_infos/reward_energy Mean                 -0.243626
exploration/env_infos/reward_energy Std                   0.192608
exploration/env_infos/reward_energy Max                  -0.0108728
exploration/env_infos/reward_energy Min                  -0.946968
exploration/env_infos/final/end_effector_loc Mean        -0.104964
exploration/env_infos/final/end_effector_loc Std          0.399285
exploration/env_infos/final/end_effector_loc Max          0.482113
exploration/env_infos/final/end_effector_loc Min         -0.948119
exploration/env_infos/initial/end_effector_loc Mean      -0.002475
exploration/env_infos/initial/end_effector_loc Std        0.0219466
exploration/env_infos/initial/end_effector_loc Max        0.0287791
exploration/env_infos/initial/end_effector_loc Min       -0.0469121
exploration/env_infos/end_effector_loc Mean              -0.0853416
exploration/env_infos/end_effector_loc Std                0.315033
exploration/env_infos/end_effector_loc Max                0.482113
exploration/env_infos/end_effector_loc Min               -0.971392
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0274437
exploration/env_infos/final/reward_dist Std               0.0548873
exploration/env_infos/final/reward_dist Max               0.137218
exploration/env_infos/final/reward_dist Min               5.35503e-57
exploration/env_infos/initial/reward_dist Mean            0.0132139
exploration/env_infos/initial/reward_dist Std             0.0247536
exploration/env_infos/initial/reward_dist Max             0.0626776
exploration/env_infos/initial/reward_dist Min             0.000156044
exploration/env_infos/reward_dist Mean                    0.0994189
exploration/env_infos/reward_dist Std                     0.165165
exploration/env_infos/reward_dist Max                     0.642938
exploration/env_infos/reward_dist Min                     4.39051e-67
evaluation/num steps total                           198000
evaluation/num paths total                             9900
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.13545
evaluation/Rewards Std                                    0.167979
evaluation/Rewards Max                                    0.138687
evaluation/Rewards Min                                   -1.03262
evaluation/Returns Mean                                  -2.709
evaluation/Returns Std                                    2.91341
evaluation/Returns Max                                    1.79623
evaluation/Returns Min                                  -13.96
evaluation/Actions Mean                                  -0.00205263
evaluation/Actions Std                                    0.200756
evaluation/Actions Max                                    0.93607
evaluation/Actions Min                                   -0.991701
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.709
evaluation/env_infos/final/reward_energy Mean            -0.13914
evaluation/env_infos/final/reward_energy Std              0.193806
evaluation/env_infos/final/reward_energy Max             -0.0128276
evaluation/env_infos/final/reward_energy Min             -1.03984
evaluation/env_infos/initial/reward_energy Mean          -0.396464
evaluation/env_infos/initial/reward_energy Std            0.348079
evaluation/env_infos/initial/reward_energy Max           -0.000919674
evaluation/env_infos/initial/reward_energy Min           -1.04579
evaluation/env_infos/reward_energy Mean                  -0.165383
evaluation/env_infos/reward_energy Std                    0.230788
evaluation/env_infos/reward_energy Max                   -0.000832619
evaluation/env_infos/reward_energy Min                   -1.28527
evaluation/env_infos/final/end_effector_loc Mean         -0.0664945
evaluation/env_infos/final/end_effector_loc Std           0.442585
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00236574
evaluation/env_infos/initial/end_effector_loc Std         0.0185022
evaluation/env_infos/initial/end_effector_loc Max         0.043476
evaluation/env_infos/initial/end_effector_loc Min        -0.049585
evaluation/env_infos/end_effector_loc Mean               -0.0696688
evaluation/env_infos/end_effector_loc Std                 0.318486
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0712375
evaluation/env_infos/final/reward_dist Std                0.140974
evaluation/env_infos/final/reward_dist Max                0.653983
evaluation/env_infos/final/reward_dist Min                7.59815e-172
evaluation/env_infos/initial/reward_dist Mean             0.00578192
evaluation/env_infos/initial/reward_dist Std              0.0122485
evaluation/env_infos/initial/reward_dist Max              0.0555815
evaluation/env_infos/initial/reward_dist Min              7.98801e-07
evaluation/env_infos/reward_dist Mean                     0.103055
evaluation/env_infos/reward_dist Std                      0.214651
evaluation/env_infos/reward_dist Max                      0.999767
evaluation/env_infos/reward_dist Min                      7.59815e-172
time/data storing (s)                                    72.1306
time/evaluation sampling (s)                              1.26424
time/exploration sampling (s)                             0.160042
time/logging (s)                                          0.0289031
time/saving (s)                                           1.63092
time/training (s)                                        72.5678
time/epoch (s)                                          147.782
time/total (s)                                        14434.5
Epoch                                                   197
---------------------------------------------------  -----------------
2021-05-29 03:59:02.562904 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 198 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00432305
trainer/QF2 Loss                                          0.00257688
trainer/Policy Loss                                       2.63551
trainer/Q1 Predictions Mean                              -0.651931
trainer/Q1 Predictions Std                                0.719767
trainer/Q1 Predictions Max                                1.01361
trainer/Q1 Predictions Min                               -2.97476
trainer/Q2 Predictions Mean                              -0.664301
trainer/Q2 Predictions Std                                0.713467
trainer/Q2 Predictions Max                                1.018
trainer/Q2 Predictions Min                               -2.98132
trainer/Q Targets Mean                                   -0.654597
trainer/Q Targets Std                                     0.716077
trainer/Q Targets Max                                     1.00233
trainer/Q Targets Min                                    -3.03782
trainer/Log Pis Mean                                      1.98827
trainer/Log Pis Std                                       1.15881
trainer/Log Pis Max                                       4.26644
trainer/Log Pis Min                                      -3.98624
trainer/Policy mu Mean                                   -0.0219205
trainer/Policy mu Std                                     0.24224
trainer/Policy mu Max                                     1.21724
trainer/Policy mu Min                                    -1.78989
trainer/Policy log std Mean                              -2.32664
trainer/Policy log std Std                                0.377425
trainer/Policy log std Max                               -0.401707
trainer/Policy log std Min                               -3.16281
trainer/Alpha                                             0.0203887
trainer/Alpha Loss                                       -0.0456461
exploration/num steps total                           20900
exploration/num paths total                            1045
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.16118
exploration/Rewards Std                                   0.141124
exploration/Rewards Max                                   0.112474
exploration/Rewards Min                                  -0.562994
exploration/Returns Mean                                 -3.22361
exploration/Returns Std                                   2.177
exploration/Returns Max                                   0.658522
exploration/Returns Min                                  -5.3085
exploration/Actions Mean                                 -0.038467
exploration/Actions Std                                   0.140215
exploration/Actions Max                                   0.334859
exploration/Actions Min                                  -0.522949
exploration/Num Paths                                     5
exploration/Average Returns                              -3.22361
exploration/env_infos/final/reward_energy Mean           -0.204175
exploration/env_infos/final/reward_energy Std             0.159511
exploration/env_infos/final/reward_energy Max            -0.046863
exploration/env_infos/final/reward_energy Min            -0.503507
exploration/env_infos/initial/reward_energy Mean         -0.395445
exploration/env_infos/initial/reward_energy Std           0.170308
exploration/env_infos/initial/reward_energy Max          -0.129527
exploration/env_infos/initial/reward_energy Min          -0.596414
exploration/env_infos/reward_energy Mean                 -0.16553
exploration/env_infos/reward_energy Std                   0.121982
exploration/env_infos/reward_energy Max                  -0.0169088
exploration/env_infos/reward_energy Min                  -0.596414
exploration/env_infos/final/end_effector_loc Mean        -0.321481
exploration/env_infos/final/end_effector_loc Std          0.484852
exploration/env_infos/final/end_effector_loc Max          0.353355
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00427788
exploration/env_infos/initial/end_effector_loc Std        0.0146091
exploration/env_infos/initial/end_effector_loc Max        0.0159248
exploration/env_infos/initial/end_effector_loc Min       -0.0261474
exploration/env_infos/end_effector_loc Mean              -0.137163
exploration/env_infos/end_effector_loc Std                0.295335
exploration/env_infos/end_effector_loc Max                0.353355
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0162566
exploration/env_infos/final/reward_dist Std               0.0325131
exploration/env_infos/final/reward_dist Max               0.0812828
exploration/env_infos/final/reward_dist Min               1.24095e-69
exploration/env_infos/initial/reward_dist Mean            0.000115459
exploration/env_infos/initial/reward_dist Std             7.64137e-05
exploration/env_infos/initial/reward_dist Max             0.00020333
exploration/env_infos/initial/reward_dist Min             5.96399e-06
exploration/env_infos/reward_dist Mean                    0.105486
exploration/env_infos/reward_dist Std                     0.210629
exploration/env_infos/reward_dist Max                     0.767925
exploration/env_infos/reward_dist Min                     1.24095e-69
evaluation/num steps total                           199000
evaluation/num paths total                             9950
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0905009
evaluation/Rewards Std                                    0.126775
evaluation/Rewards Max                                    0.127084
evaluation/Rewards Min                                   -0.874842
evaluation/Returns Mean                                  -1.81002
evaluation/Returns Std                                    2.04459
evaluation/Returns Max                                    1.05727
evaluation/Returns Min                                   -9.27702
evaluation/Actions Mean                                  -0.0138895
evaluation/Actions Std                                    0.103077
evaluation/Actions Max                                    0.753932
evaluation/Actions Min                                   -0.792455
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.81002
evaluation/env_infos/final/reward_energy Mean            -0.0839501
evaluation/env_infos/final/reward_energy Std              0.096358
evaluation/env_infos/final/reward_energy Max             -0.0172624
evaluation/env_infos/final/reward_energy Min             -0.610542
evaluation/env_infos/initial/reward_energy Mean          -0.291609
evaluation/env_infos/initial/reward_energy Std            0.235118
evaluation/env_infos/initial/reward_energy Max           -0.0426983
evaluation/env_infos/initial/reward_energy Min           -0.931083
evaluation/env_infos/reward_energy Mean                  -0.0956653
evaluation/env_infos/reward_energy Std                    0.11173
evaluation/env_infos/reward_energy Max                   -0.00352673
evaluation/env_infos/reward_energy Min                   -0.931083
evaluation/env_infos/final/end_effector_loc Mean         -0.151297
evaluation/env_infos/final/end_effector_loc Std           0.414429
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.0019723
evaluation/env_infos/initial/end_effector_loc Std         0.013096
evaluation/env_infos/initial/end_effector_loc Max         0.0376966
evaluation/env_infos/initial/end_effector_loc Min        -0.0396227
evaluation/env_infos/end_effector_loc Mean               -0.0736302
evaluation/env_infos/end_effector_loc Std                 0.248113
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0511626
evaluation/env_infos/final/reward_dist Std                0.157057
evaluation/env_infos/final/reward_dist Max                0.823842
evaluation/env_infos/final/reward_dist Min                1.40974e-161
evaluation/env_infos/initial/reward_dist Mean             0.00676456
evaluation/env_infos/initial/reward_dist Std              0.0118708
evaluation/env_infos/initial/reward_dist Max              0.0563304
evaluation/env_infos/initial/reward_dist Min              1.86453e-06
evaluation/env_infos/reward_dist Mean                     0.115076
evaluation/env_infos/reward_dist Std                      0.219719
evaluation/env_infos/reward_dist Max                      0.988633
evaluation/env_infos/reward_dist Min                      1.40974e-161
time/data storing (s)                                    74.003
time/evaluation sampling (s)                              1.32632
time/exploration sampling (s)                             0.168166
time/logging (s)                                          0.0287587
time/saving (s)                                           1.46033
time/training (s)                                        73.4823
time/epoch (s)                                          150.469
time/total (s)                                        14589.1
Epoch                                                   198
---------------------------------------------------  -----------------
2021-05-29 04:01:38.643730 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 199 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00304173
trainer/QF2 Loss                                          0.00333798
trainer/Policy Loss                                       2.74441
trainer/Q1 Predictions Mean                              -0.749413
trainer/Q1 Predictions Std                                0.732236
trainer/Q1 Predictions Max                                0.913656
trainer/Q1 Predictions Min                               -3.20819
trainer/Q2 Predictions Mean                              -0.742392
trainer/Q2 Predictions Std                                0.728474
trainer/Q2 Predictions Max                                0.904031
trainer/Q2 Predictions Min                               -3.19723
trainer/Q Targets Mean                                   -0.760431
trainer/Q Targets Std                                     0.733936
trainer/Q Targets Max                                     0.915467
trainer/Q Targets Min                                    -3.25437
trainer/Log Pis Mean                                      2.01547
trainer/Log Pis Std                                       1.21997
trainer/Log Pis Max                                       6.04214
trainer/Log Pis Min                                      -3.45616
trainer/Policy mu Mean                                    0.0143784
trainer/Policy mu Std                                     0.342464
trainer/Policy mu Max                                     2.06304
trainer/Policy mu Min                                    -2.43926
trainer/Policy log std Mean                              -2.32418
trainer/Policy log std Std                                0.45839
trainer/Policy log std Max                               -0.13174
trainer/Policy log std Min                               -3.20203
trainer/Alpha                                             0.0206699
trainer/Alpha Loss                                        0.0600122
exploration/num steps total                           21000
exploration/num paths total                            1050
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.13619
exploration/Rewards Std                                   0.11495
exploration/Rewards Max                                   0.0578387
exploration/Rewards Min                                  -0.519956
exploration/Returns Mean                                 -2.7238
exploration/Returns Std                                   1.77191
exploration/Returns Max                                   0.0463266
exploration/Returns Min                                  -5.543
exploration/Actions Mean                                 -0.0136623
exploration/Actions Std                                   0.116387
exploration/Actions Max                                   0.345777
exploration/Actions Min                                  -0.778994
exploration/Num Paths                                     5
exploration/Average Returns                              -2.7238
exploration/env_infos/final/reward_energy Mean           -0.113177
exploration/env_infos/final/reward_energy Std             0.050123
exploration/env_infos/final/reward_energy Max            -0.0690836
exploration/env_infos/final/reward_energy Min            -0.209622
exploration/env_infos/initial/reward_energy Mean         -0.395526
exploration/env_infos/initial/reward_energy Std           0.323267
exploration/env_infos/initial/reward_energy Max          -0.0239408
exploration/env_infos/initial/reward_energy Min          -0.798869
exploration/env_infos/reward_energy Mean                 -0.116147
exploration/env_infos/reward_energy Std                   0.118217
exploration/env_infos/reward_energy Max                  -0.0118271
exploration/env_infos/reward_energy Min                  -0.798869
exploration/env_infos/final/end_effector_loc Mean        -0.192093
exploration/env_infos/final/end_effector_loc Std          0.418998
exploration/env_infos/final/end_effector_loc Max          0.491642
exploration/env_infos/final/end_effector_loc Min         -0.953683
exploration/env_infos/initial/end_effector_loc Mean      -0.00528962
exploration/env_infos/initial/end_effector_loc Std        0.0172684
exploration/env_infos/initial/end_effector_loc Max        0.0172888
exploration/env_infos/initial/end_effector_loc Min       -0.0389497
exploration/env_infos/end_effector_loc Mean              -0.0808828
exploration/env_infos/end_effector_loc Std                0.262944
exploration/env_infos/end_effector_loc Max                0.491642
exploration/env_infos/end_effector_loc Min               -0.953683
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0669552
exploration/env_infos/final/reward_dist Std               0.13391
exploration/env_infos/final/reward_dist Max               0.334776
exploration/env_infos/final/reward_dist Min               5.77836e-58
exploration/env_infos/initial/reward_dist Mean            7.48241e-05
exploration/env_infos/initial/reward_dist Std             0.000138001
exploration/env_infos/initial/reward_dist Max             0.000350754
exploration/env_infos/initial/reward_dist Min             1.8165e-06
exploration/env_infos/reward_dist Mean                    0.0541249
exploration/env_infos/reward_dist Std                     0.142365
exploration/env_infos/reward_dist Max                     0.545354
exploration/env_infos/reward_dist Min                     5.77836e-58
evaluation/num steps total                           200000
evaluation/num paths total                            10000
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0806014
evaluation/Rewards Std                                    0.102692
evaluation/Rewards Max                                    0.136222
evaluation/Rewards Min                                   -0.642026
evaluation/Returns Mean                                  -1.61203
evaluation/Returns Std                                    1.66652
evaluation/Returns Max                                    0.823874
evaluation/Returns Min                                   -8.05517
evaluation/Actions Mean                                  -0.0188914
evaluation/Actions Std                                    0.159682
evaluation/Actions Max                                    0.807112
evaluation/Actions Min                                   -0.999129
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.61203
evaluation/env_infos/final/reward_energy Mean            -0.0860684
evaluation/env_infos/final/reward_energy Std              0.185687
evaluation/env_infos/final/reward_energy Max             -0.0081979
evaluation/env_infos/final/reward_energy Min             -0.99798
evaluation/env_infos/initial/reward_energy Mean          -0.316176
evaluation/env_infos/initial/reward_energy Std            0.288795
evaluation/env_infos/initial/reward_energy Max           -0.0186503
evaluation/env_infos/initial/reward_energy Min           -1.01538
evaluation/env_infos/reward_energy Mean                  -0.117984
evaluation/env_infos/reward_energy Std                    0.194397
evaluation/env_infos/reward_energy Max                   -0.00101756
evaluation/env_infos/reward_energy Min                   -1.12794
evaluation/env_infos/final/end_effector_loc Mean         -0.0162861
evaluation/env_infos/final/end_effector_loc Std           0.338845
evaluation/env_infos/final/end_effector_loc Max           0.999908
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00117557
evaluation/env_infos/initial/end_effector_loc Std         0.0150941
evaluation/env_infos/initial/end_effector_loc Max         0.0403556
evaluation/env_infos/initial/end_effector_loc Min        -0.039589
evaluation/env_infos/end_effector_loc Mean               -0.00242906
evaluation/env_infos/end_effector_loc Std                 0.227861
evaluation/env_infos/end_effector_loc Max                 0.999908
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.159868
evaluation/env_infos/final/reward_dist Std                0.264175
evaluation/env_infos/final/reward_dist Max                0.960792
evaluation/env_infos/final/reward_dist Min                4.4318e-115
evaluation/env_infos/initial/reward_dist Mean             0.00832534
evaluation/env_infos/initial/reward_dist Std              0.0135903
evaluation/env_infos/initial/reward_dist Max              0.0634329
evaluation/env_infos/initial/reward_dist Min              1.68686e-06
evaluation/env_infos/reward_dist Mean                     0.162123
evaluation/env_infos/reward_dist Std                      0.249746
evaluation/env_infos/reward_dist Max                      0.992095
evaluation/env_infos/reward_dist Min                      4.4318e-115
time/data storing (s)                                    73.7952
time/evaluation sampling (s)                              1.26272
time/exploration sampling (s)                             0.156997
time/logging (s)                                          0.0324653
time/saving (s)                                           1.51852
time/training (s)                                        74.7021
time/epoch (s)                                          151.468
time/total (s)                                        14745.1
Epoch                                                   199
---------------------------------------------------  ----------------
2021-05-29 04:03:09.317634 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 200 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00629901
trainer/QF2 Loss                                          0.00775454
trainer/Policy Loss                                       3.13805
trainer/Q1 Predictions Mean                              -0.914511
trainer/Q1 Predictions Std                                0.802084
trainer/Q1 Predictions Max                                0.908426
trainer/Q1 Predictions Min                               -3.60167
trainer/Q2 Predictions Mean                              -0.920852
trainer/Q2 Predictions Std                                0.801973
trainer/Q2 Predictions Max                                0.922661
trainer/Q2 Predictions Min                               -3.66838
trainer/Q Targets Mean                                   -0.918507
trainer/Q Targets Std                                     0.804117
trainer/Q Targets Max                                     0.943222
trainer/Q Targets Min                                    -3.66903
trainer/Log Pis Mean                                      2.24611
trainer/Log Pis Std                                       1.163
trainer/Log Pis Max                                       4.50137
trainer/Log Pis Min                                      -2.32608
trainer/Policy mu Mean                                    0.00831416
trainer/Policy mu Std                                     0.285914
trainer/Policy mu Max                                     1.70883
trainer/Policy mu Min                                    -1.40316
trainer/Policy log std Mean                              -2.44018
trainer/Policy log std Std                                0.45465
trainer/Policy log std Max                               -0.725035
trainer/Policy log std Min                               -3.29773
trainer/Alpha                                             0.0185573
trainer/Alpha Loss                                        0.982042
exploration/num steps total                           21100
exploration/num paths total                            1055
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.176822
exploration/Rewards Std                                   0.201197
exploration/Rewards Max                                   0.0353776
exploration/Rewards Min                                  -0.919912
exploration/Returns Mean                                 -3.53644
exploration/Returns Std                                   2.97094
exploration/Returns Max                                  -1.44264
exploration/Returns Min                                  -9.34395
exploration/Actions Mean                                 -0.0157586
exploration/Actions Std                                   0.171333
exploration/Actions Max                                   0.665601
exploration/Actions Min                                  -0.792675
exploration/Num Paths                                     5
exploration/Average Returns                              -3.53644
exploration/env_infos/final/reward_energy Mean           -0.15097
exploration/env_infos/final/reward_energy Std             0.0799755
exploration/env_infos/final/reward_energy Max            -0.0193473
exploration/env_infos/final/reward_energy Min            -0.243927
exploration/env_infos/initial/reward_energy Mean         -0.324172
exploration/env_infos/initial/reward_energy Std           0.291598
exploration/env_infos/initial/reward_energy Max          -0.0726417
exploration/env_infos/initial/reward_energy Min          -0.889302
exploration/env_infos/reward_energy Mean                 -0.183929
exploration/env_infos/reward_energy Std                   0.159301
exploration/env_infos/reward_energy Max                  -0.0147708
exploration/env_infos/reward_energy Min                  -0.963763
exploration/env_infos/final/end_effector_loc Mean        -0.156743
exploration/env_infos/final/end_effector_loc Std          0.477407
exploration/env_infos/final/end_effector_loc Max          0.585909
exploration/env_infos/final/end_effector_loc Min         -0.913731
exploration/env_infos/initial/end_effector_loc Mean       0.00172008
exploration/env_infos/initial/end_effector_loc Std        0.0153195
exploration/env_infos/initial/end_effector_loc Max        0.0201571
exploration/env_infos/initial/end_effector_loc Min       -0.0396338
exploration/env_infos/end_effector_loc Mean              -0.0309417
exploration/env_infos/end_effector_loc Std                0.308762
exploration/env_infos/end_effector_loc Max                0.585909
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000528252
exploration/env_infos/final/reward_dist Std               0.0010565
exploration/env_infos/final/reward_dist Max               0.00264125
exploration/env_infos/final/reward_dist Min               9.87446e-108
exploration/env_infos/initial/reward_dist Mean            0.0284675
exploration/env_infos/initial/reward_dist Std             0.0436713
exploration/env_infos/initial/reward_dist Max             0.113704
exploration/env_infos/initial/reward_dist Min             4.83966e-05
exploration/env_infos/reward_dist Mean                    0.135842
exploration/env_infos/reward_dist Std                     0.258995
exploration/env_infos/reward_dist Max                     0.960118
exploration/env_infos/reward_dist Min                     9.87446e-108
evaluation/num steps total                           201000
evaluation/num paths total                            10050
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.123426
evaluation/Rewards Std                                    0.175233
evaluation/Rewards Max                                    0.159018
evaluation/Rewards Min                                   -0.888384
evaluation/Returns Mean                                  -2.46851
evaluation/Returns Std                                    3.20339
evaluation/Returns Max                                    1.51327
evaluation/Returns Min                                  -14.4732
evaluation/Actions Mean                                  -0.0229166
evaluation/Actions Std                                    0.194291
evaluation/Actions Max                                    0.837107
evaluation/Actions Min                                   -0.997453
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.46851
evaluation/env_infos/final/reward_energy Mean            -0.102611
evaluation/env_infos/final/reward_energy Std              0.167072
evaluation/env_infos/final/reward_energy Max             -0.00488781
evaluation/env_infos/final/reward_energy Min             -0.982614
evaluation/env_infos/initial/reward_energy Mean          -0.367721
evaluation/env_infos/initial/reward_energy Std            0.29675
evaluation/env_infos/initial/reward_energy Max           -0.0333493
evaluation/env_infos/initial/reward_energy Min           -1.07404
evaluation/env_infos/reward_energy Mean                  -0.159628
evaluation/env_infos/reward_energy Std                    0.225981
evaluation/env_infos/reward_energy Max                   -0.00164394
evaluation/env_infos/reward_energy Min                   -1.15047
evaluation/env_infos/final/end_effector_loc Mean         -0.0257387
evaluation/env_infos/final/end_effector_loc Std           0.444274
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.0032339
evaluation/env_infos/initial/end_effector_loc Std         0.0163903
evaluation/env_infos/initial/end_effector_loc Max         0.0392994
evaluation/env_infos/initial/end_effector_loc Min        -0.0481921
evaluation/env_infos/end_effector_loc Mean               -0.010034
evaluation/env_infos/end_effector_loc Std                 0.312957
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.149159
evaluation/env_infos/final/reward_dist Std                0.254018
evaluation/env_infos/final/reward_dist Max                0.86712
evaluation/env_infos/final/reward_dist Min                1.71977e-150
evaluation/env_infos/initial/reward_dist Mean             0.00763268
evaluation/env_infos/initial/reward_dist Std              0.016449
evaluation/env_infos/initial/reward_dist Max              0.0928021
evaluation/env_infos/initial/reward_dist Min              9.74371e-08
evaluation/env_infos/reward_dist Mean                     0.110818
evaluation/env_infos/reward_dist Std                      0.223214
evaluation/env_infos/reward_dist Max                      0.986012
evaluation/env_infos/reward_dist Min                      1.71977e-150
time/data storing (s)                                    43.0219
time/evaluation sampling (s)                              1.38789
time/exploration sampling (s)                             0.108042
time/logging (s)                                          0.016166
time/saving (s)                                           1.59527
time/training (s)                                        40.3119
time/epoch (s)                                           86.4412
time/total (s)                                        14835.8
Epoch                                                   200
---------------------------------------------------  -----------------
2021-05-29 04:04:31.502265 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 201 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00451202
trainer/QF2 Loss                                          0.00510507
trainer/Policy Loss                                       2.88707
trainer/Q1 Predictions Mean                              -0.905759
trainer/Q1 Predictions Std                                0.772999
trainer/Q1 Predictions Max                                1.00563
trainer/Q1 Predictions Min                               -2.87376
trainer/Q2 Predictions Mean                              -0.887348
trainer/Q2 Predictions Std                                0.767642
trainer/Q2 Predictions Max                                0.999428
trainer/Q2 Predictions Min                               -2.83266
trainer/Q Targets Mean                                   -0.891323
trainer/Q Targets Std                                     0.778708
trainer/Q Targets Max                                     1.05177
trainer/Q Targets Min                                    -2.8598
trainer/Log Pis Mean                                      1.99791
trainer/Log Pis Std                                       1.27062
trainer/Log Pis Max                                       4.86817
trainer/Log Pis Min                                      -5.47368
trainer/Policy mu Mean                                   -0.0210594
trainer/Policy mu Std                                     0.321018
trainer/Policy mu Max                                     1.43928
trainer/Policy mu Min                                    -2.00445
trainer/Policy log std Mean                              -2.30306
trainer/Policy log std Std                                0.417604
trainer/Policy log std Max                               -0.597015
trainer/Policy log std Min                               -3.30097
trainer/Alpha                                             0.019116
trainer/Alpha Loss                                       -0.0082749
exploration/num steps total                           21200
exploration/num paths total                            1060
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0810457
exploration/Rewards Std                                   0.0858579
exploration/Rewards Max                                   0.0717356
exploration/Rewards Min                                  -0.354726
exploration/Returns Mean                                 -1.62091
exploration/Returns Std                                   1.42833
exploration/Returns Max                                   0.0106482
exploration/Returns Min                                  -3.9173
exploration/Actions Mean                                  0.00552757
exploration/Actions Std                                   0.112986
exploration/Actions Max                                   0.497537
exploration/Actions Min                                  -0.823027
exploration/Num Paths                                     5
exploration/Average Returns                              -1.62091
exploration/env_infos/final/reward_energy Mean           -0.0784345
exploration/env_infos/final/reward_energy Std             0.023209
exploration/env_infos/final/reward_energy Max            -0.0454894
exploration/env_infos/final/reward_energy Min            -0.117445
exploration/env_infos/initial/reward_energy Mean         -0.264412
exploration/env_infos/initial/reward_energy Std           0.289113
exploration/env_infos/initial/reward_energy Max          -0.0596599
exploration/env_infos/initial/reward_energy Min          -0.82688
exploration/env_infos/reward_energy Mean                 -0.112695
exploration/env_infos/reward_energy Std                   0.113546
exploration/env_infos/reward_energy Max                  -0.0150873
exploration/env_infos/reward_energy Min                  -0.82688
exploration/env_infos/final/end_effector_loc Mean         0.0407902
exploration/env_infos/final/end_effector_loc Std          0.214011
exploration/env_infos/final/end_effector_loc Max          0.2402
exploration/env_infos/final/end_effector_loc Min         -0.384403
exploration/env_infos/initial/end_effector_loc Mean      -0.00622972
exploration/env_infos/initial/end_effector_loc Std        0.012372
exploration/env_infos/initial/end_effector_loc Max        0.00407511
exploration/env_infos/initial/end_effector_loc Min       -0.0411514
exploration/env_infos/end_effector_loc Mean              -0.00160991
exploration/env_infos/end_effector_loc Std                0.143446
exploration/env_infos/end_effector_loc Max                0.2402
exploration/env_infos/end_effector_loc Min               -0.384403
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.178865
exploration/env_infos/final/reward_dist Std               0.357722
exploration/env_infos/final/reward_dist Max               0.894309
exploration/env_infos/final/reward_dist Min               1.82086e-15
exploration/env_infos/initial/reward_dist Mean            0.00225862
exploration/env_infos/initial/reward_dist Std             0.00217417
exploration/env_infos/initial/reward_dist Max             0.00607717
exploration/env_infos/initial/reward_dist Min             0.000309703
exploration/env_infos/reward_dist Mean                    0.142217
exploration/env_infos/reward_dist Std                     0.255759
exploration/env_infos/reward_dist Max                     0.916448
exploration/env_infos/reward_dist Min                     1.82086e-15
evaluation/num steps total                           202000
evaluation/num paths total                            10100
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0752876
evaluation/Rewards Std                                    0.160959
evaluation/Rewards Max                                    0.146206
evaluation/Rewards Min                                   -0.878633
evaluation/Returns Mean                                  -1.50575
evaluation/Returns Std                                    2.86435
evaluation/Returns Max                                    1.89788
evaluation/Returns Min                                  -12.7151
evaluation/Actions Mean                                  -0.0180865
evaluation/Actions Std                                    0.186997
evaluation/Actions Max                                    0.905363
evaluation/Actions Min                                   -0.999074
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.50575
evaluation/env_infos/final/reward_energy Mean            -0.0865478
evaluation/env_infos/final/reward_energy Std              0.158003
evaluation/env_infos/final/reward_energy Max             -0.0054548
evaluation/env_infos/final/reward_energy Min             -1.0917
evaluation/env_infos/initial/reward_energy Mean          -0.379899
evaluation/env_infos/initial/reward_energy Std            0.336736
evaluation/env_infos/initial/reward_energy Max           -0.0275393
evaluation/env_infos/initial/reward_energy Min           -1.11705
evaluation/env_infos/reward_energy Mean                  -0.141006
evaluation/env_infos/reward_energy Std                    0.225183
evaluation/env_infos/reward_energy Max                   -0.00268047
evaluation/env_infos/reward_energy Min                   -1.40527
evaluation/env_infos/final/end_effector_loc Mean         -0.00770634
evaluation/env_infos/final/end_effector_loc Std           0.353768
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00282915
evaluation/env_infos/initial/end_effector_loc Std         0.017724
evaluation/env_infos/initial/end_effector_loc Max         0.0448231
evaluation/env_infos/initial/end_effector_loc Min        -0.0479283
evaluation/env_infos/end_effector_loc Mean                0.00786104
evaluation/env_infos/end_effector_loc Std                 0.256779
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.136133
evaluation/env_infos/final/reward_dist Std                0.216264
evaluation/env_infos/final/reward_dist Max                0.83657
evaluation/env_infos/final/reward_dist Min                1.96698e-138
evaluation/env_infos/initial/reward_dist Mean             0.00709363
evaluation/env_infos/initial/reward_dist Std              0.0121525
evaluation/env_infos/initial/reward_dist Max              0.058209
evaluation/env_infos/initial/reward_dist Min              6.8671e-08
evaluation/env_infos/reward_dist Mean                     0.193773
evaluation/env_infos/reward_dist Std                      0.283553
evaluation/env_infos/reward_dist Max                      0.999935
evaluation/env_infos/reward_dist Min                      1.96698e-138
time/data storing (s)                                    38.9484
time/evaluation sampling (s)                              0.659093
time/exploration sampling (s)                             0.0902448
time/logging (s)                                          0.0154813
time/saving (s)                                           0.794313
time/training (s)                                        39.5104
time/epoch (s)                                           80.018
time/total (s)                                        14917.9
Epoch                                                   201
---------------------------------------------------  -----------------
2021-05-29 04:05:52.740315 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 202 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0049127
trainer/QF2 Loss                                          0.00584846
trainer/Policy Loss                                       2.92887
trainer/Q1 Predictions Mean                              -0.950844
trainer/Q1 Predictions Std                                0.818503
trainer/Q1 Predictions Max                                0.69217
trainer/Q1 Predictions Min                               -3.3231
trainer/Q2 Predictions Mean                              -0.937645
trainer/Q2 Predictions Std                                0.829194
trainer/Q2 Predictions Max                                0.708056
trainer/Q2 Predictions Min                               -3.39869
trainer/Q Targets Mean                                   -0.936606
trainer/Q Targets Std                                     0.831501
trainer/Q Targets Max                                     0.64543
trainer/Q Targets Min                                    -3.32344
trainer/Log Pis Mean                                      1.99126
trainer/Log Pis Std                                       1.16821
trainer/Log Pis Max                                       4.40154
trainer/Log Pis Min                                      -2.02994
trainer/Policy mu Mean                                   -0.00236892
trainer/Policy mu Std                                     0.350551
trainer/Policy mu Max                                     2.13185
trainer/Policy mu Min                                    -2.52486
trainer/Policy log std Mean                              -2.31424
trainer/Policy log std Std                                0.451629
trainer/Policy log std Max                               -0.428684
trainer/Policy log std Min                               -3.24576
trainer/Alpha                                             0.019925
trainer/Alpha Loss                                       -0.034219
exploration/num steps total                           21300
exploration/num paths total                            1065
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.188165
exploration/Rewards Std                                   0.17355
exploration/Rewards Max                                  -0.00734718
exploration/Rewards Min                                  -0.804998
exploration/Returns Mean                                 -3.7633
exploration/Returns Std                                   2.49422
exploration/Returns Max                                  -0.84514
exploration/Returns Min                                  -7.59021
exploration/Actions Mean                                 -0.04632
exploration/Actions Std                                   0.196135
exploration/Actions Max                                   0.608528
exploration/Actions Min                                  -0.874627
exploration/Num Paths                                     5
exploration/Average Returns                              -3.7633
exploration/env_infos/final/reward_energy Mean           -0.159344
exploration/env_infos/final/reward_energy Std             0.136849
exploration/env_infos/final/reward_energy Max            -0.0162566
exploration/env_infos/final/reward_energy Min            -0.420805
exploration/env_infos/initial/reward_energy Mean         -0.239825
exploration/env_infos/initial/reward_energy Std           0.190947
exploration/env_infos/initial/reward_energy Max          -0.0618423
exploration/env_infos/initial/reward_energy Min          -0.586552
exploration/env_infos/reward_energy Mean                 -0.207688
exploration/env_infos/reward_energy Std                   0.195178
exploration/env_infos/reward_energy Max                  -0.00721831
exploration/env_infos/reward_energy Min                  -0.955384
exploration/env_infos/final/end_effector_loc Mean        -0.174625
exploration/env_infos/final/end_effector_loc Std          0.450318
exploration/env_infos/final/end_effector_loc Max          0.281111
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.000262156
exploration/env_infos/initial/end_effector_loc Std        0.0108352
exploration/env_infos/initial/end_effector_loc Max        0.0126633
exploration/env_infos/initial/end_effector_loc Min       -0.0286111
exploration/env_infos/end_effector_loc Mean              -0.0675836
exploration/env_infos/end_effector_loc Std                0.271132
exploration/env_infos/end_effector_loc Max                0.281111
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0139006
exploration/env_infos/final/reward_dist Std               0.0227718
exploration/env_infos/final/reward_dist Max               0.0590945
exploration/env_infos/final/reward_dist Min               3.9204e-125
exploration/env_infos/initial/reward_dist Mean            0.00258778
exploration/env_infos/initial/reward_dist Std             0.00372379
exploration/env_infos/initial/reward_dist Max             0.00999468
exploration/env_infos/initial/reward_dist Min             3.53413e-05
exploration/env_infos/reward_dist Mean                    0.0223259
exploration/env_infos/reward_dist Std                     0.056036
exploration/env_infos/reward_dist Max                     0.275353
exploration/env_infos/reward_dist Min                     3.9204e-125
evaluation/num steps total                           203000
evaluation/num paths total                            10150
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0568569
evaluation/Rewards Std                                    0.106622
evaluation/Rewards Max                                    0.159414
evaluation/Rewards Min                                   -0.523906
evaluation/Returns Mean                                  -1.13714
evaluation/Returns Std                                    1.72028
evaluation/Returns Max                                    1.83328
evaluation/Returns Min                                   -7.00719
evaluation/Actions Mean                                  -0.00598947
evaluation/Actions Std                                    0.113379
evaluation/Actions Max                                    0.873554
evaluation/Actions Min                                   -0.918379
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.13714
evaluation/env_infos/final/reward_energy Mean            -0.0635831
evaluation/env_infos/final/reward_energy Std              0.112722
evaluation/env_infos/final/reward_energy Max             -0.00186761
evaluation/env_infos/final/reward_energy Min             -0.566721
evaluation/env_infos/initial/reward_energy Mean          -0.326382
evaluation/env_infos/initial/reward_energy Std            0.292171
evaluation/env_infos/initial/reward_energy Max           -0.00929938
evaluation/env_infos/initial/reward_energy Min           -0.978809
evaluation/env_infos/reward_energy Mean                  -0.091368
evaluation/env_infos/reward_energy Std                    0.132036
evaluation/env_infos/reward_energy Max                   -0.00186761
evaluation/env_infos/reward_energy Min                   -0.978809
evaluation/env_infos/final/end_effector_loc Mean          0.0175215
evaluation/env_infos/final/end_effector_loc Std           0.361005
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00148656
evaluation/env_infos/initial/end_effector_loc Std         0.015416
evaluation/env_infos/initial/end_effector_loc Max         0.0436777
evaluation/env_infos/initial/end_effector_loc Min        -0.045919
evaluation/env_infos/end_effector_loc Mean                0.0188758
evaluation/env_infos/end_effector_loc Std                 0.231618
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0996863
evaluation/env_infos/final/reward_dist Std                0.214418
evaluation/env_infos/final/reward_dist Max                0.975369
evaluation/env_infos/final/reward_dist Min                2.347e-94
evaluation/env_infos/initial/reward_dist Mean             0.00717939
evaluation/env_infos/initial/reward_dist Std              0.0146741
evaluation/env_infos/initial/reward_dist Max              0.0683093
evaluation/env_infos/initial/reward_dist Min              9.91237e-07
evaluation/env_infos/reward_dist Mean                     0.130682
evaluation/env_infos/reward_dist Std                      0.239087
evaluation/env_infos/reward_dist Max                      0.998394
evaluation/env_infos/reward_dist Min                      2.347e-94
time/data storing (s)                                    38.0553
time/evaluation sampling (s)                              0.525286
time/exploration sampling (s)                             0.0822943
time/logging (s)                                          0.0169548
time/saving (s)                                           0.780941
time/training (s)                                        39.6203
time/epoch (s)                                           79.081
time/total (s)                                        14999.2
Epoch                                                   202
---------------------------------------------------  ----------------
2021-05-29 04:07:14.759543 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 203 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00491496
trainer/QF2 Loss                                          0.00329255
trainer/Policy Loss                                       3.17341
trainer/Q1 Predictions Mean                              -1.01468
trainer/Q1 Predictions Std                                0.865074
trainer/Q1 Predictions Max                                0.813336
trainer/Q1 Predictions Min                               -3.71945
trainer/Q2 Predictions Mean                              -1.03843
trainer/Q2 Predictions Std                                0.856384
trainer/Q2 Predictions Max                                0.751801
trainer/Q2 Predictions Min                               -3.7624
trainer/Q Targets Mean                                   -1.02626
trainer/Q Targets Std                                     0.861542
trainer/Q Targets Max                                     0.776453
trainer/Q Targets Min                                    -3.73518
trainer/Log Pis Mean                                      2.15629
trainer/Log Pis Std                                       1.20802
trainer/Log Pis Max                                       5.07359
trainer/Log Pis Min                                      -2.00372
trainer/Policy mu Mean                                   -0.0323097
trainer/Policy mu Std                                     0.350739
trainer/Policy mu Max                                     1.94063
trainer/Policy mu Min                                    -2.3037
trainer/Policy log std Mean                              -2.35571
trainer/Policy log std Std                                0.520971
trainer/Policy log std Max                               -0.110455
trainer/Policy log std Min                               -3.3003
trainer/Alpha                                             0.021414
trainer/Alpha Loss                                        0.600903
exploration/num steps total                           21400
exploration/num paths total                            1070
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0787852
exploration/Rewards Std                                   0.0798825
exploration/Rewards Max                                   0.11139
exploration/Rewards Min                                  -0.314446
exploration/Returns Mean                                 -1.5757
exploration/Returns Std                                   1.14115
exploration/Returns Max                                  -0.0821894
exploration/Returns Min                                  -3.42007
exploration/Actions Mean                                  0.00236665
exploration/Actions Std                                   0.142787
exploration/Actions Max                                   0.649296
exploration/Actions Min                                  -0.686889
exploration/Num Paths                                     5
exploration/Average Returns                              -1.5757
exploration/env_infos/final/reward_energy Mean           -0.0667016
exploration/env_infos/final/reward_energy Std             0.044441
exploration/env_infos/final/reward_energy Max            -0.0162516
exploration/env_infos/final/reward_energy Min            -0.12877
exploration/env_infos/initial/reward_energy Mean         -0.388311
exploration/env_infos/initial/reward_energy Std           0.256613
exploration/env_infos/initial/reward_energy Max          -0.00855238
exploration/env_infos/initial/reward_energy Min          -0.697094
exploration/env_infos/reward_energy Mean                 -0.155354
exploration/env_infos/reward_energy Std                   0.129045
exploration/env_infos/reward_energy Max                  -0.00621571
exploration/env_infos/reward_energy Min                  -0.697094
exploration/env_infos/final/end_effector_loc Mean         0.0838587
exploration/env_infos/final/end_effector_loc Std          0.282681
exploration/env_infos/final/end_effector_loc Max          0.426438
exploration/env_infos/final/end_effector_loc Min         -0.472973
exploration/env_infos/initial/end_effector_loc Mean      -0.000940962
exploration/env_infos/initial/end_effector_loc Std        0.0164289
exploration/env_infos/initial/end_effector_loc Max        0.0324648
exploration/env_infos/initial/end_effector_loc Min       -0.0343445
exploration/env_infos/end_effector_loc Mean               0.0346138
exploration/env_infos/end_effector_loc Std                0.199011
exploration/env_infos/end_effector_loc Max                0.426438
exploration/env_infos/end_effector_loc Min               -0.472973
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.238193
exploration/env_infos/final/reward_dist Std               0.367857
exploration/env_infos/final/reward_dist Max               0.949794
exploration/env_infos/final/reward_dist Min               1.73603e-14
exploration/env_infos/initial/reward_dist Mean            0.0177059
exploration/env_infos/initial/reward_dist Std             0.023386
exploration/env_infos/initial/reward_dist Max             0.0629219
exploration/env_infos/initial/reward_dist Min             1.51212e-05
exploration/env_infos/reward_dist Mean                    0.136274
exploration/env_infos/reward_dist Std                     0.235127
exploration/env_infos/reward_dist Max                     0.994961
exploration/env_infos/reward_dist Min                     1.73603e-14
evaluation/num steps total                           204000
evaluation/num paths total                            10200
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0675259
evaluation/Rewards Std                                    0.120974
evaluation/Rewards Max                                    0.159101
evaluation/Rewards Min                                   -0.625852
evaluation/Returns Mean                                  -1.35052
evaluation/Returns Std                                    1.94598
evaluation/Returns Max                                    2.3806
evaluation/Returns Min                                   -7.24947
evaluation/Actions Mean                                  -0.0155492
evaluation/Actions Std                                    0.129194
evaluation/Actions Max                                    0.940827
evaluation/Actions Min                                   -0.979876
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.35052
evaluation/env_infos/final/reward_energy Mean            -0.0695131
evaluation/env_infos/final/reward_energy Std              0.113836
evaluation/env_infos/final/reward_energy Max             -0.00250174
evaluation/env_infos/final/reward_energy Min             -0.725096
evaluation/env_infos/initial/reward_energy Mean          -0.311233
evaluation/env_infos/initial/reward_energy Std            0.326285
evaluation/env_infos/initial/reward_energy Max           -0.0174305
evaluation/env_infos/initial/reward_energy Min           -1.25896
evaluation/env_infos/reward_energy Mean                  -0.0944858
evaluation/env_infos/reward_energy Std                    0.157919
evaluation/env_infos/reward_energy Max                   -0.00144269
evaluation/env_infos/reward_energy Min                   -1.25896
evaluation/env_infos/final/end_effector_loc Mean         -0.0930184
evaluation/env_infos/final/end_effector_loc Std           0.339306
evaluation/env_infos/final/end_effector_loc Max           0.842962
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00233994
evaluation/env_infos/initial/end_effector_loc Std         0.0157697
evaluation/env_infos/initial/end_effector_loc Max         0.0470413
evaluation/env_infos/initial/end_effector_loc Min        -0.0471986
evaluation/env_infos/end_effector_loc Mean               -0.0397304
evaluation/env_infos/end_effector_loc Std                 0.221547
evaluation/env_infos/end_effector_loc Max                 0.842962
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.174263
evaluation/env_infos/final/reward_dist Std                0.278711
evaluation/env_infos/final/reward_dist Max                0.92377
evaluation/env_infos/final/reward_dist Min                1.53951e-96
evaluation/env_infos/initial/reward_dist Mean             0.00736221
evaluation/env_infos/initial/reward_dist Std              0.0139794
evaluation/env_infos/initial/reward_dist Max              0.0749893
evaluation/env_infos/initial/reward_dist Min              5.38116e-07
evaluation/env_infos/reward_dist Mean                     0.161253
evaluation/env_infos/reward_dist Std                      0.259863
evaluation/env_infos/reward_dist Max                      0.998373
evaluation/env_infos/reward_dist Min                      1.53951e-96
time/data storing (s)                                    38.4067
time/evaluation sampling (s)                              0.633243
time/exploration sampling (s)                             0.088845
time/logging (s)                                          0.0144961
time/saving (s)                                           0.775965
time/training (s)                                        39.9351
time/epoch (s)                                           79.8543
time/total (s)                                        15081.2
Epoch                                                   203
---------------------------------------------------  ----------------
2021-05-29 04:08:35.715279 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 204 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00460807
trainer/QF2 Loss                                          0.00414115
trainer/Policy Loss                                       2.92334
trainer/Q1 Predictions Mean                              -1.0295
trainer/Q1 Predictions Std                                0.909839
trainer/Q1 Predictions Max                                0.930267
trainer/Q1 Predictions Min                               -3.85955
trainer/Q2 Predictions Mean                              -1.03576
trainer/Q2 Predictions Std                                0.912896
trainer/Q2 Predictions Max                                0.955129
trainer/Q2 Predictions Min                               -3.89094
trainer/Q Targets Mean                                   -1.04031
trainer/Q Targets Std                                     0.906451
trainer/Q Targets Max                                     1.00422
trainer/Q Targets Min                                    -3.91774
trainer/Log Pis Mean                                      1.90007
trainer/Log Pis Std                                       1.24972
trainer/Log Pis Max                                       4.50727
trainer/Log Pis Min                                      -3.3297
trainer/Policy mu Mean                                   -0.0147581
trainer/Policy mu Std                                     0.431763
trainer/Policy mu Max                                     2.16482
trainer/Policy mu Min                                    -2.00241
trainer/Policy log std Mean                              -2.22853
trainer/Policy log std Std                                0.560836
trainer/Policy log std Max                                0.3122
trainer/Policy log std Min                               -3.1956
trainer/Alpha                                             0.0227744
trainer/Alpha Loss                                       -0.377903
exploration/num steps total                           21500
exploration/num paths total                            1075
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.127071
exploration/Rewards Std                                   0.0819244
exploration/Rewards Max                                  -0.00208578
exploration/Rewards Min                                  -0.319149
exploration/Returns Mean                                 -2.54142
exploration/Returns Std                                   1.15799
exploration/Returns Max                                  -1.54042
exploration/Returns Min                                  -4.73436
exploration/Actions Mean                                 -0.0774188
exploration/Actions Std                                   0.284306
exploration/Actions Max                                   0.689608
exploration/Actions Min                                  -0.994685
exploration/Num Paths                                     5
exploration/Average Returns                              -2.54142
exploration/env_infos/final/reward_energy Mean           -0.275282
exploration/env_infos/final/reward_energy Std             0.237587
exploration/env_infos/final/reward_energy Max            -0.0852955
exploration/env_infos/final/reward_energy Min            -0.741201
exploration/env_infos/initial/reward_energy Mean         -0.420362
exploration/env_infos/initial/reward_energy Std           0.398747
exploration/env_infos/initial/reward_energy Max          -0.0736818
exploration/env_infos/initial/reward_energy Min          -1.01663
exploration/env_infos/reward_energy Mean                 -0.263724
exploration/env_infos/reward_energy Std                   0.322641
exploration/env_infos/reward_energy Max                  -0.0130818
exploration/env_infos/reward_energy Min                  -1.07781
exploration/env_infos/final/end_effector_loc Mean        -0.0778279
exploration/env_infos/final/end_effector_loc Std          0.479228
exploration/env_infos/final/end_effector_loc Max          0.375909
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.010398
exploration/env_infos/initial/end_effector_loc Std        0.0176497
exploration/env_infos/initial/end_effector_loc Max        0.00436172
exploration/env_infos/initial/end_effector_loc Min       -0.0398108
exploration/env_infos/end_effector_loc Mean              -0.0786993
exploration/env_infos/end_effector_loc Std                0.358089
exploration/env_infos/end_effector_loc Max                0.375909
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0253648
exploration/env_infos/final/reward_dist Std               0.0297539
exploration/env_infos/final/reward_dist Max               0.0769869
exploration/env_infos/final/reward_dist Min               8.68946e-98
exploration/env_infos/initial/reward_dist Mean            0.0037116
exploration/env_infos/initial/reward_dist Std             0.00379908
exploration/env_infos/initial/reward_dist Max             0.0106044
exploration/env_infos/initial/reward_dist Min             5.41137e-06
exploration/env_infos/reward_dist Mean                    0.0162904
exploration/env_infos/reward_dist Std                     0.0330155
exploration/env_infos/reward_dist Max                     0.175316
exploration/env_infos/reward_dist Min                     8.68946e-98
evaluation/num steps total                           205000
evaluation/num paths total                            10250
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0664402
evaluation/Rewards Std                                    0.117453
evaluation/Rewards Max                                    0.139312
evaluation/Rewards Min                                   -0.742
evaluation/Returns Mean                                  -1.3288
evaluation/Returns Std                                    1.85931
evaluation/Returns Max                                    1.59007
evaluation/Returns Min                                  -10.2332
evaluation/Actions Mean                                  -0.00525489
evaluation/Actions Std                                    0.137445
evaluation/Actions Max                                    0.952902
evaluation/Actions Min                                   -0.962037
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.3288
evaluation/env_infos/final/reward_energy Mean            -0.0628294
evaluation/env_infos/final/reward_energy Std              0.145857
evaluation/env_infos/final/reward_energy Max             -0.00429479
evaluation/env_infos/final/reward_energy Min             -1.04468
evaluation/env_infos/initial/reward_energy Mean          -0.310532
evaluation/env_infos/initial/reward_energy Std            0.274646
evaluation/env_infos/initial/reward_energy Max           -0.0239235
evaluation/env_infos/initial/reward_energy Min           -0.889496
evaluation/env_infos/reward_energy Mean                  -0.0948519
evaluation/env_infos/reward_energy Std                    0.169825
evaluation/env_infos/reward_energy Max                   -0.000523392
evaluation/env_infos/reward_energy Min                   -1.18976
evaluation/env_infos/final/end_effector_loc Mean         -0.0444736
evaluation/env_infos/final/end_effector_loc Std           0.366361
evaluation/env_infos/final/end_effector_loc Max           0.862086
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00234091
evaluation/env_infos/initial/end_effector_loc Std         0.0144688
evaluation/env_infos/initial/end_effector_loc Max         0.0443845
evaluation/env_infos/initial/end_effector_loc Min        -0.040089
evaluation/env_infos/end_effector_loc Mean               -0.0321137
evaluation/env_infos/end_effector_loc Std                 0.247804
evaluation/env_infos/end_effector_loc Max                 0.862086
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.14434
evaluation/env_infos/final/reward_dist Std                0.2392
evaluation/env_infos/final/reward_dist Max                0.90163
evaluation/env_infos/final/reward_dist Min                6.32108e-146
evaluation/env_infos/initial/reward_dist Mean             0.0068087
evaluation/env_infos/initial/reward_dist Std              0.0130705
evaluation/env_infos/initial/reward_dist Max              0.0633389
evaluation/env_infos/initial/reward_dist Min              1.39482e-06
evaluation/env_infos/reward_dist Mean                     0.133828
evaluation/env_infos/reward_dist Std                      0.219405
evaluation/env_infos/reward_dist Max                      0.96807
evaluation/env_infos/reward_dist Min                      6.32108e-146
time/data storing (s)                                    38.0857
time/evaluation sampling (s)                              0.537787
time/exploration sampling (s)                             0.0894607
time/logging (s)                                          0.0163584
time/saving (s)                                           0.797643
time/training (s)                                        39.2866
time/epoch (s)                                           78.8136
time/total (s)                                        15162.1
Epoch                                                   204
---------------------------------------------------  -----------------
2021-05-29 04:09:56.754695 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 205 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00410482
trainer/QF2 Loss                                          0.00351
trainer/Policy Loss                                       3.00346
trainer/Q1 Predictions Mean                              -1.00934
trainer/Q1 Predictions Std                                0.848253
trainer/Q1 Predictions Max                                0.796042
trainer/Q1 Predictions Min                               -3.77209
trainer/Q2 Predictions Mean                              -0.996676
trainer/Q2 Predictions Std                                0.84804
trainer/Q2 Predictions Max                                0.693907
trainer/Q2 Predictions Min                               -3.75692
trainer/Q Targets Mean                                   -1.01004
trainer/Q Targets Std                                     0.850428
trainer/Q Targets Max                                     0.779603
trainer/Q Targets Min                                    -3.73221
trainer/Log Pis Mean                                      2.01957
trainer/Log Pis Std                                       1.08781
trainer/Log Pis Max                                       4.37414
trainer/Log Pis Min                                      -2.09441
trainer/Policy mu Mean                                   -0.0332237
trainer/Policy mu Std                                     0.343537
trainer/Policy mu Max                                     1.46156
trainer/Policy mu Min                                    -2.40849
trainer/Policy log std Mean                              -2.33268
trainer/Policy log std Std                                0.469289
trainer/Policy log std Max                               -0.203993
trainer/Policy log std Min                               -3.16683
trainer/Alpha                                             0.0216661
trainer/Alpha Loss                                        0.075046
exploration/num steps total                           21600
exploration/num paths total                            1080
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0626464
exploration/Rewards Std                                   0.0794687
exploration/Rewards Max                                   0.0965178
exploration/Rewards Min                                  -0.219819
exploration/Returns Mean                                 -1.25293
exploration/Returns Std                                   1.149
exploration/Returns Max                                   0.621615
exploration/Returns Min                                  -2.45315
exploration/Actions Mean                                 -0.00480647
exploration/Actions Std                                   0.151638
exploration/Actions Max                                   0.952952
exploration/Actions Min                                  -0.696323
exploration/Num Paths                                     5
exploration/Average Returns                              -1.25293
exploration/env_infos/final/reward_energy Mean           -0.125385
exploration/env_infos/final/reward_energy Std             0.0696945
exploration/env_infos/final/reward_energy Max            -0.0494405
exploration/env_infos/final/reward_energy Min            -0.253063
exploration/env_infos/initial/reward_energy Mean         -0.400023
exploration/env_infos/initial/reward_energy Std           0.420863
exploration/env_infos/initial/reward_energy Max          -0.0409078
exploration/env_infos/initial/reward_energy Min          -1.18025
exploration/env_infos/reward_energy Mean                 -0.153356
exploration/env_infos/reward_energy Std                   0.150055
exploration/env_infos/reward_energy Max                  -0.00634351
exploration/env_infos/reward_energy Min                  -1.18025
exploration/env_infos/final/end_effector_loc Mean         0.018219
exploration/env_infos/final/end_effector_loc Std          0.190921
exploration/env_infos/final/end_effector_loc Max          0.367921
exploration/env_infos/final/end_effector_loc Min         -0.305406
exploration/env_infos/initial/end_effector_loc Mean      -0.000429085
exploration/env_infos/initial/end_effector_loc Std        0.0205243
exploration/env_infos/initial/end_effector_loc Max        0.0476476
exploration/env_infos/initial/end_effector_loc Min       -0.0348161
exploration/env_infos/end_effector_loc Mean               0.0175948
exploration/env_infos/end_effector_loc Std                0.144323
exploration/env_infos/end_effector_loc Max                0.367921
exploration/env_infos/end_effector_loc Min               -0.305406
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.181364
exploration/env_infos/final/reward_dist Std               0.259402
exploration/env_infos/final/reward_dist Max               0.665807
exploration/env_infos/final/reward_dist Min               8.55357e-06
exploration/env_infos/initial/reward_dist Mean            0.000302727
exploration/env_infos/initial/reward_dist Std             0.000183864
exploration/env_infos/initial/reward_dist Max             0.000532312
exploration/env_infos/initial/reward_dist Min             7.62148e-05
exploration/env_infos/reward_dist Mean                    0.151068
exploration/env_infos/reward_dist Std                     0.253143
exploration/env_infos/reward_dist Max                     0.758639
exploration/env_infos/reward_dist Min                     6.75655e-09
evaluation/num steps total                           206000
evaluation/num paths total                            10300
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0851315
evaluation/Rewards Std                                    0.115977
evaluation/Rewards Max                                    0.171798
evaluation/Rewards Min                                   -0.686944
evaluation/Returns Mean                                  -1.70263
evaluation/Returns Std                                    1.7308
evaluation/Returns Max                                    1.52677
evaluation/Returns Min                                   -8.54798
evaluation/Actions Mean                                  -0.0253188
evaluation/Actions Std                                    0.159049
evaluation/Actions Max                                    0.929127
evaluation/Actions Min                                   -0.992087
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.70263
evaluation/env_infos/final/reward_energy Mean            -0.0904805
evaluation/env_infos/final/reward_energy Std              0.186668
evaluation/env_infos/final/reward_energy Max             -0.00861133
evaluation/env_infos/final/reward_energy Min             -1.01543
evaluation/env_infos/initial/reward_energy Mean          -0.376884
evaluation/env_infos/initial/reward_energy Std            0.367257
evaluation/env_infos/initial/reward_energy Max           -0.00360173
evaluation/env_infos/initial/reward_energy Min           -1.28525
evaluation/env_infos/reward_energy Mean                  -0.116538
evaluation/env_infos/reward_energy Std                    0.195688
evaluation/env_infos/reward_energy Max                   -0.000612595
evaluation/env_infos/reward_energy Min                   -1.29394
evaluation/env_infos/final/end_effector_loc Mean         -0.109825
evaluation/env_infos/final/end_effector_loc Std           0.412262
evaluation/env_infos/final/end_effector_loc Max           0.813341
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00217221
evaluation/env_infos/initial/end_effector_loc Std         0.0184778
evaluation/env_infos/initial/end_effector_loc Max         0.0464563
evaluation/env_infos/initial/end_effector_loc Min        -0.048083
evaluation/env_infos/end_effector_loc Mean               -0.0439931
evaluation/env_infos/end_effector_loc Std                 0.30392
evaluation/env_infos/end_effector_loc Max                 0.813341
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.125613
evaluation/env_infos/final/reward_dist Std                0.239377
evaluation/env_infos/final/reward_dist Max                0.895675
evaluation/env_infos/final/reward_dist Min                2.56769e-156
evaluation/env_infos/initial/reward_dist Mean             0.00760272
evaluation/env_infos/initial/reward_dist Std              0.0152357
evaluation/env_infos/initial/reward_dist Max              0.0907839
evaluation/env_infos/initial/reward_dist Min              4.39006e-07
evaluation/env_infos/reward_dist Mean                     0.119084
evaluation/env_infos/reward_dist Std                      0.219589
evaluation/env_infos/reward_dist Max                      0.999908
evaluation/env_infos/reward_dist Min                      2.56769e-156
time/data storing (s)                                    37.9858
time/evaluation sampling (s)                              0.632
time/exploration sampling (s)                             0.0844329
time/logging (s)                                          0.015003
time/saving (s)                                           0.792685
time/training (s)                                        39.3601
time/epoch (s)                                           78.87
time/total (s)                                        15243.2
Epoch                                                   205
---------------------------------------------------  -----------------
2021-05-29 04:11:17.945000 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 206 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00383508
trainer/QF2 Loss                                          0.00330908
trainer/Policy Loss                                       2.92993
trainer/Q1 Predictions Mean                              -0.969269
trainer/Q1 Predictions Std                                0.834043
trainer/Q1 Predictions Max                                0.670215
trainer/Q1 Predictions Min                               -3.53395
trainer/Q2 Predictions Mean                              -0.967373
trainer/Q2 Predictions Std                                0.824472
trainer/Q2 Predictions Max                                0.637673
trainer/Q2 Predictions Min                               -3.5446
trainer/Q Targets Mean                                   -0.961068
trainer/Q Targets Std                                     0.833114
trainer/Q Targets Max                                     0.717307
trainer/Q Targets Min                                    -3.50562
trainer/Log Pis Mean                                      1.98054
trainer/Log Pis Std                                       1.223
trainer/Log Pis Max                                       4.87356
trainer/Log Pis Min                                      -4.94986
trainer/Policy mu Mean                                    0.00514054
trainer/Policy mu Std                                     0.476747
trainer/Policy mu Max                                     3.09104
trainer/Policy mu Min                                    -2.36038
trainer/Policy log std Mean                              -2.21303
trainer/Policy log std Std                                0.530766
trainer/Policy log std Max                               -0.536638
trainer/Policy log std Min                               -3.27047
trainer/Alpha                                             0.0239275
trainer/Alpha Loss                                       -0.0726227
exploration/num steps total                           21700
exploration/num paths total                            1085
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0549125
exploration/Rewards Std                                   0.092937
exploration/Rewards Max                                   0.120777
exploration/Rewards Min                                  -0.417267
exploration/Returns Mean                                 -1.09825
exploration/Returns Std                                   1.11886
exploration/Returns Max                                   0.699917
exploration/Returns Min                                  -2.14272
exploration/Actions Mean                                 -0.0146752
exploration/Actions Std                                   0.158757
exploration/Actions Max                                   0.525833
exploration/Actions Min                                  -0.702872
exploration/Num Paths                                     5
exploration/Average Returns                              -1.09825
exploration/env_infos/final/reward_energy Mean           -0.166833
exploration/env_infos/final/reward_energy Std             0.101108
exploration/env_infos/final/reward_energy Max            -0.0866292
exploration/env_infos/final/reward_energy Min            -0.363313
exploration/env_infos/initial/reward_energy Mean         -0.398256
exploration/env_infos/initial/reward_energy Std           0.254997
exploration/env_infos/initial/reward_energy Max          -0.0580998
exploration/env_infos/initial/reward_energy Min          -0.794121
exploration/env_infos/reward_energy Mean                 -0.166709
exploration/env_infos/reward_energy Std                   0.15181
exploration/env_infos/reward_energy Max                  -0.00620194
exploration/env_infos/reward_energy Min                  -0.794121
exploration/env_infos/final/end_effector_loc Mean        -0.141013
exploration/env_infos/final/end_effector_loc Std          0.299136
exploration/env_infos/final/end_effector_loc Max          0.346491
exploration/env_infos/final/end_effector_loc Min         -0.733015
exploration/env_infos/initial/end_effector_loc Mean      -0.00362203
exploration/env_infos/initial/end_effector_loc Std        0.0163224
exploration/env_infos/initial/end_effector_loc Max        0.0184797
exploration/env_infos/initial/end_effector_loc Min       -0.0351436
exploration/env_infos/end_effector_loc Mean              -0.0658683
exploration/env_infos/end_effector_loc Std                0.180746
exploration/env_infos/end_effector_loc Max                0.346491
exploration/env_infos/end_effector_loc Min               -0.733015
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0449463
exploration/env_infos/final/reward_dist Std               0.0565399
exploration/env_infos/final/reward_dist Max               0.15219
exploration/env_infos/final/reward_dist Min               1.15438e-14
exploration/env_infos/initial/reward_dist Mean            0.00102859
exploration/env_infos/initial/reward_dist Std             0.00181504
exploration/env_infos/initial/reward_dist Max             0.00464223
exploration/env_infos/initial/reward_dist Min             4.9996e-06
exploration/env_infos/reward_dist Mean                    0.149353
exploration/env_infos/reward_dist Std                     0.247138
exploration/env_infos/reward_dist Max                     0.956343
exploration/env_infos/reward_dist Min                     1.15438e-14
evaluation/num steps total                           207000
evaluation/num paths total                            10350
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.085296
evaluation/Rewards Std                                    0.118744
evaluation/Rewards Max                                    0.131029
evaluation/Rewards Min                                   -0.832103
evaluation/Returns Mean                                  -1.70592
evaluation/Returns Std                                    1.8298
evaluation/Returns Max                                    1.35924
evaluation/Returns Min                                   -9.44478
evaluation/Actions Mean                                  -0.0100609
evaluation/Actions Std                                    0.117202
evaluation/Actions Max                                    0.832462
evaluation/Actions Min                                   -0.891876
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.70592
evaluation/env_infos/final/reward_energy Mean            -0.060856
evaluation/env_infos/final/reward_energy Std              0.0867388
evaluation/env_infos/final/reward_energy Max             -0.00423846
evaluation/env_infos/final/reward_energy Min             -0.431073
evaluation/env_infos/initial/reward_energy Mean          -0.295036
evaluation/env_infos/initial/reward_energy Std            0.303763
evaluation/env_infos/initial/reward_energy Max           -0.00664765
evaluation/env_infos/initial/reward_energy Min           -1.25785
evaluation/env_infos/reward_energy Mean                  -0.0893609
evaluation/env_infos/reward_energy Std                    0.14032
evaluation/env_infos/reward_energy Max                   -0.00326575
evaluation/env_infos/reward_energy Min                   -1.25785
evaluation/env_infos/final/end_effector_loc Mean         -0.127955
evaluation/env_infos/final/end_effector_loc Std           0.38454
evaluation/env_infos/final/end_effector_loc Max           0.918302
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00127436
evaluation/env_infos/initial/end_effector_loc Std         0.0149172
evaluation/env_infos/initial/end_effector_loc Max         0.0416231
evaluation/env_infos/initial/end_effector_loc Min        -0.0445938
evaluation/env_infos/end_effector_loc Mean               -0.0605843
evaluation/env_infos/end_effector_loc Std                 0.255247
evaluation/env_infos/end_effector_loc Max                 0.918302
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0660274
evaluation/env_infos/final/reward_dist Std                0.173634
evaluation/env_infos/final/reward_dist Max                0.81899
evaluation/env_infos/final/reward_dist Min                2.39219e-111
evaluation/env_infos/initial/reward_dist Mean             0.0109079
evaluation/env_infos/initial/reward_dist Std              0.025243
evaluation/env_infos/initial/reward_dist Max              0.133431
evaluation/env_infos/initial/reward_dist Min              7.52989e-08
evaluation/env_infos/reward_dist Mean                     0.0820556
evaluation/env_infos/reward_dist Std                      0.174182
evaluation/env_infos/reward_dist Max                      0.933003
evaluation/env_infos/reward_dist Min                      2.39219e-111
time/data storing (s)                                    37.9997
time/evaluation sampling (s)                              0.630493
time/exploration sampling (s)                             0.0893863
time/logging (s)                                          0.0151764
time/saving (s)                                           0.798767
time/training (s)                                        39.4855
time/epoch (s)                                           79.019
time/total (s)                                        15324.3
Epoch                                                   206
---------------------------------------------------  -----------------
2021-05-29 04:12:39.824342 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 207 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0137672
trainer/QF2 Loss                                          0.0135352
trainer/Policy Loss                                       2.7747
trainer/Q1 Predictions Mean                              -0.818099
trainer/Q1 Predictions Std                                0.866409
trainer/Q1 Predictions Max                                0.912992
trainer/Q1 Predictions Min                               -3.45309
trainer/Q2 Predictions Mean                              -0.807682
trainer/Q2 Predictions Std                                0.869908
trainer/Q2 Predictions Max                                1.21417
trainer/Q2 Predictions Min                               -3.31448
trainer/Q Targets Mean                                   -0.829133
trainer/Q Targets Std                                     0.860317
trainer/Q Targets Max                                     0.941106
trainer/Q Targets Min                                    -3.57681
trainer/Log Pis Mean                                      1.96139
trainer/Log Pis Std                                       1.45985
trainer/Log Pis Max                                       5.32462
trainer/Log Pis Min                                      -6.599
trainer/Policy mu Mean                                   -0.0590405
trainer/Policy mu Std                                     0.392096
trainer/Policy mu Max                                     2.19238
trainer/Policy mu Min                                    -2.64526
trainer/Policy log std Mean                              -2.30829
trainer/Policy log std Std                                0.493585
trainer/Policy log std Max                               -0.185002
trainer/Policy log std Min                               -3.38459
trainer/Alpha                                             0.0230334
trainer/Alpha Loss                                       -0.145618
exploration/num steps total                           21800
exploration/num paths total                            1090
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.137336
exploration/Rewards Std                                   0.114362
exploration/Rewards Max                                   0.0725149
exploration/Rewards Min                                  -0.597064
exploration/Returns Mean                                 -2.74671
exploration/Returns Std                                   1.31269
exploration/Returns Max                                  -1.5087
exploration/Returns Min                                  -5.22098
exploration/Actions Mean                                 -0.0730632
exploration/Actions Std                                   0.224639
exploration/Actions Max                                   0.435485
exploration/Actions Min                                  -0.959643
exploration/Num Paths                                     5
exploration/Average Returns                              -2.74671
exploration/env_infos/final/reward_energy Mean           -0.115545
exploration/env_infos/final/reward_energy Std             0.0889434
exploration/env_infos/final/reward_energy Max            -0.0466322
exploration/env_infos/final/reward_energy Min            -0.286562
exploration/env_infos/initial/reward_energy Mean         -0.344309
exploration/env_infos/initial/reward_energy Std           0.475838
exploration/env_infos/initial/reward_energy Max          -0.0562183
exploration/env_infos/initial/reward_energy Min          -1.28541
exploration/env_infos/reward_energy Mean                 -0.210137
exploration/env_infos/reward_energy Std                   0.2597
exploration/env_infos/reward_energy Max                  -0.0062612
exploration/env_infos/reward_energy Min                  -1.28541
exploration/env_infos/final/end_effector_loc Mean        -0.288299
exploration/env_infos/final/end_effector_loc Std          0.495942
exploration/env_infos/final/end_effector_loc Max          0.446858
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.0077117
exploration/env_infos/initial/end_effector_loc Std        0.0192806
exploration/env_infos/initial/end_effector_loc Max        0.0121217
exploration/env_infos/initial/end_effector_loc Min       -0.0479821
exploration/env_infos/end_effector_loc Mean              -0.18333
exploration/env_infos/end_effector_loc Std                0.387735
exploration/env_infos/end_effector_loc Max                0.446858
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0608386
exploration/env_infos/final/reward_dist Std               0.0744967
exploration/env_infos/final/reward_dist Max               0.155096
exploration/env_infos/final/reward_dist Min               4.17835e-106
exploration/env_infos/initial/reward_dist Mean            0.0330374
exploration/env_infos/initial/reward_dist Std             0.0548544
exploration/env_infos/initial/reward_dist Max             0.141179
exploration/env_infos/initial/reward_dist Min             6.30696e-06
exploration/env_infos/reward_dist Mean                    0.0573411
exploration/env_infos/reward_dist Std                     0.115261
exploration/env_infos/reward_dist Max                     0.787044
exploration/env_infos/reward_dist Min                     4.17835e-106
evaluation/num steps total                           208000
evaluation/num paths total                            10400
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.117013
evaluation/Rewards Std                                    0.166654
evaluation/Rewards Max                                    0.141269
evaluation/Rewards Min                                   -0.985662
evaluation/Returns Mean                                  -2.34026
evaluation/Returns Std                                    2.93533
evaluation/Returns Max                                    1.42559
evaluation/Returns Min                                  -13.5269
evaluation/Actions Mean                                  -0.0180044
evaluation/Actions Std                                    0.217856
evaluation/Actions Max                                    0.999631
evaluation/Actions Min                                   -0.998051
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.34026
evaluation/env_infos/final/reward_energy Mean            -0.115918
evaluation/env_infos/final/reward_energy Std              0.174335
evaluation/env_infos/final/reward_energy Max             -0.00308649
evaluation/env_infos/final/reward_energy Min             -0.881596
evaluation/env_infos/initial/reward_energy Mean          -0.416894
evaluation/env_infos/initial/reward_energy Std            0.369607
evaluation/env_infos/initial/reward_energy Max           -0.0370912
evaluation/env_infos/initial/reward_energy Min           -1.19359
evaluation/env_infos/reward_energy Mean                  -0.160996
evaluation/env_infos/reward_energy Std                    0.263914
evaluation/env_infos/reward_energy Max                   -0.00119489
evaluation/env_infos/reward_energy Min                   -1.38805
evaluation/env_infos/final/end_effector_loc Mean         -0.14256
evaluation/env_infos/final/end_effector_loc Std           0.425879
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000693622
evaluation/env_infos/initial/end_effector_loc Std         0.0196858
evaluation/env_infos/initial/end_effector_loc Max         0.0461737
evaluation/env_infos/initial/end_effector_loc Min        -0.0493339
evaluation/env_infos/end_effector_loc Mean               -0.0765178
evaluation/env_infos/end_effector_loc Std                 0.295144
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0638056
evaluation/env_infos/final/reward_dist Std                0.15254
evaluation/env_infos/final/reward_dist Max                0.719992
evaluation/env_infos/final/reward_dist Min                1.91707e-121
evaluation/env_infos/initial/reward_dist Mean             0.00820997
evaluation/env_infos/initial/reward_dist Std              0.0187237
evaluation/env_infos/initial/reward_dist Max              0.123295
evaluation/env_infos/initial/reward_dist Min              7.40047e-07
evaluation/env_infos/reward_dist Mean                     0.0839803
evaluation/env_infos/reward_dist Std                      0.182929
evaluation/env_infos/reward_dist Max                      0.979046
evaluation/env_infos/reward_dist Min                      1.91707e-121
time/data storing (s)                                    38.2835
time/evaluation sampling (s)                              0.630299
time/exploration sampling (s)                             0.0873556
time/logging (s)                                          0.0162062
time/saving (s)                                           0.796403
time/training (s)                                        39.8646
time/epoch (s)                                           79.6783
time/total (s)                                        15406.2
Epoch                                                   207
---------------------------------------------------  -----------------
2021-05-29 04:14:00.696079 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 208 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00450957
trainer/QF2 Loss                                          0.00327916
trainer/Policy Loss                                       3.08575
trainer/Q1 Predictions Mean                              -0.992698
trainer/Q1 Predictions Std                                0.836004
trainer/Q1 Predictions Max                                0.918079
trainer/Q1 Predictions Min                               -3.3519
trainer/Q2 Predictions Mean                              -0.99248
trainer/Q2 Predictions Std                                0.832208
trainer/Q2 Predictions Max                                0.87088
trainer/Q2 Predictions Min                               -3.34099
trainer/Q Targets Mean                                   -0.993262
trainer/Q Targets Std                                     0.84201
trainer/Q Targets Max                                     0.833912
trainer/Q Targets Min                                    -3.33423
trainer/Log Pis Mean                                      2.10197
trainer/Log Pis Std                                       1.18998
trainer/Log Pis Max                                       7.00359
trainer/Log Pis Min                                      -1.38543
trainer/Policy mu Mean                                   -0.0167245
trainer/Policy mu Std                                     0.483538
trainer/Policy mu Max                                     2.95411
trainer/Policy mu Min                                    -2.30535
trainer/Policy log std Mean                              -2.263
trainer/Policy log std Std                                0.549947
trainer/Policy log std Max                                0.0335963
trainer/Policy log std Min                               -3.16136
trainer/Alpha                                             0.0230832
trainer/Alpha Loss                                        0.384486
exploration/num steps total                           21900
exploration/num paths total                            1095
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.123614
exploration/Rewards Std                                   0.0549824
exploration/Rewards Max                                  -0.0395268
exploration/Rewards Min                                  -0.285779
exploration/Returns Mean                                 -2.47229
exploration/Returns Std                                   0.688509
exploration/Returns Max                                  -1.4546
exploration/Returns Min                                  -3.53559
exploration/Actions Mean                                 -0.00147187
exploration/Actions Std                                   0.0707784
exploration/Actions Max                                   0.242841
exploration/Actions Min                                  -0.201872
exploration/Num Paths                                     5
exploration/Average Returns                              -2.47229
exploration/env_infos/final/reward_energy Mean           -0.0814532
exploration/env_infos/final/reward_energy Std             0.0235975
exploration/env_infos/final/reward_energy Max            -0.0494728
exploration/env_infos/final/reward_energy Min            -0.109188
exploration/env_infos/initial/reward_energy Mean         -0.170789
exploration/env_infos/initial/reward_energy Std           0.0590933
exploration/env_infos/initial/reward_energy Max          -0.0728492
exploration/env_infos/initial/reward_energy Min          -0.256219
exploration/env_infos/reward_energy Mean                 -0.088658
exploration/env_infos/reward_energy Std                   0.0465109
exploration/env_infos/reward_energy Max                  -0.0189683
exploration/env_infos/reward_energy Min                  -0.256219
exploration/env_infos/final/end_effector_loc Mean        -0.054918
exploration/env_infos/final/end_effector_loc Std          0.35767
exploration/env_infos/final/end_effector_loc Max          0.418158
exploration/env_infos/final/end_effector_loc Min         -0.967901
exploration/env_infos/initial/end_effector_loc Mean      -0.000677998
exploration/env_infos/initial/end_effector_loc Std        0.00635345
exploration/env_infos/initial/end_effector_loc Max        0.012142
exploration/env_infos/initial/end_effector_loc Min       -0.00822113
exploration/env_infos/end_effector_loc Mean              -0.0296116
exploration/env_infos/end_effector_loc Std                0.181168
exploration/env_infos/end_effector_loc Max                0.418158
exploration/env_infos/end_effector_loc Min               -0.967901
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000215068
exploration/env_infos/final/reward_dist Std               0.000418008
exploration/env_infos/final/reward_dist Max               0.00105087
exploration/env_infos/final/reward_dist Min               8.20421e-64
exploration/env_infos/initial/reward_dist Mean            0.00595454
exploration/env_infos/initial/reward_dist Std             0.00700571
exploration/env_infos/initial/reward_dist Max             0.0183739
exploration/env_infos/initial/reward_dist Min             0.000101735
exploration/env_infos/reward_dist Mean                    0.00850295
exploration/env_infos/reward_dist Std                     0.0198888
exploration/env_infos/reward_dist Max                     0.0791963
exploration/env_infos/reward_dist Min                     8.20421e-64
evaluation/num steps total                           209000
evaluation/num paths total                            10450
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0681125
evaluation/Rewards Std                                    0.100886
evaluation/Rewards Max                                    0.134441
evaluation/Rewards Min                                   -0.602883
evaluation/Returns Mean                                  -1.36225
evaluation/Returns Std                                    1.37162
evaluation/Returns Max                                    1.37037
evaluation/Returns Min                                   -5.90574
evaluation/Actions Mean                                  -0.0100896
evaluation/Actions Std                                    0.112554
evaluation/Actions Max                                    0.856689
evaluation/Actions Min                                   -0.868221
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.36225
evaluation/env_infos/final/reward_energy Mean            -0.0482042
evaluation/env_infos/final/reward_energy Std              0.0705283
evaluation/env_infos/final/reward_energy Max             -0.00262532
evaluation/env_infos/final/reward_energy Min             -0.425046
evaluation/env_infos/initial/reward_energy Mean          -0.324185
evaluation/env_infos/initial/reward_energy Std            0.279213
evaluation/env_infos/initial/reward_energy Max           -0.0119625
evaluation/env_infos/initial/reward_energy Min           -1.13301
evaluation/env_infos/reward_energy Mean                  -0.0919983
evaluation/env_infos/reward_energy Std                    0.130678
evaluation/env_infos/reward_energy Max                   -0.000586332
evaluation/env_infos/reward_energy Min                   -1.13301
evaluation/env_infos/final/end_effector_loc Mean         -0.123624
evaluation/env_infos/final/end_effector_loc Std           0.373823
evaluation/env_infos/final/end_effector_loc Max           0.525066
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000505535
evaluation/env_infos/initial/end_effector_loc Std         0.0151183
evaluation/env_infos/initial/end_effector_loc Max         0.0428345
evaluation/env_infos/initial/end_effector_loc Min        -0.043411
evaluation/env_infos/end_effector_loc Mean               -0.0584165
evaluation/env_infos/end_effector_loc Std                 0.240402
evaluation/env_infos/end_effector_loc Max                 0.525066
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0713271
evaluation/env_infos/final/reward_dist Std                0.149972
evaluation/env_infos/final/reward_dist Max                0.755272
evaluation/env_infos/final/reward_dist Min                9.84238e-141
evaluation/env_infos/initial/reward_dist Mean             0.00679985
evaluation/env_infos/initial/reward_dist Std              0.0144418
evaluation/env_infos/initial/reward_dist Max              0.0655164
evaluation/env_infos/initial/reward_dist Min              1.86656e-06
evaluation/env_infos/reward_dist Mean                     0.10692
evaluation/env_infos/reward_dist Std                      0.209415
evaluation/env_infos/reward_dist Max                      0.99868
evaluation/env_infos/reward_dist Min                      9.84238e-141
time/data storing (s)                                    37.8879
time/evaluation sampling (s)                              0.653424
time/exploration sampling (s)                             0.0908323
time/logging (s)                                          0.014466
time/saving (s)                                           0.781035
time/training (s)                                        39.2142
time/epoch (s)                                           78.6419
time/total (s)                                        15487.1
Epoch                                                   208
---------------------------------------------------  -----------------
2021-05-29 04:15:21.899828 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 209 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00650388
trainer/QF2 Loss                                          0.00726954
trainer/Policy Loss                                       2.94308
trainer/Q1 Predictions Mean                              -0.941793
trainer/Q1 Predictions Std                                0.881685
trainer/Q1 Predictions Max                                0.613568
trainer/Q1 Predictions Min                               -3.31516
trainer/Q2 Predictions Mean                              -0.949294
trainer/Q2 Predictions Std                                0.874825
trainer/Q2 Predictions Max                                0.588405
trainer/Q2 Predictions Min                               -3.37082
trainer/Q Targets Mean                                   -0.970578
trainer/Q Targets Std                                     0.879783
trainer/Q Targets Max                                     0.583829
trainer/Q Targets Min                                    -3.28426
trainer/Log Pis Mean                                      1.99865
trainer/Log Pis Std                                       1.38597
trainer/Log Pis Max                                       8.85177
trainer/Log Pis Min                                      -2.42119
trainer/Policy mu Mean                                   -5.81332e-06
trainer/Policy mu Std                                     0.334626
trainer/Policy mu Max                                     1.94756
trainer/Policy mu Min                                    -1.94019
trainer/Policy log std Mean                              -2.29695
trainer/Policy log std Std                                0.591557
trainer/Policy log std Max                                2
trainer/Policy log std Min                               -3.06356
trainer/Alpha                                             0.0250315
trainer/Alpha Loss                                       -0.00496595
exploration/num steps total                           22000
exploration/num paths total                            1100
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.111458
exploration/Rewards Std                                   0.0936894
exploration/Rewards Max                                   0.0673667
exploration/Rewards Min                                  -0.485987
exploration/Returns Mean                                 -2.22915
exploration/Returns Std                                   0.831401
exploration/Returns Max                                  -0.854954
exploration/Returns Min                                  -3.20616
exploration/Actions Mean                                 -0.00821989
exploration/Actions Std                                   0.125459
exploration/Actions Max                                   0.626381
exploration/Actions Min                                  -0.603392
exploration/Num Paths                                     5
exploration/Average Returns                              -2.22915
exploration/env_infos/final/reward_energy Mean           -0.0702141
exploration/env_infos/final/reward_energy Std             0.0303618
exploration/env_infos/final/reward_energy Max            -0.0300135
exploration/env_infos/final/reward_energy Min            -0.118129
exploration/env_infos/initial/reward_energy Mean         -0.3732
exploration/env_infos/initial/reward_energy Std           0.275859
exploration/env_infos/initial/reward_energy Max          -0.130802
exploration/env_infos/initial/reward_energy Min          -0.869733
exploration/env_infos/reward_energy Mean                 -0.134927
exploration/env_infos/reward_energy Std                   0.1158
exploration/env_infos/reward_energy Max                  -0.00595459
exploration/env_infos/reward_energy Min                  -0.869733
exploration/env_infos/final/end_effector_loc Mean         0.00180402
exploration/env_infos/final/end_effector_loc Std          0.527174
exploration/env_infos/final/end_effector_loc Max          0.815939
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00307343
exploration/env_infos/initial/end_effector_loc Std        0.0161175
exploration/env_infos/initial/end_effector_loc Max        0.031319
exploration/env_infos/initial/end_effector_loc Min       -0.0301696
exploration/env_infos/end_effector_loc Mean               0.0218999
exploration/env_infos/end_effector_loc Std                0.310729
exploration/env_infos/end_effector_loc Max                0.815939
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0643758
exploration/env_infos/final/reward_dist Std               0.128752
exploration/env_infos/final/reward_dist Max               0.321879
exploration/env_infos/final/reward_dist Min               6.34993e-99
exploration/env_infos/initial/reward_dist Mean            0.0186274
exploration/env_infos/initial/reward_dist Std             0.0366457
exploration/env_infos/initial/reward_dist Max             0.0919133
exploration/env_infos/initial/reward_dist Min             1.27781e-06
exploration/env_infos/reward_dist Mean                    0.0372499
exploration/env_infos/reward_dist Std                     0.0780714
exploration/env_infos/reward_dist Max                     0.328005
exploration/env_infos/reward_dist Min                     6.34993e-99
evaluation/num steps total                           210000
evaluation/num paths total                            10500
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0839675
evaluation/Rewards Std                                    0.0934909
evaluation/Rewards Max                                    0.128621
evaluation/Rewards Min                                   -0.65476
evaluation/Returns Mean                                  -1.67935
evaluation/Returns Std                                    1.42683
evaluation/Returns Max                                    0.306889
evaluation/Returns Min                                   -7.00031
evaluation/Actions Mean                                  -0.00113655
evaluation/Actions Std                                    0.114359
evaluation/Actions Max                                    0.893737
evaluation/Actions Min                                   -0.86483
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.67935
evaluation/env_infos/final/reward_energy Mean            -0.0449422
evaluation/env_infos/final/reward_energy Std              0.0403485
evaluation/env_infos/final/reward_energy Max             -0.00493514
evaluation/env_infos/final/reward_energy Min             -0.17692
evaluation/env_infos/initial/reward_energy Mean          -0.284467
evaluation/env_infos/initial/reward_energy Std            0.298239
evaluation/env_infos/initial/reward_energy Max           -0.00403957
evaluation/env_infos/initial/reward_energy Min           -0.986397
evaluation/env_infos/reward_energy Mean                  -0.081267
evaluation/env_infos/reward_energy Std                    0.139836
evaluation/env_infos/reward_energy Max                   -0.00321401
evaluation/env_infos/reward_energy Min                   -1.06847
evaluation/env_infos/final/end_effector_loc Mean         -0.0196915
evaluation/env_infos/final/end_effector_loc Std           0.286502
evaluation/env_infos/final/end_effector_loc Max           0.857655
evaluation/env_infos/final/end_effector_loc Min          -0.732607
evaluation/env_infos/initial/end_effector_loc Mean        0.00197696
evaluation/env_infos/initial/end_effector_loc Std         0.014437
evaluation/env_infos/initial/end_effector_loc Max         0.0390579
evaluation/env_infos/initial/end_effector_loc Min        -0.0432415
evaluation/env_infos/end_effector_loc Mean               -0.00106842
evaluation/env_infos/end_effector_loc Std                 0.184279
evaluation/env_infos/end_effector_loc Max                 0.857655
evaluation/env_infos/end_effector_loc Min                -0.732607
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.107868
evaluation/env_infos/final/reward_dist Std                0.207033
evaluation/env_infos/final/reward_dist Max                0.888757
evaluation/env_infos/final/reward_dist Min                7.66181e-73
evaluation/env_infos/initial/reward_dist Mean             0.00686359
evaluation/env_infos/initial/reward_dist Std              0.0140348
evaluation/env_infos/initial/reward_dist Max              0.0853675
evaluation/env_infos/initial/reward_dist Min              1.55681e-06
evaluation/env_infos/reward_dist Mean                     0.101778
evaluation/env_infos/reward_dist Std                      0.200001
evaluation/env_infos/reward_dist Max                      0.99449
evaluation/env_infos/reward_dist Min                      7.66181e-73
time/data storing (s)                                    37.5339
time/evaluation sampling (s)                              0.644735
time/exploration sampling (s)                             0.0891273
time/logging (s)                                          0.0150347
time/saving (s)                                           0.782969
time/training (s)                                        39.5156
time/epoch (s)                                           78.5814
time/total (s)                                        15568.3
Epoch                                                   209
---------------------------------------------------  ----------------
2021-05-29 04:16:42.134494 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 210 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00405394
trainer/QF2 Loss                                          0.00572591
trainer/Policy Loss                                       3.05369
trainer/Q1 Predictions Mean                              -1.02293
trainer/Q1 Predictions Std                                0.942141
trainer/Q1 Predictions Max                                0.702083
trainer/Q1 Predictions Min                               -3.69359
trainer/Q2 Predictions Mean                              -1.02492
trainer/Q2 Predictions Std                                0.940483
trainer/Q2 Predictions Max                                0.672589
trainer/Q2 Predictions Min                               -3.82476
trainer/Q Targets Mean                                   -1.03095
trainer/Q Targets Std                                     0.942349
trainer/Q Targets Max                                     0.701797
trainer/Q Targets Min                                    -3.84279
trainer/Log Pis Mean                                      2.02907
trainer/Log Pis Std                                       1.10397
trainer/Log Pis Max                                       4.14529
trainer/Log Pis Min                                      -2.65331
trainer/Policy mu Mean                                    0.0397646
trainer/Policy mu Std                                     0.300937
trainer/Policy mu Max                                     2.21685
trainer/Policy mu Min                                    -1.46558
trainer/Policy log std Mean                              -2.34419
trainer/Policy log std Std                                0.421303
trainer/Policy log std Max                               -0.683586
trainer/Policy log std Min                               -3.07137
trainer/Alpha                                             0.0236285
trainer/Alpha Loss                                        0.108942
exploration/num steps total                           22100
exploration/num paths total                            1105
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0900524
exploration/Rewards Std                                   0.0993704
exploration/Rewards Max                                   0.0956764
exploration/Rewards Min                                  -0.52607
exploration/Returns Mean                                 -1.80105
exploration/Returns Std                                   1.21915
exploration/Returns Max                                  -0.0274462
exploration/Returns Min                                  -3.24111
exploration/Actions Mean                                 -0.00807622
exploration/Actions Std                                   0.0987381
exploration/Actions Max                                   0.225402
exploration/Actions Min                                  -0.617885
exploration/Num Paths                                     5
exploration/Average Returns                              -1.80105
exploration/env_infos/final/reward_energy Mean           -0.0795584
exploration/env_infos/final/reward_energy Std             0.0561565
exploration/env_infos/final/reward_energy Max            -0.00720493
exploration/env_infos/final/reward_energy Min            -0.159619
exploration/env_infos/initial/reward_energy Mean         -0.232183
exploration/env_infos/initial/reward_energy Std           0.199751
exploration/env_infos/initial/reward_energy Max          -0.0752356
exploration/env_infos/initial/reward_energy Min          -0.622089
exploration/env_infos/reward_energy Mean                 -0.110691
exploration/env_infos/reward_energy Std                   0.0858863
exploration/env_infos/reward_energy Max                  -0.00720493
exploration/env_infos/reward_energy Min                  -0.622089
exploration/env_infos/final/end_effector_loc Mean        -0.0674957
exploration/env_infos/final/end_effector_loc Std          0.346994
exploration/env_infos/final/end_effector_loc Max          0.338639
exploration/env_infos/final/end_effector_loc Min         -0.865471
exploration/env_infos/initial/end_effector_loc Mean      -0.00276594
exploration/env_infos/initial/end_effector_loc Std        0.0104695
exploration/env_infos/initial/end_effector_loc Max        0.00899417
exploration/env_infos/initial/end_effector_loc Min       -0.0308942
exploration/env_infos/end_effector_loc Mean              -0.0210157
exploration/env_infos/end_effector_loc Std                0.21002
exploration/env_infos/end_effector_loc Max                0.338639
exploration/env_infos/end_effector_loc Min               -0.865471
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.201578
exploration/env_infos/final/reward_dist Std               0.362263
exploration/env_infos/final/reward_dist Max               0.923124
exploration/env_infos/final/reward_dist Min               1.92752e-29
exploration/env_infos/initial/reward_dist Mean            6.81668e-05
exploration/env_infos/initial/reward_dist Std             0.000115314
exploration/env_infos/initial/reward_dist Max             0.000298628
exploration/env_infos/initial/reward_dist Min             2.92749e-06
exploration/env_infos/reward_dist Mean                    0.172698
exploration/env_infos/reward_dist Std                     0.31542
exploration/env_infos/reward_dist Max                     0.996059
exploration/env_infos/reward_dist Min                     1.92752e-29
evaluation/num steps total                           211000
evaluation/num paths total                            10550
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.104163
evaluation/Rewards Std                                    0.172133
evaluation/Rewards Max                                    0.144443
evaluation/Rewards Min                                   -1.35949
evaluation/Returns Mean                                  -2.08326
evaluation/Returns Std                                    2.4588
evaluation/Returns Max                                    1.54925
evaluation/Returns Min                                  -12.8061
evaluation/Actions Mean                                  -0.0110726
evaluation/Actions Std                                    0.171216
evaluation/Actions Max                                    0.990085
evaluation/Actions Min                                   -0.998378
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.08326
evaluation/env_infos/final/reward_energy Mean            -0.0829891
evaluation/env_infos/final/reward_energy Std              0.137174
evaluation/env_infos/final/reward_energy Max             -0.006945
evaluation/env_infos/final/reward_energy Min             -0.890145
evaluation/env_infos/initial/reward_energy Mean          -0.413375
evaluation/env_infos/initial/reward_energy Std            0.362135
evaluation/env_infos/initial/reward_energy Max           -0.00739058
evaluation/env_infos/initial/reward_energy Min           -1.34392
evaluation/env_infos/reward_energy Mean                  -0.133582
evaluation/env_infos/reward_energy Std                    0.20256
evaluation/env_infos/reward_energy Max                   -0.00218403
evaluation/env_infos/reward_energy Min                   -1.37147
evaluation/env_infos/final/end_effector_loc Mean         -0.103369
evaluation/env_infos/final/end_effector_loc Std           0.400135
evaluation/env_infos/final/end_effector_loc Max           0.849581
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00178645
evaluation/env_infos/initial/end_effector_loc Std         0.0193477
evaluation/env_infos/initial/end_effector_loc Max         0.0486778
evaluation/env_infos/initial/end_effector_loc Min        -0.047521
evaluation/env_infos/end_effector_loc Mean               -0.0434068
evaluation/env_infos/end_effector_loc Std                 0.287679
evaluation/env_infos/end_effector_loc Max                 0.849581
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0533983
evaluation/env_infos/final/reward_dist Std                0.132759
evaluation/env_infos/final/reward_dist Max                0.817696
evaluation/env_infos/final/reward_dist Min                1.0424e-177
evaluation/env_infos/initial/reward_dist Mean             0.00394549
evaluation/env_infos/initial/reward_dist Std              0.00710108
evaluation/env_infos/initial/reward_dist Max              0.0295321
evaluation/env_infos/initial/reward_dist Min              4.00195e-07
evaluation/env_infos/reward_dist Mean                     0.10534
evaluation/env_infos/reward_dist Std                      0.207274
evaluation/env_infos/reward_dist Max                      0.99804
evaluation/env_infos/reward_dist Min                      1.0424e-177
time/data storing (s)                                    37.699
time/evaluation sampling (s)                              0.524572
time/exploration sampling (s)                             0.0830909
time/logging (s)                                          0.0159623
time/saving (s)                                           0.79862
time/training (s)                                        38.8673
time/epoch (s)                                           77.9886
time/total (s)                                        15648.5
Epoch                                                   210
---------------------------------------------------  ----------------
2021-05-29 04:18:04.051084 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 211 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00421987
trainer/QF2 Loss                                          0.00633507
trainer/Policy Loss                                       3.0672
trainer/Q1 Predictions Mean                              -0.997686
trainer/Q1 Predictions Std                                0.819163
trainer/Q1 Predictions Max                                0.971497
trainer/Q1 Predictions Min                               -3.08953
trainer/Q2 Predictions Mean                              -1.00684
trainer/Q2 Predictions Std                                0.815458
trainer/Q2 Predictions Max                                0.89172
trainer/Q2 Predictions Min                               -3.051
trainer/Q Targets Mean                                   -1.00589
trainer/Q Targets Std                                     0.813865
trainer/Q Targets Max                                     0.936009
trainer/Q Targets Min                                    -3.09568
trainer/Log Pis Mean                                      2.05478
trainer/Log Pis Std                                       1.26558
trainer/Log Pis Max                                       4.19774
trainer/Log Pis Min                                      -4.34971
trainer/Policy mu Mean                                   -0.0180786
trainer/Policy mu Std                                     0.276116
trainer/Policy mu Max                                     1.97367
trainer/Policy mu Min                                    -1.49907
trainer/Policy log std Mean                              -2.36298
trainer/Policy log std Std                                0.454148
trainer/Policy log std Max                               -0.526347
trainer/Policy log std Min                               -3.10868
trainer/Alpha                                             0.0227448
trainer/Alpha Loss                                        0.207306
exploration/num steps total                           22200
exploration/num paths total                            1110
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.169617
exploration/Rewards Std                                   0.173536
exploration/Rewards Max                                   0.0921017
exploration/Rewards Min                                  -0.65089
exploration/Returns Mean                                 -3.39234
exploration/Returns Std                                   2.83157
exploration/Returns Max                                  -0.0177878
exploration/Returns Min                                  -8.60745
exploration/Actions Mean                                 -0.0428499
exploration/Actions Std                                   0.220527
exploration/Actions Max                                   0.701365
exploration/Actions Min                                  -0.962024
exploration/Num Paths                                     5
exploration/Average Returns                              -3.39234
exploration/env_infos/final/reward_energy Mean           -0.284443
exploration/env_infos/final/reward_energy Std             0.159284
exploration/env_infos/final/reward_energy Max            -0.160572
exploration/env_infos/final/reward_energy Min            -0.593015
exploration/env_infos/initial/reward_energy Mean         -0.542961
exploration/env_infos/initial/reward_energy Std           0.377129
exploration/env_infos/initial/reward_energy Max          -0.100996
exploration/env_infos/initial/reward_energy Min          -1.17834
exploration/env_infos/reward_energy Mean                 -0.25067
exploration/env_infos/reward_energy Std                   0.195196
exploration/env_infos/reward_energy Max                  -0.0153438
exploration/env_infos/reward_energy Min                  -1.17834
exploration/env_infos/final/end_effector_loc Mean        -0.265923
exploration/env_infos/final/end_effector_loc Std          0.490195
exploration/env_infos/final/end_effector_loc Max          0.517611
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00684016
exploration/env_infos/initial/end_effector_loc Std        0.0223496
exploration/env_infos/initial/end_effector_loc Max        0.0350682
exploration/env_infos/initial/end_effector_loc Min       -0.0481012
exploration/env_infos/end_effector_loc Mean              -0.154638
exploration/env_infos/end_effector_loc Std                0.350748
exploration/env_infos/end_effector_loc Max                0.517611
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0660093
exploration/env_infos/final/reward_dist Std               0.13201
exploration/env_infos/final/reward_dist Max               0.330028
exploration/env_infos/final/reward_dist Min               6.55558e-167
exploration/env_infos/initial/reward_dist Mean            0.00427455
exploration/env_infos/initial/reward_dist Std             0.0082753
exploration/env_infos/initial/reward_dist Max             0.0208206
exploration/env_infos/initial/reward_dist Min             2.51229e-08
exploration/env_infos/reward_dist Mean                    0.119201
exploration/env_infos/reward_dist Std                     0.220699
exploration/env_infos/reward_dist Max                     0.97163
exploration/env_infos/reward_dist Min                     6.55558e-167
evaluation/num steps total                           212000
evaluation/num paths total                            10600
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0804817
evaluation/Rewards Std                                    0.116313
evaluation/Rewards Max                                    0.166591
evaluation/Rewards Min                                   -1.04519
evaluation/Returns Mean                                  -1.60963
evaluation/Returns Std                                    1.82839
evaluation/Returns Max                                    1.88564
evaluation/Returns Min                                   -6.81978
evaluation/Actions Mean                                  -0.00614817
evaluation/Actions Std                                    0.137508
evaluation/Actions Max                                    0.884945
evaluation/Actions Min                                   -0.98731
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.60963
evaluation/env_infos/final/reward_energy Mean            -0.0727346
evaluation/env_infos/final/reward_energy Std              0.103913
evaluation/env_infos/final/reward_energy Max             -0.00217849
evaluation/env_infos/final/reward_energy Min             -0.691852
evaluation/env_infos/initial/reward_energy Mean          -0.342421
evaluation/env_infos/initial/reward_energy Std            0.299851
evaluation/env_infos/initial/reward_energy Max           -0.00348936
evaluation/env_infos/initial/reward_energy Min           -1.19559
evaluation/env_infos/reward_energy Mean                  -0.110117
evaluation/env_infos/reward_energy Std                    0.16052
evaluation/env_infos/reward_energy Max                   -0.00194335
evaluation/env_infos/reward_energy Min                   -1.19559
evaluation/env_infos/final/end_effector_loc Mean         -0.0726003
evaluation/env_infos/final/end_effector_loc Std           0.429029
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -4.43133e-05
evaluation/env_infos/initial/end_effector_loc Std         0.016092
evaluation/env_infos/initial/end_effector_loc Max         0.0442473
evaluation/env_infos/initial/end_effector_loc Min        -0.0493655
evaluation/env_infos/end_effector_loc Mean               -0.0431039
evaluation/env_infos/end_effector_loc Std                 0.291828
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.102725
evaluation/env_infos/final/reward_dist Std                0.219824
evaluation/env_infos/final/reward_dist Max                0.919629
evaluation/env_infos/final/reward_dist Min                5.10304e-151
evaluation/env_infos/initial/reward_dist Mean             0.00455845
evaluation/env_infos/initial/reward_dist Std              0.00946178
evaluation/env_infos/initial/reward_dist Max              0.0538989
evaluation/env_infos/initial/reward_dist Min              9.11615e-07
evaluation/env_infos/reward_dist Mean                     0.134639
evaluation/env_infos/reward_dist Std                      0.234155
evaluation/env_infos/reward_dist Max                      0.998213
evaluation/env_infos/reward_dist Min                      5.10304e-151
time/data storing (s)                                    37.7976
time/evaluation sampling (s)                              0.619741
time/exploration sampling (s)                             0.0873462
time/logging (s)                                          0.0161147
time/saving (s)                                           0.791564
time/training (s)                                        40.3443
time/epoch (s)                                           79.6567
time/total (s)                                        15730.4
Epoch                                                   211
---------------------------------------------------  -----------------
2021-05-29 04:19:24.549714 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 212 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0036461
trainer/QF2 Loss                                          0.00337669
trainer/Policy Loss                                       2.74337
trainer/Q1 Predictions Mean                              -0.850286
trainer/Q1 Predictions Std                                0.820273
trainer/Q1 Predictions Max                                0.810721
trainer/Q1 Predictions Min                               -3.16131
trainer/Q2 Predictions Mean                              -0.877162
trainer/Q2 Predictions Std                                0.815855
trainer/Q2 Predictions Max                                0.893554
trainer/Q2 Predictions Min                               -3.18255
trainer/Q Targets Mean                                   -0.861641
trainer/Q Targets Std                                     0.822218
trainer/Q Targets Max                                     0.880503
trainer/Q Targets Min                                    -3.18373
trainer/Log Pis Mean                                      1.87792
trainer/Log Pis Std                                       1.2227
trainer/Log Pis Max                                       3.73425
trainer/Log Pis Min                                      -3.02601
trainer/Policy mu Mean                                   -0.00198321
trainer/Policy mu Std                                     0.320657
trainer/Policy mu Max                                     2.01312
trainer/Policy mu Min                                    -1.91198
trainer/Policy log std Mean                              -2.27716
trainer/Policy log std Std                                0.478548
trainer/Policy log std Max                               -0.201346
trainer/Policy log std Min                               -2.97474
trainer/Alpha                                             0.0236325
trainer/Alpha Loss                                       -0.457116
exploration/num steps total                           22300
exploration/num paths total                            1115
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.154694
exploration/Rewards Std                                   0.150507
exploration/Rewards Max                                   0.00721839
exploration/Rewards Min                                  -0.589717
exploration/Returns Mean                                 -3.09387
exploration/Returns Std                                   2.74057
exploration/Returns Max                                  -1.14772
exploration/Returns Min                                  -8.51564
exploration/Actions Mean                                  0.0203693
exploration/Actions Std                                   0.246938
exploration/Actions Max                                   0.887201
exploration/Actions Min                                  -0.728798
exploration/Num Paths                                     5
exploration/Average Returns                              -3.09387
exploration/env_infos/final/reward_energy Mean           -0.278944
exploration/env_infos/final/reward_energy Std             0.272389
exploration/env_infos/final/reward_energy Max            -0.0889427
exploration/env_infos/final/reward_energy Min            -0.808845
exploration/env_infos/initial/reward_energy Mean         -0.535257
exploration/env_infos/initial/reward_energy Std           0.448327
exploration/env_infos/initial/reward_energy Max          -0.0788801
exploration/env_infos/initial/reward_energy Min          -1.17817
exploration/env_infos/reward_energy Mean                 -0.251038
exploration/env_infos/reward_energy Std                   0.244472
exploration/env_infos/reward_energy Max                  -0.0209389
exploration/env_infos/reward_energy Min                  -1.17817
exploration/env_infos/final/end_effector_loc Mean        -0.0633055
exploration/env_infos/final/end_effector_loc Std          0.225012
exploration/env_infos/final/end_effector_loc Max          0.392494
exploration/env_infos/final/end_effector_loc Min         -0.548631
exploration/env_infos/initial/end_effector_loc Mean      -0.00111703
exploration/env_infos/initial/end_effector_loc Std        0.0246602
exploration/env_infos/initial/end_effector_loc Max        0.0443503
exploration/env_infos/initial/end_effector_loc Min       -0.0360118
exploration/env_infos/end_effector_loc Mean              -0.0864047
exploration/env_infos/end_effector_loc Std                0.225396
exploration/env_infos/end_effector_loc Max                0.392494
exploration/env_infos/end_effector_loc Min               -0.769761
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.010539
exploration/env_infos/final/reward_dist Std               0.00999704
exploration/env_infos/final/reward_dist Max               0.0267283
exploration/env_infos/final/reward_dist Min               1.08113e-12
exploration/env_infos/initial/reward_dist Mean            0.00350641
exploration/env_infos/initial/reward_dist Std             0.00361678
exploration/env_infos/initial/reward_dist Max             0.0104229
exploration/env_infos/initial/reward_dist Min             0.00029472
exploration/env_infos/reward_dist Mean                    0.0615513
exploration/env_infos/reward_dist Std                     0.128316
exploration/env_infos/reward_dist Max                     0.649903
exploration/env_infos/reward_dist Min                     3.37415e-78
evaluation/num steps total                           213000
evaluation/num paths total                            10650
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.143668
evaluation/Rewards Std                                    0.192282
evaluation/Rewards Max                                    0.0955111
evaluation/Rewards Min                                   -1.41715
evaluation/Returns Mean                                  -2.87335
evaluation/Returns Std                                    3.17002
evaluation/Returns Max                                    0.55724
evaluation/Returns Min                                  -15.3138
evaluation/Actions Mean                                  -0.0267391
evaluation/Actions Std                                    0.213434
evaluation/Actions Max                                    0.995591
evaluation/Actions Min                                   -0.994398
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.87335
evaluation/env_infos/final/reward_energy Mean            -0.0896963
evaluation/env_infos/final/reward_energy Std              0.153603
evaluation/env_infos/final/reward_energy Max             -0.00692916
evaluation/env_infos/final/reward_energy Min             -0.926228
evaluation/env_infos/initial/reward_energy Mean          -0.367084
evaluation/env_infos/initial/reward_energy Std            0.354801
evaluation/env_infos/initial/reward_energy Max           -0.00556211
evaluation/env_infos/initial/reward_energy Min           -1.26902
evaluation/env_infos/reward_energy Mean                  -0.164873
evaluation/env_infos/reward_energy Std                    0.255646
evaluation/env_infos/reward_energy Max                   -0.00178895
evaluation/env_infos/reward_energy Min                   -1.32539
evaluation/env_infos/final/end_effector_loc Mean         -0.109471
evaluation/env_infos/final/end_effector_loc Std           0.442541
evaluation/env_infos/final/end_effector_loc Max           0.891501
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00341509
evaluation/env_infos/initial/end_effector_loc Std         0.0177237
evaluation/env_infos/initial/end_effector_loc Max         0.0497795
evaluation/env_infos/initial/end_effector_loc Min        -0.0458919
evaluation/env_infos/end_effector_loc Mean               -0.0948611
evaluation/env_infos/end_effector_loc Std                 0.308603
evaluation/env_infos/end_effector_loc Max                 0.891501
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0643792
evaluation/env_infos/final/reward_dist Std                0.18316
evaluation/env_infos/final/reward_dist Max                0.87513
evaluation/env_infos/final/reward_dist Min                5.73952e-184
evaluation/env_infos/initial/reward_dist Mean             0.00671284
evaluation/env_infos/initial/reward_dist Std              0.0137683
evaluation/env_infos/initial/reward_dist Max              0.0529275
evaluation/env_infos/initial/reward_dist Min              1.73767e-06
evaluation/env_infos/reward_dist Mean                     0.0709962
evaluation/env_infos/reward_dist Std                      0.171003
evaluation/env_infos/reward_dist Max                      0.992056
evaluation/env_infos/reward_dist Min                      5.73952e-184
time/data storing (s)                                    37.8844
time/evaluation sampling (s)                              0.614791
time/exploration sampling (s)                             0.0872722
time/logging (s)                                          0.0147213
time/saving (s)                                           0.8236
time/training (s)                                        38.8993
time/epoch (s)                                           78.3241
time/total (s)                                        15810.9
Epoch                                                   212
---------------------------------------------------  -----------------
2021-05-29 04:20:45.128343 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 213 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00458114
trainer/QF2 Loss                                          0.00460436
trainer/Policy Loss                                       2.84221
trainer/Q1 Predictions Mean                              -0.938573
trainer/Q1 Predictions Std                                0.838859
trainer/Q1 Predictions Max                                0.96717
trainer/Q1 Predictions Min                               -3.22795
trainer/Q2 Predictions Mean                              -0.915937
trainer/Q2 Predictions Std                                0.844252
trainer/Q2 Predictions Max                                0.945212
trainer/Q2 Predictions Min                               -3.29542
trainer/Q Targets Mean                                   -0.922745
trainer/Q Targets Std                                     0.840124
trainer/Q Targets Max                                     0.985672
trainer/Q Targets Min                                    -3.23171
trainer/Log Pis Mean                                      1.92002
trainer/Log Pis Std                                       1.28643
trainer/Log Pis Max                                       3.95344
trainer/Log Pis Min                                      -3.88443
trainer/Policy mu Mean                                   -0.00241919
trainer/Policy mu Std                                     0.404735
trainer/Policy mu Max                                     2.02776
trainer/Policy mu Min                                    -2.94644
trainer/Policy log std Mean                              -2.24777
trainer/Policy log std Std                                0.5105
trainer/Policy log std Max                                0.0965287
trainer/Policy log std Min                               -3.02812
trainer/Alpha                                             0.0223621
trainer/Alpha Loss                                       -0.303928
exploration/num steps total                           22400
exploration/num paths total                            1120
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0841284
exploration/Rewards Std                                   0.12757
exploration/Rewards Max                                   0.124534
exploration/Rewards Min                                  -0.632986
exploration/Returns Mean                                 -1.68257
exploration/Returns Std                                   1.97096
exploration/Returns Max                                   0.73987
exploration/Returns Min                                  -4.9857
exploration/Actions Mean                                  0.00193574
exploration/Actions Std                                   0.179475
exploration/Actions Max                                   0.613558
exploration/Actions Min                                  -0.837482
exploration/Num Paths                                     5
exploration/Average Returns                              -1.68257
exploration/env_infos/final/reward_energy Mean           -0.151678
exploration/env_infos/final/reward_energy Std             0.0606667
exploration/env_infos/final/reward_energy Max            -0.0792534
exploration/env_infos/final/reward_energy Min            -0.241072
exploration/env_infos/initial/reward_energy Mean         -0.289331
exploration/env_infos/initial/reward_energy Std           0.232233
exploration/env_infos/initial/reward_energy Max          -0.0610424
exploration/env_infos/initial/reward_energy Min          -0.609794
exploration/env_infos/reward_energy Mean                 -0.18595
exploration/env_infos/reward_energy Std                   0.17278
exploration/env_infos/reward_energy Max                  -0.00714571
exploration/env_infos/reward_energy Min                  -0.921445
exploration/env_infos/final/end_effector_loc Mean        -0.0770905
exploration/env_infos/final/end_effector_loc Std          0.25021
exploration/env_infos/final/end_effector_loc Max          0.267644
exploration/env_infos/final/end_effector_loc Min         -0.635314
exploration/env_infos/initial/end_effector_loc Mean      -0.00210944
exploration/env_infos/initial/end_effector_loc Std        0.0129463
exploration/env_infos/initial/end_effector_loc Max        0.026445
exploration/env_infos/initial/end_effector_loc Min       -0.0270978
exploration/env_infos/end_effector_loc Mean              -0.0409456
exploration/env_infos/end_effector_loc Std                0.181738
exploration/env_infos/end_effector_loc Max                0.315109
exploration/env_infos/end_effector_loc Min               -0.638787
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.250243
exploration/env_infos/final/reward_dist Std               0.367296
exploration/env_infos/final/reward_dist Max               0.945663
exploration/env_infos/final/reward_dist Min               2.45315e-13
exploration/env_infos/initial/reward_dist Mean            0.0110664
exploration/env_infos/initial/reward_dist Std             0.0111628
exploration/env_infos/initial/reward_dist Max             0.0316176
exploration/env_infos/initial/reward_dist Min             0.000138591
exploration/env_infos/reward_dist Mean                    0.18585
exploration/env_infos/reward_dist Std                     0.279171
exploration/env_infos/reward_dist Max                     0.945663
exploration/env_infos/reward_dist Min                     1.13217e-13
evaluation/num steps total                           214000
evaluation/num paths total                            10700
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.114816
evaluation/Rewards Std                                    0.207038
evaluation/Rewards Max                                    0.157165
evaluation/Rewards Min                                   -1.03074
evaluation/Returns Mean                                  -2.29633
evaluation/Returns Std                                    3.69975
evaluation/Returns Max                                    1.95868
evaluation/Returns Min                                  -17.5212
evaluation/Actions Mean                                  -0.0578864
evaluation/Actions Std                                    0.24439
evaluation/Actions Max                                    0.913561
evaluation/Actions Min                                   -0.995159
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.29633
evaluation/env_infos/final/reward_energy Mean            -0.145735
evaluation/env_infos/final/reward_energy Std              0.265294
evaluation/env_infos/final/reward_energy Max             -0.00496867
evaluation/env_infos/final/reward_energy Min             -1.10554
evaluation/env_infos/initial/reward_energy Mean          -0.523606
evaluation/env_infos/initial/reward_energy Std            0.408355
evaluation/env_infos/initial/reward_energy Max           -0.0343721
evaluation/env_infos/initial/reward_energy Min           -1.36338
evaluation/env_infos/reward_energy Mean                  -0.200243
evaluation/env_infos/reward_energy Std                    0.293356
evaluation/env_infos/reward_energy Max                   -0.000365003
evaluation/env_infos/reward_energy Min                   -1.40671
evaluation/env_infos/final/end_effector_loc Mean         -0.15489
evaluation/env_infos/final/end_effector_loc Std           0.467089
evaluation/env_infos/final/end_effector_loc Max           0.605355
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00613661
evaluation/env_infos/initial/end_effector_loc Std         0.0226603
evaluation/env_infos/initial/end_effector_loc Max         0.0456781
evaluation/env_infos/initial/end_effector_loc Min        -0.0484901
evaluation/env_infos/end_effector_loc Mean               -0.128169
evaluation/env_infos/end_effector_loc Std                 0.368285
evaluation/env_infos/end_effector_loc Max                 0.605355
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.114285
evaluation/env_infos/final/reward_dist Std                0.211029
evaluation/env_infos/final/reward_dist Max                0.840217
evaluation/env_infos/final/reward_dist Min                1.8868e-192
evaluation/env_infos/initial/reward_dist Mean             0.00556834
evaluation/env_infos/initial/reward_dist Std              0.0108011
evaluation/env_infos/initial/reward_dist Max              0.0464221
evaluation/env_infos/initial/reward_dist Min              1.91076e-08
evaluation/env_infos/reward_dist Mean                     0.165871
evaluation/env_infos/reward_dist Std                      0.258785
evaluation/env_infos/reward_dist Max                      0.991845
evaluation/env_infos/reward_dist Min                      1.8868e-192
time/data storing (s)                                    37.6397
time/evaluation sampling (s)                              0.569259
time/exploration sampling (s)                             0.0812823
time/logging (s)                                          0.0148932
time/saving (s)                                           0.774128
time/training (s)                                        39.2403
time/epoch (s)                                           78.3195
time/total (s)                                        15891.5
Epoch                                                   213
---------------------------------------------------  ----------------
2021-05-29 04:22:06.335595 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 214 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00374055
trainer/QF2 Loss                                          0.00524682
trainer/Policy Loss                                       2.95526
trainer/Q1 Predictions Mean                              -0.93144
trainer/Q1 Predictions Std                                0.854603
trainer/Q1 Predictions Max                                0.694857
trainer/Q1 Predictions Min                               -3.89424
trainer/Q2 Predictions Mean                              -0.926277
trainer/Q2 Predictions Std                                0.850156
trainer/Q2 Predictions Max                                0.61624
trainer/Q2 Predictions Min                               -3.83653
trainer/Q Targets Mean                                   -0.939269
trainer/Q Targets Std                                     0.860489
trainer/Q Targets Max                                     0.690081
trainer/Q Targets Min                                    -3.98906
trainer/Log Pis Mean                                      2.05678
trainer/Log Pis Std                                       1.3813
trainer/Log Pis Max                                       7.04121
trainer/Log Pis Min                                      -2.60889
trainer/Policy mu Mean                                   -0.068627
trainer/Policy mu Std                                     0.540566
trainer/Policy mu Max                                     2.59691
trainer/Policy mu Min                                    -3.1157
trainer/Policy log std Mean                              -2.22074
trainer/Policy log std Std                                0.597449
trainer/Policy log std Max                               -0.177668
trainer/Policy log std Min                               -3.23153
trainer/Alpha                                             0.0230752
trainer/Alpha Loss                                        0.213948
exploration/num steps total                           22500
exploration/num paths total                            1125
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0959579
exploration/Rewards Std                                   0.0890509
exploration/Rewards Max                                   0.093342
exploration/Rewards Min                                  -0.383949
exploration/Returns Mean                                 -1.91916
exploration/Returns Std                                   1.3532
exploration/Returns Max                                   0.585176
exploration/Returns Min                                  -3.21916
exploration/Actions Mean                                 -0.00456111
exploration/Actions Std                                   0.0904651
exploration/Actions Max                                   0.369038
exploration/Actions Min                                  -0.338538
exploration/Num Paths                                     5
exploration/Average Returns                              -1.91916
exploration/env_infos/final/reward_energy Mean           -0.10613
exploration/env_infos/final/reward_energy Std             0.0551124
exploration/env_infos/final/reward_energy Max            -0.0463358
exploration/env_infos/final/reward_energy Min            -0.198349
exploration/env_infos/initial/reward_energy Mean         -0.12058
exploration/env_infos/initial/reward_energy Std           0.102543
exploration/env_infos/initial/reward_energy Max          -0.0286022
exploration/env_infos/initial/reward_energy Min          -0.312389
exploration/env_infos/reward_energy Mean                 -0.10464
exploration/env_infos/reward_energy Std                   0.0738908
exploration/env_infos/reward_energy Max                  -0.0136949
exploration/env_infos/reward_energy Min                  -0.381439
exploration/env_infos/final/end_effector_loc Mean        -0.121909
exploration/env_infos/final/end_effector_loc Std          0.288555
exploration/env_infos/final/end_effector_loc Max          0.284474
exploration/env_infos/final/end_effector_loc Min         -0.507325
exploration/env_infos/initial/end_effector_loc Mean       0.000403737
exploration/env_infos/initial/end_effector_loc Std        0.0055817
exploration/env_infos/initial/end_effector_loc Max        0.0140804
exploration/env_infos/initial/end_effector_loc Min       -0.00676087
exploration/env_infos/end_effector_loc Mean              -0.0561994
exploration/env_infos/end_effector_loc Std                0.166111
exploration/env_infos/end_effector_loc Max                0.284474
exploration/env_infos/end_effector_loc Min               -0.507325
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0150021
exploration/env_infos/final/reward_dist Std               0.0298895
exploration/env_infos/final/reward_dist Max               0.0747809
exploration/env_infos/final/reward_dist Min               7.5516e-20
exploration/env_infos/initial/reward_dist Mean            0.00270038
exploration/env_infos/initial/reward_dist Std             0.00344362
exploration/env_infos/initial/reward_dist Max             0.00851188
exploration/env_infos/initial/reward_dist Min             1.60194e-05
exploration/env_infos/reward_dist Mean                    0.0748097
exploration/env_infos/reward_dist Std                     0.159073
exploration/env_infos/reward_dist Max                     0.673749
exploration/env_infos/reward_dist Min                     7.5516e-20
evaluation/num steps total                           215000
evaluation/num paths total                            10750
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0655935
evaluation/Rewards Std                                    0.140927
evaluation/Rewards Max                                    0.144721
evaluation/Rewards Min                                   -0.993791
evaluation/Returns Mean                                  -1.31187
evaluation/Returns Std                                    2.55459
evaluation/Returns Max                                    1.14756
evaluation/Returns Min                                  -17.743
evaluation/Actions Mean                                  -0.0118257
evaluation/Actions Std                                    0.14139
evaluation/Actions Max                                    0.960455
evaluation/Actions Min                                   -0.996337
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.31187
evaluation/env_infos/final/reward_energy Mean            -0.0790818
evaluation/env_infos/final/reward_energy Std              0.154823
evaluation/env_infos/final/reward_energy Max             -0.00167942
evaluation/env_infos/final/reward_energy Min             -1.00673
evaluation/env_infos/initial/reward_energy Mean          -0.311362
evaluation/env_infos/initial/reward_energy Std            0.317374
evaluation/env_infos/initial/reward_energy Max           -0.00610926
evaluation/env_infos/initial/reward_energy Min           -1.15132
evaluation/env_infos/reward_energy Mean                  -0.100264
evaluation/env_infos/reward_energy Std                    0.173808
evaluation/env_infos/reward_energy Max                   -0.000781429
evaluation/env_infos/reward_energy Min                   -1.33362
evaluation/env_infos/final/end_effector_loc Mean         -0.0187518
evaluation/env_infos/final/end_effector_loc Std           0.292349
evaluation/env_infos/final/end_effector_loc Max           0.529445
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00114015
evaluation/env_infos/initial/end_effector_loc Std         0.0156777
evaluation/env_infos/initial/end_effector_loc Max         0.0480227
evaluation/env_infos/initial/end_effector_loc Min        -0.0440788
evaluation/env_infos/end_effector_loc Mean               -0.00635621
evaluation/env_infos/end_effector_loc Std                 0.206081
evaluation/env_infos/end_effector_loc Max                 0.529445
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.102153
evaluation/env_infos/final/reward_dist Std                0.187502
evaluation/env_infos/final/reward_dist Max                0.93237
evaluation/env_infos/final/reward_dist Min                1.1749e-168
evaluation/env_infos/initial/reward_dist Mean             0.00322803
evaluation/env_infos/initial/reward_dist Std              0.00514616
evaluation/env_infos/initial/reward_dist Max              0.0245172
evaluation/env_infos/initial/reward_dist Min              8.30308e-07
evaluation/env_infos/reward_dist Mean                     0.182758
evaluation/env_infos/reward_dist Std                      0.280394
evaluation/env_infos/reward_dist Max                      0.999245
evaluation/env_infos/reward_dist Min                      1.1749e-168
time/data storing (s)                                    37.3257
time/evaluation sampling (s)                              0.628537
time/exploration sampling (s)                             0.0847228
time/logging (s)                                          0.0153008
time/saving (s)                                           0.809107
time/training (s)                                        40.0495
time/epoch (s)                                           78.9129
time/total (s)                                        15972.7
Epoch                                                   214
---------------------------------------------------  ----------------
2021-05-29 04:23:26.693166 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 215 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0105688
trainer/QF2 Loss                                          0.0172174
trainer/Policy Loss                                       2.82686
trainer/Q1 Predictions Mean                              -0.928128
trainer/Q1 Predictions Std                                0.911578
trainer/Q1 Predictions Max                                1.47292
trainer/Q1 Predictions Min                               -4.38546
trainer/Q2 Predictions Mean                              -0.921218
trainer/Q2 Predictions Std                                0.921512
trainer/Q2 Predictions Max                                1.23087
trainer/Q2 Predictions Min                               -4.31799
trainer/Q Targets Mean                                   -0.933755
trainer/Q Targets Std                                     0.919945
trainer/Q Targets Max                                     1.45986
trainer/Q Targets Min                                    -4.51274
trainer/Log Pis Mean                                      1.91339
trainer/Log Pis Std                                       1.20176
trainer/Log Pis Max                                       5.75294
trainer/Log Pis Min                                      -1.67776
trainer/Policy mu Mean                                   -0.0379434
trainer/Policy mu Std                                     0.460028
trainer/Policy mu Max                                     1.47494
trainer/Policy mu Min                                    -3.05355
trainer/Policy log std Mean                              -2.22011
trainer/Policy log std Std                                0.564527
trainer/Policy log std Max                                0.527071
trainer/Policy log std Min                               -3.24137
trainer/Alpha                                             0.0243278
trainer/Alpha Loss                                       -0.321968
exploration/num steps total                           22600
exploration/num paths total                            1130
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.300732
exploration/Rewards Std                                   0.239703
exploration/Rewards Max                                   0.0819668
exploration/Rewards Min                                  -0.878506
exploration/Returns Mean                                 -6.01464
exploration/Returns Std                                   4.48775
exploration/Returns Max                                  -2.03858
exploration/Returns Min                                 -12.5294
exploration/Actions Mean                                 -0.264239
exploration/Actions Std                                   0.448537
exploration/Actions Max                                   0.616779
exploration/Actions Min                                  -0.999989
exploration/Num Paths                                     5
exploration/Average Returns                              -6.01464
exploration/env_infos/final/reward_energy Mean           -0.405709
exploration/env_infos/final/reward_energy Std             0.335098
exploration/env_infos/final/reward_energy Max            -0.117637
exploration/env_infos/final/reward_energy Min            -0.973191
exploration/env_infos/initial/reward_energy Mean         -0.762296
exploration/env_infos/initial/reward_energy Std           0.349973
exploration/env_infos/initial/reward_energy Max          -0.436544
exploration/env_infos/initial/reward_energy Min          -1.40912
exploration/env_infos/reward_energy Mean                 -0.557378
exploration/env_infos/reward_energy Std                   0.480983
exploration/env_infos/reward_energy Max                  -0.0324079
exploration/env_infos/reward_energy Min                  -1.41372
exploration/env_infos/final/end_effector_loc Mean        -0.323925
exploration/env_infos/final/end_effector_loc Std          0.606931
exploration/env_infos/final/end_effector_loc Max          0.454847
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.0111087
exploration/env_infos/initial/end_effector_loc Std        0.0274967
exploration/env_infos/initial/end_effector_loc Max        0.030839
exploration/env_infos/initial/end_effector_loc Min       -0.0498721
exploration/env_infos/end_effector_loc Mean              -0.277682
exploration/env_infos/end_effector_loc Std                0.517296
exploration/env_infos/end_effector_loc Max                0.454847
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0208855
exploration/env_infos/final/reward_dist Std               0.0417709
exploration/env_infos/final/reward_dist Max               0.104427
exploration/env_infos/final/reward_dist Min               3.25759e-150
exploration/env_infos/initial/reward_dist Mean            0.00765376
exploration/env_infos/initial/reward_dist Std             0.0152389
exploration/env_infos/initial/reward_dist Max             0.0381315
exploration/env_infos/initial/reward_dist Min             2.67357e-06
exploration/env_infos/reward_dist Mean                    0.10425
exploration/env_infos/reward_dist Std                     0.223047
exploration/env_infos/reward_dist Max                     0.996301
exploration/env_infos/reward_dist Min                     3.25759e-150
evaluation/num steps total                           216000
evaluation/num paths total                            10800
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.100313
evaluation/Rewards Std                                    0.174611
evaluation/Rewards Max                                    0.146508
evaluation/Rewards Min                                   -0.936395
evaluation/Returns Mean                                  -2.00627
evaluation/Returns Std                                    3.28653
evaluation/Returns Max                                    1.38879
evaluation/Returns Min                                  -16.7077
evaluation/Actions Mean                                  -0.0382753
evaluation/Actions Std                                    0.204262
evaluation/Actions Max                                    0.994399
evaluation/Actions Min                                   -0.998127
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.00627
evaluation/env_infos/final/reward_energy Mean            -0.0900705
evaluation/env_infos/final/reward_energy Std              0.165382
evaluation/env_infos/final/reward_energy Max             -0.00516257
evaluation/env_infos/final/reward_energy Min             -1.0318
evaluation/env_infos/initial/reward_energy Mean          -0.423888
evaluation/env_infos/initial/reward_energy Std            0.390901
evaluation/env_infos/initial/reward_energy Max           -0.0158582
evaluation/env_infos/initial/reward_energy Min           -1.38243
evaluation/env_infos/reward_energy Mean                  -0.147728
evaluation/env_infos/reward_energy Std                    0.254071
evaluation/env_infos/reward_energy Max                   -0.000694072
evaluation/env_infos/reward_energy Min                   -1.39499
evaluation/env_infos/final/end_effector_loc Mean         -0.151373
evaluation/env_infos/final/end_effector_loc Std           0.409938
evaluation/env_infos/final/end_effector_loc Max           0.623262
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00547262
evaluation/env_infos/initial/end_effector_loc Std         0.0196381
evaluation/env_infos/initial/end_effector_loc Max         0.04972
evaluation/env_infos/initial/end_effector_loc Min        -0.0495214
evaluation/env_infos/end_effector_loc Mean               -0.103833
evaluation/env_infos/end_effector_loc Std                 0.314437
evaluation/env_infos/end_effector_loc Max                 0.623262
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0463484
evaluation/env_infos/final/reward_dist Std                0.139355
evaluation/env_infos/final/reward_dist Max                0.862214
evaluation/env_infos/final/reward_dist Min                2.60959e-168
evaluation/env_infos/initial/reward_dist Mean             0.00870312
evaluation/env_infos/initial/reward_dist Std              0.0115062
evaluation/env_infos/initial/reward_dist Max              0.0452527
evaluation/env_infos/initial/reward_dist Min              1.04018e-06
evaluation/env_infos/reward_dist Mean                     0.12334
evaluation/env_infos/reward_dist Std                      0.222327
evaluation/env_infos/reward_dist Max                      0.999388
evaluation/env_infos/reward_dist Min                      1.19877e-169
time/data storing (s)                                    38.0695
time/evaluation sampling (s)                              0.619133
time/exploration sampling (s)                             0.100806
time/logging (s)                                          0.01505
time/saving (s)                                           0.794075
time/training (s)                                        38.373
time/epoch (s)                                           77.9715
time/total (s)                                        16053
Epoch                                                   215
---------------------------------------------------  -----------------
2021-05-29 04:24:47.247340 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 216 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0185849
trainer/QF2 Loss                                          0.0307845
trainer/Policy Loss                                       2.69282
trainer/Q1 Predictions Mean                              -0.926966
trainer/Q1 Predictions Std                                0.890438
trainer/Q1 Predictions Max                                1.14412
trainer/Q1 Predictions Min                               -4.5896
trainer/Q2 Predictions Mean                              -0.905619
trainer/Q2 Predictions Std                                0.891189
trainer/Q2 Predictions Max                                1.24049
trainer/Q2 Predictions Min                               -4.59099
trainer/Q Targets Mean                                   -0.933349
trainer/Q Targets Std                                     0.915763
trainer/Q Targets Max                                     1.30929
trainer/Q Targets Min                                    -4.71327
trainer/Log Pis Mean                                      1.78223
trainer/Log Pis Std                                       1.47188
trainer/Log Pis Max                                       6.86879
trainer/Log Pis Min                                      -3.2216
trainer/Policy mu Mean                                   -0.0719875
trainer/Policy mu Std                                     0.52378
trainer/Policy mu Max                                     2.3583
trainer/Policy mu Min                                    -2.92182
trainer/Policy log std Mean                              -2.20886
trainer/Policy log std Std                                0.564228
trainer/Policy log std Max                               -0.186913
trainer/Policy log std Min                               -3.07288
trainer/Alpha                                             0.0222068
trainer/Alpha Loss                                       -0.828672
exploration/num steps total                           22700
exploration/num paths total                            1135
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.255356
exploration/Rewards Std                                   0.370989
exploration/Rewards Max                                   0.151974
exploration/Rewards Min                                  -1.06754
exploration/Returns Mean                                 -5.10712
exploration/Returns Std                                   7.19938
exploration/Returns Max                                   1.78835
exploration/Returns Min                                 -15.8691
exploration/Actions Mean                                 -0.0764032
exploration/Actions Std                                   0.302038
exploration/Actions Max                                   0.655068
exploration/Actions Min                                  -0.967456
exploration/Num Paths                                     5
exploration/Average Returns                              -5.10712
exploration/env_infos/final/reward_energy Mean           -0.24418
exploration/env_infos/final/reward_energy Std             0.0969169
exploration/env_infos/final/reward_energy Max            -0.145933
exploration/env_infos/final/reward_energy Min            -0.390297
exploration/env_infos/initial/reward_energy Mean         -0.555948
exploration/env_infos/initial/reward_energy Std           0.466807
exploration/env_infos/initial/reward_energy Max          -0.139421
exploration/env_infos/initial/reward_energy Min          -1.36256
exploration/env_infos/reward_energy Mean                 -0.328999
exploration/env_infos/reward_energy Std                   0.293069
exploration/env_infos/reward_energy Max                  -0.0408352
exploration/env_infos/reward_energy Min                  -1.36256
exploration/env_infos/final/end_effector_loc Mean        -0.197284
exploration/env_infos/final/end_effector_loc Std          0.496218
exploration/env_infos/final/end_effector_loc Max          0.383486
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.0137373
exploration/env_infos/initial/end_effector_loc Std        0.0216799
exploration/env_infos/initial/end_effector_loc Max        0.0117544
exploration/env_infos/initial/end_effector_loc Min       -0.0483206
exploration/env_infos/end_effector_loc Mean              -0.214948
exploration/env_infos/end_effector_loc Std                0.415153
exploration/env_infos/end_effector_loc Max                0.383486
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0928896
exploration/env_infos/final/reward_dist Std               0.132931
exploration/env_infos/final/reward_dist Max               0.34112
exploration/env_infos/final/reward_dist Min               9.45028e-165
exploration/env_infos/initial/reward_dist Mean            0.01506
exploration/env_infos/initial/reward_dist Std             0.0165155
exploration/env_infos/initial/reward_dist Max             0.0371222
exploration/env_infos/initial/reward_dist Min             0.000170562
exploration/env_infos/reward_dist Mean                    0.221997
exploration/env_infos/reward_dist Std                     0.292167
exploration/env_infos/reward_dist Max                     0.965812
exploration/env_infos/reward_dist Min                     9.45028e-165
evaluation/num steps total                           217000
evaluation/num paths total                            10850
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.128604
evaluation/Rewards Std                                    0.197575
evaluation/Rewards Max                                    0.136585
evaluation/Rewards Min                                   -1.00226
evaluation/Returns Mean                                  -2.57208
evaluation/Returns Std                                    3.57674
evaluation/Returns Max                                    1.57607
evaluation/Returns Min                                  -13.613
evaluation/Actions Mean                                  -0.0499952
evaluation/Actions Std                                    0.202925
evaluation/Actions Max                                    0.776031
evaluation/Actions Min                                   -0.999482
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.57208
evaluation/env_infos/final/reward_energy Mean            -0.136354
evaluation/env_infos/final/reward_energy Std              0.259956
evaluation/env_infos/final/reward_energy Max             -0.0018985
evaluation/env_infos/final/reward_energy Min             -1.0841
evaluation/env_infos/initial/reward_energy Mean          -0.363956
evaluation/env_infos/initial/reward_energy Std            0.37713
evaluation/env_infos/initial/reward_energy Max           -0.032698
evaluation/env_infos/initial/reward_energy Min           -1.39914
evaluation/env_infos/reward_energy Mean                  -0.147774
evaluation/env_infos/reward_energy Std                    0.255966
evaluation/env_infos/reward_energy Max                   -0.000699775
evaluation/env_infos/reward_energy Min                   -1.40996
evaluation/env_infos/final/end_effector_loc Mean         -0.234669
evaluation/env_infos/final/end_effector_loc Std           0.434862
evaluation/env_infos/final/end_effector_loc Max           0.527318
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00671678
evaluation/env_infos/initial/end_effector_loc Std         0.0172699
evaluation/env_infos/initial/end_effector_loc Max         0.0388016
evaluation/env_infos/initial/end_effector_loc Min        -0.0496092
evaluation/env_infos/end_effector_loc Mean               -0.157078
evaluation/env_infos/end_effector_loc Std                 0.342543
evaluation/env_infos/end_effector_loc Max                 0.527318
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0726411
evaluation/env_infos/final/reward_dist Std                0.162267
evaluation/env_infos/final/reward_dist Max                0.719805
evaluation/env_infos/final/reward_dist Min                1.40901e-180
evaluation/env_infos/initial/reward_dist Mean             0.00672024
evaluation/env_infos/initial/reward_dist Std              0.0123959
evaluation/env_infos/initial/reward_dist Max              0.0626937
evaluation/env_infos/initial/reward_dist Min              6.81322e-07
evaluation/env_infos/reward_dist Mean                     0.138909
evaluation/env_infos/reward_dist Std                      0.241831
evaluation/env_infos/reward_dist Max                      0.998624
evaluation/env_infos/reward_dist Min                      1.40901e-180
time/data storing (s)                                    37.5156
time/evaluation sampling (s)                              0.621988
time/exploration sampling (s)                             0.0875363
time/logging (s)                                          0.0152259
time/saving (s)                                           0.774425
time/training (s)                                        39.2518
time/epoch (s)                                           78.2665
time/total (s)                                        16133.6
Epoch                                                   216
---------------------------------------------------  -----------------
2021-05-29 04:26:08.175805 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 217 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00832124
trainer/QF2 Loss                                          0.011842
trainer/Policy Loss                                       3.04055
trainer/Q1 Predictions Mean                              -1.01258
trainer/Q1 Predictions Std                                0.867875
trainer/Q1 Predictions Max                                0.698686
trainer/Q1 Predictions Min                               -3.06194
trainer/Q2 Predictions Mean                              -1.00575
trainer/Q2 Predictions Std                                0.884709
trainer/Q2 Predictions Max                                0.729719
trainer/Q2 Predictions Min                               -3.08151
trainer/Q Targets Mean                                   -1.01287
trainer/Q Targets Std                                     0.884362
trainer/Q Targets Max                                     0.922342
trainer/Q Targets Min                                    -3.04414
trainer/Log Pis Mean                                      2.0481
trainer/Log Pis Std                                       1.14849
trainer/Log Pis Max                                       6.80579
trainer/Log Pis Min                                      -2.69957
trainer/Policy mu Mean                                   -0.0693111
trainer/Policy mu Std                                     0.452564
trainer/Policy mu Max                                     1.66671
trainer/Policy mu Min                                    -2.52058
trainer/Policy log std Mean                              -2.24252
trainer/Policy log std Std                                0.499373
trainer/Policy log std Max                               -0.480951
trainer/Policy log std Min                               -3.14073
trainer/Alpha                                             0.021703
trainer/Alpha Loss                                        0.184267
exploration/num steps total                           22800
exploration/num paths total                            1140
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.221607
exploration/Rewards Std                                   0.33022
exploration/Rewards Max                                   0.139673
exploration/Rewards Min                                  -1.06933
exploration/Returns Mean                                 -4.43215
exploration/Returns Std                                   6.34092
exploration/Returns Max                                   0.0947178
exploration/Returns Min                                 -16.994
exploration/Actions Mean                                 -0.0833061
exploration/Actions Std                                   0.263699
exploration/Actions Max                                   0.546272
exploration/Actions Min                                  -0.98442
exploration/Num Paths                                     5
exploration/Average Returns                              -4.43215
exploration/env_infos/final/reward_energy Mean           -0.176506
exploration/env_infos/final/reward_energy Std             0.144911
exploration/env_infos/final/reward_energy Max            -0.0318031
exploration/env_infos/final/reward_energy Min            -0.423155
exploration/env_infos/initial/reward_energy Mean         -0.553963
exploration/env_infos/initial/reward_energy Std           0.363631
exploration/env_infos/initial/reward_energy Max          -0.175907
exploration/env_infos/initial/reward_energy Min          -1.2329
exploration/env_infos/reward_energy Mean                 -0.27427
exploration/env_infos/reward_energy Std                   0.2788
exploration/env_infos/reward_energy Max                  -0.0190718
exploration/env_infos/reward_energy Min                  -1.25916
exploration/env_infos/final/end_effector_loc Mean        -0.180114
exploration/env_infos/final/end_effector_loc Std          0.497729
exploration/env_infos/final/end_effector_loc Max          0.405539
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00725486
exploration/env_infos/initial/end_effector_loc Std        0.0222765
exploration/env_infos/initial/end_effector_loc Max        0.0273136
exploration/env_infos/initial/end_effector_loc Min       -0.0445807
exploration/env_infos/end_effector_loc Mean              -0.15106
exploration/env_infos/end_effector_loc Std                0.401806
exploration/env_infos/end_effector_loc Max                0.405539
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00021237
exploration/env_infos/final/reward_dist Std               0.000357494
exploration/env_infos/final/reward_dist Max               0.000918748
exploration/env_infos/final/reward_dist Min               6.70762e-188
exploration/env_infos/initial/reward_dist Mean            0.0164382
exploration/env_infos/initial/reward_dist Std             0.0201911
exploration/env_infos/initial/reward_dist Max             0.0437877
exploration/env_infos/initial/reward_dist Min             3.55341e-07
exploration/env_infos/reward_dist Mean                    0.146865
exploration/env_infos/reward_dist Std                     0.262173
exploration/env_infos/reward_dist Max                     0.994475
exploration/env_infos/reward_dist Min                     6.70762e-188
evaluation/num steps total                           218000
evaluation/num paths total                            10900
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0710053
evaluation/Rewards Std                                    0.17959
evaluation/Rewards Max                                    0.152038
evaluation/Rewards Min                                   -1.17688
evaluation/Returns Mean                                  -1.42011
evaluation/Returns Std                                    3.30277
evaluation/Returns Max                                    2.22566
evaluation/Returns Min                                  -20.1657
evaluation/Actions Mean                                  -0.0257879
evaluation/Actions Std                                    0.178748
evaluation/Actions Max                                    0.936297
evaluation/Actions Min                                   -0.999698
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.42011
evaluation/env_infos/final/reward_energy Mean            -0.115139
evaluation/env_infos/final/reward_energy Std              0.189874
evaluation/env_infos/final/reward_energy Max             -0.010945
evaluation/env_infos/final/reward_energy Min             -0.953499
evaluation/env_infos/initial/reward_energy Mean          -0.300516
evaluation/env_infos/initial/reward_energy Std            0.314751
evaluation/env_infos/initial/reward_energy Max           -0.0101218
evaluation/env_infos/initial/reward_energy Min           -1.4087
evaluation/env_infos/reward_energy Mean                  -0.133009
evaluation/env_infos/reward_energy Std                    0.218037
evaluation/env_infos/reward_energy Max                   -0.00393635
evaluation/env_infos/reward_energy Min                   -1.4124
evaluation/env_infos/final/end_effector_loc Mean         -0.0124405
evaluation/env_infos/final/end_effector_loc Std           0.410488
evaluation/env_infos/final/end_effector_loc Max           0.998169
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000524212
evaluation/env_infos/initial/end_effector_loc Std         0.0153769
evaluation/env_infos/initial/end_effector_loc Max         0.0468148
evaluation/env_infos/initial/end_effector_loc Min        -0.0499232
evaluation/env_infos/end_effector_loc Mean               -0.0325603
evaluation/env_infos/end_effector_loc Std                 0.296534
evaluation/env_infos/end_effector_loc Max                 0.998169
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.108451
evaluation/env_infos/final/reward_dist Std                0.199077
evaluation/env_infos/final/reward_dist Max                0.814929
evaluation/env_infos/final/reward_dist Min                1.08671e-174
evaluation/env_infos/initial/reward_dist Mean             0.0104559
evaluation/env_infos/initial/reward_dist Std              0.0233096
evaluation/env_infos/initial/reward_dist Max              0.128093
evaluation/env_infos/initial/reward_dist Min              1.15222e-07
evaluation/env_infos/reward_dist Mean                     0.182849
evaluation/env_infos/reward_dist Std                      0.277222
evaluation/env_infos/reward_dist Max                      0.999832
evaluation/env_infos/reward_dist Min                      1.08671e-174
time/data storing (s)                                    37.7769
time/evaluation sampling (s)                              0.626308
time/exploration sampling (s)                             0.0864898
time/logging (s)                                          0.0152896
time/saving (s)                                           0.7968
time/training (s)                                        39.328
time/epoch (s)                                           78.6298
time/total (s)                                        16214.5
Epoch                                                   217
---------------------------------------------------  -----------------
2021-05-29 04:27:29.040759 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 218 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00846619
trainer/QF2 Loss                                          0.00629459
trainer/Policy Loss                                       2.84847
trainer/Q1 Predictions Mean                              -0.860096
trainer/Q1 Predictions Std                                0.874143
trainer/Q1 Predictions Max                                1.09237
trainer/Q1 Predictions Min                               -3.86333
trainer/Q2 Predictions Mean                              -0.880789
trainer/Q2 Predictions Std                                0.871767
trainer/Q2 Predictions Max                                1.007
trainer/Q2 Predictions Min                               -3.84351
trainer/Q Targets Mean                                   -0.882195
trainer/Q Targets Std                                     0.871285
trainer/Q Targets Max                                     1.06001
trainer/Q Targets Min                                    -3.99485
trainer/Log Pis Mean                                      1.98634
trainer/Log Pis Std                                       1.35309
trainer/Log Pis Max                                       9.69502
trainer/Log Pis Min                                      -2.81334
trainer/Policy mu Mean                                   -0.0713233
trainer/Policy mu Std                                     0.482679
trainer/Policy mu Max                                     1.70627
trainer/Policy mu Min                                    -3.2118
trainer/Policy log std Mean                              -2.22568
trainer/Policy log std Std                                0.533361
trainer/Policy log std Max                               -0.140262
trainer/Policy log std Min                               -3.19854
trainer/Alpha                                             0.0220022
trainer/Alpha Loss                                       -0.0521462
exploration/num steps total                           22900
exploration/num paths total                            1145
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0892466
exploration/Rewards Std                                   0.100049
exploration/Rewards Max                                   0.119452
exploration/Rewards Min                                  -0.279005
exploration/Returns Mean                                 -1.78493
exploration/Returns Std                                   1.62415
exploration/Returns Max                                   1.10754
exploration/Returns Min                                  -3.61764
exploration/Actions Mean                                 -0.00356726
exploration/Actions Std                                   0.130014
exploration/Actions Max                                   0.324987
exploration/Actions Min                                  -0.456536
exploration/Num Paths                                     5
exploration/Average Returns                              -1.78493
exploration/env_infos/final/reward_energy Mean           -0.111762
exploration/env_infos/final/reward_energy Std             0.0430631
exploration/env_infos/final/reward_energy Max            -0.0593638
exploration/env_infos/final/reward_energy Min            -0.156554
exploration/env_infos/initial/reward_energy Mean         -0.25797
exploration/env_infos/initial/reward_energy Std           0.0738873
exploration/env_infos/initial/reward_energy Max          -0.146479
exploration/env_infos/initial/reward_energy Min          -0.347216
exploration/env_infos/reward_energy Mean                 -0.152903
exploration/env_infos/reward_energy Std                   0.10224
exploration/env_infos/reward_energy Max                  -0.00579467
exploration/env_infos/reward_energy Min                  -0.492494
exploration/env_infos/final/end_effector_loc Mean        -0.0691875
exploration/env_infos/final/end_effector_loc Std          0.28274
exploration/env_infos/final/end_effector_loc Max          0.404781
exploration/env_infos/final/end_effector_loc Min         -0.588765
exploration/env_infos/initial/end_effector_loc Mean      -0.00386678
exploration/env_infos/initial/end_effector_loc Std        0.00866358
exploration/env_infos/initial/end_effector_loc Max        0.0150576
exploration/env_infos/initial/end_effector_loc Min       -0.0159459
exploration/env_infos/end_effector_loc Mean              -0.0413451
exploration/env_infos/end_effector_loc Std                0.170232
exploration/env_infos/end_effector_loc Max                0.404781
exploration/env_infos/end_effector_loc Min               -0.588765
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.140246
exploration/env_infos/final/reward_dist Std               0.277499
exploration/env_infos/final/reward_dist Max               0.695234
exploration/env_infos/final/reward_dist Min               1.22496e-06
exploration/env_infos/initial/reward_dist Mean            0.00526333
exploration/env_infos/initial/reward_dist Std             0.00761602
exploration/env_infos/initial/reward_dist Max             0.0201804
exploration/env_infos/initial/reward_dist Min             9.23699e-07
exploration/env_infos/reward_dist Mean                    0.261853
exploration/env_infos/reward_dist Std                     0.350494
exploration/env_infos/reward_dist Max                     0.999313
exploration/env_infos/reward_dist Min                     9.23699e-07
evaluation/num steps total                           219000
evaluation/num paths total                            10950
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.101241
evaluation/Rewards Std                                    0.148485
evaluation/Rewards Max                                    0.158377
evaluation/Rewards Min                                   -0.900887
evaluation/Returns Mean                                  -2.02482
evaluation/Returns Std                                    2.56354
evaluation/Returns Max                                    1.38004
evaluation/Returns Min                                  -11.5833
evaluation/Actions Mean                                  -0.0552384
evaluation/Actions Std                                    0.203499
evaluation/Actions Max                                    0.828584
evaluation/Actions Min                                   -0.995737
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.02482
evaluation/env_infos/final/reward_energy Mean            -0.0791637
evaluation/env_infos/final/reward_energy Std              0.107251
evaluation/env_infos/final/reward_energy Max             -0.00406009
evaluation/env_infos/final/reward_energy Min             -0.583557
evaluation/env_infos/initial/reward_energy Mean          -0.393383
evaluation/env_infos/initial/reward_energy Std            0.379118
evaluation/env_infos/initial/reward_energy Max           -0.0190476
evaluation/env_infos/initial/reward_energy Min           -1.36399
evaluation/env_infos/reward_energy Mean                  -0.165226
evaluation/env_infos/reward_energy Std                    0.248247
evaluation/env_infos/reward_energy Max                   -0.00221308
evaluation/env_infos/reward_energy Min                   -1.39677
evaluation/env_infos/final/end_effector_loc Mean         -0.177887
evaluation/env_infos/final/end_effector_loc Std           0.418208
evaluation/env_infos/final/end_effector_loc Max           0.887383
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00495688
evaluation/env_infos/initial/end_effector_loc Std         0.0186689
evaluation/env_infos/initial/end_effector_loc Max         0.0409397
evaluation/env_infos/initial/end_effector_loc Min        -0.0490346
evaluation/env_infos/end_effector_loc Mean               -0.128587
evaluation/env_infos/end_effector_loc Std                 0.338345
evaluation/env_infos/end_effector_loc Max                 0.887383
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.145345
evaluation/env_infos/final/reward_dist Std                0.248298
evaluation/env_infos/final/reward_dist Max                0.863413
evaluation/env_infos/final/reward_dist Min                4.09552e-181
evaluation/env_infos/initial/reward_dist Mean             0.00920286
evaluation/env_infos/initial/reward_dist Std              0.0272754
evaluation/env_infos/initial/reward_dist Max              0.165934
evaluation/env_infos/initial/reward_dist Min              2.736e-06
evaluation/env_infos/reward_dist Mean                     0.128554
evaluation/env_infos/reward_dist Std                      0.245487
evaluation/env_infos/reward_dist Max                      0.997227
evaluation/env_infos/reward_dist Min                      4.09552e-181
time/data storing (s)                                    38.1315
time/evaluation sampling (s)                              0.520462
time/exploration sampling (s)                             0.0788504
time/logging (s)                                          0.0151197
time/saving (s)                                           0.79576
time/training (s)                                        39.0592
time/epoch (s)                                           78.6009
time/total (s)                                        16295.4
Epoch                                                   218
---------------------------------------------------  -----------------
2021-05-29 04:28:50.281346 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 219 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00650704
trainer/QF2 Loss                                          0.0120263
trainer/Policy Loss                                       2.91356
trainer/Q1 Predictions Mean                              -0.931525
trainer/Q1 Predictions Std                                1.02101
trainer/Q1 Predictions Max                                1.0608
trainer/Q1 Predictions Min                               -4.92002
trainer/Q2 Predictions Mean                              -0.915679
trainer/Q2 Predictions Std                                1.01306
trainer/Q2 Predictions Max                                1.09422
trainer/Q2 Predictions Min                               -4.93215
trainer/Q Targets Mean                                   -0.943696
trainer/Q Targets Std                                     1.02672
trainer/Q Targets Max                                     1.0847
trainer/Q Targets Min                                    -4.95988
trainer/Log Pis Mean                                      2.01287
trainer/Log Pis Std                                       1.25243
trainer/Log Pis Max                                       4.28777
trainer/Log Pis Min                                      -4.57576
trainer/Policy mu Mean                                   -0.0373088
trainer/Policy mu Std                                     0.394212
trainer/Policy mu Max                                     1.87087
trainer/Policy mu Min                                    -2.32295
trainer/Policy log std Mean                              -2.28178
trainer/Policy log std Std                                0.489748
trainer/Policy log std Max                               -0.36373
trainer/Policy log std Min                               -3.22337
trainer/Alpha                                             0.0211491
trainer/Alpha Loss                                        0.0496088
exploration/num steps total                           23000
exploration/num paths total                            1150
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.12386
exploration/Rewards Std                                   0.0746909
exploration/Rewards Max                                   0.0320272
exploration/Rewards Min                                  -0.40189
exploration/Returns Mean                                 -2.4772
exploration/Returns Std                                   0.987489
exploration/Returns Max                                  -0.811416
exploration/Returns Min                                  -3.6196
exploration/Actions Mean                                 -0.0151228
exploration/Actions Std                                   0.132464
exploration/Actions Max                                   0.441451
exploration/Actions Min                                  -0.381537
exploration/Num Paths                                     5
exploration/Average Returns                              -2.4772
exploration/env_infos/final/reward_energy Mean           -0.18184
exploration/env_infos/final/reward_energy Std             0.0951378
exploration/env_infos/final/reward_energy Max            -0.0760888
exploration/env_infos/final/reward_energy Min            -0.351279
exploration/env_infos/initial/reward_energy Mean         -0.22451
exploration/env_infos/initial/reward_energy Std           0.144598
exploration/env_infos/initial/reward_energy Max          -0.0288864
exploration/env_infos/initial/reward_energy Min          -0.387733
exploration/env_infos/reward_energy Mean                 -0.160734
exploration/env_infos/reward_energy Std                   0.0985681
exploration/env_infos/reward_energy Max                  -0.0114574
exploration/env_infos/reward_energy Min                  -0.457294
exploration/env_infos/final/end_effector_loc Mean        -0.00166297
exploration/env_infos/final/end_effector_loc Std          0.323908
exploration/env_infos/final/end_effector_loc Max          0.552154
exploration/env_infos/final/end_effector_loc Min         -0.66534
exploration/env_infos/initial/end_effector_loc Mean       0.00268204
exploration/env_infos/initial/end_effector_loc Std        0.00905254
exploration/env_infos/initial/end_effector_loc Max        0.015281
exploration/env_infos/initial/end_effector_loc Min       -0.0190768
exploration/env_infos/end_effector_loc Mean               0.0400441
exploration/env_infos/end_effector_loc Std                0.178946
exploration/env_infos/end_effector_loc Max                0.552154
exploration/env_infos/end_effector_loc Min               -0.66534
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.163743
exploration/env_infos/final/reward_dist Std               0.240883
exploration/env_infos/final/reward_dist Max               0.620348
exploration/env_infos/final/reward_dist Min               3.6286e-17
exploration/env_infos/initial/reward_dist Mean            0.00124975
exploration/env_infos/initial/reward_dist Std             0.00224634
exploration/env_infos/initial/reward_dist Max             0.00573978
exploration/env_infos/initial/reward_dist Min             3.87417e-06
exploration/env_infos/reward_dist Mean                    0.0419076
exploration/env_infos/reward_dist Std                     0.0932141
exploration/env_infos/reward_dist Max                     0.620348
exploration/env_infos/reward_dist Min                     3.6286e-17
evaluation/num steps total                           220000
evaluation/num paths total                            11000
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0726228
evaluation/Rewards Std                                    0.115777
evaluation/Rewards Max                                    0.156787
evaluation/Rewards Min                                   -0.86784
evaluation/Returns Mean                                  -1.45246
evaluation/Returns Std                                    1.78542
evaluation/Returns Max                                    2.05955
evaluation/Returns Min                                   -7.19446
evaluation/Actions Mean                                  -0.0258044
evaluation/Actions Std                                    0.154129
evaluation/Actions Max                                    0.663877
evaluation/Actions Min                                   -0.982731
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.45246
evaluation/env_infos/final/reward_energy Mean            -0.0795039
evaluation/env_infos/final/reward_energy Std              0.0718078
evaluation/env_infos/final/reward_energy Max             -0.00732793
evaluation/env_infos/final/reward_energy Min             -0.340097
evaluation/env_infos/initial/reward_energy Mean          -0.373036
evaluation/env_infos/initial/reward_energy Std            0.27315
evaluation/env_infos/initial/reward_energy Max           -0.0462255
evaluation/env_infos/initial/reward_energy Min           -1.1748
evaluation/env_infos/reward_energy Mean                  -0.128242
evaluation/env_infos/reward_energy Std                    0.179993
evaluation/env_infos/reward_energy Max                   -0.00187669
evaluation/env_infos/reward_energy Min                   -1.30899
evaluation/env_infos/final/end_effector_loc Mean         -0.0633123
evaluation/env_infos/final/end_effector_loc Std           0.405714
evaluation/env_infos/final/end_effector_loc Max           0.737849
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00271118
evaluation/env_infos/initial/end_effector_loc Std         0.0161201
evaluation/env_infos/initial/end_effector_loc Max         0.0331939
evaluation/env_infos/initial/end_effector_loc Min        -0.0491365
evaluation/env_infos/end_effector_loc Mean               -0.0488594
evaluation/env_infos/end_effector_loc Std                 0.30467
evaluation/env_infos/end_effector_loc Max                 0.737849
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0892688
evaluation/env_infos/final/reward_dist Std                0.182401
evaluation/env_infos/final/reward_dist Max                0.708927
evaluation/env_infos/final/reward_dist Min                7.05534e-189
evaluation/env_infos/initial/reward_dist Mean             0.00929597
evaluation/env_infos/initial/reward_dist Std              0.024199
evaluation/env_infos/initial/reward_dist Max              0.151228
evaluation/env_infos/initial/reward_dist Min              8.74034e-08
evaluation/env_infos/reward_dist Mean                     0.164727
evaluation/env_infos/reward_dist Std                      0.270908
evaluation/env_infos/reward_dist Max                      0.998769
evaluation/env_infos/reward_dist Min                      7.05534e-189
time/data storing (s)                                    37.4531
time/evaluation sampling (s)                              0.622498
time/exploration sampling (s)                             0.0894427
time/logging (s)                                          0.0144647
time/saving (s)                                           1.11239
time/training (s)                                        39.5716
time/epoch (s)                                           78.8635
time/total (s)                                        16376.6
Epoch                                                   219
---------------------------------------------------  -----------------
2021-05-29 04:30:11.022797 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 220 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00487613
trainer/QF2 Loss                                          0.00762998
trainer/Policy Loss                                       2.79904
trainer/Q1 Predictions Mean                              -0.849366
trainer/Q1 Predictions Std                                1.05882
trainer/Q1 Predictions Max                                1.04201
trainer/Q1 Predictions Min                               -6.31114
trainer/Q2 Predictions Mean                              -0.833592
trainer/Q2 Predictions Std                                1.05562
trainer/Q2 Predictions Max                                0.908777
trainer/Q2 Predictions Min                               -6.39516
trainer/Q Targets Mean                                   -0.83842
trainer/Q Targets Std                                     1.05248
trainer/Q Targets Max                                     0.984259
trainer/Q Targets Min                                    -6.21377
trainer/Log Pis Mean                                      1.96907
trainer/Log Pis Std                                       1.16645
trainer/Log Pis Max                                       4.29214
trainer/Log Pis Min                                      -3.51975
trainer/Policy mu Mean                                   -0.0410345
trainer/Policy mu Std                                     0.323574
trainer/Policy mu Max                                     1.26191
trainer/Policy mu Min                                    -1.90801
trainer/Policy log std Mean                              -2.28622
trainer/Policy log std Std                                0.443516
trainer/Policy log std Max                               -0.382615
trainer/Policy log std Min                               -3.14295
trainer/Alpha                                             0.0221537
trainer/Alpha Loss                                       -0.117852
exploration/num steps total                           23100
exploration/num paths total                            1155
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0687789
exploration/Rewards Std                                   0.0893933
exploration/Rewards Max                                   0.0942599
exploration/Rewards Min                                  -0.331637
exploration/Returns Mean                                 -1.37558
exploration/Returns Std                                   1.05238
exploration/Returns Max                                   0.507292
exploration/Returns Min                                  -2.69458
exploration/Actions Mean                                 -0.0147178
exploration/Actions Std                                   0.0834927
exploration/Actions Max                                   0.227351
exploration/Actions Min                                  -0.284457
exploration/Num Paths                                     5
exploration/Average Returns                              -1.37558
exploration/env_infos/final/reward_energy Mean           -0.115297
exploration/env_infos/final/reward_energy Std             0.088488
exploration/env_infos/final/reward_energy Max            -0.0337203
exploration/env_infos/final/reward_energy Min            -0.284919
exploration/env_infos/initial/reward_energy Mean         -0.178875
exploration/env_infos/initial/reward_energy Std           0.0740876
exploration/env_infos/initial/reward_energy Max          -0.0842259
exploration/env_infos/initial/reward_energy Min          -0.297257
exploration/env_infos/reward_energy Mean                 -0.103392
exploration/env_infos/reward_energy Std                   0.0607072
exploration/env_infos/reward_energy Max                  -0.00886358
exploration/env_infos/reward_energy Min                  -0.300734
exploration/env_infos/final/end_effector_loc Mean        -0.0307941
exploration/env_infos/final/end_effector_loc Std          0.257279
exploration/env_infos/final/end_effector_loc Max          0.379189
exploration/env_infos/final/end_effector_loc Min         -0.606448
exploration/env_infos/initial/end_effector_loc Mean      -0.000156799
exploration/env_infos/initial/end_effector_loc Std        0.00684339
exploration/env_infos/initial/end_effector_loc Max        0.0111439
exploration/env_infos/initial/end_effector_loc Min       -0.00983455
exploration/env_infos/end_effector_loc Mean               0.0119379
exploration/env_infos/end_effector_loc Std                0.156712
exploration/env_infos/end_effector_loc Max                0.379189
exploration/env_infos/end_effector_loc Min               -0.606448
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0752137
exploration/env_infos/final/reward_dist Std               0.0940998
exploration/env_infos/final/reward_dist Max               0.218413
exploration/env_infos/final/reward_dist Min               1.83236e-17
exploration/env_infos/initial/reward_dist Mean            0.010921
exploration/env_infos/initial/reward_dist Std             0.0160947
exploration/env_infos/initial/reward_dist Max             0.0426543
exploration/env_infos/initial/reward_dist Min             1.26283e-05
exploration/env_infos/reward_dist Mean                    0.0906513
exploration/env_infos/reward_dist Std                     0.13749
exploration/env_infos/reward_dist Max                     0.644624
exploration/env_infos/reward_dist Min                     1.83236e-17
evaluation/num steps total                           221000
evaluation/num paths total                            11050
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0656009
evaluation/Rewards Std                                    0.0948352
evaluation/Rewards Max                                    0.117709
evaluation/Rewards Min                                   -0.564188
evaluation/Returns Mean                                  -1.31202
evaluation/Returns Std                                    1.39933
evaluation/Returns Max                                    1.38878
evaluation/Returns Min                                   -6.0023
evaluation/Actions Mean                                  -0.0161167
evaluation/Actions Std                                    0.107601
evaluation/Actions Max                                    0.720041
evaluation/Actions Min                                   -0.922073
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.31202
evaluation/env_infos/final/reward_energy Mean            -0.0726262
evaluation/env_infos/final/reward_energy Std              0.0761728
evaluation/env_infos/final/reward_energy Max             -0.00171089
evaluation/env_infos/final/reward_energy Min             -0.40787
evaluation/env_infos/initial/reward_energy Mean          -0.294364
evaluation/env_infos/initial/reward_energy Std            0.2776
evaluation/env_infos/initial/reward_energy Max           -0.0228259
evaluation/env_infos/initial/reward_energy Min           -1.14575
evaluation/env_infos/reward_energy Mean                  -0.0894648
evaluation/env_infos/reward_energy Std                    0.125186
evaluation/env_infos/reward_energy Max                   -0.00124438
evaluation/env_infos/reward_energy Min                   -1.14575
evaluation/env_infos/final/end_effector_loc Mean         -0.146879
evaluation/env_infos/final/end_effector_loc Std           0.352017
evaluation/env_infos/final/end_effector_loc Max           0.73121
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00512408
evaluation/env_infos/initial/end_effector_loc Std         0.013356
evaluation/env_infos/initial/end_effector_loc Max         0.0244479
evaluation/env_infos/initial/end_effector_loc Min        -0.0449756
evaluation/env_infos/end_effector_loc Mean               -0.077113
evaluation/env_infos/end_effector_loc Std                 0.240676
evaluation/env_infos/end_effector_loc Max                 0.73121
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0759083
evaluation/env_infos/final/reward_dist Std                0.173201
evaluation/env_infos/final/reward_dist Max                0.865387
evaluation/env_infos/final/reward_dist Min                1.80594e-119
evaluation/env_infos/initial/reward_dist Mean             0.00989029
evaluation/env_infos/initial/reward_dist Std              0.0208132
evaluation/env_infos/initial/reward_dist Max              0.138099
evaluation/env_infos/initial/reward_dist Min              1.09167e-06
evaluation/env_infos/reward_dist Mean                     0.162531
evaluation/env_infos/reward_dist Std                      0.259526
evaluation/env_infos/reward_dist Max                      0.994712
evaluation/env_infos/reward_dist Min                      1.80594e-119
time/data storing (s)                                    38.0745
time/evaluation sampling (s)                              0.625404
time/exploration sampling (s)                             0.0850344
time/logging (s)                                          0.0160498
time/saving (s)                                           0.797484
time/training (s)                                        38.8768
time/epoch (s)                                           78.4753
time/total (s)                                        16457.3
Epoch                                                   220
---------------------------------------------------  -----------------
2021-05-29 04:31:31.997168 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 221 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00497832
trainer/QF2 Loss                                          0.00583774
trainer/Policy Loss                                       3.01907
trainer/Q1 Predictions Mean                              -1.102
trainer/Q1 Predictions Std                                1.26475
trainer/Q1 Predictions Max                                1.02716
trainer/Q1 Predictions Min                               -7.54399
trainer/Q2 Predictions Mean                              -1.1113
trainer/Q2 Predictions Std                                1.27142
trainer/Q2 Predictions Max                                1.01198
trainer/Q2 Predictions Min                               -7.50556
trainer/Q Targets Mean                                   -1.11567
trainer/Q Targets Std                                     1.26696
trainer/Q Targets Max                                     0.976333
trainer/Q Targets Min                                    -7.51069
trainer/Log Pis Mean                                      1.93485
trainer/Log Pis Std                                       1.28933
trainer/Log Pis Max                                       6.63381
trainer/Log Pis Min                                      -2.36196
trainer/Policy mu Mean                                   -0.00230933
trainer/Policy mu Std                                     0.384074
trainer/Policy mu Max                                     2.51547
trainer/Policy mu Min                                    -2.78676
trainer/Policy log std Mean                              -2.30421
trainer/Policy log std Std                                0.47702
trainer/Policy log std Max                               -0.0947293
trainer/Policy log std Min                               -3.07323
trainer/Alpha                                             0.0237623
trainer/Alpha Loss                                       -0.243642
exploration/num steps total                           23200
exploration/num paths total                            1160
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0838719
exploration/Rewards Std                                   0.0879411
exploration/Rewards Max                                   0.116588
exploration/Rewards Min                                  -0.48726
exploration/Returns Mean                                 -1.67744
exploration/Returns Std                                   0.940254
exploration/Returns Max                                  -0.146729
exploration/Returns Min                                  -2.62317
exploration/Actions Mean                                 -0.00193558
exploration/Actions Std                                   0.113361
exploration/Actions Max                                   0.451352
exploration/Actions Min                                  -0.543471
exploration/Num Paths                                     5
exploration/Average Returns                              -1.67744
exploration/env_infos/final/reward_energy Mean           -0.167037
exploration/env_infos/final/reward_energy Std             0.199752
exploration/env_infos/final/reward_energy Max            -0.0253057
exploration/env_infos/final/reward_energy Min            -0.563586
exploration/env_infos/initial/reward_energy Mean         -0.237137
exploration/env_infos/initial/reward_energy Std           0.175148
exploration/env_infos/initial/reward_energy Max          -0.0325464
exploration/env_infos/initial/reward_energy Min          -0.547345
exploration/env_infos/reward_energy Mean                 -0.125506
exploration/env_infos/reward_energy Std                   0.0997858
exploration/env_infos/reward_energy Max                  -0.00585505
exploration/env_infos/reward_energy Min                  -0.563586
exploration/env_infos/final/end_effector_loc Mean         0.0157211
exploration/env_infos/final/end_effector_loc Std          0.31061
exploration/env_infos/final/end_effector_loc Max          0.514772
exploration/env_infos/final/end_effector_loc Min         -0.50822
exploration/env_infos/initial/end_effector_loc Mean      -0.000162557
exploration/env_infos/initial/end_effector_loc Std        0.0104217
exploration/env_infos/initial/end_effector_loc Max        0.0107366
exploration/env_infos/initial/end_effector_loc Min       -0.0271736
exploration/env_infos/end_effector_loc Mean               0.0224882
exploration/env_infos/end_effector_loc Std                0.190841
exploration/env_infos/end_effector_loc Max                0.514772
exploration/env_infos/end_effector_loc Min               -0.50822
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              7.8772e-06
exploration/env_infos/final/reward_dist Std               9.68706e-06
exploration/env_infos/final/reward_dist Max               2.38343e-05
exploration/env_infos/final/reward_dist Min               7.69671e-13
exploration/env_infos/initial/reward_dist Mean            0.0100413
exploration/env_infos/initial/reward_dist Std             0.0149935
exploration/env_infos/initial/reward_dist Max             0.0391389
exploration/env_infos/initial/reward_dist Min             1.71196e-06
exploration/env_infos/reward_dist Mean                    0.105946
exploration/env_infos/reward_dist Std                     0.21695
exploration/env_infos/reward_dist Max                     0.928498
exploration/env_infos/reward_dist Min                     7.69671e-13
evaluation/num steps total                           222000
evaluation/num paths total                            11100
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0605688
evaluation/Rewards Std                                    0.102084
evaluation/Rewards Max                                    0.168396
evaluation/Rewards Min                                   -0.586726
evaluation/Returns Mean                                  -1.21138
evaluation/Returns Std                                    1.57392
evaluation/Returns Max                                    2.48239
evaluation/Returns Min                                   -5.09091
evaluation/Actions Mean                                  -0.00389724
evaluation/Actions Std                                    0.0909453
evaluation/Actions Max                                    0.60373
evaluation/Actions Min                                   -0.950299
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.21138
evaluation/env_infos/final/reward_energy Mean            -0.0735316
evaluation/env_infos/final/reward_energy Std              0.0721784
evaluation/env_infos/final/reward_energy Max             -0.0066295
evaluation/env_infos/final/reward_energy Min             -0.341256
evaluation/env_infos/initial/reward_energy Mean          -0.27827
evaluation/env_infos/initial/reward_energy Std            0.225394
evaluation/env_infos/initial/reward_energy Max           -0.016959
evaluation/env_infos/initial/reward_energy Min           -0.994883
evaluation/env_infos/reward_energy Mean                  -0.0848902
evaluation/env_infos/reward_energy Std                    0.0967786
evaluation/env_infos/reward_energy Max                   -0.00102237
evaluation/env_infos/reward_energy Min                   -0.994883
evaluation/env_infos/final/end_effector_loc Mean         -0.00694117
evaluation/env_infos/final/end_effector_loc Std           0.298223
evaluation/env_infos/final/end_effector_loc Max           0.596786
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00082596
evaluation/env_infos/initial/end_effector_loc Std         0.0126338
evaluation/env_infos/initial/end_effector_loc Max         0.0301865
evaluation/env_infos/initial/end_effector_loc Min        -0.047515
evaluation/env_infos/end_effector_loc Mean                0.00458754
evaluation/env_infos/end_effector_loc Std                 0.184342
evaluation/env_infos/end_effector_loc Max                 0.596786
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.118358
evaluation/env_infos/final/reward_dist Std                0.217722
evaluation/env_infos/final/reward_dist Max                0.955144
evaluation/env_infos/final/reward_dist Min                1.89494e-37
evaluation/env_infos/initial/reward_dist Mean             0.00296779
evaluation/env_infos/initial/reward_dist Std              0.00511404
evaluation/env_infos/initial/reward_dist Max              0.0233112
evaluation/env_infos/initial/reward_dist Min              1.65676e-06
evaluation/env_infos/reward_dist Mean                     0.149732
evaluation/env_infos/reward_dist Std                      0.261345
evaluation/env_infos/reward_dist Max                      0.999154
evaluation/env_infos/reward_dist Min                      6.81081e-38
time/data storing (s)                                    37.6429
time/evaluation sampling (s)                              0.664534
time/exploration sampling (s)                             0.079587
time/logging (s)                                          0.0157975
time/saving (s)                                           0.792958
time/training (s)                                        39.4226
time/epoch (s)                                           78.6184
time/total (s)                                        16538.3
Epoch                                                   221
---------------------------------------------------  ----------------
2021-05-29 04:32:54.120124 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 222 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00547882
trainer/QF2 Loss                                          0.00511079
trainer/Policy Loss                                       2.91734
trainer/Q1 Predictions Mean                              -0.998595
trainer/Q1 Predictions Std                                1.22756
trainer/Q1 Predictions Max                                1.13591
trainer/Q1 Predictions Min                               -8.38796
trainer/Q2 Predictions Mean                              -1.00623
trainer/Q2 Predictions Std                                1.2253
trainer/Q2 Predictions Max                                1.11426
trainer/Q2 Predictions Min                               -8.49738
trainer/Q Targets Mean                                   -1.03272
trainer/Q Targets Std                                     1.22274
trainer/Q Targets Max                                     1.12907
trainer/Q Targets Min                                    -8.50257
trainer/Log Pis Mean                                      1.9336
trainer/Log Pis Std                                       1.26041
trainer/Log Pis Max                                       4.156
trainer/Log Pis Min                                      -4.98874
trainer/Policy mu Mean                                    0.0024364
trainer/Policy mu Std                                     0.314225
trainer/Policy mu Max                                     2.04143
trainer/Policy mu Min                                    -1.80799
trainer/Policy log std Mean                              -2.32167
trainer/Policy log std Std                                0.442094
trainer/Policy log std Max                               -0.333062
trainer/Policy log std Min                               -3.06134
trainer/Alpha                                             0.0230749
trainer/Alpha Loss                                       -0.250192
exploration/num steps total                           23300
exploration/num paths total                            1165
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.043693
exploration/Rewards Std                                   0.0696599
exploration/Rewards Max                                   0.13236
exploration/Rewards Min                                  -0.223035
exploration/Returns Mean                                 -0.87386
exploration/Returns Std                                   0.945589
exploration/Returns Max                                   0.757918
exploration/Returns Min                                  -2.07755
exploration/Actions Mean                                  0.00540093
exploration/Actions Std                                   0.132085
exploration/Actions Max                                   0.684047
exploration/Actions Min                                  -0.581664
exploration/Num Paths                                     5
exploration/Average Returns                              -0.87386
exploration/env_infos/final/reward_energy Mean           -0.0687014
exploration/env_infos/final/reward_energy Std             0.0295961
exploration/env_infos/final/reward_energy Max            -0.0377335
exploration/env_infos/final/reward_energy Min            -0.106804
exploration/env_infos/initial/reward_energy Mean         -0.32395
exploration/env_infos/initial/reward_energy Std           0.31189
exploration/env_infos/initial/reward_energy Max          -0.0482666
exploration/env_infos/initial/reward_energy Min          -0.899495
exploration/env_infos/reward_energy Mean                 -0.136811
exploration/env_infos/reward_energy Std                   0.127413
exploration/env_infos/reward_energy Max                  -0.0136444
exploration/env_infos/reward_energy Min                  -0.899495
exploration/env_infos/final/end_effector_loc Mean         0.0518701
exploration/env_infos/final/end_effector_loc Std          0.203764
exploration/env_infos/final/end_effector_loc Max          0.319715
exploration/env_infos/final/end_effector_loc Min         -0.362137
exploration/env_infos/initial/end_effector_loc Mean       0.00470644
exploration/env_infos/initial/end_effector_loc Std        0.0151863
exploration/env_infos/initial/end_effector_loc Max        0.0342023
exploration/env_infos/initial/end_effector_loc Min       -0.018411
exploration/env_infos/end_effector_loc Mean               0.0188022
exploration/env_infos/end_effector_loc Std                0.141095
exploration/env_infos/end_effector_loc Max                0.319715
exploration/env_infos/end_effector_loc Min               -0.362137
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.162067
exploration/env_infos/final/reward_dist Std               0.230959
exploration/env_infos/final/reward_dist Max               0.609834
exploration/env_infos/final/reward_dist Min               2.62972e-05
exploration/env_infos/initial/reward_dist Mean            0.00444786
exploration/env_infos/initial/reward_dist Std             0.00493355
exploration/env_infos/initial/reward_dist Max             0.0138818
exploration/env_infos/initial/reward_dist Min             0.000160413
exploration/env_infos/reward_dist Mean                    0.208154
exploration/env_infos/reward_dist Std                     0.266971
exploration/env_infos/reward_dist Max                     0.975552
exploration/env_infos/reward_dist Min                     2.62972e-05
evaluation/num steps total                           223000
evaluation/num paths total                            11150
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0873344
evaluation/Rewards Std                                    0.110639
evaluation/Rewards Max                                    0.183789
evaluation/Rewards Min                                   -0.742918
evaluation/Returns Mean                                  -1.74669
evaluation/Returns Std                                    1.63088
evaluation/Returns Max                                    2.57039
evaluation/Returns Min                                   -8.42531
evaluation/Actions Mean                                  -0.0127232
evaluation/Actions Std                                    0.126467
evaluation/Actions Max                                    0.831286
evaluation/Actions Min                                   -0.963472
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.74669
evaluation/env_infos/final/reward_energy Mean            -0.0861687
evaluation/env_infos/final/reward_energy Std              0.0968721
evaluation/env_infos/final/reward_energy Max             -0.00259895
evaluation/env_infos/final/reward_energy Min             -0.539851
evaluation/env_infos/initial/reward_energy Mean          -0.327132
evaluation/env_infos/initial/reward_energy Std            0.311335
evaluation/env_infos/initial/reward_energy Max           -0.0265365
evaluation/env_infos/initial/reward_energy Min           -1.26733
evaluation/env_infos/reward_energy Mean                  -0.101943
evaluation/env_infos/reward_energy Std                    0.148051
evaluation/env_infos/reward_energy Max                   -0.0016914
evaluation/env_infos/reward_energy Min                   -1.26733
evaluation/env_infos/final/end_effector_loc Mean         -0.0804524
evaluation/env_infos/final/end_effector_loc Std           0.389795
evaluation/env_infos/final/end_effector_loc Max           0.60723
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00264182
evaluation/env_infos/initial/end_effector_loc Std         0.0157465
evaluation/env_infos/initial/end_effector_loc Max         0.0415643
evaluation/env_infos/initial/end_effector_loc Min        -0.0481736
evaluation/env_infos/end_effector_loc Mean               -0.0485751
evaluation/env_infos/end_effector_loc Std                 0.251377
evaluation/env_infos/end_effector_loc Max                 0.60723
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0989464
evaluation/env_infos/final/reward_dist Std                0.230734
evaluation/env_infos/final/reward_dist Max                0.905735
evaluation/env_infos/final/reward_dist Min                6.81019e-118
evaluation/env_infos/initial/reward_dist Mean             0.00788339
evaluation/env_infos/initial/reward_dist Std              0.0149468
evaluation/env_infos/initial/reward_dist Max              0.0695929
evaluation/env_infos/initial/reward_dist Min              1.53418e-06
evaluation/env_infos/reward_dist Mean                     0.119149
evaluation/env_infos/reward_dist Std                      0.231814
evaluation/env_infos/reward_dist Max                      0.997485
evaluation/env_infos/reward_dist Min                      6.81019e-118
time/data storing (s)                                    38.2901
time/evaluation sampling (s)                              0.62423
time/exploration sampling (s)                             0.0868567
time/logging (s)                                          0.0160896
time/saving (s)                                           0.812981
time/training (s)                                        39.9545
time/epoch (s)                                           79.7847
time/total (s)                                        16620.4
Epoch                                                   222
---------------------------------------------------  -----------------
2021-05-29 04:34:16.955842 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 223 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00461641
trainer/QF2 Loss                                          0.00519487
trainer/Policy Loss                                       2.86684
trainer/Q1 Predictions Mean                              -0.914119
trainer/Q1 Predictions Std                                1.14082
trainer/Q1 Predictions Max                                1.063
trainer/Q1 Predictions Min                               -8.3981
trainer/Q2 Predictions Mean                              -0.929845
trainer/Q2 Predictions Std                                1.14487
trainer/Q2 Predictions Max                                1.06262
trainer/Q2 Predictions Min                               -8.59771
trainer/Q Targets Mean                                   -0.923541
trainer/Q Targets Std                                     1.14016
trainer/Q Targets Max                                     1.10785
trainer/Q Targets Min                                    -8.4451
trainer/Log Pis Mean                                      1.97535
trainer/Log Pis Std                                       1.29657
trainer/Log Pis Max                                       4.19905
trainer/Log Pis Min                                      -3.38453
trainer/Policy mu Mean                                   -0.019739
trainer/Policy mu Std                                     0.406745
trainer/Policy mu Max                                     2.08575
trainer/Policy mu Min                                    -1.94744
trainer/Policy log std Mean                              -2.28259
trainer/Policy log std Std                                0.515333
trainer/Policy log std Max                               -0.679944
trainer/Policy log std Min                               -3.13065
trainer/Alpha                                             0.0227172
trainer/Alpha Loss                                       -0.0933022
exploration/num steps total                           23400
exploration/num paths total                            1170
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.180316
exploration/Rewards Std                                   0.0812107
exploration/Rewards Max                                  -0.0595676
exploration/Rewards Min                                  -0.498541
exploration/Returns Mean                                 -3.60633
exploration/Returns Std                                   1.10222
exploration/Returns Max                                  -2.57188
exploration/Returns Min                                  -5.61349
exploration/Actions Mean                                 -0.0749118
exploration/Actions Std                                   0.265833
exploration/Actions Max                                   0.790433
exploration/Actions Min                                  -0.971498
exploration/Num Paths                                     5
exploration/Average Returns                              -3.60633
exploration/env_infos/final/reward_energy Mean           -0.116728
exploration/env_infos/final/reward_energy Std             0.083245
exploration/env_infos/final/reward_energy Max            -0.033432
exploration/env_infos/final/reward_energy Min            -0.26816
exploration/env_infos/initial/reward_energy Mean         -0.504855
exploration/env_infos/initial/reward_energy Std           0.375701
exploration/env_infos/initial/reward_energy Max          -0.0110114
exploration/env_infos/initial/reward_energy Min          -0.88985
exploration/env_infos/reward_energy Mean                 -0.250009
exploration/env_infos/reward_energy Std                   0.300089
exploration/env_infos/reward_energy Max                  -0.0110114
exploration/env_infos/reward_energy Min                  -1.2502
exploration/env_infos/final/end_effector_loc Mean        -0.455045
exploration/env_infos/final/end_effector_loc Std          0.464589
exploration/env_infos/final/end_effector_loc Max          0.165782
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.0132533
exploration/env_infos/initial/end_effector_loc Std        0.0178714
exploration/env_infos/initial/end_effector_loc Max        0.00485188
exploration/env_infos/initial/end_effector_loc Min       -0.0442272
exploration/env_infos/end_effector_loc Mean              -0.282144
exploration/env_infos/end_effector_loc Std                0.383948
exploration/env_infos/end_effector_loc Max                0.165782
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00055367
exploration/env_infos/final/reward_dist Std               0.00110725
exploration/env_infos/final/reward_dist Max               0.00276816
exploration/env_infos/final/reward_dist Min               9.13514e-132
exploration/env_infos/initial/reward_dist Mean            0.000649959
exploration/env_infos/initial/reward_dist Std             0.000706645
exploration/env_infos/initial/reward_dist Max             0.0015176
exploration/env_infos/initial/reward_dist Min             7.89085e-07
exploration/env_infos/reward_dist Mean                    0.00880376
exploration/env_infos/reward_dist Std                     0.0587842
exploration/env_infos/reward_dist Max                     0.572623
exploration/env_infos/reward_dist Min                     9.13514e-132
evaluation/num steps total                           224000
evaluation/num paths total                            11200
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0851315
evaluation/Rewards Std                                    0.134307
evaluation/Rewards Max                                    0.165753
evaluation/Rewards Min                                   -0.933476
evaluation/Returns Mean                                  -1.70263
evaluation/Returns Std                                    2.21692
evaluation/Returns Max                                    2.22921
evaluation/Returns Min                                  -12.7118
evaluation/Actions Mean                                  -0.034119
evaluation/Actions Std                                    0.16133
evaluation/Actions Max                                    0.798208
evaluation/Actions Min                                   -0.987844
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.70263
evaluation/env_infos/final/reward_energy Mean            -0.0850467
evaluation/env_infos/final/reward_energy Std              0.152255
evaluation/env_infos/final/reward_energy Max             -0.00315663
evaluation/env_infos/final/reward_energy Min             -0.915329
evaluation/env_infos/initial/reward_energy Mean          -0.29273
evaluation/env_infos/initial/reward_energy Std            0.302631
evaluation/env_infos/initial/reward_energy Max           -0.00316084
evaluation/env_infos/initial/reward_energy Min           -1.30224
evaluation/env_infos/reward_energy Mean                  -0.119585
evaluation/env_infos/reward_energy Std                    0.200205
evaluation/env_infos/reward_energy Max                   -0.00229185
evaluation/env_infos/reward_energy Min                   -1.36598
evaluation/env_infos/final/end_effector_loc Mean         -0.113529
evaluation/env_infos/final/end_effector_loc Std           0.373273
evaluation/env_infos/final/end_effector_loc Max           0.521966
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00243539
evaluation/env_infos/initial/end_effector_loc Std         0.0146855
evaluation/env_infos/initial/end_effector_loc Max         0.0399104
evaluation/env_infos/initial/end_effector_loc Min        -0.0492688
evaluation/env_infos/end_effector_loc Mean               -0.0578968
evaluation/env_infos/end_effector_loc Std                 0.263665
evaluation/env_infos/end_effector_loc Max                 0.521966
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.113107
evaluation/env_infos/final/reward_dist Std                0.246539
evaluation/env_infos/final/reward_dist Max                0.874158
evaluation/env_infos/final/reward_dist Min                7.98139e-115
evaluation/env_infos/initial/reward_dist Mean             0.00389421
evaluation/env_infos/initial/reward_dist Std              0.00626113
evaluation/env_infos/initial/reward_dist Max              0.0277998
evaluation/env_infos/initial/reward_dist Min              2.0823e-06
evaluation/env_infos/reward_dist Mean                     0.135356
evaluation/env_infos/reward_dist Std                      0.247447
evaluation/env_infos/reward_dist Max                      0.989631
evaluation/env_infos/reward_dist Min                      7.98139e-115
time/data storing (s)                                    39.0861
time/evaluation sampling (s)                              0.664467
time/exploration sampling (s)                             0.0859643
time/logging (s)                                          0.0159079
time/saving (s)                                           0.793556
time/training (s)                                        39.7828
time/epoch (s)                                           80.4287
time/total (s)                                        16703.2
Epoch                                                   223
---------------------------------------------------  -----------------
2021-05-29 04:35:39.401865 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 224 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00856576
trainer/QF2 Loss                                          0.0133197
trainer/Policy Loss                                       3.10274
trainer/Q1 Predictions Mean                              -1.12195
trainer/Q1 Predictions Std                                1.21873
trainer/Q1 Predictions Max                                1.86404
trainer/Q1 Predictions Min                               -6.14581
trainer/Q2 Predictions Mean                              -1.12485
trainer/Q2 Predictions Std                                1.22832
trainer/Q2 Predictions Max                                1.87016
trainer/Q2 Predictions Min                               -6.15329
trainer/Q Targets Mean                                   -1.14403
trainer/Q Targets Std                                     1.22362
trainer/Q Targets Max                                     1.6578
trainer/Q Targets Min                                    -6.20136
trainer/Log Pis Mean                                      1.99628
trainer/Log Pis Std                                       1.22333
trainer/Log Pis Max                                       5.96157
trainer/Log Pis Min                                      -2.311
trainer/Policy mu Mean                                   -0.0251811
trainer/Policy mu Std                                     0.41938
trainer/Policy mu Max                                     2.77717
trainer/Policy mu Min                                    -2.62633
trainer/Policy log std Mean                              -2.2776
trainer/Policy log std Std                                0.533393
trainer/Policy log std Max                                1.35765
trainer/Policy log std Min                               -3.24216
trainer/Alpha                                             0.0215147
trainer/Alpha Loss                                       -0.0143016
exploration/num steps total                           23500
exploration/num paths total                            1175
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0870731
exploration/Rewards Std                                   0.0570833
exploration/Rewards Max                                   0.0467425
exploration/Rewards Min                                  -0.289477
exploration/Returns Mean                                 -1.74146
exploration/Returns Std                                   0.697203
exploration/Returns Max                                  -0.838356
exploration/Returns Min                                  -2.66787
exploration/Actions Mean                                 -0.00213643
exploration/Actions Std                                   0.224877
exploration/Actions Max                                   0.897418
exploration/Actions Min                                  -0.943371
exploration/Num Paths                                     5
exploration/Average Returns                              -1.74146
exploration/env_infos/final/reward_energy Mean           -0.165282
exploration/env_infos/final/reward_energy Std             0.0950022
exploration/env_infos/final/reward_energy Max            -0.0454212
exploration/env_infos/final/reward_energy Min            -0.276618
exploration/env_infos/initial/reward_energy Mean         -0.504276
exploration/env_infos/initial/reward_energy Std           0.289733
exploration/env_infos/initial/reward_energy Max          -0.150464
exploration/env_infos/initial/reward_energy Min          -0.927155
exploration/env_infos/reward_energy Mean                 -0.229787
exploration/env_infos/reward_energy Std                   0.219877
exploration/env_infos/reward_energy Max                  -0.0203414
exploration/env_infos/reward_energy Min                  -1.30204
exploration/env_infos/final/end_effector_loc Mean         0.0748744
exploration/env_infos/final/end_effector_loc Std          0.270902
exploration/env_infos/final/end_effector_loc Max          0.520049
exploration/env_infos/final/end_effector_loc Min         -0.413084
exploration/env_infos/initial/end_effector_loc Mean      -0.00248406
exploration/env_infos/initial/end_effector_loc Std        0.0204115
exploration/env_infos/initial/end_effector_loc Max        0.0220803
exploration/env_infos/initial/end_effector_loc Min       -0.0442377
exploration/env_infos/end_effector_loc Mean               0.0210734
exploration/env_infos/end_effector_loc Std                0.172617
exploration/env_infos/end_effector_loc Max                0.520049
exploration/env_infos/end_effector_loc Min               -0.413084
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.17766
exploration/env_infos/final/reward_dist Std               0.236982
exploration/env_infos/final/reward_dist Max               0.59315
exploration/env_infos/final/reward_dist Min               3.2734e-35
exploration/env_infos/initial/reward_dist Mean            0.00353755
exploration/env_infos/initial/reward_dist Std             0.00399914
exploration/env_infos/initial/reward_dist Max             0.0105031
exploration/env_infos/initial/reward_dist Min             0.000117729
exploration/env_infos/reward_dist Mean                    0.173966
exploration/env_infos/reward_dist Std                     0.213862
exploration/env_infos/reward_dist Max                     0.916029
exploration/env_infos/reward_dist Min                     3.2734e-35
evaluation/num steps total                           225000
evaluation/num paths total                            11250
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.082423
evaluation/Rewards Std                                    0.126243
evaluation/Rewards Max                                    0.14749
evaluation/Rewards Min                                   -0.733985
evaluation/Returns Mean                                  -1.64846
evaluation/Returns Std                                    2.14871
evaluation/Returns Max                                    1.75233
evaluation/Returns Min                                   -9.91324
evaluation/Actions Mean                                  -0.0265504
evaluation/Actions Std                                    0.185194
evaluation/Actions Max                                    0.886058
evaluation/Actions Min                                   -0.999983
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.64846
evaluation/env_infos/final/reward_energy Mean            -0.117998
evaluation/env_infos/final/reward_energy Std              0.175597
evaluation/env_infos/final/reward_energy Max             -0.0128655
evaluation/env_infos/final/reward_energy Min             -0.765398
evaluation/env_infos/initial/reward_energy Mean          -0.43708
evaluation/env_infos/initial/reward_energy Std            0.364073
evaluation/env_infos/initial/reward_energy Max           -0.0151789
evaluation/env_infos/initial/reward_energy Min           -1.39669
evaluation/env_infos/reward_energy Mean                  -0.150184
evaluation/env_infos/reward_energy Std                    0.217827
evaluation/env_infos/reward_energy Max                   -0.00277119
evaluation/env_infos/reward_energy Min                   -1.39669
evaluation/env_infos/final/end_effector_loc Mean         -0.143046
evaluation/env_infos/final/end_effector_loc Std           0.319025
evaluation/env_infos/final/end_effector_loc Max           0.480935
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00414763
evaluation/env_infos/initial/end_effector_loc Std         0.0196795
evaluation/env_infos/initial/end_effector_loc Max         0.0443029
evaluation/env_infos/initial/end_effector_loc Min        -0.0499991
evaluation/env_infos/end_effector_loc Mean               -0.0792297
evaluation/env_infos/end_effector_loc Std                 0.236801
evaluation/env_infos/end_effector_loc Max                 0.480935
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.123899
evaluation/env_infos/final/reward_dist Std                0.231641
evaluation/env_infos/final/reward_dist Max                0.941404
evaluation/env_infos/final/reward_dist Min                1.04734e-100
evaluation/env_infos/initial/reward_dist Mean             0.0055106
evaluation/env_infos/initial/reward_dist Std              0.0101879
evaluation/env_infos/initial/reward_dist Max              0.0499701
evaluation/env_infos/initial/reward_dist Min              1.04659e-06
evaluation/env_infos/reward_dist Mean                     0.161483
evaluation/env_infos/reward_dist Std                      0.263372
evaluation/env_infos/reward_dist Max                      0.996459
evaluation/env_infos/reward_dist Min                      1.04734e-100
time/data storing (s)                                    38.1487
time/evaluation sampling (s)                              0.659484
time/exploration sampling (s)                             0.0895937
time/logging (s)                                          0.0137425
time/saving (s)                                           0.769149
time/training (s)                                        40.3435
time/epoch (s)                                           80.0242
time/total (s)                                        16785.7
Epoch                                                   224
---------------------------------------------------  -----------------
2021-05-29 04:37:01.655200 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 225 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00539101
trainer/QF2 Loss                                          0.0063427
trainer/Policy Loss                                       3.03671
trainer/Q1 Predictions Mean                              -0.999587
trainer/Q1 Predictions Std                                1.15334
trainer/Q1 Predictions Max                                1.56636
trainer/Q1 Predictions Min                               -6.69923
trainer/Q2 Predictions Mean                              -1.00114
trainer/Q2 Predictions Std                                1.14602
trainer/Q2 Predictions Max                                1.52466
trainer/Q2 Predictions Min                               -6.64927
trainer/Q Targets Mean                                   -0.993974
trainer/Q Targets Std                                     1.15655
trainer/Q Targets Max                                     1.79274
trainer/Q Targets Min                                    -6.66905
trainer/Log Pis Mean                                      2.08389
trainer/Log Pis Std                                       1.33297
trainer/Log Pis Max                                       7.15259
trainer/Log Pis Min                                      -4.84869
trainer/Policy mu Mean                                   -0.0974905
trainer/Policy mu Std                                     0.511635
trainer/Policy mu Max                                     2.3015
trainer/Policy mu Min                                    -3.26019
trainer/Policy log std Mean                              -2.26561
trainer/Policy log std Std                                0.53464
trainer/Policy log std Max                                0.0632331
trainer/Policy log std Min                               -3.10146
trainer/Alpha                                             0.0206409
trainer/Alpha Loss                                        0.325641
exploration/num steps total                           23600
exploration/num paths total                            1180
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.149079
exploration/Rewards Std                                   0.132531
exploration/Rewards Max                                  -0.0141205
exploration/Rewards Min                                  -0.720271
exploration/Returns Mean                                 -2.98158
exploration/Returns Std                                   1.55424
exploration/Returns Max                                  -1.59484
exploration/Returns Min                                  -5.85438
exploration/Actions Mean                                 -0.0274802
exploration/Actions Std                                   0.0996517
exploration/Actions Max                                   0.356461
exploration/Actions Min                                  -0.485423
exploration/Num Paths                                     5
exploration/Average Returns                              -2.98158
exploration/env_infos/final/reward_energy Mean           -0.191093
exploration/env_infos/final/reward_energy Std             0.122311
exploration/env_infos/final/reward_energy Max            -0.0220001
exploration/env_infos/final/reward_energy Min            -0.395866
exploration/env_infos/initial/reward_energy Mean         -0.142367
exploration/env_infos/initial/reward_energy Std           0.120215
exploration/env_infos/initial/reward_energy Max          -0.00411308
exploration/env_infos/initial/reward_energy Min          -0.366208
exploration/env_infos/reward_energy Mean                 -0.110109
exploration/env_infos/reward_energy Std                   0.0961632
exploration/env_infos/reward_energy Max                  -0.00411308
exploration/env_infos/reward_energy Min                  -0.507752
exploration/env_infos/final/end_effector_loc Mean        -0.310201
exploration/env_infos/final/end_effector_loc Std          0.295831
exploration/env_infos/final/end_effector_loc Max          0.122483
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00381828
exploration/env_infos/initial/end_effector_loc Std        0.0053685
exploration/env_infos/initial/end_effector_loc Max        0.00406738
exploration/env_infos/initial/end_effector_loc Min       -0.017749
exploration/env_infos/end_effector_loc Mean              -0.138873
exploration/env_infos/end_effector_loc Std                0.197798
exploration/env_infos/end_effector_loc Max                0.122483
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0117115
exploration/env_infos/final/reward_dist Std               0.0144205
exploration/env_infos/final/reward_dist Max               0.0316303
exploration/env_infos/final/reward_dist Min               6.16374e-61
exploration/env_infos/initial/reward_dist Mean            0.000811027
exploration/env_infos/initial/reward_dist Std             0.000915309
exploration/env_infos/initial/reward_dist Max             0.00197483
exploration/env_infos/initial/reward_dist Min             1.37326e-06
exploration/env_infos/reward_dist Mean                    0.0290314
exploration/env_infos/reward_dist Std                     0.0829858
exploration/env_infos/reward_dist Max                     0.428192
exploration/env_infos/reward_dist Min                     1.15738e-61
evaluation/num steps total                           226000
evaluation/num paths total                            11300
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.100542
evaluation/Rewards Std                                    0.135673
evaluation/Rewards Max                                    0.153757
evaluation/Rewards Min                                   -0.778831
evaluation/Returns Mean                                  -2.01083
evaluation/Returns Std                                    2.01286
evaluation/Returns Max                                    1.5757
evaluation/Returns Min                                   -8.84245
evaluation/Actions Mean                                  -0.0282592
evaluation/Actions Std                                    0.178639
evaluation/Actions Max                                    0.874189
evaluation/Actions Min                                   -0.983741
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.01083
evaluation/env_infos/final/reward_energy Mean            -0.157594
evaluation/env_infos/final/reward_energy Std              0.254625
evaluation/env_infos/final/reward_energy Max             -0.00403318
evaluation/env_infos/final/reward_energy Min             -1.09841
evaluation/env_infos/initial/reward_energy Mean          -0.403823
evaluation/env_infos/initial/reward_energy Std            0.379273
evaluation/env_infos/initial/reward_energy Max           -0.0124339
evaluation/env_infos/initial/reward_energy Min           -1.35753
evaluation/env_infos/reward_energy Mean                  -0.1521
evaluation/env_infos/reward_energy Std                    0.205637
evaluation/env_infos/reward_energy Max                   -0.0031433
evaluation/env_infos/reward_energy Min                   -1.35753
evaluation/env_infos/final/end_effector_loc Mean         -0.150476
evaluation/env_infos/final/end_effector_loc Std           0.374295
evaluation/env_infos/final/end_effector_loc Max           0.40706
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00476072
evaluation/env_infos/initial/end_effector_loc Std         0.0189996
evaluation/env_infos/initial/end_effector_loc Max         0.0437095
evaluation/env_infos/initial/end_effector_loc Min        -0.049187
evaluation/env_infos/end_effector_loc Mean               -0.0856815
evaluation/env_infos/end_effector_loc Std                 0.263642
evaluation/env_infos/end_effector_loc Max                 0.40706
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0964766
evaluation/env_infos/final/reward_dist Std                0.207948
evaluation/env_infos/final/reward_dist Max                0.969881
evaluation/env_infos/final/reward_dist Min                1.98943e-126
evaluation/env_infos/initial/reward_dist Mean             0.00773797
evaluation/env_infos/initial/reward_dist Std              0.015674
evaluation/env_infos/initial/reward_dist Max              0.0746015
evaluation/env_infos/initial/reward_dist Min              9.18895e-07
evaluation/env_infos/reward_dist Mean                     0.126058
evaluation/env_infos/reward_dist Std                      0.237514
evaluation/env_infos/reward_dist Max                      0.996084
evaluation/env_infos/reward_dist Min                      1.98943e-126
time/data storing (s)                                    38.5605
time/evaluation sampling (s)                              0.659005
time/exploration sampling (s)                             0.0921549
time/logging (s)                                          0.0178992
time/saving (s)                                           0.790639
time/training (s)                                        39.7717
time/epoch (s)                                           79.8919
time/total (s)                                        16867.9
Epoch                                                   225
---------------------------------------------------  -----------------
2021-05-29 04:38:24.530548 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 226 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00676751
trainer/QF2 Loss                                          0.00717578
trainer/Policy Loss                                       2.97021
trainer/Q1 Predictions Mean                              -0.91967
trainer/Q1 Predictions Std                                1.08871
trainer/Q1 Predictions Max                                1.63777
trainer/Q1 Predictions Min                               -6.80994
trainer/Q2 Predictions Mean                              -0.901984
trainer/Q2 Predictions Std                                1.08382
trainer/Q2 Predictions Max                                1.59426
trainer/Q2 Predictions Min                               -6.62899
trainer/Q Targets Mean                                   -0.900786
trainer/Q Targets Std                                     1.10571
trainer/Q Targets Max                                     1.73679
trainer/Q Targets Min                                    -6.74086
trainer/Log Pis Mean                                      2.07236
trainer/Log Pis Std                                       1.12033
trainer/Log Pis Max                                       6.02614
trainer/Log Pis Min                                      -4.40131
trainer/Policy mu Mean                                   -0.0882898
trainer/Policy mu Std                                     0.446235
trainer/Policy mu Max                                     1.58351
trainer/Policy mu Min                                    -3.41386
trainer/Policy log std Mean                              -2.2789
trainer/Policy log std Std                                0.451586
trainer/Policy log std Max                                0.241269
trainer/Policy log std Min                               -3.09383
trainer/Alpha                                             0.0229179
trainer/Alpha Loss                                        0.273333
exploration/num steps total                           23700
exploration/num paths total                            1185
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0768725
exploration/Rewards Std                                   0.098389
exploration/Rewards Max                                   0.121718
exploration/Rewards Min                                  -0.306566
exploration/Returns Mean                                 -1.53745
exploration/Returns Std                                   1.76031
exploration/Returns Max                                   1.10406
exploration/Returns Min                                  -3.85498
exploration/Actions Mean                                 -0.0212279
exploration/Actions Std                                   0.185912
exploration/Actions Max                                   0.66194
exploration/Actions Min                                  -0.53806
exploration/Num Paths                                     5
exploration/Average Returns                              -1.53745
exploration/env_infos/final/reward_energy Mean           -0.164441
exploration/env_infos/final/reward_energy Std             0.108951
exploration/env_infos/final/reward_energy Max            -0.0374605
exploration/env_infos/final/reward_energy Min            -0.305543
exploration/env_infos/initial/reward_energy Mean         -0.357565
exploration/env_infos/initial/reward_energy Std           0.237402
exploration/env_infos/initial/reward_energy Max          -0.0580904
exploration/env_infos/initial/reward_energy Min          -0.641993
exploration/env_infos/reward_energy Mean                 -0.221426
exploration/env_infos/reward_energy Std                   0.144909
exploration/env_infos/reward_energy Max                  -0.0135764
exploration/env_infos/reward_energy Min                  -0.664616
exploration/env_infos/final/end_effector_loc Mean        -0.14013
exploration/env_infos/final/end_effector_loc Std          0.414421
exploration/env_infos/final/end_effector_loc Max          0.328395
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00161023
exploration/env_infos/initial/end_effector_loc Std        0.0150888
exploration/env_infos/initial/end_effector_loc Max        0.0284511
exploration/env_infos/initial/end_effector_loc Min       -0.026903
exploration/env_infos/end_effector_loc Mean              -0.0408089
exploration/env_infos/end_effector_loc Std                0.248183
exploration/env_infos/end_effector_loc Max                0.328395
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00752202
exploration/env_infos/final/reward_dist Std               0.0149809
exploration/env_infos/final/reward_dist Max               0.0374838
exploration/env_infos/final/reward_dist Min               4.26989e-68
exploration/env_infos/initial/reward_dist Mean            0.00921722
exploration/env_infos/initial/reward_dist Std             0.00896851
exploration/env_infos/initial/reward_dist Max             0.024247
exploration/env_infos/initial/reward_dist Min             0.000138238
exploration/env_infos/reward_dist Mean                    0.150283
exploration/env_infos/reward_dist Std                     0.217054
exploration/env_infos/reward_dist Max                     0.793265
exploration/env_infos/reward_dist Min                     5.49523e-69
evaluation/num steps total                           227000
evaluation/num paths total                            11350
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.116989
evaluation/Rewards Std                                    0.174094
evaluation/Rewards Max                                    0.160389
evaluation/Rewards Min                                   -1.28449
evaluation/Returns Mean                                  -2.33978
evaluation/Returns Std                                    2.76504
evaluation/Returns Max                                    1.43042
evaluation/Returns Min                                  -13.0408
evaluation/Actions Mean                                  -0.0717423
evaluation/Actions Std                                    0.259189
evaluation/Actions Max                                    0.86232
evaluation/Actions Min                                   -0.997271
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.33978
evaluation/env_infos/final/reward_energy Mean            -0.234808
evaluation/env_infos/final/reward_energy Std              0.3022
evaluation/env_infos/final/reward_energy Max             -0.0120432
evaluation/env_infos/final/reward_energy Min             -1.04529
evaluation/env_infos/initial/reward_energy Mean          -0.513604
evaluation/env_infos/initial/reward_energy Std            0.431873
evaluation/env_infos/initial/reward_energy Max           -0.0365433
evaluation/env_infos/initial/reward_energy Min           -1.40098
evaluation/env_infos/reward_energy Mean                  -0.230856
evaluation/env_infos/reward_energy Std                    0.302253
evaluation/env_infos/reward_energy Max                   -0.000586678
evaluation/env_infos/reward_energy Min                   -1.40098
evaluation/env_infos/final/end_effector_loc Mean         -0.133662
evaluation/env_infos/final/end_effector_loc Std           0.470926
evaluation/env_infos/final/end_effector_loc Max           0.973981
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00777087
evaluation/env_infos/initial/end_effector_loc Std         0.0224164
evaluation/env_infos/initial/end_effector_loc Max         0.0418411
evaluation/env_infos/initial/end_effector_loc Min        -0.0498635
evaluation/env_infos/end_effector_loc Mean               -0.0874406
evaluation/env_infos/end_effector_loc Std                 0.35487
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0901001
evaluation/env_infos/final/reward_dist Std                0.21123
evaluation/env_infos/final/reward_dist Max                0.762549
evaluation/env_infos/final/reward_dist Min                7.54993e-194
evaluation/env_infos/initial/reward_dist Mean             0.00720552
evaluation/env_infos/initial/reward_dist Std              0.0163934
evaluation/env_infos/initial/reward_dist Max              0.0815312
evaluation/env_infos/initial/reward_dist Min              2.51988e-09
evaluation/env_infos/reward_dist Mean                     0.143835
evaluation/env_infos/reward_dist Std                      0.240667
evaluation/env_infos/reward_dist Max                      0.999199
evaluation/env_infos/reward_dist Min                      3.66736e-198
time/data storing (s)                                    38.545
time/evaluation sampling (s)                              0.639372
time/exploration sampling (s)                             0.0867635
time/logging (s)                                          0.0158296
time/saving (s)                                           0.824917
time/training (s)                                        40.3264
time/epoch (s)                                           80.4383
time/total (s)                                        16950.8
Epoch                                                   226
---------------------------------------------------  -----------------
2021-05-29 04:39:47.154619 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 227 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00498142
trainer/QF2 Loss                                          0.0042634
trainer/Policy Loss                                       2.83248
trainer/Q1 Predictions Mean                              -0.929571
trainer/Q1 Predictions Std                                0.95254
trainer/Q1 Predictions Max                                1.20539
trainer/Q1 Predictions Min                               -4.11506
trainer/Q2 Predictions Mean                              -0.94568
trainer/Q2 Predictions Std                                0.949778
trainer/Q2 Predictions Max                                1.10963
trainer/Q2 Predictions Min                               -4.12928
trainer/Q Targets Mean                                   -0.934615
trainer/Q Targets Std                                     0.953122
trainer/Q Targets Max                                     1.06564
trainer/Q Targets Min                                    -4.12633
trainer/Log Pis Mean                                      1.90684
trainer/Log Pis Std                                       1.24086
trainer/Log Pis Max                                       5.24237
trainer/Log Pis Min                                      -6.00428
trainer/Policy mu Mean                                   -0.0616027
trainer/Policy mu Std                                     0.345999
trainer/Policy mu Max                                     1.61491
trainer/Policy mu Min                                    -2.44564
trainer/Policy log std Mean                              -2.27879
trainer/Policy log std Std                                0.445874
trainer/Policy log std Max                               -0.36087
trainer/Policy log std Min                               -3.0145
trainer/Alpha                                             0.0230383
trainer/Alpha Loss                                       -0.351125
exploration/num steps total                           23800
exploration/num paths total                            1190
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0943237
exploration/Rewards Std                                   0.0774528
exploration/Rewards Max                                   0.0366964
exploration/Rewards Min                                  -0.280696
exploration/Returns Mean                                 -1.88647
exploration/Returns Std                                   1.11979
exploration/Returns Max                                  -0.269855
exploration/Returns Min                                  -3.76353
exploration/Actions Mean                                 -0.00501958
exploration/Actions Std                                   0.190744
exploration/Actions Max                                   0.816056
exploration/Actions Min                                  -0.916694
exploration/Num Paths                                     5
exploration/Average Returns                              -1.88647
exploration/env_infos/final/reward_energy Mean           -0.159032
exploration/env_infos/final/reward_energy Std             0.0947359
exploration/env_infos/final/reward_energy Max            -0.0354652
exploration/env_infos/final/reward_energy Min            -0.254589
exploration/env_infos/initial/reward_energy Mean         -0.25711
exploration/env_infos/initial/reward_energy Std           0.110366
exploration/env_infos/initial/reward_energy Max          -0.142417
exploration/env_infos/initial/reward_energy Min          -0.391122
exploration/env_infos/reward_energy Mean                 -0.194636
exploration/env_infos/reward_energy Std                   0.186906
exploration/env_infos/reward_energy Max                  -0.016039
exploration/env_infos/reward_energy Min                  -1.08901
exploration/env_infos/final/end_effector_loc Mean         0.0754338
exploration/env_infos/final/end_effector_loc Std          0.183689
exploration/env_infos/final/end_effector_loc Max          0.328606
exploration/env_infos/final/end_effector_loc Min         -0.224846
exploration/env_infos/initial/end_effector_loc Mean       0.00280594
exploration/env_infos/initial/end_effector_loc Std        0.00948602
exploration/env_infos/initial/end_effector_loc Max        0.0195535
exploration/env_infos/initial/end_effector_loc Min       -0.0192932
exploration/env_infos/end_effector_loc Mean               0.0657686
exploration/env_infos/end_effector_loc Std                0.153988
exploration/env_infos/end_effector_loc Max                0.436757
exploration/env_infos/end_effector_loc Min               -0.224846
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0146021
exploration/env_infos/final/reward_dist Std               0.0287828
exploration/env_infos/final/reward_dist Max               0.0721649
exploration/env_infos/final/reward_dist Min               2.89215e-06
exploration/env_infos/initial/reward_dist Mean            0.012895
exploration/env_infos/initial/reward_dist Std             0.0170284
exploration/env_infos/initial/reward_dist Max             0.0450458
exploration/env_infos/initial/reward_dist Min             1.96903e-06
exploration/env_infos/reward_dist Mean                    0.0581143
exploration/env_infos/reward_dist Std                     0.116475
exploration/env_infos/reward_dist Max                     0.814349
exploration/env_infos/reward_dist Min                     8.49869e-09
evaluation/num steps total                           228000
evaluation/num paths total                            11400
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0701987
evaluation/Rewards Std                                    0.0980268
evaluation/Rewards Max                                    0.165876
evaluation/Rewards Min                                   -0.773576
evaluation/Returns Mean                                  -1.40397
evaluation/Returns Std                                    1.42398
evaluation/Returns Max                                    1.01356
evaluation/Returns Min                                   -6.80962
evaluation/Actions Mean                                  -0.00649431
evaluation/Actions Std                                    0.112857
evaluation/Actions Max                                    0.91507
evaluation/Actions Min                                   -0.874259
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.40397
evaluation/env_infos/final/reward_energy Mean            -0.0647438
evaluation/env_infos/final/reward_energy Std              0.0929518
evaluation/env_infos/final/reward_energy Max             -0.00257612
evaluation/env_infos/final/reward_energy Min             -0.603588
evaluation/env_infos/initial/reward_energy Mean          -0.272573
evaluation/env_infos/initial/reward_energy Std            0.281323
evaluation/env_infos/initial/reward_energy Max           -0.00869635
evaluation/env_infos/initial/reward_energy Min           -1.08368
evaluation/env_infos/reward_energy Mean                  -0.0957077
evaluation/env_infos/reward_energy Std                    0.128054
evaluation/env_infos/reward_energy Max                   -0.000654791
evaluation/env_infos/reward_energy Min                   -1.08368
evaluation/env_infos/final/end_effector_loc Mean         -0.0762873
evaluation/env_infos/final/end_effector_loc Std           0.317028
evaluation/env_infos/final/end_effector_loc Max           0.607873
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.0015076
evaluation/env_infos/initial/end_effector_loc Std         0.0137668
evaluation/env_infos/initial/end_effector_loc Max         0.0457535
evaluation/env_infos/initial/end_effector_loc Min        -0.0421093
evaluation/env_infos/end_effector_loc Mean               -0.0400885
evaluation/env_infos/end_effector_loc Std                 0.21424
evaluation/env_infos/end_effector_loc Max                 0.607873
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0807821
evaluation/env_infos/final/reward_dist Std                0.160104
evaluation/env_infos/final/reward_dist Max                0.824691
evaluation/env_infos/final/reward_dist Min                2.77713e-98
evaluation/env_infos/initial/reward_dist Mean             0.00622063
evaluation/env_infos/initial/reward_dist Std              0.0107096
evaluation/env_infos/initial/reward_dist Max              0.0497132
evaluation/env_infos/initial/reward_dist Min              1.50469e-06
evaluation/env_infos/reward_dist Mean                     0.117111
evaluation/env_infos/reward_dist Std                      0.21315
evaluation/env_infos/reward_dist Max                      0.999411
evaluation/env_infos/reward_dist Min                      2.77713e-98
time/data storing (s)                                    38.6828
time/evaluation sampling (s)                              0.641717
time/exploration sampling (s)                             0.088684
time/logging (s)                                          0.0166916
time/saving (s)                                           0.77324
time/training (s)                                        39.9834
time/epoch (s)                                           80.1865
time/total (s)                                        17033.4
Epoch                                                   227
---------------------------------------------------  ----------------
2021-05-29 04:41:08.346932 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 228 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00595603
trainer/QF2 Loss                                          0.00470028
trainer/Policy Loss                                       3.12759
trainer/Q1 Predictions Mean                              -0.975734
trainer/Q1 Predictions Std                                0.984039
trainer/Q1 Predictions Max                                2.23893
trainer/Q1 Predictions Min                               -3.6919
trainer/Q2 Predictions Mean                              -0.980427
trainer/Q2 Predictions Std                                0.986385
trainer/Q2 Predictions Max                                2.41207
trainer/Q2 Predictions Min                               -3.676
trainer/Q Targets Mean                                   -0.971131
trainer/Q Targets Std                                     0.977427
trainer/Q Targets Max                                     2.32217
trainer/Q Targets Min                                    -3.68474
trainer/Log Pis Mean                                      2.16308
trainer/Log Pis Std                                       1.27215
trainer/Log Pis Max                                       7.04247
trainer/Log Pis Min                                      -1.93114
trainer/Policy mu Mean                                   -0.11667
trainer/Policy mu Std                                     0.600646
trainer/Policy mu Max                                     2.7347
trainer/Policy mu Min                                    -3.37403
trainer/Policy log std Mean                              -2.20238
trainer/Policy log std Std                                0.571262
trainer/Policy log std Max                                0.680981
trainer/Policy log std Min                               -3.04567
trainer/Alpha                                             0.0249382
trainer/Alpha Loss                                        0.602263
exploration/num steps total                           23900
exploration/num paths total                            1195
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.137602
exploration/Rewards Std                                   0.100531
exploration/Rewards Max                                   0.118419
exploration/Rewards Min                                  -0.375027
exploration/Returns Mean                                 -2.75205
exploration/Returns Std                                   1.58265
exploration/Returns Max                                   0.385533
exploration/Returns Min                                  -3.86132
exploration/Actions Mean                                  0.00221918
exploration/Actions Std                                   0.165655
exploration/Actions Max                                   0.540087
exploration/Actions Min                                  -0.740347
exploration/Num Paths                                     5
exploration/Average Returns                              -2.75205
exploration/env_infos/final/reward_energy Mean           -0.159936
exploration/env_infos/final/reward_energy Std             0.0985298
exploration/env_infos/final/reward_energy Max            -0.0420593
exploration/env_infos/final/reward_energy Min            -0.31841
exploration/env_infos/initial/reward_energy Mean         -0.359525
exploration/env_infos/initial/reward_energy Std           0.210762
exploration/env_infos/initial/reward_energy Max          -0.0361873
exploration/env_infos/initial/reward_energy Min          -0.563916
exploration/env_infos/reward_energy Mean                 -0.181789
exploration/env_infos/reward_energy Std                   0.147803
exploration/env_infos/reward_energy Max                  -0.0148787
exploration/env_infos/reward_energy Min                  -0.750701
exploration/env_infos/final/end_effector_loc Mean         0.171264
exploration/env_infos/final/end_effector_loc Std          0.219979
exploration/env_infos/final/end_effector_loc Max          0.461109
exploration/env_infos/final/end_effector_loc Min         -0.302208
exploration/env_infos/initial/end_effector_loc Mean       0.00356372
exploration/env_infos/initial/end_effector_loc Std        0.0142968
exploration/env_infos/initial/end_effector_loc Max        0.0269995
exploration/env_infos/initial/end_effector_loc Min       -0.0256395
exploration/env_infos/end_effector_loc Mean               0.102089
exploration/env_infos/end_effector_loc Std                0.148624
exploration/env_infos/end_effector_loc Max                0.461109
exploration/env_infos/end_effector_loc Min               -0.302208
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.043153
exploration/env_infos/final/reward_dist Std               0.0528976
exploration/env_infos/final/reward_dist Max               0.12915
exploration/env_infos/final/reward_dist Min               3.2148e-06
exploration/env_infos/initial/reward_dist Mean            0.000602995
exploration/env_infos/initial/reward_dist Std             0.000560119
exploration/env_infos/initial/reward_dist Max             0.00143776
exploration/env_infos/initial/reward_dist Min             1.44268e-05
exploration/env_infos/reward_dist Mean                    0.0902569
exploration/env_infos/reward_dist Std                     0.18636
exploration/env_infos/reward_dist Max                     0.842634
exploration/env_infos/reward_dist Min                     5.47816e-07
evaluation/num steps total                           229000
evaluation/num paths total                            11450
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.110931
evaluation/Rewards Std                                    0.137224
evaluation/Rewards Max                                    0.109297
evaluation/Rewards Min                                   -1.01003
evaluation/Returns Mean                                  -2.21863
evaluation/Returns Std                                    2.19367
evaluation/Returns Max                                    1.09526
evaluation/Returns Min                                  -12.4397
evaluation/Actions Mean                                  -0.0097682
evaluation/Actions Std                                    0.178621
evaluation/Actions Max                                    0.989714
evaluation/Actions Min                                   -0.984186
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.21863
evaluation/env_infos/final/reward_energy Mean            -0.0979337
evaluation/env_infos/final/reward_energy Std              0.152923
evaluation/env_infos/final/reward_energy Max             -0.00925192
evaluation/env_infos/final/reward_energy Min             -0.919483
evaluation/env_infos/initial/reward_energy Mean          -0.412516
evaluation/env_infos/initial/reward_energy Std            0.383099
evaluation/env_infos/initial/reward_energy Max           -0.0103631
evaluation/env_infos/initial/reward_energy Min           -1.39093
evaluation/env_infos/reward_energy Mean                  -0.140048
evaluation/env_infos/reward_energy Std                    0.210685
evaluation/env_infos/reward_energy Max                   -0.00324467
evaluation/env_infos/reward_energy Min                   -1.39093
evaluation/env_infos/final/end_effector_loc Mean         -0.0205281
evaluation/env_infos/final/end_effector_loc Std           0.34356
evaluation/env_infos/final/end_effector_loc Max           0.910766
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00230531
evaluation/env_infos/initial/end_effector_loc Std         0.01977
evaluation/env_infos/initial/end_effector_loc Max         0.0494857
evaluation/env_infos/initial/end_effector_loc Min        -0.0492093
evaluation/env_infos/end_effector_loc Mean               -0.0132534
evaluation/env_infos/end_effector_loc Std                 0.244008
evaluation/env_infos/end_effector_loc Max                 0.947365
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.120294
evaluation/env_infos/final/reward_dist Std                0.222081
evaluation/env_infos/final/reward_dist Max                0.814937
evaluation/env_infos/final/reward_dist Min                4.13427e-155
evaluation/env_infos/initial/reward_dist Mean             0.00496617
evaluation/env_infos/initial/reward_dist Std              0.00764105
evaluation/env_infos/initial/reward_dist Max              0.0328967
evaluation/env_infos/initial/reward_dist Min              6.5213e-07
evaluation/env_infos/reward_dist Mean                     0.111484
evaluation/env_infos/reward_dist Std                      0.202918
evaluation/env_infos/reward_dist Max                      0.988691
evaluation/env_infos/reward_dist Min                      2.38793e-160
time/data storing (s)                                    38.2762
time/evaluation sampling (s)                              0.531326
time/exploration sampling (s)                             0.0851909
time/logging (s)                                          0.0143711
time/saving (s)                                           0.79849
time/training (s)                                        39.1037
time/epoch (s)                                           78.8092
time/total (s)                                        17114.6
Epoch                                                   228
---------------------------------------------------  -----------------
2021-05-29 04:42:30.947846 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 229 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00479647
trainer/QF2 Loss                                          0.00383345
trainer/Policy Loss                                       3.12809
trainer/Q1 Predictions Mean                              -0.987387
trainer/Q1 Predictions Std                                0.946041
trainer/Q1 Predictions Max                                2.17309
trainer/Q1 Predictions Min                               -3.42094
trainer/Q2 Predictions Mean                              -0.990523
trainer/Q2 Predictions Std                                0.95614
trainer/Q2 Predictions Max                                2.09524
trainer/Q2 Predictions Min                               -3.4341
trainer/Q Targets Mean                                   -0.988988
trainer/Q Targets Std                                     0.95438
trainer/Q Targets Max                                     2.21102
trainer/Q Targets Min                                    -3.39735
trainer/Log Pis Mean                                      2.15885
trainer/Log Pis Std                                       1.17029
trainer/Log Pis Max                                       5.08274
trainer/Log Pis Min                                      -2.71156
trainer/Policy mu Mean                                   -0.120918
trainer/Policy mu Std                                     0.479431
trainer/Policy mu Max                                     1.66333
trainer/Policy mu Min                                    -2.78089
trainer/Policy log std Mean                              -2.26129
trainer/Policy log std Std                                0.474511
trainer/Policy log std Max                               -0.369784
trainer/Policy log std Min                               -2.90702
trainer/Alpha                                             0.0242624
trainer/Alpha Loss                                        0.590958
exploration/num steps total                           24000
exploration/num paths total                            1200
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0435309
exploration/Rewards Std                                   0.116719
exploration/Rewards Max                                   0.149979
exploration/Rewards Min                                  -0.23988
exploration/Returns Mean                                 -0.870617
exploration/Returns Std                                   2.14183
exploration/Returns Max                                   1.99279
exploration/Returns Min                                  -3.43798
exploration/Actions Mean                                 -0.0127359
exploration/Actions Std                                   0.137335
exploration/Actions Max                                   0.762925
exploration/Actions Min                                  -0.43546
exploration/Num Paths                                     5
exploration/Average Returns                              -0.870617
exploration/env_infos/final/reward_energy Mean           -0.126314
exploration/env_infos/final/reward_energy Std             0.0508659
exploration/env_infos/final/reward_energy Max            -0.0657572
exploration/env_infos/final/reward_energy Min            -0.214396
exploration/env_infos/initial/reward_energy Mean         -0.281003
exploration/env_infos/initial/reward_energy Std           0.263542
exploration/env_infos/initial/reward_energy Max          -0.0132784
exploration/env_infos/initial/reward_energy Min          -0.764693
exploration/env_infos/reward_energy Mean                 -0.153869
exploration/env_infos/reward_energy Std                   0.119877
exploration/env_infos/reward_energy Max                  -0.0120942
exploration/env_infos/reward_energy Min                  -0.764693
exploration/env_infos/final/end_effector_loc Mean        -0.127129
exploration/env_infos/final/end_effector_loc Std          0.289321
exploration/env_infos/final/end_effector_loc Max          0.243643
exploration/env_infos/final/end_effector_loc Min         -0.725554
exploration/env_infos/initial/end_effector_loc Mean       0.00276552
exploration/env_infos/initial/end_effector_loc Std        0.0133369
exploration/env_infos/initial/end_effector_loc Max        0.0381462
exploration/env_infos/initial/end_effector_loc Min       -0.0090825
exploration/env_infos/end_effector_loc Mean              -0.0341927
exploration/env_infos/end_effector_loc Std                0.168745
exploration/env_infos/end_effector_loc Max                0.243643
exploration/env_infos/end_effector_loc Min               -0.725554
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.170271
exploration/env_infos/final/reward_dist Std               0.149054
exploration/env_infos/final/reward_dist Max               0.347347
exploration/env_infos/final/reward_dist Min               1.28282e-23
exploration/env_infos/initial/reward_dist Mean            0.00315566
exploration/env_infos/initial/reward_dist Std             0.00336038
exploration/env_infos/initial/reward_dist Max             0.00910366
exploration/env_infos/initial/reward_dist Min             0.000469329
exploration/env_infos/reward_dist Mean                    0.31499
exploration/env_infos/reward_dist Std                     0.308079
exploration/env_infos/reward_dist Max                     0.968578
exploration/env_infos/reward_dist Min                     1.28282e-23
evaluation/num steps total                           230000
evaluation/num paths total                            11500
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.120193
evaluation/Rewards Std                                    0.16174
evaluation/Rewards Max                                    0.120157
evaluation/Rewards Min                                   -0.941594
evaluation/Returns Mean                                  -2.40386
evaluation/Returns Std                                    2.8764
evaluation/Returns Max                                    0.69582
evaluation/Returns Min                                  -15.5193
evaluation/Actions Mean                                  -0.025584
evaluation/Actions Std                                    0.168257
evaluation/Actions Max                                    0.799584
evaluation/Actions Min                                   -0.983023
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.40386
evaluation/env_infos/final/reward_energy Mean            -0.0896823
evaluation/env_infos/final/reward_energy Std              0.164946
evaluation/env_infos/final/reward_energy Max             -0.005597
evaluation/env_infos/final/reward_energy Min             -1.14857
evaluation/env_infos/initial/reward_energy Mean          -0.364202
evaluation/env_infos/initial/reward_energy Std            0.294999
evaluation/env_infos/initial/reward_energy Max           -0.0312173
evaluation/env_infos/initial/reward_energy Min           -1.00165
evaluation/env_infos/reward_energy Mean                  -0.135442
evaluation/env_infos/reward_energy Std                    0.198961
evaluation/env_infos/reward_energy Max                   -0.00323069
evaluation/env_infos/reward_energy Min                   -1.19644
evaluation/env_infos/final/end_effector_loc Mean         -0.0881305
evaluation/env_infos/final/end_effector_loc Std           0.388328
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00482083
evaluation/env_infos/initial/end_effector_loc Std         0.0158538
evaluation/env_infos/initial/end_effector_loc Max         0.0361772
evaluation/env_infos/initial/end_effector_loc Min        -0.0483742
evaluation/env_infos/end_effector_loc Mean               -0.0527158
evaluation/env_infos/end_effector_loc Std                 0.273515
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0755327
evaluation/env_infos/final/reward_dist Std                0.197547
evaluation/env_infos/final/reward_dist Max                0.851539
evaluation/env_infos/final/reward_dist Min                8.39823e-188
evaluation/env_infos/initial/reward_dist Mean             0.00680825
evaluation/env_infos/initial/reward_dist Std              0.0123856
evaluation/env_infos/initial/reward_dist Max              0.0535882
evaluation/env_infos/initial/reward_dist Min              1.63333e-07
evaluation/env_infos/reward_dist Mean                     0.0909257
evaluation/env_infos/reward_dist Std                      0.188105
evaluation/env_infos/reward_dist Max                      0.990144
evaluation/env_infos/reward_dist Min                      8.39823e-188
time/data storing (s)                                    38.3597
time/evaluation sampling (s)                              0.652901
time/exploration sampling (s)                             0.0964822
time/logging (s)                                          0.0157419
time/saving (s)                                           0.799843
time/training (s)                                        40.242
time/epoch (s)                                           80.1666
time/total (s)                                        17197.2
Epoch                                                   229
---------------------------------------------------  -----------------
2021-05-29 04:43:52.755418 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 230 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00374701
trainer/QF2 Loss                                          0.00413203
trainer/Policy Loss                                       2.76778
trainer/Q1 Predictions Mean                              -0.948691
trainer/Q1 Predictions Std                                0.976611
trainer/Q1 Predictions Max                                2.88495
trainer/Q1 Predictions Min                               -3.41254
trainer/Q2 Predictions Mean                              -0.936321
trainer/Q2 Predictions Std                                0.973137
trainer/Q2 Predictions Max                                2.99221
trainer/Q2 Predictions Min                               -3.3227
trainer/Q Targets Mean                                   -0.944843
trainer/Q Targets Std                                     0.976625
trainer/Q Targets Max                                     2.89262
trainer/Q Targets Min                                    -3.35991
trainer/Log Pis Mean                                      1.82745
trainer/Log Pis Std                                       1.36968
trainer/Log Pis Max                                       5.5903
trainer/Log Pis Min                                      -5.27361
trainer/Policy mu Mean                                   -0.0855376
trainer/Policy mu Std                                     0.452611
trainer/Policy mu Max                                     1.93021
trainer/Policy mu Min                                    -2.87013
trainer/Policy log std Mean                              -2.21382
trainer/Policy log std Std                                0.495736
trainer/Policy log std Max                                0.0228672
trainer/Policy log std Min                               -2.97397
trainer/Alpha                                             0.0260266
trainer/Alpha Loss                                       -0.629585
exploration/num steps total                           24100
exploration/num paths total                            1205
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.309336
exploration/Rewards Std                                   0.22168
exploration/Rewards Max                                  -0.00868598
exploration/Rewards Min                                  -0.848413
exploration/Returns Mean                                 -6.18672
exploration/Returns Std                                   3.51359
exploration/Returns Max                                  -1.93978
exploration/Returns Min                                 -12.5423
exploration/Actions Mean                                 -0.1465
exploration/Actions Std                                   0.366431
exploration/Actions Max                                   0.6655
exploration/Actions Min                                  -0.999306
exploration/Num Paths                                     5
exploration/Average Returns                              -6.18672
exploration/env_infos/final/reward_energy Mean           -0.399336
exploration/env_infos/final/reward_energy Std             0.347988
exploration/env_infos/final/reward_energy Max            -0.0703539
exploration/env_infos/final/reward_energy Min            -0.980304
exploration/env_infos/initial/reward_energy Mean         -0.602071
exploration/env_infos/initial/reward_energy Std           0.243893
exploration/env_infos/initial/reward_energy Max          -0.222743
exploration/env_infos/initial/reward_energy Min          -0.93593
exploration/env_infos/reward_energy Mean                 -0.417328
exploration/env_infos/reward_energy Std                   0.370548
exploration/env_infos/reward_energy Max                  -0.0145907
exploration/env_infos/reward_energy Min                  -1.22022
exploration/env_infos/final/end_effector_loc Mean        -0.423696
exploration/env_infos/final/end_effector_loc Std          0.429651
exploration/env_infos/final/end_effector_loc Max          0.344267
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.0153781
exploration/env_infos/initial/end_effector_loc Std        0.0170582
exploration/env_infos/initial/end_effector_loc Max        0.0172804
exploration/env_infos/initial/end_effector_loc Min       -0.0434891
exploration/env_infos/end_effector_loc Mean              -0.2796
exploration/env_infos/end_effector_loc Std                0.422696
exploration/env_infos/end_effector_loc Max                0.639232
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000617571
exploration/env_infos/final/reward_dist Std               0.00123514
exploration/env_infos/final/reward_dist Max               0.00308786
exploration/env_infos/final/reward_dist Min               4.61676e-103
exploration/env_infos/initial/reward_dist Mean            0.00265371
exploration/env_infos/initial/reward_dist Std             0.00395292
exploration/env_infos/initial/reward_dist Max             0.0104659
exploration/env_infos/initial/reward_dist Min             5.72711e-05
exploration/env_infos/reward_dist Mean                    0.0187864
exploration/env_infos/reward_dist Std                     0.084994
exploration/env_infos/reward_dist Max                     0.687384
exploration/env_infos/reward_dist Min                     6.199e-130
evaluation/num steps total                           231000
evaluation/num paths total                            11550
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.106371
evaluation/Rewards Std                                    0.158824
evaluation/Rewards Max                                    0.153612
evaluation/Rewards Min                                   -0.979603
evaluation/Returns Mean                                  -2.12741
evaluation/Returns Std                                    2.83647
evaluation/Returns Max                                    1.84995
evaluation/Returns Min                                  -14.1655
evaluation/Actions Mean                                  -0.0223942
evaluation/Actions Std                                    0.161452
evaluation/Actions Max                                    0.817129
evaluation/Actions Min                                   -0.990809
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.12741
evaluation/env_infos/final/reward_energy Mean            -0.10667
evaluation/env_infos/final/reward_energy Std              0.166691
evaluation/env_infos/final/reward_energy Max             -0.0102606
evaluation/env_infos/final/reward_energy Min             -0.715601
evaluation/env_infos/initial/reward_energy Mean          -0.349016
evaluation/env_infos/initial/reward_energy Std            0.32528
evaluation/env_infos/initial/reward_energy Max           -0.0199201
evaluation/env_infos/initial/reward_energy Min           -1.27445
evaluation/env_infos/reward_energy Mean                  -0.128064
evaluation/env_infos/reward_energy Std                    0.191666
evaluation/env_infos/reward_energy Max                   -0.00134627
evaluation/env_infos/reward_energy Min                   -1.27445
evaluation/env_infos/final/end_effector_loc Mean         -0.10689
evaluation/env_infos/final/end_effector_loc Std           0.380487
evaluation/env_infos/final/end_effector_loc Max           0.453209
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00301846
evaluation/env_infos/initial/end_effector_loc Std         0.0165956
evaluation/env_infos/initial/end_effector_loc Max         0.0408565
evaluation/env_infos/initial/end_effector_loc Min        -0.0473153
evaluation/env_infos/end_effector_loc Mean               -0.0682808
evaluation/env_infos/end_effector_loc Std                 0.280374
evaluation/env_infos/end_effector_loc Max                 0.453209
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.10183
evaluation/env_infos/final/reward_dist Std                0.202048
evaluation/env_infos/final/reward_dist Max                0.841921
evaluation/env_infos/final/reward_dist Min                9.04791e-152
evaluation/env_infos/initial/reward_dist Mean             0.00953387
evaluation/env_infos/initial/reward_dist Std              0.0299796
evaluation/env_infos/initial/reward_dist Max              0.19948
evaluation/env_infos/initial/reward_dist Min              1.3957e-06
evaluation/env_infos/reward_dist Mean                     0.135987
evaluation/env_infos/reward_dist Std                      0.243271
evaluation/env_infos/reward_dist Max                      0.99563
evaluation/env_infos/reward_dist Min                      9.04791e-152
time/data storing (s)                                    38.2289
time/evaluation sampling (s)                              0.652281
time/exploration sampling (s)                             0.0861809
time/logging (s)                                          0.0143588
time/saving (s)                                           0.800883
time/training (s)                                        39.1398
time/epoch (s)                                           78.9223
time/total (s)                                        17279
Epoch                                                   230
---------------------------------------------------  -----------------
2021-05-29 04:45:14.272628 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 231 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00604804
trainer/QF2 Loss                                          0.0070114
trainer/Policy Loss                                       2.98191
trainer/Q1 Predictions Mean                              -0.881408
trainer/Q1 Predictions Std                                1.03998
trainer/Q1 Predictions Max                                2.40593
trainer/Q1 Predictions Min                               -3.76976
trainer/Q2 Predictions Mean                              -0.906729
trainer/Q2 Predictions Std                                1.04462
trainer/Q2 Predictions Max                                2.63396
trainer/Q2 Predictions Min                               -3.8016
trainer/Q Targets Mean                                   -0.885848
trainer/Q Targets Std                                     1.04355
trainer/Q Targets Max                                     2.57661
trainer/Q Targets Min                                    -3.74206
trainer/Log Pis Mean                                      2.11779
trainer/Log Pis Std                                       1.2303
trainer/Log Pis Max                                       8.20305
trainer/Log Pis Min                                      -3.03052
trainer/Policy mu Mean                                   -0.0845407
trainer/Policy mu Std                                     0.531508
trainer/Policy mu Max                                     1.65723
trainer/Policy mu Min                                    -3.77747
trainer/Policy log std Mean                              -2.19318
trainer/Policy log std Std                                0.538413
trainer/Policy log std Max                                0.330222
trainer/Policy log std Min                               -2.90123
trainer/Alpha                                             0.021082
trainer/Alpha Loss                                        0.45456
exploration/num steps total                           24200
exploration/num paths total                            1210
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0769307
exploration/Rewards Std                                   0.133762
exploration/Rewards Max                                   0.134253
exploration/Rewards Min                                  -0.537068
exploration/Returns Mean                                 -1.53861
exploration/Returns Std                                   2.26368
exploration/Returns Max                                   1.84528
exploration/Returns Min                                  -5.17634
exploration/Actions Mean                                  0.00273101
exploration/Actions Std                                   0.181405
exploration/Actions Max                                   0.638063
exploration/Actions Min                                  -0.817248
exploration/Num Paths                                     5
exploration/Average Returns                              -1.53861
exploration/env_infos/final/reward_energy Mean           -0.153715
exploration/env_infos/final/reward_energy Std             0.0733357
exploration/env_infos/final/reward_energy Max            -0.0241826
exploration/env_infos/final/reward_energy Min            -0.223148
exploration/env_infos/initial/reward_energy Mean         -0.478734
exploration/env_infos/initial/reward_energy Std           0.385236
exploration/env_infos/initial/reward_energy Max          -0.0425746
exploration/env_infos/initial/reward_energy Min          -1.03683
exploration/env_infos/reward_energy Mean                 -0.186244
exploration/env_infos/reward_energy Std                   0.176475
exploration/env_infos/reward_energy Max                  -0.0157737
exploration/env_infos/reward_energy Min                  -1.03683
exploration/env_infos/final/end_effector_loc Mean         0.0159339
exploration/env_infos/final/end_effector_loc Std          0.217078
exploration/env_infos/final/end_effector_loc Max          0.278102
exploration/env_infos/final/end_effector_loc Min         -0.388372
exploration/env_infos/initial/end_effector_loc Mean       0.00445725
exploration/env_infos/initial/end_effector_loc Std        0.0212632
exploration/env_infos/initial/end_effector_loc Max        0.0319031
exploration/env_infos/initial/end_effector_loc Min       -0.0408624
exploration/env_infos/end_effector_loc Mean               0.00946406
exploration/env_infos/end_effector_loc Std                0.167544
exploration/env_infos/end_effector_loc Max                0.328008
exploration/env_infos/end_effector_loc Min               -0.40842
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.158971
exploration/env_infos/final/reward_dist Std               0.278534
exploration/env_infos/final/reward_dist Max               0.712659
exploration/env_infos/final/reward_dist Min               1.19989e-09
exploration/env_infos/initial/reward_dist Mean            0.00397312
exploration/env_infos/initial/reward_dist Std             0.0021076
exploration/env_infos/initial/reward_dist Max             0.00718829
exploration/env_infos/initial/reward_dist Min             0.00103943
exploration/env_infos/reward_dist Mean                    0.270103
exploration/env_infos/reward_dist Std                     0.357432
exploration/env_infos/reward_dist Max                     0.990062
exploration/env_infos/reward_dist Min                     1.19989e-09
evaluation/num steps total                           232000
evaluation/num paths total                            11600
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.103498
evaluation/Rewards Std                                    0.124414
evaluation/Rewards Max                                    0.127347
evaluation/Rewards Min                                   -0.737984
evaluation/Returns Mean                                  -2.06996
evaluation/Returns Std                                    2.12287
evaluation/Returns Max                                    0.914332
evaluation/Returns Min                                  -12.7682
evaluation/Actions Mean                                  -0.00530057
evaluation/Actions Std                                    0.118458
evaluation/Actions Max                                    0.735702
evaluation/Actions Min                                   -0.968708
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.06996
evaluation/env_infos/final/reward_energy Mean            -0.0886424
evaluation/env_infos/final/reward_energy Std              0.0875194
evaluation/env_infos/final/reward_energy Max             -0.0112547
evaluation/env_infos/final/reward_energy Min             -0.537237
evaluation/env_infos/initial/reward_energy Mean          -0.311232
evaluation/env_infos/initial/reward_energy Std            0.293687
evaluation/env_infos/initial/reward_energy Max           -0.00866312
evaluation/env_infos/initial/reward_energy Min           -1.36439
evaluation/env_infos/reward_energy Mean                  -0.104235
evaluation/env_infos/reward_energy Std                    0.131362
evaluation/env_infos/reward_energy Max                   -0.00394186
evaluation/env_infos/reward_energy Min                   -1.36439
evaluation/env_infos/final/end_effector_loc Mean         -0.114795
evaluation/env_infos/final/end_effector_loc Std           0.347422
evaluation/env_infos/final/end_effector_loc Max           0.806214
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00399489
evaluation/env_infos/initial/end_effector_loc Std         0.0145924
evaluation/env_infos/initial/end_effector_loc Max         0.0278164
evaluation/env_infos/initial/end_effector_loc Min        -0.0484354
evaluation/env_infos/end_effector_loc Mean               -0.0661015
evaluation/env_infos/end_effector_loc Std                 0.229114
evaluation/env_infos/end_effector_loc Max                 0.806214
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0647345
evaluation/env_infos/final/reward_dist Std                0.160732
evaluation/env_infos/final/reward_dist Max                0.87324
evaluation/env_infos/final/reward_dist Min                1.00888e-87
evaluation/env_infos/initial/reward_dist Mean             0.00841602
evaluation/env_infos/initial/reward_dist Std              0.0166557
evaluation/env_infos/initial/reward_dist Max              0.0869265
evaluation/env_infos/initial/reward_dist Min              1.3406e-06
evaluation/env_infos/reward_dist Mean                     0.109761
evaluation/env_infos/reward_dist Std                      0.21696
evaluation/env_infos/reward_dist Max                      0.997392
evaluation/env_infos/reward_dist Min                      1.00888e-87
time/data storing (s)                                    38.3748
time/evaluation sampling (s)                              0.640082
time/exploration sampling (s)                             0.08423
time/logging (s)                                          0.0166937
time/saving (s)                                           0.783886
time/training (s)                                        39.1309
time/epoch (s)                                           79.0306
time/total (s)                                        17360.5
Epoch                                                   231
---------------------------------------------------  ----------------
2021-05-29 04:46:36.203077 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 232 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00457495
trainer/QF2 Loss                                          0.0105247
trainer/Policy Loss                                       2.75866
trainer/Q1 Predictions Mean                              -0.822358
trainer/Q1 Predictions Std                                0.953987
trainer/Q1 Predictions Max                                1.96411
trainer/Q1 Predictions Min                               -3.47684
trainer/Q2 Predictions Mean                              -0.816086
trainer/Q2 Predictions Std                                0.949788
trainer/Q2 Predictions Max                                1.94985
trainer/Q2 Predictions Min                               -3.52503
trainer/Q Targets Mean                                   -0.82023
trainer/Q Targets Std                                     0.945297
trainer/Q Targets Max                                     1.90125
trainer/Q Targets Min                                    -3.53638
trainer/Log Pis Mean                                      1.95886
trainer/Log Pis Std                                       1.25005
trainer/Log Pis Max                                       5.65562
trainer/Log Pis Min                                      -3.88613
trainer/Policy mu Mean                                   -0.0338366
trainer/Policy mu Std                                     0.532404
trainer/Policy mu Max                                     1.98067
trainer/Policy mu Min                                    -2.91722
trainer/Policy log std Mean                              -2.172
trainer/Policy log std Std                                0.562763
trainer/Policy log std Max                               -0.0549942
trainer/Policy log std Min                               -3.11093
trainer/Alpha                                             0.0221178
trainer/Alpha Loss                                       -0.156867
exploration/num steps total                           24300
exploration/num paths total                            1215
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.156272
exploration/Rewards Std                                   0.141311
exploration/Rewards Max                                   0.0133207
exploration/Rewards Min                                  -0.705937
exploration/Returns Mean                                 -3.12544
exploration/Returns Std                                   1.88208
exploration/Returns Max                                  -0.569948
exploration/Returns Min                                  -6.17411
exploration/Actions Mean                                  0.00227118
exploration/Actions Std                                   0.257612
exploration/Actions Max                                   0.935734
exploration/Actions Min                                  -0.997763
exploration/Num Paths                                     5
exploration/Average Returns                              -3.12544
exploration/env_infos/final/reward_energy Mean           -0.0870873
exploration/env_infos/final/reward_energy Std             0.0600733
exploration/env_infos/final/reward_energy Max            -0.0195283
exploration/env_infos/final/reward_energy Min            -0.184922
exploration/env_infos/initial/reward_energy Mean         -0.445616
exploration/env_infos/initial/reward_energy Std           0.344729
exploration/env_infos/initial/reward_energy Max          -0.135189
exploration/env_infos/initial/reward_energy Min          -1.02852
exploration/env_infos/reward_energy Mean                 -0.250026
exploration/env_infos/reward_energy Std                   0.264999
exploration/env_infos/reward_energy Max                  -0.0195283
exploration/env_infos/reward_energy Min                  -1.32806
exploration/env_infos/final/end_effector_loc Mean         0.0137828
exploration/env_infos/final/end_effector_loc Std          0.294135
exploration/env_infos/final/end_effector_loc Max          0.436115
exploration/env_infos/final/end_effector_loc Min         -0.641534
exploration/env_infos/initial/end_effector_loc Mean      -0.00624215
exploration/env_infos/initial/end_effector_loc Std        0.0189156
exploration/env_infos/initial/end_effector_loc Max        0.0325015
exploration/env_infos/initial/end_effector_loc Min       -0.0440507
exploration/env_infos/end_effector_loc Mean              -0.00253037
exploration/env_infos/end_effector_loc Std                0.182208
exploration/env_infos/end_effector_loc Max                0.436115
exploration/env_infos/end_effector_loc Min               -0.641534
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0450273
exploration/env_infos/final/reward_dist Std               0.0674907
exploration/env_infos/final/reward_dist Max               0.174163
exploration/env_infos/final/reward_dist Min               9.68559e-34
exploration/env_infos/initial/reward_dist Mean            0.00568269
exploration/env_infos/initial/reward_dist Std             0.00961427
exploration/env_infos/initial/reward_dist Max             0.0247056
exploration/env_infos/initial/reward_dist Min             9.45946e-07
exploration/env_infos/reward_dist Mean                    0.105658
exploration/env_infos/reward_dist Std                     0.202153
exploration/env_infos/reward_dist Max                     0.921412
exploration/env_infos/reward_dist Min                     9.68559e-34
evaluation/num steps total                           233000
evaluation/num paths total                            11650
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.111836
evaluation/Rewards Std                                    0.12549
evaluation/Rewards Max                                    0.146403
evaluation/Rewards Min                                   -0.700728
evaluation/Returns Mean                                  -2.23673
evaluation/Returns Std                                    1.93861
evaluation/Returns Max                                    1.29681
evaluation/Returns Min                                   -9.53325
evaluation/Actions Mean                                  -0.00165138
evaluation/Actions Std                                    0.174198
evaluation/Actions Max                                    0.992636
evaluation/Actions Min                                   -0.995923
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.23673
evaluation/env_infos/final/reward_energy Mean            -0.0780155
evaluation/env_infos/final/reward_energy Std              0.104905
evaluation/env_infos/final/reward_energy Max             -0.00294979
evaluation/env_infos/final/reward_energy Min             -0.684869
evaluation/env_infos/initial/reward_energy Mean          -0.362088
evaluation/env_infos/initial/reward_energy Std            0.338049
evaluation/env_infos/initial/reward_energy Max           -0.0119496
evaluation/env_infos/initial/reward_energy Min           -1.13426
evaluation/env_infos/reward_energy Mean                  -0.138153
evaluation/env_infos/reward_energy Std                    0.203983
evaluation/env_infos/reward_energy Max                   -0.00278094
evaluation/env_infos/reward_energy Min                   -1.32413
evaluation/env_infos/final/end_effector_loc Mean         -0.00756073
evaluation/env_infos/final/end_effector_loc Std           0.443843
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00225683
evaluation/env_infos/initial/end_effector_loc Std         0.0173677
evaluation/env_infos/initial/end_effector_loc Max         0.0458405
evaluation/env_infos/initial/end_effector_loc Min        -0.0496218
evaluation/env_infos/end_effector_loc Mean               -0.0284028
evaluation/env_infos/end_effector_loc Std                 0.303786
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0569498
evaluation/env_infos/final/reward_dist Std                0.154991
evaluation/env_infos/final/reward_dist Max                0.884838
evaluation/env_infos/final/reward_dist Min                7.27116e-100
evaluation/env_infos/initial/reward_dist Mean             0.00780279
evaluation/env_infos/initial/reward_dist Std              0.0142383
evaluation/env_infos/initial/reward_dist Max              0.0590542
evaluation/env_infos/initial/reward_dist Min              5.52129e-07
evaluation/env_infos/reward_dist Mean                     0.0970158
evaluation/env_infos/reward_dist Std                      0.20834
evaluation/env_infos/reward_dist Max                      0.997923
evaluation/env_infos/reward_dist Min                      7.27116e-100
time/data storing (s)                                    37.9511
time/evaluation sampling (s)                              0.646168
time/exploration sampling (s)                             0.0904156
time/logging (s)                                          0.0160282
time/saving (s)                                           0.793774
time/training (s)                                        39.9387
time/epoch (s)                                           79.4361
time/total (s)                                        17442.4
Epoch                                                   232
---------------------------------------------------  -----------------
2021-05-29 04:47:58.102043 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 233 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00843991
trainer/QF2 Loss                                          0.00852342
trainer/Policy Loss                                       3.00404
trainer/Q1 Predictions Mean                              -0.927079
trainer/Q1 Predictions Std                                0.909889
trainer/Q1 Predictions Max                                1.25651
trainer/Q1 Predictions Min                               -3.20763
trainer/Q2 Predictions Mean                              -0.909213
trainer/Q2 Predictions Std                                0.918118
trainer/Q2 Predictions Max                                1.32892
trainer/Q2 Predictions Min                               -3.26704
trainer/Q Targets Mean                                   -0.931202
trainer/Q Targets Std                                     0.922081
trainer/Q Targets Max                                     1.24537
trainer/Q Targets Min                                    -3.17837
trainer/Log Pis Mean                                      2.09224
trainer/Log Pis Std                                       1.20621
trainer/Log Pis Max                                       4.79102
trainer/Log Pis Min                                      -3.40459
trainer/Policy mu Mean                                   -0.0461711
trainer/Policy mu Std                                     0.489693
trainer/Policy mu Max                                     1.49355
trainer/Policy mu Min                                    -3.44626
trainer/Policy log std Mean                              -2.26207
trainer/Policy log std Std                                0.491878
trainer/Policy log std Max                                0.703863
trainer/Policy log std Min                               -3.16121
trainer/Alpha                                             0.0203031
trainer/Alpha Loss                                        0.359557
exploration/num steps total                           24400
exploration/num paths total                            1220
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.142082
exploration/Rewards Std                                   0.0680965
exploration/Rewards Max                                  -0.0217953
exploration/Rewards Min                                  -0.362217
exploration/Returns Mean                                 -2.84165
exploration/Returns Std                                   0.505213
exploration/Returns Max                                  -2.1478
exploration/Returns Min                                  -3.53251
exploration/Actions Mean                                 -0.0181212
exploration/Actions Std                                   0.209115
exploration/Actions Max                                   0.964841
exploration/Actions Min                                  -0.99997
exploration/Num Paths                                     5
exploration/Average Returns                              -2.84165
exploration/env_infos/final/reward_energy Mean           -0.136589
exploration/env_infos/final/reward_energy Std             0.0956091
exploration/env_infos/final/reward_energy Max            -0.0382124
exploration/env_infos/final/reward_energy Min            -0.303674
exploration/env_infos/initial/reward_energy Mean         -0.340745
exploration/env_infos/initial/reward_energy Std           0.355326
exploration/env_infos/initial/reward_energy Max          -0.0931832
exploration/env_infos/initial/reward_energy Min          -1.03086
exploration/env_infos/reward_energy Mean                 -0.176812
exploration/env_infos/reward_energy Std                   0.238438
exploration/env_infos/reward_energy Max                  -0.0151477
exploration/env_infos/reward_energy Min                  -1.30901
exploration/env_infos/final/end_effector_loc Mean        -0.147887
exploration/env_infos/final/end_effector_loc Std          0.468594
exploration/env_infos/final/end_effector_loc Max          0.519392
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00264303
exploration/env_infos/initial/end_effector_loc Std        0.0172038
exploration/env_infos/initial/end_effector_loc Max        0.0163944
exploration/env_infos/initial/end_effector_loc Min       -0.0499985
exploration/env_infos/end_effector_loc Mean              -0.105651
exploration/env_infos/end_effector_loc Std                0.345091
exploration/env_infos/end_effector_loc Max                0.519392
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              4.41152e-05
exploration/env_infos/final/reward_dist Std               8.82303e-05
exploration/env_infos/final/reward_dist Max               0.000220576
exploration/env_infos/final/reward_dist Min               1.7449e-86
exploration/env_infos/initial/reward_dist Mean            0.000905958
exploration/env_infos/initial/reward_dist Std             0.00157291
exploration/env_infos/initial/reward_dist Max             0.00404039
exploration/env_infos/initial/reward_dist Min             1.26814e-05
exploration/env_infos/reward_dist Mean                    0.0295582
exploration/env_infos/reward_dist Std                     0.0918791
exploration/env_infos/reward_dist Max                     0.499997
exploration/env_infos/reward_dist Min                     1.24264e-109
evaluation/num steps total                           234000
evaluation/num paths total                            11700
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0831977
evaluation/Rewards Std                                    0.120071
evaluation/Rewards Max                                    0.151479
evaluation/Rewards Min                                   -0.93261
evaluation/Returns Mean                                  -1.66395
evaluation/Returns Std                                    1.86218
evaluation/Returns Max                                    1.17919
evaluation/Returns Min                                   -7.0331
evaluation/Actions Mean                                  -0.0164924
evaluation/Actions Std                                    0.163743
evaluation/Actions Max                                    0.980336
evaluation/Actions Min                                   -0.999996
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.66395
evaluation/env_infos/final/reward_energy Mean            -0.106655
evaluation/env_infos/final/reward_energy Std              0.182919
evaluation/env_infos/final/reward_energy Max             -0.00778976
evaluation/env_infos/final/reward_energy Min             -1.32645
evaluation/env_infos/initial/reward_energy Mean          -0.388755
evaluation/env_infos/initial/reward_energy Std            0.340535
evaluation/env_infos/initial/reward_energy Max           -0.023867
evaluation/env_infos/initial/reward_energy Min           -1.23333
evaluation/env_infos/reward_energy Mean                  -0.135462
evaluation/env_infos/reward_energy Std                    0.189256
evaluation/env_infos/reward_energy Max                   -0.00379619
evaluation/env_infos/reward_energy Min                   -1.32645
evaluation/env_infos/final/end_effector_loc Mean         -0.0911602
evaluation/env_infos/final/end_effector_loc Std           0.35768
evaluation/env_infos/final/end_effector_loc Max           0.526377
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000532053
evaluation/env_infos/initial/end_effector_loc Std         0.0182643
evaluation/env_infos/initial/end_effector_loc Max         0.0474576
evaluation/env_infos/initial/end_effector_loc Min        -0.0447112
evaluation/env_infos/end_effector_loc Mean               -0.0445835
evaluation/env_infos/end_effector_loc Std                 0.240845
evaluation/env_infos/end_effector_loc Max                 0.526377
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0801982
evaluation/env_infos/final/reward_dist Std                0.181355
evaluation/env_infos/final/reward_dist Max                0.763215
evaluation/env_infos/final/reward_dist Min                1.05141e-78
evaluation/env_infos/initial/reward_dist Mean             0.00528884
evaluation/env_infos/initial/reward_dist Std              0.00939216
evaluation/env_infos/initial/reward_dist Max              0.0489427
evaluation/env_infos/initial/reward_dist Min              5.42978e-08
evaluation/env_infos/reward_dist Mean                     0.140037
evaluation/env_infos/reward_dist Std                      0.229873
evaluation/env_infos/reward_dist Max                      0.999717
evaluation/env_infos/reward_dist Min                      8.90159e-79
time/data storing (s)                                    38.4011
time/evaluation sampling (s)                              0.525066
time/exploration sampling (s)                             0.0869886
time/logging (s)                                          0.0145625
time/saving (s)                                           0.79735
time/training (s)                                        39.5935
time/epoch (s)                                           79.4185
time/total (s)                                        17524.3
Epoch                                                   233
---------------------------------------------------  -----------------
2021-05-29 04:49:19.895613 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 234 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00769775
trainer/QF2 Loss                                          0.00465991
trainer/Policy Loss                                       2.93754
trainer/Q1 Predictions Mean                              -0.922148
trainer/Q1 Predictions Std                                0.92565
trainer/Q1 Predictions Max                                0.952981
trainer/Q1 Predictions Min                               -3.78124
trainer/Q2 Predictions Mean                              -0.931558
trainer/Q2 Predictions Std                                0.921358
trainer/Q2 Predictions Max                                0.953138
trainer/Q2 Predictions Min                               -3.67795
trainer/Q Targets Mean                                   -0.931592
trainer/Q Targets Std                                     0.918366
trainer/Q Targets Max                                     0.981614
trainer/Q Targets Min                                    -3.69999
trainer/Log Pis Mean                                      2.02148
trainer/Log Pis Std                                       1.21002
trainer/Log Pis Max                                       6.37136
trainer/Log Pis Min                                      -2.45721
trainer/Policy mu Mean                                    0.0115771
trainer/Policy mu Std                                     0.411603
trainer/Policy mu Max                                     1.81937
trainer/Policy mu Min                                    -3.1807
trainer/Policy log std Mean                              -2.26382
trainer/Policy log std Std                                0.480185
trainer/Policy log std Max                               -0.24867
trainer/Policy log std Min                               -3.19896
trainer/Alpha                                             0.0201391
trainer/Alpha Loss                                        0.0838567
exploration/num steps total                           24500
exploration/num paths total                            1225
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.154893
exploration/Rewards Std                                   0.0900242
exploration/Rewards Max                                   0.0164547
exploration/Rewards Min                                  -0.566571
exploration/Returns Mean                                 -3.09787
exploration/Returns Std                                   0.850401
exploration/Returns Max                                  -1.87295
exploration/Returns Min                                  -4.047
exploration/Actions Mean                                 -0.0203407
exploration/Actions Std                                   0.130886
exploration/Actions Max                                   0.322398
exploration/Actions Min                                  -0.621054
exploration/Num Paths                                     5
exploration/Average Returns                              -3.09787
exploration/env_infos/final/reward_energy Mean           -0.135245
exploration/env_infos/final/reward_energy Std             0.0479202
exploration/env_infos/final/reward_energy Max            -0.0919962
exploration/env_infos/final/reward_energy Min            -0.220534
exploration/env_infos/initial/reward_energy Mean         -0.247159
exploration/env_infos/initial/reward_energy Std           0.214088
exploration/env_infos/initial/reward_energy Max          -0.0929363
exploration/env_infos/initial/reward_energy Min          -0.666139
exploration/env_infos/reward_energy Mean                 -0.152597
exploration/env_infos/reward_energy Std                   0.108647
exploration/env_infos/reward_energy Max                  -0.0104362
exploration/env_infos/reward_energy Min                  -0.666139
exploration/env_infos/final/end_effector_loc Mean        -0.112979
exploration/env_infos/final/end_effector_loc Std          0.380918
exploration/env_infos/final/end_effector_loc Max          0.567216
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00164224
exploration/env_infos/initial/end_effector_loc Std        0.0114436
exploration/env_infos/initial/end_effector_loc Max        0.012045
exploration/env_infos/initial/end_effector_loc Min       -0.0310527
exploration/env_infos/end_effector_loc Mean              -0.0576661
exploration/env_infos/end_effector_loc Std                0.268685
exploration/env_infos/end_effector_loc Max                0.567216
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00228824
exploration/env_infos/final/reward_dist Std               0.00431551
exploration/env_infos/final/reward_dist Max               0.0109111
exploration/env_infos/final/reward_dist Min               1.23377e-50
exploration/env_infos/initial/reward_dist Mean            0.00155966
exploration/env_infos/initial/reward_dist Std             0.00229444
exploration/env_infos/initial/reward_dist Max             0.00610621
exploration/env_infos/initial/reward_dist Min             2.06982e-05
exploration/env_infos/reward_dist Mean                    0.0389481
exploration/env_infos/reward_dist Std                     0.146654
exploration/env_infos/reward_dist Max                     0.952711
exploration/env_infos/reward_dist Min                     1.23377e-50
evaluation/num steps total                           235000
evaluation/num paths total                            11750
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0931537
evaluation/Rewards Std                                    0.11504
evaluation/Rewards Max                                    0.164578
evaluation/Rewards Min                                   -0.68024
evaluation/Returns Mean                                  -1.86307
evaluation/Returns Std                                    1.84383
evaluation/Returns Max                                    2.08562
evaluation/Returns Min                                   -7.58349
evaluation/Actions Mean                                  -0.0266479
evaluation/Actions Std                                    0.183505
evaluation/Actions Max                                    0.969478
evaluation/Actions Min                                   -0.999131
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.86307
evaluation/env_infos/final/reward_energy Mean            -0.109495
evaluation/env_infos/final/reward_energy Std              0.167319
evaluation/env_infos/final/reward_energy Max             -0.00801435
evaluation/env_infos/final/reward_energy Min             -0.753564
evaluation/env_infos/initial/reward_energy Mean          -0.346808
evaluation/env_infos/initial/reward_energy Std            0.311136
evaluation/env_infos/initial/reward_energy Max           -0.0234742
evaluation/env_infos/initial/reward_energy Min           -1.11852
evaluation/env_infos/reward_energy Mean                  -0.139878
evaluation/env_infos/reward_energy Std                    0.221817
evaluation/env_infos/reward_energy Max                   -0.000917523
evaluation/env_infos/reward_energy Min                   -1.40573
evaluation/env_infos/final/end_effector_loc Mean         -0.093963
evaluation/env_infos/final/end_effector_loc Std           0.380574
evaluation/env_infos/final/end_effector_loc Max           0.543025
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000968648
evaluation/env_infos/initial/end_effector_loc Std         0.0164443
evaluation/env_infos/initial/end_effector_loc Max         0.0442636
evaluation/env_infos/initial/end_effector_loc Min        -0.0489832
evaluation/env_infos/end_effector_loc Mean               -0.0477236
evaluation/env_infos/end_effector_loc Std                 0.27527
evaluation/env_infos/end_effector_loc Max                 0.543025
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0936075
evaluation/env_infos/final/reward_dist Std                0.2049
evaluation/env_infos/final/reward_dist Max                0.991058
evaluation/env_infos/final/reward_dist Min                3.04577e-128
evaluation/env_infos/initial/reward_dist Mean             0.00627621
evaluation/env_infos/initial/reward_dist Std              0.0103697
evaluation/env_infos/initial/reward_dist Max              0.0440581
evaluation/env_infos/initial/reward_dist Min              1.49265e-06
evaluation/env_infos/reward_dist Mean                     0.115597
evaluation/env_infos/reward_dist Std                      0.222948
evaluation/env_infos/reward_dist Max                      0.995268
evaluation/env_infos/reward_dist Min                      3.04577e-128
time/data storing (s)                                    37.9287
time/evaluation sampling (s)                              0.654687
time/exploration sampling (s)                             0.085554
time/logging (s)                                          0.0149072
time/saving (s)                                           0.768639
time/training (s)                                        39.8497
time/epoch (s)                                           79.3021
time/total (s)                                        17606.1
Epoch                                                   234
---------------------------------------------------  -----------------
2021-05-29 04:50:41.402804 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 235 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00465561
trainer/QF2 Loss                                          0.00644594
trainer/Policy Loss                                       3.00573
trainer/Q1 Predictions Mean                              -1.02571
trainer/Q1 Predictions Std                                0.95648
trainer/Q1 Predictions Max                                0.958712
trainer/Q1 Predictions Min                               -3.58664
trainer/Q2 Predictions Mean                              -1.03285
trainer/Q2 Predictions Std                                0.948846
trainer/Q2 Predictions Max                                0.926107
trainer/Q2 Predictions Min                               -3.55216
trainer/Q Targets Mean                                   -1.02164
trainer/Q Targets Std                                     0.96091
trainer/Q Targets Max                                     0.961192
trainer/Q Targets Min                                    -3.67993
trainer/Log Pis Mean                                      1.9887
trainer/Log Pis Std                                       1.19102
trainer/Log Pis Max                                       4.10345
trainer/Log Pis Min                                      -2.67396
trainer/Policy mu Mean                                   -0.0234336
trainer/Policy mu Std                                     0.404915
trainer/Policy mu Max                                     2.08911
trainer/Policy mu Min                                    -2.42372
trainer/Policy log std Mean                              -2.28573
trainer/Policy log std Std                                0.45725
trainer/Policy log std Max                               -0.413407
trainer/Policy log std Min                               -2.97594
trainer/Alpha                                             0.019896
trainer/Alpha Loss                                       -0.0442773
exploration/num steps total                           24600
exploration/num paths total                            1230
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.152558
exploration/Rewards Std                                   0.0729737
exploration/Rewards Max                                  -0.00090417
exploration/Rewards Min                                  -0.354655
exploration/Returns Mean                                 -3.05117
exploration/Returns Std                                   0.937635
exploration/Returns Max                                  -1.80892
exploration/Returns Min                                  -4.6814
exploration/Actions Mean                                  0.00719677
exploration/Actions Std                                   0.132303
exploration/Actions Max                                   0.738262
exploration/Actions Min                                  -0.492066
exploration/Num Paths                                     5
exploration/Average Returns                              -3.05117
exploration/env_infos/final/reward_energy Mean           -0.126064
exploration/env_infos/final/reward_energy Std             0.038115
exploration/env_infos/final/reward_energy Max            -0.0833001
exploration/env_infos/final/reward_energy Min            -0.193476
exploration/env_infos/initial/reward_energy Mean         -0.350065
exploration/env_infos/initial/reward_energy Std           0.288675
exploration/env_infos/initial/reward_energy Max          -0.0586062
exploration/env_infos/initial/reward_energy Min          -0.770473
exploration/env_infos/reward_energy Mean                 -0.151891
exploration/env_infos/reward_energy Std                   0.109731
exploration/env_infos/reward_energy Max                  -0.00744197
exploration/env_infos/reward_energy Min                  -0.770473
exploration/env_infos/final/end_effector_loc Mean         0.117772
exploration/env_infos/final/end_effector_loc Std          0.521985
exploration/env_infos/final/end_effector_loc Max          0.887027
exploration/env_infos/final/end_effector_loc Min         -0.824265
exploration/env_infos/initial/end_effector_loc Mean       0.00497892
exploration/env_infos/initial/end_effector_loc Std        0.0152499
exploration/env_infos/initial/end_effector_loc Max        0.0369131
exploration/env_infos/initial/end_effector_loc Min       -0.0246033
exploration/env_infos/end_effector_loc Mean               0.0512251
exploration/env_infos/end_effector_loc Std                0.293137
exploration/env_infos/end_effector_loc Max                0.887027
exploration/env_infos/end_effector_loc Min               -0.824265
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              1.22863e-06
exploration/env_infos/final/reward_dist Std               2.3051e-06
exploration/env_infos/final/reward_dist Max               5.83254e-06
exploration/env_infos/final/reward_dist Min               1.13731e-69
exploration/env_infos/initial/reward_dist Mean            0.00052792
exploration/env_infos/initial/reward_dist Std             0.00088393
exploration/env_infos/initial/reward_dist Max             0.00228615
exploration/env_infos/initial/reward_dist Min             2.78316e-06
exploration/env_infos/reward_dist Mean                    0.102034
exploration/env_infos/reward_dist Std                     0.214111
exploration/env_infos/reward_dist Max                     0.891712
exploration/env_infos/reward_dist Min                     1.13731e-69
evaluation/num steps total                           236000
evaluation/num paths total                            11800
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.12617
evaluation/Rewards Std                                    0.155316
evaluation/Rewards Max                                    0.161573
evaluation/Rewards Min                                   -0.807849
evaluation/Returns Mean                                  -2.5234
evaluation/Returns Std                                    2.68843
evaluation/Returns Max                                    1.58392
evaluation/Returns Min                                  -12.7385
evaluation/Actions Mean                                  -0.0398979
evaluation/Actions Std                                    0.20325
evaluation/Actions Max                                    0.797946
evaluation/Actions Min                                   -0.994591
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.5234
evaluation/env_infos/final/reward_energy Mean            -0.161849
evaluation/env_infos/final/reward_energy Std              0.206473
evaluation/env_infos/final/reward_energy Max             -0.0131602
evaluation/env_infos/final/reward_energy Min             -0.992042
evaluation/env_infos/initial/reward_energy Mean          -0.392753
evaluation/env_infos/initial/reward_energy Std            0.282263
evaluation/env_infos/initial/reward_energy Max           -0.0159923
evaluation/env_infos/initial/reward_energy Min           -1.23915
evaluation/env_infos/reward_energy Mean                  -0.181286
evaluation/env_infos/reward_energy Std                    0.230088
evaluation/env_infos/reward_energy Max                   -0.000928889
evaluation/env_infos/reward_energy Min                   -1.37485
evaluation/env_infos/final/end_effector_loc Mean         -0.196629
evaluation/env_infos/final/end_effector_loc Std           0.433595
evaluation/env_infos/final/end_effector_loc Max           0.573506
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.0014295
evaluation/env_infos/initial/end_effector_loc Std         0.0170401
evaluation/env_infos/initial/end_effector_loc Max         0.0398973
evaluation/env_infos/initial/end_effector_loc Min        -0.0456031
evaluation/env_infos/end_effector_loc Mean               -0.105513
evaluation/env_infos/end_effector_loc Std                 0.312699
evaluation/env_infos/end_effector_loc Max                 0.573506
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0803072
evaluation/env_infos/final/reward_dist Std                0.195333
evaluation/env_infos/final/reward_dist Max                0.980959
evaluation/env_infos/final/reward_dist Min                3.88568e-153
evaluation/env_infos/initial/reward_dist Mean             0.00553233
evaluation/env_infos/initial/reward_dist Std              0.0121217
evaluation/env_infos/initial/reward_dist Max              0.0584314
evaluation/env_infos/initial/reward_dist Min              2.93753e-07
evaluation/env_infos/reward_dist Mean                     0.125203
evaluation/env_infos/reward_dist Std                      0.234603
evaluation/env_infos/reward_dist Max                      0.999291
evaluation/env_infos/reward_dist Min                      3.88568e-153
time/data storing (s)                                    38.2799
time/evaluation sampling (s)                              0.646249
time/exploration sampling (s)                             0.0916458
time/logging (s)                                          0.0143665
time/saving (s)                                           0.79997
time/training (s)                                        39.1253
time/epoch (s)                                           78.9575
time/total (s)                                        17687.6
Epoch                                                   235
---------------------------------------------------  -----------------
2021-05-29 04:52:03.082300 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 236 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00381558
trainer/QF2 Loss                                          0.00437441
trainer/Policy Loss                                       2.88021
trainer/Q1 Predictions Mean                              -1.06305
trainer/Q1 Predictions Std                                0.957947
trainer/Q1 Predictions Max                                1.07121
trainer/Q1 Predictions Min                               -3.66875
trainer/Q2 Predictions Mean                              -1.04702
trainer/Q2 Predictions Std                                0.967626
trainer/Q2 Predictions Max                                1.16431
trainer/Q2 Predictions Min                               -3.69375
trainer/Q Targets Mean                                   -1.0493
trainer/Q Targets Std                                     0.960637
trainer/Q Targets Max                                     1.17912
trainer/Q Targets Min                                    -3.62334
trainer/Log Pis Mean                                      1.84275
trainer/Log Pis Std                                       1.35926
trainer/Log Pis Max                                       6.97632
trainer/Log Pis Min                                      -5.02014
trainer/Policy mu Mean                                   -0.0187989
trainer/Policy mu Std                                     0.507133
trainer/Policy mu Max                                     2.42571
trainer/Policy mu Min                                    -2.9177
trainer/Policy log std Mean                              -2.20954
trainer/Policy log std Std                                0.548396
trainer/Policy log std Max                               -0.153465
trainer/Policy log std Min                               -2.98365
trainer/Alpha                                             0.0196644
trainer/Alpha Loss                                       -0.617719
exploration/num steps total                           24700
exploration/num paths total                            1235
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.163988
exploration/Rewards Std                                   0.158641
exploration/Rewards Max                                   0.110981
exploration/Rewards Min                                  -0.517154
exploration/Returns Mean                                 -3.27975
exploration/Returns Std                                   2.82799
exploration/Returns Max                                   0.872807
exploration/Returns Min                                  -7.56881
exploration/Actions Mean                                 -0.0101323
exploration/Actions Std                                   0.388639
exploration/Actions Max                                   0.991291
exploration/Actions Min                                  -1
exploration/Num Paths                                     5
exploration/Average Returns                              -3.27975
exploration/env_infos/final/reward_energy Mean           -0.213099
exploration/env_infos/final/reward_energy Std             0.257227
exploration/env_infos/final/reward_energy Max            -0.0749538
exploration/env_infos/final/reward_energy Min            -0.727348
exploration/env_infos/initial/reward_energy Mean         -0.539247
exploration/env_infos/initial/reward_energy Std           0.370768
exploration/env_infos/initial/reward_energy Max          -0.0672417
exploration/env_infos/initial/reward_energy Min          -0.970715
exploration/env_infos/reward_energy Mean                 -0.354495
exploration/env_infos/reward_energy Std                   0.420261
exploration/env_infos/reward_energy Max                  -0.0120563
exploration/env_infos/reward_energy Min                  -1.41412
exploration/env_infos/final/end_effector_loc Mean        -0.0957532
exploration/env_infos/final/end_effector_loc Std          0.511177
exploration/env_infos/final/end_effector_loc Max          0.809717
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00325697
exploration/env_infos/initial/end_effector_loc Std        0.0229066
exploration/env_infos/initial/end_effector_loc Max        0.0407506
exploration/env_infos/initial/end_effector_loc Min       -0.0424677
exploration/env_infos/end_effector_loc Mean              -0.0847486
exploration/env_infos/end_effector_loc Std                0.40321
exploration/env_infos/end_effector_loc Max                0.809717
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0856393
exploration/env_infos/final/reward_dist Std               0.171279
exploration/env_infos/final/reward_dist Max               0.428196
exploration/env_infos/final/reward_dist Min               1.285e-125
exploration/env_infos/initial/reward_dist Mean            0.00159484
exploration/env_infos/initial/reward_dist Std             0.00163469
exploration/env_infos/initial/reward_dist Max             0.00470308
exploration/env_infos/initial/reward_dist Min             8.52767e-05
exploration/env_infos/reward_dist Mean                    0.101572
exploration/env_infos/reward_dist Std                     0.241574
exploration/env_infos/reward_dist Max                     0.883571
exploration/env_infos/reward_dist Min                     5.7872e-166
evaluation/num steps total                           237000
evaluation/num paths total                            11850
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0829459
evaluation/Rewards Std                                    0.11641
evaluation/Rewards Max                                    0.116002
evaluation/Rewards Min                                   -0.697276
evaluation/Returns Mean                                  -1.65892
evaluation/Returns Std                                    1.75665
evaluation/Returns Max                                    0.985172
evaluation/Returns Min                                  -10.6968
evaluation/Actions Mean                                  -0.00501576
evaluation/Actions Std                                    0.164955
evaluation/Actions Max                                    0.97776
evaluation/Actions Min                                   -0.999987
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.65892
evaluation/env_infos/final/reward_energy Mean            -0.096635
evaluation/env_infos/final/reward_energy Std              0.187742
evaluation/env_infos/final/reward_energy Max             -0.00695237
evaluation/env_infos/final/reward_energy Min             -1.30661
evaluation/env_infos/initial/reward_energy Mean          -0.333262
evaluation/env_infos/initial/reward_energy Std            0.297605
evaluation/env_infos/initial/reward_energy Max           -0.0196147
evaluation/env_infos/initial/reward_energy Min           -1.19515
evaluation/env_infos/reward_energy Mean                  -0.126277
evaluation/env_infos/reward_energy Std                    0.196278
evaluation/env_infos/reward_energy Max                   -0.00309435
evaluation/env_infos/reward_energy Min                   -1.40467
evaluation/env_infos/final/end_effector_loc Mean         -0.0110904
evaluation/env_infos/final/end_effector_loc Std           0.360809
evaluation/env_infos/final/end_effector_loc Max           0.783224
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00231743
evaluation/env_infos/initial/end_effector_loc Std         0.0156259
evaluation/env_infos/initial/end_effector_loc Max         0.0436424
evaluation/env_infos/initial/end_effector_loc Min        -0.0451664
evaluation/env_infos/end_effector_loc Mean               -0.00372795
evaluation/env_infos/end_effector_loc Std                 0.240159
evaluation/env_infos/end_effector_loc Max                 0.783224
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0625408
evaluation/env_infos/final/reward_dist Std                0.192545
evaluation/env_infos/final/reward_dist Max                0.969514
evaluation/env_infos/final/reward_dist Min                3.04816e-153
evaluation/env_infos/initial/reward_dist Mean             0.00473701
evaluation/env_infos/initial/reward_dist Std              0.00832518
evaluation/env_infos/initial/reward_dist Max              0.0311302
evaluation/env_infos/initial/reward_dist Min              7.83631e-07
evaluation/env_infos/reward_dist Mean                     0.105839
evaluation/env_infos/reward_dist Std                      0.19297
evaluation/env_infos/reward_dist Max                      0.990931
evaluation/env_infos/reward_dist Min                      3.04816e-153
time/data storing (s)                                    37.9446
time/evaluation sampling (s)                              0.528834
time/exploration sampling (s)                             0.0817496
time/logging (s)                                          0.0150446
time/saving (s)                                           0.801222
time/training (s)                                        39.7565
time/epoch (s)                                           79.1279
time/total (s)                                        17769.2
Epoch                                                   236
---------------------------------------------------  -----------------
2021-05-29 04:53:25.353601 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 237 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00990887
trainer/QF2 Loss                                          0.00657641
trainer/Policy Loss                                       3.18193
trainer/Q1 Predictions Mean                              -1.10113
trainer/Q1 Predictions Std                                1.01954
trainer/Q1 Predictions Max                                1.07912
trainer/Q1 Predictions Min                               -3.91919
trainer/Q2 Predictions Mean                              -1.10953
trainer/Q2 Predictions Std                                1.02753
trainer/Q2 Predictions Max                                1.01672
trainer/Q2 Predictions Min                               -4.13325
trainer/Q Targets Mean                                   -1.11921
trainer/Q Targets Std                                     1.02841
trainer/Q Targets Max                                     1.06459
trainer/Q Targets Min                                    -4.00339
trainer/Log Pis Mean                                      2.09941
trainer/Log Pis Std                                       1.1981
trainer/Log Pis Max                                       5.94991
trainer/Log Pis Min                                      -3.09286
trainer/Policy mu Mean                                    0.023231
trainer/Policy mu Std                                     0.533786
trainer/Policy mu Max                                     3.4409
trainer/Policy mu Min                                    -2.11691
trainer/Policy log std Mean                              -2.25178
trainer/Policy log std Std                                0.551632
trainer/Policy log std Max                               -0.464436
trainer/Policy log std Min                               -3.01236
trainer/Alpha                                             0.0193058
trainer/Alpha Loss                                        0.392528
exploration/num steps total                           24800
exploration/num paths total                            1240
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.12255
exploration/Rewards Std                                   0.108523
exploration/Rewards Max                                   0.0938749
exploration/Rewards Min                                  -0.452455
exploration/Returns Mean                                 -2.45101
exploration/Returns Std                                   1.59938
exploration/Returns Max                                   0.638441
exploration/Returns Min                                  -3.80636
exploration/Actions Mean                                  0.00104173
exploration/Actions Std                                   0.169936
exploration/Actions Max                                   0.633067
exploration/Actions Min                                  -0.924897
exploration/Num Paths                                     5
exploration/Average Returns                              -2.45101
exploration/env_infos/final/reward_energy Mean           -0.102056
exploration/env_infos/final/reward_energy Std             0.0620043
exploration/env_infos/final/reward_energy Max            -0.052911
exploration/env_infos/final/reward_energy Min            -0.219973
exploration/env_infos/initial/reward_energy Mean         -0.368445
exploration/env_infos/initial/reward_energy Std           0.420967
exploration/env_infos/initial/reward_energy Max          -0.0452209
exploration/env_infos/initial/reward_energy Min          -1.1709
exploration/env_infos/reward_energy Mean                 -0.167049
exploration/env_infos/reward_energy Std                   0.17278
exploration/env_infos/reward_energy Max                  -0.0078594
exploration/env_infos/reward_energy Min                  -1.1709
exploration/env_infos/final/end_effector_loc Mean         0.0806328
exploration/env_infos/final/end_effector_loc Std          0.363789
exploration/env_infos/final/end_effector_loc Max          0.805763
exploration/env_infos/final/end_effector_loc Min         -0.540553
exploration/env_infos/initial/end_effector_loc Mean      -0.00552522
exploration/env_infos/initial/end_effector_loc Std        0.0189915
exploration/env_infos/initial/end_effector_loc Max        0.0143837
exploration/env_infos/initial/end_effector_loc Min       -0.0462449
exploration/env_infos/end_effector_loc Mean               0.0344889
exploration/env_infos/end_effector_loc Std                0.201331
exploration/env_infos/end_effector_loc Max                0.805763
exploration/env_infos/end_effector_loc Min               -0.540553
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00365258
exploration/env_infos/final/reward_dist Std               0.00473374
exploration/env_infos/final/reward_dist Max               0.0115863
exploration/env_infos/final/reward_dist Min               3.85106e-37
exploration/env_infos/initial/reward_dist Mean            0.00363983
exploration/env_infos/initial/reward_dist Std             0.00355144
exploration/env_infos/initial/reward_dist Max             0.00799265
exploration/env_infos/initial/reward_dist Min             1.78497e-05
exploration/env_infos/reward_dist Mean                    0.124057
exploration/env_infos/reward_dist Std                     0.215159
exploration/env_infos/reward_dist Max                     0.874012
exploration/env_infos/reward_dist Min                     3.85106e-37
evaluation/num steps total                           238000
evaluation/num paths total                            11900
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0925113
evaluation/Rewards Std                                    0.12544
evaluation/Rewards Max                                    0.173324
evaluation/Rewards Min                                   -0.998742
evaluation/Returns Mean                                  -1.85023
evaluation/Returns Std                                    1.80437
evaluation/Returns Max                                    2.69252
evaluation/Returns Min                                   -7.09299
evaluation/Actions Mean                                  -0.000401377
evaluation/Actions Std                                    0.158021
evaluation/Actions Max                                    0.894384
evaluation/Actions Min                                   -0.99473
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.85023
evaluation/env_infos/final/reward_energy Mean            -0.110518
evaluation/env_infos/final/reward_energy Std              0.137566
evaluation/env_infos/final/reward_energy Max             -0.00345472
evaluation/env_infos/final/reward_energy Min             -0.797876
evaluation/env_infos/initial/reward_energy Mean          -0.368815
evaluation/env_infos/initial/reward_energy Std            0.31044
evaluation/env_infos/initial/reward_energy Max           -0.0153814
evaluation/env_infos/initial/reward_energy Min           -1.27339
evaluation/env_infos/reward_energy Mean                  -0.138297
evaluation/env_infos/reward_energy Std                    0.175543
evaluation/env_infos/reward_energy Max                   -0.00122272
evaluation/env_infos/reward_energy Min                   -1.27339
evaluation/env_infos/final/end_effector_loc Mean          0.0639845
evaluation/env_infos/final/end_effector_loc Std           0.399512
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00380461
evaluation/env_infos/initial/end_effector_loc Std         0.0166139
evaluation/env_infos/initial/end_effector_loc Max         0.041745
evaluation/env_infos/initial/end_effector_loc Min        -0.0497365
evaluation/env_infos/end_effector_loc Mean                0.0291954
evaluation/env_infos/end_effector_loc Std                 0.267748
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0724519
evaluation/env_infos/final/reward_dist Std                0.180736
evaluation/env_infos/final/reward_dist Max                0.821759
evaluation/env_infos/final/reward_dist Min                1.2378e-123
evaluation/env_infos/initial/reward_dist Mean             0.00624625
evaluation/env_infos/initial/reward_dist Std              0.0107025
evaluation/env_infos/initial/reward_dist Max              0.056346
evaluation/env_infos/initial/reward_dist Min              1.78648e-06
evaluation/env_infos/reward_dist Mean                     0.121335
evaluation/env_infos/reward_dist Std                      0.229016
evaluation/env_infos/reward_dist Max                      0.994061
evaluation/env_infos/reward_dist Min                      1.2378e-123
time/data storing (s)                                    38.3295
time/evaluation sampling (s)                              0.63188
time/exploration sampling (s)                             0.0892661
time/logging (s)                                          0.0157125
time/saving (s)                                           0.773238
time/training (s)                                        39.8852
time/epoch (s)                                           79.7248
time/total (s)                                        17851.5
Epoch                                                   237
---------------------------------------------------  ----------------
2021-05-29 04:54:46.556795 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 238 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00452942
trainer/QF2 Loss                                          0.00613898
trainer/Policy Loss                                       2.74532
trainer/Q1 Predictions Mean                              -0.910901
trainer/Q1 Predictions Std                                0.944472
trainer/Q1 Predictions Max                                1.07875
trainer/Q1 Predictions Min                               -3.50666
trainer/Q2 Predictions Mean                              -0.91796
trainer/Q2 Predictions Std                                0.945949
trainer/Q2 Predictions Max                                1.08663
trainer/Q2 Predictions Min                               -3.51093
trainer/Q Targets Mean                                   -0.920426
trainer/Q Targets Std                                     0.939121
trainer/Q Targets Max                                     1.14713
trainer/Q Targets Min                                    -3.48915
trainer/Log Pis Mean                                      1.85235
trainer/Log Pis Std                                       1.30287
trainer/Log Pis Max                                       6.43947
trainer/Log Pis Min                                      -4.31417
trainer/Policy mu Mean                                    0.00810574
trainer/Policy mu Std                                     0.509468
trainer/Policy mu Max                                     3.44348
trainer/Policy mu Min                                    -2.74368
trainer/Policy log std Mean                              -2.15362
trainer/Policy log std Std                                0.481039
trainer/Policy log std Max                               -0.289526
trainer/Policy log std Min                               -2.79963
trainer/Alpha                                             0.0214611
trainer/Alpha Loss                                       -0.567159
exploration/num steps total                           24900
exploration/num paths total                            1245
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.133468
exploration/Rewards Std                                   0.0757931
exploration/Rewards Max                                   0.00258366
exploration/Rewards Min                                  -0.314224
exploration/Returns Mean                                 -2.66936
exploration/Returns Std                                   1.01621
exploration/Returns Max                                  -1.17004
exploration/Returns Min                                  -3.72253
exploration/Actions Mean                                 -0.00278721
exploration/Actions Std                                   0.173478
exploration/Actions Max                                   0.824801
exploration/Actions Min                                  -0.600274
exploration/Num Paths                                     5
exploration/Average Returns                              -2.66936
exploration/env_infos/final/reward_energy Mean           -0.143349
exploration/env_infos/final/reward_energy Std             0.119021
exploration/env_infos/final/reward_energy Max            -0.0600762
exploration/env_infos/final/reward_energy Min            -0.37829
exploration/env_infos/initial/reward_energy Mean         -0.433283
exploration/env_infos/initial/reward_energy Std           0.306396
exploration/env_infos/initial/reward_energy Max          -0.0679012
exploration/env_infos/initial/reward_energy Min          -0.962634
exploration/env_infos/reward_energy Mean                 -0.1814
exploration/env_infos/reward_energy Std                   0.165223
exploration/env_infos/reward_energy Max                  -0.00691111
exploration/env_infos/reward_energy Min                  -0.962634
exploration/env_infos/final/end_effector_loc Mean         0.0189669
exploration/env_infos/final/end_effector_loc Std          0.464806
exploration/env_infos/final/end_effector_loc Max          0.723662
exploration/env_infos/final/end_effector_loc Min         -0.960306
exploration/env_infos/initial/end_effector_loc Mean       0.00199582
exploration/env_infos/initial/end_effector_loc Std        0.0186556
exploration/env_infos/initial/end_effector_loc Max        0.04124
exploration/env_infos/initial/end_effector_loc Min       -0.0248178
exploration/env_infos/end_effector_loc Mean               0.0256556
exploration/env_infos/end_effector_loc Std                0.262069
exploration/env_infos/end_effector_loc Max                0.723662
exploration/env_infos/end_effector_loc Min               -0.960306
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00280953
exploration/env_infos/final/reward_dist Std               0.00561907
exploration/env_infos/final/reward_dist Max               0.0140477
exploration/env_infos/final/reward_dist Min               3.96363e-49
exploration/env_infos/initial/reward_dist Mean            0.0256782
exploration/env_infos/initial/reward_dist Std             0.0236238
exploration/env_infos/initial/reward_dist Max             0.0648535
exploration/env_infos/initial/reward_dist Min             0.000292967
exploration/env_infos/reward_dist Mean                    0.0826168
exploration/env_infos/reward_dist Std                     0.186384
exploration/env_infos/reward_dist Max                     0.942947
exploration/env_infos/reward_dist Min                     3.96363e-49
evaluation/num steps total                           239000
evaluation/num paths total                            11950
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.11936
evaluation/Rewards Std                                    0.140813
evaluation/Rewards Max                                    0.135565
evaluation/Rewards Min                                   -0.896002
evaluation/Returns Mean                                  -2.38721
evaluation/Returns Std                                    2.29067
evaluation/Returns Max                                    0.905973
evaluation/Returns Min                                  -12.111
evaluation/Actions Mean                                   0.0047144
evaluation/Actions Std                                    0.21343
evaluation/Actions Max                                    1
evaluation/Actions Min                                   -0.998274
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.38721
evaluation/env_infos/final/reward_energy Mean            -0.1412
evaluation/env_infos/final/reward_energy Std              0.246832
evaluation/env_infos/final/reward_energy Max             -0.00678076
evaluation/env_infos/final/reward_energy Min             -1.0675
evaluation/env_infos/initial/reward_energy Mean          -0.326965
evaluation/env_infos/initial/reward_energy Std            0.304213
evaluation/env_infos/initial/reward_energy Max           -0.0149138
evaluation/env_infos/initial/reward_energy Min           -1.40448
evaluation/env_infos/reward_energy Mean                  -0.165126
evaluation/env_infos/reward_energy Std                    0.25275
evaluation/env_infos/reward_energy Max                   -0.00240623
evaluation/env_infos/reward_energy Min                   -1.40448
evaluation/env_infos/final/end_effector_loc Mean          0.000203121
evaluation/env_infos/final/end_effector_loc Std           0.465239
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00130443
evaluation/env_infos/initial/end_effector_loc Std         0.0157357
evaluation/env_infos/initial/end_effector_loc Max         0.0378022
evaluation/env_infos/initial/end_effector_loc Min        -0.0499137
evaluation/env_infos/end_effector_loc Mean               -0.0172276
evaluation/env_infos/end_effector_loc Std                 0.309486
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0325662
evaluation/env_infos/final/reward_dist Std                0.0908294
evaluation/env_infos/final/reward_dist Max                0.503953
evaluation/env_infos/final/reward_dist Min                5.91779e-112
evaluation/env_infos/initial/reward_dist Mean             0.010335
evaluation/env_infos/initial/reward_dist Std              0.0220724
evaluation/env_infos/initial/reward_dist Max              0.111797
evaluation/env_infos/initial/reward_dist Min              1.72486e-06
evaluation/env_infos/reward_dist Mean                     0.0954766
evaluation/env_infos/reward_dist Std                      0.203671
evaluation/env_infos/reward_dist Max                      0.986334
evaluation/env_infos/reward_dist Min                      5.91779e-112
time/data storing (s)                                    38.2789
time/evaluation sampling (s)                              0.650868
time/exploration sampling (s)                             0.0913101
time/logging (s)                                          0.015709
time/saving (s)                                           0.778365
time/training (s)                                        38.8386
time/epoch (s)                                           78.6538
time/total (s)                                        17932.7
Epoch                                                   238
---------------------------------------------------  -----------------
2021-05-29 04:56:08.563159 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 239 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00478323
trainer/QF2 Loss                                          0.0104443
trainer/Policy Loss                                       2.94576
trainer/Q1 Predictions Mean                              -0.970018
trainer/Q1 Predictions Std                                1.01071
trainer/Q1 Predictions Max                                1.06231
trainer/Q1 Predictions Min                               -4.08847
trainer/Q2 Predictions Mean                              -0.985786
trainer/Q2 Predictions Std                                1.01001
trainer/Q2 Predictions Max                                1.09459
trainer/Q2 Predictions Min                               -4.24984
trainer/Q Targets Mean                                   -0.990375
trainer/Q Targets Std                                     1.01102
trainer/Q Targets Max                                     1.14977
trainer/Q Targets Min                                    -4.17555
trainer/Log Pis Mean                                      1.97628
trainer/Log Pis Std                                       1.27738
trainer/Log Pis Max                                       5.9362
trainer/Log Pis Min                                      -3.77388
trainer/Policy mu Mean                                   -0.0358585
trainer/Policy mu Std                                     0.501202
trainer/Policy mu Max                                     2.89985
trainer/Policy mu Min                                    -2.81494
trainer/Policy log std Mean                              -2.24668
trainer/Policy log std Std                                0.505277
trainer/Policy log std Max                               -0.211077
trainer/Policy log std Min                               -2.93744
trainer/Alpha                                             0.0198903
trainer/Alpha Loss                                       -0.0929789
exploration/num steps total                           25000
exploration/num paths total                            1250
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.158575
exploration/Rewards Std                                   0.122423
exploration/Rewards Max                                   0.0154476
exploration/Rewards Min                                  -0.749465
exploration/Returns Mean                                 -3.17149
exploration/Returns Std                                   1.41476
exploration/Returns Max                                  -1.32197
exploration/Returns Min                                  -5.58724
exploration/Actions Mean                                  0.0460427
exploration/Actions Std                                   0.25236
exploration/Actions Max                                   0.999999
exploration/Actions Min                                  -0.576005
exploration/Num Paths                                     5
exploration/Average Returns                              -3.17149
exploration/env_infos/final/reward_energy Mean           -0.352154
exploration/env_infos/final/reward_energy Std             0.392489
exploration/env_infos/final/reward_energy Max            -0.0139982
exploration/env_infos/final/reward_energy Min            -1.06422
exploration/env_infos/initial/reward_energy Mean         -0.476997
exploration/env_infos/initial/reward_energy Std           0.257709
exploration/env_infos/initial/reward_energy Max          -0.0894436
exploration/env_infos/initial/reward_energy Min          -0.842596
exploration/env_infos/reward_energy Mean                 -0.250139
exploration/env_infos/reward_energy Std                   0.262757
exploration/env_infos/reward_energy Max                  -0.0139982
exploration/env_infos/reward_energy Min                  -1.15373
exploration/env_infos/final/end_effector_loc Mean         0.211036
exploration/env_infos/final/end_effector_loc Std          0.453714
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.364914
exploration/env_infos/initial/end_effector_loc Mean       0.00221806
exploration/env_infos/initial/end_effector_loc Std        0.0190396
exploration/env_infos/initial/end_effector_loc Max        0.0390123
exploration/env_infos/initial/end_effector_loc Min       -0.0197398
exploration/env_infos/end_effector_loc Mean               0.120989
exploration/env_infos/end_effector_loc Std                0.298507
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.364914
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.062935
exploration/env_infos/final/reward_dist Std               0.12587
exploration/env_infos/final/reward_dist Max               0.314675
exploration/env_infos/final/reward_dist Min               3.16406e-46
exploration/env_infos/initial/reward_dist Mean            0.00403326
exploration/env_infos/initial/reward_dist Std             0.00692196
exploration/env_infos/initial/reward_dist Max             0.0177764
exploration/env_infos/initial/reward_dist Min             7.06606e-06
exploration/env_infos/reward_dist Mean                    0.108607
exploration/env_infos/reward_dist Std                     0.184861
exploration/env_infos/reward_dist Max                     0.857694
exploration/env_infos/reward_dist Min                     2.22521e-47
evaluation/num steps total                           240000
evaluation/num paths total                            12000
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0802752
evaluation/Rewards Std                                    0.0826778
evaluation/Rewards Max                                    0.108471
evaluation/Rewards Min                                   -0.518328
evaluation/Returns Mean                                  -1.6055
evaluation/Returns Std                                    1.1973
evaluation/Returns Max                                    0.610167
evaluation/Returns Min                                   -4.83106
evaluation/Actions Mean                                  -0.00272243
evaluation/Actions Std                                    0.101431
evaluation/Actions Max                                    0.840079
evaluation/Actions Min                                   -0.847428
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.6055
evaluation/env_infos/final/reward_energy Mean            -0.0578854
evaluation/env_infos/final/reward_energy Std              0.0476706
evaluation/env_infos/final/reward_energy Max             -0.0121776
evaluation/env_infos/final/reward_energy Min             -0.186911
evaluation/env_infos/initial/reward_energy Mean          -0.267782
evaluation/env_infos/initial/reward_energy Std            0.279314
evaluation/env_infos/initial/reward_energy Max           -0.00694288
evaluation/env_infos/initial/reward_energy Min           -1.13188
evaluation/env_infos/reward_energy Mean                  -0.0870042
evaluation/env_infos/reward_energy Std                    0.114111
evaluation/env_infos/reward_energy Max                   -0.00116139
evaluation/env_infos/reward_energy Min                   -1.13188
evaluation/env_infos/final/end_effector_loc Mean         -0.0108772
evaluation/env_infos/final/end_effector_loc Std           0.290149
evaluation/env_infos/final/end_effector_loc Max           0.751973
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.0011837
evaluation/env_infos/initial/end_effector_loc Std         0.0136291
evaluation/env_infos/initial/end_effector_loc Max         0.0420039
evaluation/env_infos/initial/end_effector_loc Min        -0.0379284
evaluation/env_infos/end_effector_loc Mean               -4.2833e-05
evaluation/env_infos/end_effector_loc Std                 0.194135
evaluation/env_infos/end_effector_loc Max                 0.751973
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0732611
evaluation/env_infos/final/reward_dist Std                0.191237
evaluation/env_infos/final/reward_dist Max                0.93278
evaluation/env_infos/final/reward_dist Min                5.01195e-51
evaluation/env_infos/initial/reward_dist Mean             0.00463372
evaluation/env_infos/initial/reward_dist Std              0.01371
evaluation/env_infos/initial/reward_dist Max              0.0923811
evaluation/env_infos/initial/reward_dist Min              1.73765e-06
evaluation/env_infos/reward_dist Mean                     0.0872448
evaluation/env_infos/reward_dist Std                      0.187859
evaluation/env_infos/reward_dist Max                      0.986475
evaluation/env_infos/reward_dist Min                      5.01195e-51
time/data storing (s)                                    37.9723
time/evaluation sampling (s)                              0.661531
time/exploration sampling (s)                             0.0873392
time/logging (s)                                          0.0150109
time/saving (s)                                           0.797338
time/training (s)                                        39.8779
time/epoch (s)                                           79.4114
time/total (s)                                        18014.7
Epoch                                                   239
---------------------------------------------------  ----------------
2021-05-29 04:57:30.090510 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 240 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00480806
trainer/QF2 Loss                                          0.00780517
trainer/Policy Loss                                       3.11402
trainer/Q1 Predictions Mean                              -1.08852
trainer/Q1 Predictions Std                                0.918652
trainer/Q1 Predictions Max                                1.09179
trainer/Q1 Predictions Min                               -3.50726
trainer/Q2 Predictions Mean                              -1.07723
trainer/Q2 Predictions Std                                0.920194
trainer/Q2 Predictions Max                                1.04164
trainer/Q2 Predictions Min                               -3.31225
trainer/Q Targets Mean                                   -1.08957
trainer/Q Targets Std                                     0.92417
trainer/Q Targets Max                                     1.05494
trainer/Q Targets Min                                    -3.54564
trainer/Log Pis Mean                                      2.04653
trainer/Log Pis Std                                       1.18383
trainer/Log Pis Max                                       5.73386
trainer/Log Pis Min                                      -2.20189
trainer/Policy mu Mean                                    0.00638965
trainer/Policy mu Std                                     0.41327
trainer/Policy mu Max                                     2.43681
trainer/Policy mu Min                                    -2.12658
trainer/Policy log std Mean                              -2.27994
trainer/Policy log std Std                                0.495283
trainer/Policy log std Max                               -0.301898
trainer/Policy log std Min                               -2.88777
trainer/Alpha                                             0.0194613
trainer/Alpha Loss                                        0.183344
exploration/num steps total                           25100
exploration/num paths total                            1255
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.127248
exploration/Rewards Std                                   0.0624835
exploration/Rewards Max                                  -0.00612792
exploration/Rewards Min                                  -0.277914
exploration/Returns Mean                                 -2.54496
exploration/Returns Std                                   0.5703
exploration/Returns Max                                  -1.64442
exploration/Returns Min                                  -3.28008
exploration/Actions Mean                                  0.0094512
exploration/Actions Std                                   0.111631
exploration/Actions Max                                   0.518175
exploration/Actions Min                                  -0.330953
exploration/Num Paths                                     5
exploration/Average Returns                              -2.54496
exploration/env_infos/final/reward_energy Mean           -0.0921598
exploration/env_infos/final/reward_energy Std             0.0319467
exploration/env_infos/final/reward_energy Max            -0.0556988
exploration/env_infos/final/reward_energy Min            -0.14399
exploration/env_infos/initial/reward_energy Mean         -0.122564
exploration/env_infos/initial/reward_energy Std           0.0502186
exploration/env_infos/initial/reward_energy Max          -0.0750142
exploration/env_infos/initial/reward_energy Min          -0.20746
exploration/env_infos/reward_energy Mean                 -0.127262
exploration/env_infos/reward_energy Std                   0.0943704
exploration/env_infos/reward_energy Max                  -0.0182592
exploration/env_infos/reward_energy Min                  -0.530376
exploration/env_infos/final/end_effector_loc Mean         0.0529379
exploration/env_infos/final/end_effector_loc Std          0.21645
exploration/env_infos/final/end_effector_loc Max          0.366157
exploration/env_infos/final/end_effector_loc Min         -0.462165
exploration/env_infos/initial/end_effector_loc Mean      -0.00120669
exploration/env_infos/initial/end_effector_loc Std        0.0045248
exploration/env_infos/initial/end_effector_loc Max        0.00677584
exploration/env_infos/initial/end_effector_loc Min       -0.00793125
exploration/env_infos/end_effector_loc Mean               0.00875956
exploration/env_infos/end_effector_loc Std                0.157963
exploration/env_infos/end_effector_loc Max                0.366157
exploration/env_infos/end_effector_loc Min               -0.566458
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              8.95008e-05
exploration/env_infos/final/reward_dist Std               0.00010867
exploration/env_infos/final/reward_dist Max               0.000295122
exploration/env_infos/final/reward_dist Min               7.65057e-10
exploration/env_infos/initial/reward_dist Mean            1.80609e-05
exploration/env_infos/initial/reward_dist Std             9.2715e-06
exploration/env_infos/initial/reward_dist Max             2.92319e-05
exploration/env_infos/initial/reward_dist Min             1.02322e-06
exploration/env_infos/reward_dist Mean                    0.00357702
exploration/env_infos/reward_dist Std                     0.00793698
exploration/env_infos/reward_dist Max                     0.0390645
exploration/env_infos/reward_dist Min                     4.23099e-13
evaluation/num steps total                           241000
evaluation/num paths total                            12050
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0935877
evaluation/Rewards Std                                    0.101951
evaluation/Rewards Max                                    0.111782
evaluation/Rewards Min                                   -0.752081
evaluation/Returns Mean                                  -1.87175
evaluation/Returns Std                                    1.48344
evaluation/Returns Max                                    1.23818
evaluation/Returns Min                                   -7.47986
evaluation/Actions Mean                                   0.00368737
evaluation/Actions Std                                    0.123378
evaluation/Actions Max                                    0.985402
evaluation/Actions Min                                   -0.945669
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.87175
evaluation/env_infos/final/reward_energy Mean            -0.0812838
evaluation/env_infos/final/reward_energy Std              0.0958252
evaluation/env_infos/final/reward_energy Max             -0.0111897
evaluation/env_infos/final/reward_energy Min             -0.5479
evaluation/env_infos/initial/reward_energy Mean          -0.261355
evaluation/env_infos/initial/reward_energy Std            0.234974
evaluation/env_infos/initial/reward_energy Max           -0.0134976
evaluation/env_infos/initial/reward_energy Min           -0.916595
evaluation/env_infos/reward_energy Mean                  -0.105391
evaluation/env_infos/reward_energy Std                    0.139154
evaluation/env_infos/reward_energy Max                   -0.000935841
evaluation/env_infos/reward_energy Min                   -1.36576
evaluation/env_infos/final/end_effector_loc Mean          0.0624266
evaluation/env_infos/final/end_effector_loc Std           0.371987
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00144523
evaluation/env_infos/initial/end_effector_loc Std         0.0123414
evaluation/env_infos/initial/end_effector_loc Max         0.0381377
evaluation/env_infos/initial/end_effector_loc Min        -0.0330631
evaluation/env_infos/end_effector_loc Mean                0.0309999
evaluation/env_infos/end_effector_loc Std                 0.238882
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0909764
evaluation/env_infos/final/reward_dist Std                0.197011
evaluation/env_infos/final/reward_dist Max                0.859193
evaluation/env_infos/final/reward_dist Min                2.33035e-155
evaluation/env_infos/initial/reward_dist Mean             0.0066236
evaluation/env_infos/initial/reward_dist Std              0.016482
evaluation/env_infos/initial/reward_dist Max              0.10849
evaluation/env_infos/initial/reward_dist Min              8.91757e-07
evaluation/env_infos/reward_dist Mean                     0.114833
evaluation/env_infos/reward_dist Std                      0.230315
evaluation/env_infos/reward_dist Max                      0.999898
evaluation/env_infos/reward_dist Min                      2.33035e-155
time/data storing (s)                                    38.3455
time/evaluation sampling (s)                              0.528183
time/exploration sampling (s)                             0.0867606
time/logging (s)                                          0.0160887
time/saving (s)                                           0.800123
time/training (s)                                        39.2061
time/epoch (s)                                           78.9828
time/total (s)                                        18096.2
Epoch                                                   240
---------------------------------------------------  -----------------
2021-05-29 04:58:52.933717 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 241 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00618447
trainer/QF2 Loss                                          0.00581461
trainer/Policy Loss                                       2.96585
trainer/Q1 Predictions Mean                              -1.0675
trainer/Q1 Predictions Std                                0.909178
trainer/Q1 Predictions Max                                1.00576
trainer/Q1 Predictions Min                               -3.27479
trainer/Q2 Predictions Mean                              -1.07784
trainer/Q2 Predictions Std                                0.902141
trainer/Q2 Predictions Max                                0.992269
trainer/Q2 Predictions Min                               -3.26396
trainer/Q Targets Mean                                   -1.06688
trainer/Q Targets Std                                     0.911307
trainer/Q Targets Max                                     0.990441
trainer/Q Targets Min                                    -3.29691
trainer/Log Pis Mean                                      1.90058
trainer/Log Pis Std                                       1.26088
trainer/Log Pis Max                                       4.73718
trainer/Log Pis Min                                      -5.39893
trainer/Policy mu Mean                                    0.0256596
trainer/Policy mu Std                                     0.360565
trainer/Policy mu Max                                     2.42078
trainer/Policy mu Min                                    -1.84853
trainer/Policy log std Mean                              -2.28878
trainer/Policy log std Std                                0.490162
trainer/Policy log std Max                               -0.252135
trainer/Policy log std Min                               -2.93857
trainer/Alpha                                             0.0202514
trainer/Alpha Loss                                       -0.387614
exploration/num steps total                           25200
exploration/num paths total                            1260
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.15842
exploration/Rewards Std                                   0.0986255
exploration/Rewards Max                                   0.0510249
exploration/Rewards Min                                  -0.436933
exploration/Returns Mean                                 -3.1684
exploration/Returns Std                                   1.2857
exploration/Returns Max                                  -0.799284
exploration/Returns Min                                  -4.2707
exploration/Actions Mean                                  0.0148511
exploration/Actions Std                                   0.098366
exploration/Actions Max                                   0.369803
exploration/Actions Min                                  -0.277812
exploration/Num Paths                                     5
exploration/Average Returns                              -3.1684
exploration/env_infos/final/reward_energy Mean           -0.0648375
exploration/env_infos/final/reward_energy Std             0.0201474
exploration/env_infos/final/reward_energy Max            -0.02767
exploration/env_infos/final/reward_energy Min            -0.083721
exploration/env_infos/initial/reward_energy Mean         -0.185372
exploration/env_infos/initial/reward_energy Std           0.118807
exploration/env_infos/initial/reward_energy Max          -0.0138498
exploration/env_infos/initial/reward_energy Min          -0.315571
exploration/env_infos/reward_energy Mean                 -0.1184
exploration/env_infos/reward_energy Std                   0.0759882
exploration/env_infos/reward_energy Max                  -0.0110702
exploration/env_infos/reward_energy Min                  -0.376749
exploration/env_infos/final/end_effector_loc Mean         0.171188
exploration/env_infos/final/end_effector_loc Std          0.508558
exploration/env_infos/final/end_effector_loc Max          0.923491
exploration/env_infos/final/end_effector_loc Min         -0.584264
exploration/env_infos/initial/end_effector_loc Mean       0.000587583
exploration/env_infos/initial/end_effector_loc Std        0.00776221
exploration/env_infos/initial/end_effector_loc Max        0.0115956
exploration/env_infos/initial/end_effector_loc Min       -0.0138906
exploration/env_infos/end_effector_loc Mean               0.0692804
exploration/env_infos/end_effector_loc Std                0.271514
exploration/env_infos/end_effector_loc Max                0.923491
exploration/env_infos/end_effector_loc Min               -0.584264
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              7.01685e-05
exploration/env_infos/final/reward_dist Std               0.000140337
exploration/env_infos/final/reward_dist Max               0.000350842
exploration/env_infos/final/reward_dist Min               5.21056e-56
exploration/env_infos/initial/reward_dist Mean            0.0111264
exploration/env_infos/initial/reward_dist Std             0.0134164
exploration/env_infos/initial/reward_dist Max             0.0359532
exploration/env_infos/initial/reward_dist Min             9.4409e-05
exploration/env_infos/reward_dist Mean                    0.0634934
exploration/env_infos/reward_dist Std                     0.151964
exploration/env_infos/reward_dist Max                     0.666318
exploration/env_infos/reward_dist Min                     5.21056e-56
evaluation/num steps total                           242000
evaluation/num paths total                            12100
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0865437
evaluation/Rewards Std                                    0.0860167
evaluation/Rewards Max                                    0.120967
evaluation/Rewards Min                                   -0.462171
evaluation/Returns Mean                                  -1.73087
evaluation/Returns Std                                    1.26054
evaluation/Returns Max                                    1.1127
evaluation/Returns Min                                   -5.62797
evaluation/Actions Mean                                   0.00409772
evaluation/Actions Std                                    0.130942
evaluation/Actions Max                                    0.965746
evaluation/Actions Min                                   -0.799866
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.73087
evaluation/env_infos/final/reward_energy Mean            -0.0688129
evaluation/env_infos/final/reward_energy Std              0.0866193
evaluation/env_infos/final/reward_energy Max             -0.00684929
evaluation/env_infos/final/reward_energy Min             -0.375047
evaluation/env_infos/initial/reward_energy Mean          -0.305625
evaluation/env_infos/initial/reward_energy Std            0.245321
evaluation/env_infos/initial/reward_energy Max           -0.00986171
evaluation/env_infos/initial/reward_energy Min           -0.933131
evaluation/env_infos/reward_energy Mean                  -0.110917
evaluation/env_infos/reward_energy Std                    0.148399
evaluation/env_infos/reward_energy Max                   -0.00222133
evaluation/env_infos/reward_energy Min                   -1.05199
evaluation/env_infos/final/end_effector_loc Mean          0.0710465
evaluation/env_infos/final/end_effector_loc Std           0.391709
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00165104
evaluation/env_infos/initial/end_effector_loc Std         0.0137572
evaluation/env_infos/initial/end_effector_loc Max         0.0288629
evaluation/env_infos/initial/end_effector_loc Min        -0.0399933
evaluation/env_infos/end_effector_loc Mean                0.0307952
evaluation/env_infos/end_effector_loc Std                 0.261273
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0527233
evaluation/env_infos/final/reward_dist Std                0.113509
evaluation/env_infos/final/reward_dist Max                0.476639
evaluation/env_infos/final/reward_dist Min                1.03636e-109
evaluation/env_infos/initial/reward_dist Mean             0.00361518
evaluation/env_infos/initial/reward_dist Std              0.00763919
evaluation/env_infos/initial/reward_dist Max              0.0441379
evaluation/env_infos/initial/reward_dist Min              1.05502e-06
evaluation/env_infos/reward_dist Mean                     0.0809697
evaluation/env_infos/reward_dist Std                      0.187684
evaluation/env_infos/reward_dist Max                      0.991232
evaluation/env_infos/reward_dist Min                      1.03636e-109
time/data storing (s)                                    38.405
time/evaluation sampling (s)                              0.737364
time/exploration sampling (s)                             0.0865073
time/logging (s)                                          0.0149915
time/saving (s)                                           0.794694
time/training (s)                                        39.6719
time/epoch (s)                                           79.7104
time/total (s)                                        18179.1
Epoch                                                   241
---------------------------------------------------  -----------------
2021-05-29 05:00:14.733876 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 242 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00658522
trainer/QF2 Loss                                          0.00741233
trainer/Policy Loss                                       2.87301
trainer/Q1 Predictions Mean                              -1.0271
trainer/Q1 Predictions Std                                0.944502
trainer/Q1 Predictions Max                                0.743733
trainer/Q1 Predictions Min                               -3.55138
trainer/Q2 Predictions Mean                              -1.03048
trainer/Q2 Predictions Std                                0.939824
trainer/Q2 Predictions Max                                0.753955
trainer/Q2 Predictions Min                               -3.61186
trainer/Q Targets Mean                                   -1.03035
trainer/Q Targets Std                                     0.938743
trainer/Q Targets Max                                     0.745557
trainer/Q Targets Min                                    -3.60291
trainer/Log Pis Mean                                      1.85449
trainer/Log Pis Std                                       1.23769
trainer/Log Pis Max                                       3.65207
trainer/Log Pis Min                                      -4.22006
trainer/Policy mu Mean                                    0.0286451
trainer/Policy mu Std                                     0.331819
trainer/Policy mu Max                                     2.05277
trainer/Policy mu Min                                    -2.01051
trainer/Policy log std Mean                              -2.2934
trainer/Policy log std Std                                0.480961
trainer/Policy log std Max                               -0.234314
trainer/Policy log std Min                               -2.8609
trainer/Alpha                                             0.0212554
trainer/Alpha Loss                                       -0.560454
exploration/num steps total                           25300
exploration/num paths total                            1265
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0955097
exploration/Rewards Std                                   0.100114
exploration/Rewards Max                                   0.128747
exploration/Rewards Min                                  -0.341179
exploration/Returns Mean                                 -1.91019
exploration/Returns Std                                   1.65982
exploration/Returns Max                                   1.20301
exploration/Returns Min                                  -3.51329
exploration/Actions Mean                                  0.0132696
exploration/Actions Std                                   0.220576
exploration/Actions Max                                   0.842808
exploration/Actions Min                                  -0.701234
exploration/Num Paths                                     5
exploration/Average Returns                              -1.91019
exploration/env_infos/final/reward_energy Mean           -0.191685
exploration/env_infos/final/reward_energy Std             0.137414
exploration/env_infos/final/reward_energy Max            -0.0924806
exploration/env_infos/final/reward_energy Min            -0.460939
exploration/env_infos/initial/reward_energy Mean         -0.502868
exploration/env_infos/initial/reward_energy Std           0.28238
exploration/env_infos/initial/reward_energy Max          -0.118599
exploration/env_infos/initial/reward_energy Min          -0.912325
exploration/env_infos/reward_energy Mean                 -0.245611
exploration/env_infos/reward_energy Std                   0.193222
exploration/env_infos/reward_energy Max                  -0.0155264
exploration/env_infos/reward_energy Min                  -0.912325
exploration/env_infos/final/end_effector_loc Mean         0.216377
exploration/env_infos/final/end_effector_loc Std          0.211938
exploration/env_infos/final/end_effector_loc Max          0.599045
exploration/env_infos/final/end_effector_loc Min         -0.0591832
exploration/env_infos/initial/end_effector_loc Mean       0.00914963
exploration/env_infos/initial/end_effector_loc Std        0.0182223
exploration/env_infos/initial/end_effector_loc Max        0.0421404
exploration/env_infos/initial/end_effector_loc Min       -0.0174651
exploration/env_infos/end_effector_loc Mean               0.115452
exploration/env_infos/end_effector_loc Std                0.163514
exploration/env_infos/end_effector_loc Max                0.599045
exploration/env_infos/end_effector_loc Min               -0.236641
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0607908
exploration/env_infos/final/reward_dist Std               0.0746863
exploration/env_infos/final/reward_dist Max               0.161299
exploration/env_infos/final/reward_dist Min               7.33483e-14
exploration/env_infos/initial/reward_dist Mean            0.00965613
exploration/env_infos/initial/reward_dist Std             0.0117709
exploration/env_infos/initial/reward_dist Max             0.031
exploration/env_infos/initial/reward_dist Min             1.44437e-05
exploration/env_infos/reward_dist Mean                    0.117819
exploration/env_infos/reward_dist Std                     0.242443
exploration/env_infos/reward_dist Max                     0.96356
exploration/env_infos/reward_dist Min                     7.33483e-14
evaluation/num steps total                           243000
evaluation/num paths total                            12150
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0789075
evaluation/Rewards Std                                    0.0712276
evaluation/Rewards Max                                    0.0998877
evaluation/Rewards Min                                   -0.544076
evaluation/Returns Mean                                  -1.57815
evaluation/Returns Std                                    1.02401
evaluation/Returns Max                                    0.589889
evaluation/Returns Min                                   -4.27981
evaluation/Actions Mean                                   0.00772378
evaluation/Actions Std                                    0.0824383
evaluation/Actions Max                                    0.764379
evaluation/Actions Min                                   -0.418172
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.57815
evaluation/env_infos/final/reward_energy Mean            -0.0681257
evaluation/env_infos/final/reward_energy Std              0.0626764
evaluation/env_infos/final/reward_energy Max             -0.00319324
evaluation/env_infos/final/reward_energy Min             -0.337326
evaluation/env_infos/initial/reward_energy Mean          -0.212284
evaluation/env_infos/initial/reward_energy Std            0.186712
evaluation/env_infos/initial/reward_energy Max           -0.000838663
evaluation/env_infos/initial/reward_energy Min           -0.807204
evaluation/env_infos/reward_energy Mean                  -0.0791122
evaluation/env_infos/reward_energy Std                    0.0863292
evaluation/env_infos/reward_energy Max                   -0.000215447
evaluation/env_infos/reward_energy Min                   -0.807204
evaluation/env_infos/final/end_effector_loc Mean          0.111354
evaluation/env_infos/final/end_effector_loc Std           0.272805
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.481269
evaluation/env_infos/initial/end_effector_loc Mean        0.00277703
evaluation/env_infos/initial/end_effector_loc Std         0.00960183
evaluation/env_infos/initial/end_effector_loc Max         0.038219
evaluation/env_infos/initial/end_effector_loc Min        -0.0209086
evaluation/env_infos/end_effector_loc Mean                0.0559327
evaluation/env_infos/end_effector_loc Std                 0.170858
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.481269
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0292794
evaluation/env_infos/final/reward_dist Std                0.0802096
evaluation/env_infos/final/reward_dist Max                0.419856
evaluation/env_infos/final/reward_dist Min                1.06377e-57
evaluation/env_infos/initial/reward_dist Mean             0.00709777
evaluation/env_infos/initial/reward_dist Std              0.0113992
evaluation/env_infos/initial/reward_dist Max              0.0450538
evaluation/env_infos/initial/reward_dist Min              3.81398e-07
evaluation/env_infos/reward_dist Mean                     0.105278
evaluation/env_infos/reward_dist Std                      0.20873
evaluation/env_infos/reward_dist Max                      0.993581
evaluation/env_infos/reward_dist Min                      1.06377e-57
time/data storing (s)                                    38.1664
time/evaluation sampling (s)                              0.66224
time/exploration sampling (s)                             0.0884353
time/logging (s)                                          0.0153556
time/saving (s)                                           0.824433
time/training (s)                                        39.4434
time/epoch (s)                                           79.2003
time/total (s)                                        18260.9
Epoch                                                   242
---------------------------------------------------  ----------------
2021-05-29 05:01:36.448957 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 243 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00539039
trainer/QF2 Loss                                          0.00772585
trainer/Policy Loss                                       3.06925
trainer/Q1 Predictions Mean                              -1.10925
trainer/Q1 Predictions Std                                0.904985
trainer/Q1 Predictions Max                                0.664535
trainer/Q1 Predictions Min                               -3.36242
trainer/Q2 Predictions Mean                              -1.11042
trainer/Q2 Predictions Std                                0.884989
trainer/Q2 Predictions Max                                0.738411
trainer/Q2 Predictions Min                               -3.29753
trainer/Q Targets Mean                                   -1.10957
trainer/Q Targets Std                                     0.901688
trainer/Q Targets Max                                     0.798883
trainer/Q Targets Min                                    -3.18034
trainer/Log Pis Mean                                      1.95078
trainer/Log Pis Std                                       1.173
trainer/Log Pis Max                                       3.63753
trainer/Log Pis Min                                      -2.03584
trainer/Policy mu Mean                                    0.00938543
trainer/Policy mu Std                                     0.294085
trainer/Policy mu Max                                     2.77858
trainer/Policy mu Min                                    -1.63161
trainer/Policy log std Mean                              -2.33586
trainer/Policy log std Std                                0.452529
trainer/Policy log std Max                               -0.365634
trainer/Policy log std Min                               -2.86904
trainer/Alpha                                             0.0211986
trainer/Alpha Loss                                       -0.189635
exploration/num steps total                           25400
exploration/num paths total                            1270
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.136552
exploration/Rewards Std                                   0.0664347
exploration/Rewards Max                                   0.0318831
exploration/Rewards Min                                  -0.291801
exploration/Returns Mean                                 -2.73104
exploration/Returns Std                                   0.690125
exploration/Returns Max                                  -1.60821
exploration/Returns Min                                  -3.75984
exploration/Actions Mean                                  0.00396244
exploration/Actions Std                                   0.116652
exploration/Actions Max                                   0.45211
exploration/Actions Min                                  -0.340893
exploration/Num Paths                                     5
exploration/Average Returns                              -2.73104
exploration/env_infos/final/reward_energy Mean           -0.165753
exploration/env_infos/final/reward_energy Std             0.0465434
exploration/env_infos/final/reward_energy Max            -0.0841855
exploration/env_infos/final/reward_energy Min            -0.21776
exploration/env_infos/initial/reward_energy Mean         -0.153415
exploration/env_infos/initial/reward_energy Std           0.0753455
exploration/env_infos/initial/reward_energy Max          -0.0514235
exploration/env_infos/initial/reward_energy Min          -0.273246
exploration/env_infos/reward_energy Mean                 -0.13512
exploration/env_infos/reward_energy Std                   0.0948115
exploration/env_infos/reward_energy Max                  -0.00174205
exploration/env_infos/reward_energy Min                  -0.568471
exploration/env_infos/final/end_effector_loc Mean         0.0298299
exploration/env_infos/final/end_effector_loc Std          0.286753
exploration/env_infos/final/end_effector_loc Max          0.60274
exploration/env_infos/final/end_effector_loc Min         -0.506112
exploration/env_infos/initial/end_effector_loc Mean       0.00344515
exploration/env_infos/initial/end_effector_loc Std        0.0049646
exploration/env_infos/initial/end_effector_loc Max        0.0121855
exploration/env_infos/initial/end_effector_loc Min       -0.00635949
exploration/env_infos/end_effector_loc Mean               0.00742618
exploration/env_infos/end_effector_loc Std                0.156818
exploration/env_infos/end_effector_loc Max                0.60274
exploration/env_infos/end_effector_loc Min               -0.506112
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00984257
exploration/env_infos/final/reward_dist Std               0.0177988
exploration/env_infos/final/reward_dist Max               0.0453116
exploration/env_infos/final/reward_dist Min               1.50408e-14
exploration/env_infos/initial/reward_dist Mean            0.0106287
exploration/env_infos/initial/reward_dist Std             0.0122724
exploration/env_infos/initial/reward_dist Max             0.0284602
exploration/env_infos/initial/reward_dist Min             6.77803e-07
exploration/env_infos/reward_dist Mean                    0.0903166
exploration/env_infos/reward_dist Std                     0.201162
exploration/env_infos/reward_dist Max                     0.946912
exploration/env_infos/reward_dist Min                     1.50408e-14
evaluation/num steps total                           244000
evaluation/num paths total                            12200
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0978525
evaluation/Rewards Std                                    0.11075
evaluation/Rewards Max                                    0.123667
evaluation/Rewards Min                                   -0.774056
evaluation/Returns Mean                                  -1.95705
evaluation/Returns Std                                    1.67644
evaluation/Returns Max                                    1.25919
evaluation/Returns Min                                   -8.69233
evaluation/Actions Mean                                   0.00282529
evaluation/Actions Std                                    0.127132
evaluation/Actions Max                                    0.930551
evaluation/Actions Min                                   -0.858303
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.95705
evaluation/env_infos/final/reward_energy Mean            -0.082768
evaluation/env_infos/final/reward_energy Std              0.0932884
evaluation/env_infos/final/reward_energy Max             -0.00592697
evaluation/env_infos/final/reward_energy Min             -0.504666
evaluation/env_infos/initial/reward_energy Mean          -0.329306
evaluation/env_infos/initial/reward_energy Std            0.249557
evaluation/env_infos/initial/reward_energy Max           -0.00496774
evaluation/env_infos/initial/reward_energy Min           -0.846237
evaluation/env_infos/reward_energy Mean                  -0.113363
evaluation/env_infos/reward_energy Std                    0.139606
evaluation/env_infos/reward_energy Max                   -0.00237148
evaluation/env_infos/reward_energy Min                   -1.15019
evaluation/env_infos/final/end_effector_loc Mean          0.00241341
evaluation/env_infos/final/end_effector_loc Std           0.349189
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000203589
evaluation/env_infos/initial/end_effector_loc Std         0.0146068
evaluation/env_infos/initial/end_effector_loc Max         0.0308631
evaluation/env_infos/initial/end_effector_loc Min        -0.0377463
evaluation/env_infos/end_effector_loc Mean                0.00248405
evaluation/env_infos/end_effector_loc Std                 0.231327
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0669694
evaluation/env_infos/final/reward_dist Std                0.164839
evaluation/env_infos/final/reward_dist Max                0.879154
evaluation/env_infos/final/reward_dist Min                1.61755e-90
evaluation/env_infos/initial/reward_dist Mean             0.00733145
evaluation/env_infos/initial/reward_dist Std              0.0143255
evaluation/env_infos/initial/reward_dist Max              0.0811864
evaluation/env_infos/initial/reward_dist Min              1.52817e-06
evaluation/env_infos/reward_dist Mean                     0.106246
evaluation/env_infos/reward_dist Std                      0.216455
evaluation/env_infos/reward_dist Max                      0.997279
evaluation/env_infos/reward_dist Min                      1.61755e-90
time/data storing (s)                                    38.0455
time/evaluation sampling (s)                              0.535345
time/exploration sampling (s)                             0.0825396
time/logging (s)                                          0.0162969
time/saving (s)                                           0.778402
time/training (s)                                        39.714
time/epoch (s)                                           79.1721
time/total (s)                                        18342.6
Epoch                                                   243
---------------------------------------------------  ----------------
2021-05-29 05:02:59.235312 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 244 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00657789
trainer/QF2 Loss                                          0.00642057
trainer/Policy Loss                                       3.2942
trainer/Q1 Predictions Mean                              -1.20088
trainer/Q1 Predictions Std                                0.986244
trainer/Q1 Predictions Max                                0.733356
trainer/Q1 Predictions Min                               -4.52796
trainer/Q2 Predictions Mean                              -1.19942
trainer/Q2 Predictions Std                                0.9835
trainer/Q2 Predictions Max                                0.771731
trainer/Q2 Predictions Min                               -4.50865
trainer/Q Targets Mean                                   -1.20969
trainer/Q Targets Std                                     0.986715
trainer/Q Targets Max                                     0.814823
trainer/Q Targets Min                                    -4.60425
trainer/Log Pis Mean                                      2.10639
trainer/Log Pis Std                                       1.04911
trainer/Log Pis Max                                       4.38333
trainer/Log Pis Min                                      -2.44203
trainer/Policy mu Mean                                   -0.00765998
trainer/Policy mu Std                                     0.350136
trainer/Policy mu Max                                     2.00015
trainer/Policy mu Min                                    -2.07456
trainer/Policy log std Mean                              -2.34344
trainer/Policy log std Std                                0.407642
trainer/Policy log std Max                               -0.469403
trainer/Policy log std Min                               -2.79263
trainer/Alpha                                             0.022751
trainer/Alpha Loss                                        0.402814
exploration/num steps total                           25500
exploration/num paths total                            1275
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0744362
exploration/Rewards Std                                   0.0824493
exploration/Rewards Max                                   0.0875185
exploration/Rewards Min                                  -0.381531
exploration/Returns Mean                                 -1.48872
exploration/Returns Std                                   1.05936
exploration/Returns Max                                   0.343106
exploration/Returns Min                                  -2.62099
exploration/Actions Mean                                 -0.000256782
exploration/Actions Std                                   0.128332
exploration/Actions Max                                   0.514032
exploration/Actions Min                                  -0.53411
exploration/Num Paths                                     5
exploration/Average Returns                              -1.48872
exploration/env_infos/final/reward_energy Mean           -0.124114
exploration/env_infos/final/reward_energy Std             0.0897226
exploration/env_infos/final/reward_energy Max            -0.0354784
exploration/env_infos/final/reward_energy Min            -0.289629
exploration/env_infos/initial/reward_energy Mean         -0.361749
exploration/env_infos/initial/reward_energy Std           0.178449
exploration/env_infos/initial/reward_energy Max          -0.130555
exploration/env_infos/initial/reward_energy Min          -0.568546
exploration/env_infos/reward_energy Mean                 -0.143545
exploration/env_infos/reward_energy Std                   0.111055
exploration/env_infos/reward_energy Max                  -0.00665279
exploration/env_infos/reward_energy Min                  -0.568546
exploration/env_infos/final/end_effector_loc Mean        -0.0356371
exploration/env_infos/final/end_effector_loc Std          0.164718
exploration/env_infos/final/end_effector_loc Max          0.195855
exploration/env_infos/final/end_effector_loc Min         -0.281345
exploration/env_infos/initial/end_effector_loc Mean       0.00126194
exploration/env_infos/initial/end_effector_loc Std        0.0142053
exploration/env_infos/initial/end_effector_loc Max        0.0257016
exploration/env_infos/initial/end_effector_loc Min       -0.0267055
exploration/env_infos/end_effector_loc Mean              -0.00974744
exploration/env_infos/end_effector_loc Std                0.13897
exploration/env_infos/end_effector_loc Max                0.195855
exploration/env_infos/end_effector_loc Min               -0.340984
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.138004
exploration/env_infos/final/reward_dist Std               0.257251
exploration/env_infos/final/reward_dist Max               0.651713
exploration/env_infos/final/reward_dist Min               1.14131e-07
exploration/env_infos/initial/reward_dist Mean            0.0130749
exploration/env_infos/initial/reward_dist Std             0.0256945
exploration/env_infos/initial/reward_dist Max             0.0644632
exploration/env_infos/initial/reward_dist Min             3.12562e-05
exploration/env_infos/reward_dist Mean                    0.266937
exploration/env_infos/reward_dist Std                     0.340276
exploration/env_infos/reward_dist Max                     0.995289
exploration/env_infos/reward_dist Min                     1.14131e-07
evaluation/num steps total                           245000
evaluation/num paths total                            12250
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0844196
evaluation/Rewards Std                                    0.0892293
evaluation/Rewards Max                                    0.120452
evaluation/Rewards Min                                   -0.582067
evaluation/Returns Mean                                  -1.68839
evaluation/Returns Std                                    1.30725
evaluation/Returns Max                                    0.869335
evaluation/Returns Min                                   -6.8298
evaluation/Actions Mean                                  -0.00497151
evaluation/Actions Std                                    0.0889066
evaluation/Actions Max                                    0.684715
evaluation/Actions Min                                   -0.672778
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.68839
evaluation/env_infos/final/reward_energy Mean            -0.0556971
evaluation/env_infos/final/reward_energy Std              0.0525301
evaluation/env_infos/final/reward_energy Max             -0.00611693
evaluation/env_infos/final/reward_energy Min             -0.225546
evaluation/env_infos/initial/reward_energy Mean          -0.261778
evaluation/env_infos/initial/reward_energy Std            0.198391
evaluation/env_infos/initial/reward_energy Max           -0.015261
evaluation/env_infos/initial/reward_energy Min           -0.825559
evaluation/env_infos/reward_energy Mean                  -0.0790544
evaluation/env_infos/reward_energy Std                    0.0980233
evaluation/env_infos/reward_energy Max                   -0.00131928
evaluation/env_infos/reward_energy Min                   -0.825559
evaluation/env_infos/final/end_effector_loc Mean         -0.0236414
evaluation/env_infos/final/end_effector_loc Std           0.337205
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.0007576
evaluation/env_infos/initial/end_effector_loc Std         0.0115881
evaluation/env_infos/initial/end_effector_loc Max         0.0342357
evaluation/env_infos/initial/end_effector_loc Min        -0.0336389
evaluation/env_infos/end_effector_loc Mean               -0.00697203
evaluation/env_infos/end_effector_loc Std                 0.219897
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0307222
evaluation/env_infos/final/reward_dist Std                0.0834675
evaluation/env_infos/final/reward_dist Max                0.53179
evaluation/env_infos/final/reward_dist Min                6.36819e-90
evaluation/env_infos/initial/reward_dist Mean             0.0045039
evaluation/env_infos/initial/reward_dist Std              0.00655128
evaluation/env_infos/initial/reward_dist Max              0.0245086
evaluation/env_infos/initial/reward_dist Min              5.65273e-07
evaluation/env_infos/reward_dist Mean                     0.0926134
evaluation/env_infos/reward_dist Std                      0.189681
evaluation/env_infos/reward_dist Max                      0.994755
evaluation/env_infos/reward_dist Min                      6.36819e-90
time/data storing (s)                                    38.2018
time/evaluation sampling (s)                              0.648025
time/exploration sampling (s)                             0.0916953
time/logging (s)                                          0.0175246
time/saving (s)                                           0.799422
time/training (s)                                        40.4231
time/epoch (s)                                           80.1816
time/total (s)                                        18425.3
Epoch                                                   244
---------------------------------------------------  ----------------
2021-05-29 05:04:20.874817 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 245 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0040468
trainer/QF2 Loss                                          0.00578884
trainer/Policy Loss                                       2.91463
trainer/Q1 Predictions Mean                              -1.04376
trainer/Q1 Predictions Std                                0.942318
trainer/Q1 Predictions Max                                1.25355
trainer/Q1 Predictions Min                               -3.98272
trainer/Q2 Predictions Mean                              -1.02174
trainer/Q2 Predictions Std                                0.954309
trainer/Q2 Predictions Max                                1.34414
trainer/Q2 Predictions Min                               -4.2285
trainer/Q Targets Mean                                   -1.04454
trainer/Q Targets Std                                     0.950743
trainer/Q Targets Max                                     1.21408
trainer/Q Targets Min                                    -4.154
trainer/Log Pis Mean                                      1.86027
trainer/Log Pis Std                                       1.31776
trainer/Log Pis Max                                       5.26194
trainer/Log Pis Min                                      -3.39093
trainer/Policy mu Mean                                   -0.0279544
trainer/Policy mu Std                                     0.394242
trainer/Policy mu Max                                     1.67453
trainer/Policy mu Min                                    -2.36532
trainer/Policy log std Mean                              -2.27843
trainer/Policy log std Std                                0.471586
trainer/Policy log std Max                               -0.283672
trainer/Policy log std Min                               -2.79429
trainer/Alpha                                             0.0235826
trainer/Alpha Loss                                       -0.523749
exploration/num steps total                           25600
exploration/num paths total                            1280
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0866646
exploration/Rewards Std                                   0.0569835
exploration/Rewards Max                                   0.012071
exploration/Rewards Min                                  -0.272646
exploration/Returns Mean                                 -1.73329
exploration/Returns Std                                   0.621796
exploration/Returns Max                                  -0.954897
exploration/Returns Min                                  -2.84522
exploration/Actions Mean                                  0.00393734
exploration/Actions Std                                   0.149197
exploration/Actions Max                                   0.646774
exploration/Actions Min                                  -0.450527
exploration/Num Paths                                     5
exploration/Average Returns                              -1.73329
exploration/env_infos/final/reward_energy Mean           -0.142963
exploration/env_infos/final/reward_energy Std             0.0612856
exploration/env_infos/final/reward_energy Max            -0.0613178
exploration/env_infos/final/reward_energy Min            -0.208874
exploration/env_infos/initial/reward_energy Mean         -0.330568
exploration/env_infos/initial/reward_energy Std           0.243988
exploration/env_infos/initial/reward_energy Max          -0.0838635
exploration/env_infos/initial/reward_energy Min          -0.78822
exploration/env_infos/reward_energy Mean                 -0.16255
exploration/env_infos/reward_energy Std                   0.134641
exploration/env_infos/reward_energy Max                  -0.00779493
exploration/env_infos/reward_energy Min                  -0.78822
exploration/env_infos/final/end_effector_loc Mean         0.00806584
exploration/env_infos/final/end_effector_loc Std          0.152216
exploration/env_infos/final/end_effector_loc Max          0.283593
exploration/env_infos/final/end_effector_loc Min         -0.183402
exploration/env_infos/initial/end_effector_loc Mean       0.000914106
exploration/env_infos/initial/end_effector_loc Std        0.0144973
exploration/env_infos/initial/end_effector_loc Max        0.0323387
exploration/env_infos/initial/end_effector_loc Min       -0.0225264
exploration/env_infos/end_effector_loc Mean               0.00939052
exploration/env_infos/end_effector_loc Std                0.109034
exploration/env_infos/end_effector_loc Max                0.283593
exploration/env_infos/end_effector_loc Min               -0.272858
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0516561
exploration/env_infos/final/reward_dist Std               0.0626492
exploration/env_infos/final/reward_dist Max               0.136988
exploration/env_infos/final/reward_dist Min               5.73443e-10
exploration/env_infos/initial/reward_dist Mean            0.000229622
exploration/env_infos/initial/reward_dist Std             0.000193856
exploration/env_infos/initial/reward_dist Max             0.000583724
exploration/env_infos/initial/reward_dist Min             2.17317e-06
exploration/env_infos/reward_dist Mean                    0.116049
exploration/env_infos/reward_dist Std                     0.191982
exploration/env_infos/reward_dist Max                     0.898897
exploration/env_infos/reward_dist Min                     5.73443e-10
evaluation/num steps total                           246000
evaluation/num paths total                            12300
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0641756
evaluation/Rewards Std                                    0.0840868
evaluation/Rewards Max                                    0.151336
evaluation/Rewards Min                                   -0.592769
evaluation/Returns Mean                                  -1.28351
evaluation/Returns Std                                    1.30141
evaluation/Returns Max                                    1.53146
evaluation/Returns Min                                   -5.55793
evaluation/Actions Mean                                   0.00268314
evaluation/Actions Std                                    0.103262
evaluation/Actions Max                                    0.888248
evaluation/Actions Min                                   -0.810455
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.28351
evaluation/env_infos/final/reward_energy Mean            -0.0522867
evaluation/env_infos/final/reward_energy Std              0.0517913
evaluation/env_infos/final/reward_energy Max             -0.00942368
evaluation/env_infos/final/reward_energy Min             -0.243732
evaluation/env_infos/initial/reward_energy Mean          -0.267138
evaluation/env_infos/initial/reward_energy Std            0.256435
evaluation/env_infos/initial/reward_energy Max           -0.013069
evaluation/env_infos/initial/reward_energy Min           -1.00977
evaluation/env_infos/reward_energy Mean                  -0.0821801
evaluation/env_infos/reward_energy Std                    0.120777
evaluation/env_infos/reward_energy Max                   -0.00165241
evaluation/env_infos/reward_energy Min                   -1.00977
evaluation/env_infos/final/end_effector_loc Mean          0.0352874
evaluation/env_infos/final/end_effector_loc Std           0.289426
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00020323
evaluation/env_infos/initial/end_effector_loc Std         0.0130905
evaluation/env_infos/initial/end_effector_loc Max         0.0393349
evaluation/env_infos/initial/end_effector_loc Min        -0.0405228
evaluation/env_infos/end_effector_loc Mean                0.0207152
evaluation/env_infos/end_effector_loc Std                 0.199894
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0696803
evaluation/env_infos/final/reward_dist Std                0.179845
evaluation/env_infos/final/reward_dist Max                0.944338
evaluation/env_infos/final/reward_dist Min                2.52486e-62
evaluation/env_infos/initial/reward_dist Mean             0.00769301
evaluation/env_infos/initial/reward_dist Std              0.0197037
evaluation/env_infos/initial/reward_dist Max              0.101847
evaluation/env_infos/initial/reward_dist Min              1.02335e-06
evaluation/env_infos/reward_dist Mean                     0.124134
evaluation/env_infos/reward_dist Std                      0.217992
evaluation/env_infos/reward_dist Max                      0.999264
evaluation/env_infos/reward_dist Min                      2.52486e-62
time/data storing (s)                                    38.3846
time/evaluation sampling (s)                              0.73258
time/exploration sampling (s)                             0.0878828
time/logging (s)                                          0.0148674
time/saving (s)                                           0.777376
time/training (s)                                        38.933
time/epoch (s)                                           78.9303
time/total (s)                                        18507
Epoch                                                   245
---------------------------------------------------  ----------------
2021-05-29 05:05:43.241406 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 246 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00611169
trainer/QF2 Loss                                          0.0067593
trainer/Policy Loss                                       3.16694
trainer/Q1 Predictions Mean                              -1.11467
trainer/Q1 Predictions Std                                0.949797
trainer/Q1 Predictions Max                                0.882247
trainer/Q1 Predictions Min                               -3.65655
trainer/Q2 Predictions Mean                              -1.09198
trainer/Q2 Predictions Std                                0.953285
trainer/Q2 Predictions Max                                0.864843
trainer/Q2 Predictions Min                               -3.58322
trainer/Q Targets Mean                                   -1.10671
trainer/Q Targets Std                                     0.950064
trainer/Q Targets Max                                     0.90349
trainer/Q Targets Min                                    -3.6723
trainer/Log Pis Mean                                      2.06385
trainer/Log Pis Std                                       1.22766
trainer/Log Pis Max                                       4.03339
trainer/Log Pis Min                                      -3.92244
trainer/Policy mu Mean                                   -0.0378049
trainer/Policy mu Std                                     0.361199
trainer/Policy mu Max                                     1.65629
trainer/Policy mu Min                                    -2.12243
trainer/Policy log std Mean                              -2.28358
trainer/Policy log std Std                                0.502781
trainer/Policy log std Max                               -0.114557
trainer/Policy log std Min                               -2.81033
trainer/Alpha                                             0.0241272
trainer/Alpha Loss                                        0.237834
exploration/num steps total                           25700
exploration/num paths total                            1285
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0798757
exploration/Rewards Std                                   0.0909227
exploration/Rewards Max                                   0.0916859
exploration/Rewards Min                                  -0.391838
exploration/Returns Mean                                 -1.59751
exploration/Returns Std                                   0.462709
exploration/Returns Max                                  -0.823439
exploration/Returns Min                                  -2.03737
exploration/Actions Mean                                 -0.000829033
exploration/Actions Std                                   0.11783
exploration/Actions Max                                   0.59535
exploration/Actions Min                                  -0.420095
exploration/Num Paths                                     5
exploration/Average Returns                              -1.59751
exploration/env_infos/final/reward_energy Mean           -0.188355
exploration/env_infos/final/reward_energy Std             0.0759884
exploration/env_infos/final/reward_energy Max            -0.0684992
exploration/env_infos/final/reward_energy Min            -0.284938
exploration/env_infos/initial/reward_energy Mean         -0.21785
exploration/env_infos/initial/reward_energy Std           0.197482
exploration/env_infos/initial/reward_energy Max          -0.0858747
exploration/env_infos/initial/reward_energy Min          -0.607575
exploration/env_infos/reward_energy Mean                 -0.137865
exploration/env_infos/reward_energy Std                   0.0936084
exploration/env_infos/reward_energy Max                  -0.025259
exploration/env_infos/reward_energy Min                  -0.607575
exploration/env_infos/final/end_effector_loc Mean        -0.0797306
exploration/env_infos/final/end_effector_loc Std          0.269207
exploration/env_infos/final/end_effector_loc Max          0.327515
exploration/env_infos/final/end_effector_loc Min         -0.571937
exploration/env_infos/initial/end_effector_loc Mean       0.00179329
exploration/env_infos/initial/end_effector_loc Std        0.0102399
exploration/env_infos/initial/end_effector_loc Max        0.0297675
exploration/env_infos/initial/end_effector_loc Min       -0.00883053
exploration/env_infos/end_effector_loc Mean              -0.0471302
exploration/env_infos/end_effector_loc Std                0.177347
exploration/env_infos/end_effector_loc Max                0.384116
exploration/env_infos/end_effector_loc Min               -0.571937
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.330729
exploration/env_infos/final/reward_dist Std               0.308981
exploration/env_infos/final/reward_dist Max               0.823755
exploration/env_infos/final/reward_dist Min               2.45174e-21
exploration/env_infos/initial/reward_dist Mean            0.00354999
exploration/env_infos/initial/reward_dist Std             0.0046328
exploration/env_infos/initial/reward_dist Max             0.0127216
exploration/env_infos/initial/reward_dist Min             0.000143711
exploration/env_infos/reward_dist Mean                    0.137732
exploration/env_infos/reward_dist Std                     0.194631
exploration/env_infos/reward_dist Max                     0.895658
exploration/env_infos/reward_dist Min                     2.45174e-21
evaluation/num steps total                           247000
evaluation/num paths total                            12350
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0753696
evaluation/Rewards Std                                    0.131621
evaluation/Rewards Max                                    0.154312
evaluation/Rewards Min                                   -0.852532
evaluation/Returns Mean                                  -1.50739
evaluation/Returns Std                                    2.03394
evaluation/Returns Max                                    1.4995
evaluation/Returns Min                                   -9.9474
evaluation/Actions Mean                                  -0.00513047
evaluation/Actions Std                                    0.133792
evaluation/Actions Max                                    0.832905
evaluation/Actions Min                                   -0.912351
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.50739
evaluation/env_infos/final/reward_energy Mean            -0.0798301
evaluation/env_infos/final/reward_energy Std              0.110304
evaluation/env_infos/final/reward_energy Max             -0.00180628
evaluation/env_infos/final/reward_energy Min             -0.631642
evaluation/env_infos/initial/reward_energy Mean          -0.400018
evaluation/env_infos/initial/reward_energy Std            0.273243
evaluation/env_infos/initial/reward_energy Max           -0.0146483
evaluation/env_infos/initial/reward_energy Min           -1.1955
evaluation/env_infos/reward_energy Mean                  -0.11322
evaluation/env_infos/reward_energy Std                    0.15177
evaluation/env_infos/reward_energy Max                   -0.00176886
evaluation/env_infos/reward_energy Min                   -1.1955
evaluation/env_infos/final/end_effector_loc Mean         -0.0262419
evaluation/env_infos/final/end_effector_loc Std           0.392241
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000275635
evaluation/env_infos/initial/end_effector_loc Std         0.0171251
evaluation/env_infos/initial/end_effector_loc Max         0.0416452
evaluation/env_infos/initial/end_effector_loc Min        -0.0456175
evaluation/env_infos/end_effector_loc Mean               -0.0154932
evaluation/env_infos/end_effector_loc Std                 0.264969
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0908606
evaluation/env_infos/final/reward_dist Std                0.191153
evaluation/env_infos/final/reward_dist Max                0.803026
evaluation/env_infos/final/reward_dist Min                1.40284e-109
evaluation/env_infos/initial/reward_dist Mean             0.011903
evaluation/env_infos/initial/reward_dist Std              0.0270277
evaluation/env_infos/initial/reward_dist Max              0.171024
evaluation/env_infos/initial/reward_dist Min              7.12073e-07
evaluation/env_infos/reward_dist Mean                     0.126114
evaluation/env_infos/reward_dist Std                      0.219718
evaluation/env_infos/reward_dist Max                      0.997585
evaluation/env_infos/reward_dist Min                      1.40284e-109
time/data storing (s)                                    38.2574
time/evaluation sampling (s)                              0.651517
time/exploration sampling (s)                             0.0866961
time/logging (s)                                          0.0148406
time/saving (s)                                           0.803338
time/training (s)                                        39.9036
time/epoch (s)                                           79.7173
time/total (s)                                        18589.3
Epoch                                                   246
---------------------------------------------------  -----------------
2021-05-29 05:07:04.851112 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 247 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00445316
trainer/QF2 Loss                                          0.00544861
trainer/Policy Loss                                       3.06579
trainer/Q1 Predictions Mean                              -1.02153
trainer/Q1 Predictions Std                                0.977767
trainer/Q1 Predictions Max                                1.51034
trainer/Q1 Predictions Min                               -3.27021
trainer/Q2 Predictions Mean                              -1.04561
trainer/Q2 Predictions Std                                0.965175
trainer/Q2 Predictions Max                                1.5038
trainer/Q2 Predictions Min                               -3.20526
trainer/Q Targets Mean                                   -1.01456
trainer/Q Targets Std                                     0.976594
trainer/Q Targets Max                                     1.50824
trainer/Q Targets Min                                    -3.24316
trainer/Log Pis Mean                                      2.02787
trainer/Log Pis Std                                       1.21215
trainer/Log Pis Max                                       3.69909
trainer/Log Pis Min                                      -3.39187
trainer/Policy mu Mean                                   -0.0111237
trainer/Policy mu Std                                     0.302597
trainer/Policy mu Max                                     1.61057
trainer/Policy mu Min                                    -1.60179
trainer/Policy log std Mean                              -2.33965
trainer/Policy log std Std                                0.407482
trainer/Policy log std Max                               -0.905192
trainer/Policy log std Min                               -2.86685
trainer/Alpha                                             0.0224688
trainer/Alpha Loss                                        0.105777
exploration/num steps total                           25800
exploration/num paths total                            1290
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0696176
exploration/Rewards Std                                   0.0878762
exploration/Rewards Max                                   0.109374
exploration/Rewards Min                                  -0.327358
exploration/Returns Mean                                 -1.39235
exploration/Returns Std                                   1.24045
exploration/Returns Max                                  -0.41952
exploration/Returns Min                                  -3.74158
exploration/Actions Mean                                  0.00916096
exploration/Actions Std                                   0.148198
exploration/Actions Max                                   0.480632
exploration/Actions Min                                  -0.621169
exploration/Num Paths                                     5
exploration/Average Returns                              -1.39235
exploration/env_infos/final/reward_energy Mean           -0.224925
exploration/env_infos/final/reward_energy Std             0.161225
exploration/env_infos/final/reward_energy Max            -0.0884998
exploration/env_infos/final/reward_energy Min            -0.54046
exploration/env_infos/initial/reward_energy Mean         -0.298628
exploration/env_infos/initial/reward_energy Std           0.200386
exploration/env_infos/initial/reward_energy Max          -0.0434521
exploration/env_infos/initial/reward_energy Min          -0.601232
exploration/env_infos/reward_energy Mean                 -0.16504
exploration/env_infos/reward_energy Std                   0.129827
exploration/env_infos/reward_energy Max                  -0.0137225
exploration/env_infos/reward_energy Min                  -0.674562
exploration/env_infos/final/end_effector_loc Mean         0.0195925
exploration/env_infos/final/end_effector_loc Std          0.208124
exploration/env_infos/final/end_effector_loc Max          0.388042
exploration/env_infos/final/end_effector_loc Min         -0.237652
exploration/env_infos/initial/end_effector_loc Mean      -0.00520819
exploration/env_infos/initial/end_effector_loc Std        0.0115992
exploration/env_infos/initial/end_effector_loc Max        0.00670575
exploration/env_infos/initial/end_effector_loc Min       -0.0300286
exploration/env_infos/end_effector_loc Mean              -0.013712
exploration/env_infos/end_effector_loc Std                0.147221
exploration/env_infos/end_effector_loc Max                0.388042
exploration/env_infos/end_effector_loc Min               -0.368464
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0993876
exploration/env_infos/final/reward_dist Std               0.132517
exploration/env_infos/final/reward_dist Max               0.350332
exploration/env_infos/final/reward_dist Min               0.000125155
exploration/env_infos/initial/reward_dist Mean            0.00731658
exploration/env_infos/initial/reward_dist Std             0.00846513
exploration/env_infos/initial/reward_dist Max             0.0232054
exploration/env_infos/initial/reward_dist Min             6.07241e-05
exploration/env_infos/reward_dist Mean                    0.173291
exploration/env_infos/reward_dist Std                     0.246405
exploration/env_infos/reward_dist Max                     0.97937
exploration/env_infos/reward_dist Min                     6.07241e-05
evaluation/num steps total                           248000
evaluation/num paths total                            12400
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0891895
evaluation/Rewards Std                                    0.143839
evaluation/Rewards Max                                    0.152111
evaluation/Rewards Min                                   -1.26444
evaluation/Returns Mean                                  -1.78379
evaluation/Returns Std                                    2.39382
evaluation/Returns Max                                    1.74039
evaluation/Returns Min                                  -15.1661
evaluation/Actions Mean                                  -0.00810695
evaluation/Actions Std                                    0.112556
evaluation/Actions Max                                    0.670115
evaluation/Actions Min                                   -0.932032
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.78379
evaluation/env_infos/final/reward_energy Mean            -0.0649482
evaluation/env_infos/final/reward_energy Std              0.0874997
evaluation/env_infos/final/reward_energy Max             -0.00946391
evaluation/env_infos/final/reward_energy Min             -0.513397
evaluation/env_infos/initial/reward_energy Mean          -0.284735
evaluation/env_infos/initial/reward_energy Std            0.280149
evaluation/env_infos/initial/reward_energy Max           -0.0140756
evaluation/env_infos/initial/reward_energy Min           -1.11229
evaluation/env_infos/reward_energy Mean                  -0.0940091
evaluation/env_infos/reward_energy Std                    0.128962
evaluation/env_infos/reward_energy Max                   -0.00130369
evaluation/env_infos/reward_energy Min                   -1.11229
evaluation/env_infos/final/end_effector_loc Mean         -0.0787239
evaluation/env_infos/final/end_effector_loc Std           0.363959
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00230967
evaluation/env_infos/initial/end_effector_loc Std         0.0139324
evaluation/env_infos/initial/end_effector_loc Max         0.0335058
evaluation/env_infos/initial/end_effector_loc Min        -0.0466016
evaluation/env_infos/end_effector_loc Mean               -0.0419492
evaluation/env_infos/end_effector_loc Std                 0.23982
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.079324
evaluation/env_infos/final/reward_dist Std                0.157969
evaluation/env_infos/final/reward_dist Max                0.605742
evaluation/env_infos/final/reward_dist Min                1.80492e-106
evaluation/env_infos/initial/reward_dist Mean             0.00794422
evaluation/env_infos/initial/reward_dist Std              0.0140031
evaluation/env_infos/initial/reward_dist Max              0.0582434
evaluation/env_infos/initial/reward_dist Min              8.7852e-07
evaluation/env_infos/reward_dist Mean                     0.110318
evaluation/env_infos/reward_dist Std                      0.208724
evaluation/env_infos/reward_dist Max                      0.999905
evaluation/env_infos/reward_dist Min                      1.80492e-106
time/data storing (s)                                    38.3306
time/evaluation sampling (s)                              0.522597
time/exploration sampling (s)                             0.0921943
time/logging (s)                                          0.0148281
time/saving (s)                                           0.79386
time/training (s)                                        39.2447
time/epoch (s)                                           78.9988
time/total (s)                                        18670.9
Epoch                                                   247
---------------------------------------------------  -----------------
2021-05-29 05:08:27.325136 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 248 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00398642
trainer/QF2 Loss                                          0.00314895
trainer/Policy Loss                                       2.84601
trainer/Q1 Predictions Mean                              -0.899832
trainer/Q1 Predictions Std                                0.967794
trainer/Q1 Predictions Max                                1.11608
trainer/Q1 Predictions Min                               -3.28879
trainer/Q2 Predictions Mean                              -0.894328
trainer/Q2 Predictions Std                                0.97153
trainer/Q2 Predictions Max                                1.10886
trainer/Q2 Predictions Min                               -3.21894
trainer/Q Targets Mean                                   -0.894775
trainer/Q Targets Std                                     0.973453
trainer/Q Targets Max                                     1.17965
trainer/Q Targets Min                                    -3.26983
trainer/Log Pis Mean                                      1.95244
trainer/Log Pis Std                                       1.24732
trainer/Log Pis Max                                       4.49499
trainer/Log Pis Min                                      -3.32716
trainer/Policy mu Mean                                    0.0272098
trainer/Policy mu Std                                     0.305508
trainer/Policy mu Max                                     2.18865
trainer/Policy mu Min                                    -1.91457
trainer/Policy log std Mean                              -2.33004
trainer/Policy log std Std                                0.443967
trainer/Policy log std Max                               -0.606111
trainer/Policy log std Min                               -2.91299
trainer/Alpha                                             0.0204992
trainer/Alpha Loss                                       -0.185027
exploration/num steps total                           25900
exploration/num paths total                            1295
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.156547
exploration/Rewards Std                                   0.116178
exploration/Rewards Max                                   0.00470606
exploration/Rewards Min                                  -0.545634
exploration/Returns Mean                                 -3.13093
exploration/Returns Std                                   1.41772
exploration/Returns Max                                  -1.547
exploration/Returns Min                                  -5.61514
exploration/Actions Mean                                 -0.0671263
exploration/Actions Std                                   0.302464
exploration/Actions Max                                   0.965098
exploration/Actions Min                                  -0.933705
exploration/Num Paths                                     5
exploration/Average Returns                              -3.13093
exploration/env_infos/final/reward_energy Mean           -0.172807
exploration/env_infos/final/reward_energy Std             0.113025
exploration/env_infos/final/reward_energy Max            -0.0932022
exploration/env_infos/final/reward_energy Min            -0.393502
exploration/env_infos/initial/reward_energy Mean         -0.53126
exploration/env_infos/initial/reward_energy Std           0.522647
exploration/env_infos/initial/reward_energy Max          -0.087755
exploration/env_infos/initial/reward_energy Min          -1.25785
exploration/env_infos/reward_energy Mean                 -0.28971
exploration/env_infos/reward_energy Std                   0.328709
exploration/env_infos/reward_energy Max                  -0.0115815
exploration/env_infos/reward_energy Min                  -1.33668
exploration/env_infos/final/end_effector_loc Mean        -0.420521
exploration/env_infos/final/end_effector_loc Std          0.440721
exploration/env_infos/final/end_effector_loc Max          0.350163
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00998156
exploration/env_infos/initial/end_effector_loc Std        0.0243847
exploration/env_infos/initial/end_effector_loc Max        0.0357955
exploration/env_infos/initial/end_effector_loc Min       -0.0465251
exploration/env_infos/end_effector_loc Mean              -0.187816
exploration/env_infos/end_effector_loc Std                0.34131
exploration/env_infos/end_effector_loc Max                0.350163
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              6.32987e-05
exploration/env_infos/final/reward_dist Std               7.75518e-05
exploration/env_infos/final/reward_dist Max               0.000162285
exploration/env_infos/final/reward_dist Min               1.12101e-150
exploration/env_infos/initial/reward_dist Mean            0.0117659
exploration/env_infos/initial/reward_dist Std             0.0160764
exploration/env_infos/initial/reward_dist Max             0.0423927
exploration/env_infos/initial/reward_dist Min             5.07009e-05
exploration/env_infos/reward_dist Mean                    0.0654123
exploration/env_infos/reward_dist Std                     0.181282
exploration/env_infos/reward_dist Max                     0.943751
exploration/env_infos/reward_dist Min                     1.12101e-150
evaluation/num steps total                           249000
evaluation/num paths total                            12450
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0541292
evaluation/Rewards Std                                    0.0773668
evaluation/Rewards Max                                    0.154402
evaluation/Rewards Min                                   -0.515622
evaluation/Returns Mean                                  -1.08258
evaluation/Returns Std                                    1.06992
evaluation/Returns Max                                    1.11459
evaluation/Returns Min                                   -4.08168
evaluation/Actions Mean                                  -0.000798108
evaluation/Actions Std                                    0.125818
evaluation/Actions Max                                    0.953248
evaluation/Actions Min                                   -0.949478
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.08258
evaluation/env_infos/final/reward_energy Mean            -0.0707124
evaluation/env_infos/final/reward_energy Std              0.142181
evaluation/env_infos/final/reward_energy Max             -0.00595802
evaluation/env_infos/final/reward_energy Min             -0.964409
evaluation/env_infos/initial/reward_energy Mean          -0.272279
evaluation/env_infos/initial/reward_energy Std            0.274638
evaluation/env_infos/initial/reward_energy Max           -0.0209075
evaluation/env_infos/initial/reward_energy Min           -1.34543
evaluation/env_infos/reward_energy Mean                  -0.0938437
evaluation/env_infos/reward_energy Std                    0.151179
evaluation/env_infos/reward_energy Max                   -0.0020582
evaluation/env_infos/reward_energy Min                   -1.34543
evaluation/env_infos/final/end_effector_loc Mean         -0.0325721
evaluation/env_infos/final/end_effector_loc Std           0.291383
evaluation/env_infos/final/end_effector_loc Max           0.672264
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.0012251
evaluation/env_infos/initial/end_effector_loc Std         0.013618
evaluation/env_infos/initial/end_effector_loc Max         0.0476624
evaluation/env_infos/initial/end_effector_loc Min        -0.0474739
evaluation/env_infos/end_effector_loc Mean               -0.0222954
evaluation/env_infos/end_effector_loc Std                 0.191546
evaluation/env_infos/end_effector_loc Max                 0.672264
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.121467
evaluation/env_infos/final/reward_dist Std                0.226525
evaluation/env_infos/final/reward_dist Max                0.954648
evaluation/env_infos/final/reward_dist Min                1.36742e-103
evaluation/env_infos/initial/reward_dist Mean             0.00728881
evaluation/env_infos/initial/reward_dist Std              0.0149492
evaluation/env_infos/initial/reward_dist Max              0.0848255
evaluation/env_infos/initial/reward_dist Min              1.87015e-06
evaluation/env_infos/reward_dist Mean                     0.128184
evaluation/env_infos/reward_dist Std                      0.216271
evaluation/env_infos/reward_dist Max                      0.999189
evaluation/env_infos/reward_dist Min                      5.53103e-124
time/data storing (s)                                    38.613
time/evaluation sampling (s)                              0.649729
time/exploration sampling (s)                             0.0862638
time/logging (s)                                          0.0152249
time/saving (s)                                           0.798177
time/training (s)                                        39.6867
time/epoch (s)                                           79.8491
time/total (s)                                        18753.4
Epoch                                                   248
---------------------------------------------------  -----------------
2021-05-29 05:09:49.201365 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 249 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00401235
trainer/QF2 Loss                                          0.00781337
trainer/Policy Loss                                       2.98654
trainer/Q1 Predictions Mean                              -0.984671
trainer/Q1 Predictions Std                                0.961263
trainer/Q1 Predictions Max                                1.22355
trainer/Q1 Predictions Min                               -3.18287
trainer/Q2 Predictions Mean                              -0.953527
trainer/Q2 Predictions Std                                0.976578
trainer/Q2 Predictions Max                                1.35435
trainer/Q2 Predictions Min                               -3.21726
trainer/Q Targets Mean                                   -0.989876
trainer/Q Targets Std                                     0.963292
trainer/Q Targets Max                                     1.29978
trainer/Q Targets Min                                    -3.21309
trainer/Log Pis Mean                                      2.01972
trainer/Log Pis Std                                       1.11019
trainer/Log Pis Max                                       3.67243
trainer/Log Pis Min                                      -2.16085
trainer/Policy mu Mean                                   -0.0315668
trainer/Policy mu Std                                     0.276044
trainer/Policy mu Max                                     1.16263
trainer/Policy mu Min                                    -2.12921
trainer/Policy log std Mean                              -2.33617
trainer/Policy log std Std                                0.43774
trainer/Policy log std Max                               -0.173341
trainer/Policy log std Min                               -2.9339
trainer/Alpha                                             0.0204459
trainer/Alpha Loss                                        0.0766896
exploration/num steps total                           26000
exploration/num paths total                            1300
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0907995
exploration/Rewards Std                                   0.101952
exploration/Rewards Max                                   0.115422
exploration/Rewards Min                                  -0.2993
exploration/Returns Mean                                 -1.81599
exploration/Returns Std                                   1.61621
exploration/Returns Max                                   1.17681
exploration/Returns Min                                  -3.27842
exploration/Actions Mean                                  0.00764908
exploration/Actions Std                                   0.143056
exploration/Actions Max                                   0.460869
exploration/Actions Min                                  -0.549195
exploration/Num Paths                                     5
exploration/Average Returns                              -1.81599
exploration/env_infos/final/reward_energy Mean           -0.150529
exploration/env_infos/final/reward_energy Std             0.0574901
exploration/env_infos/final/reward_energy Max            -0.077729
exploration/env_infos/final/reward_energy Min            -0.237773
exploration/env_infos/initial/reward_energy Mean         -0.28407
exploration/env_infos/initial/reward_energy Std           0.199642
exploration/env_infos/initial/reward_energy Max          -0.0210444
exploration/env_infos/initial/reward_energy Min          -0.504223
exploration/env_infos/reward_energy Mean                 -0.164145
exploration/env_infos/reward_energy Std                   0.118759
exploration/env_infos/reward_energy Max                  -0.00179092
exploration/env_infos/reward_energy Min                  -0.578525
exploration/env_infos/final/end_effector_loc Mean        -0.109994
exploration/env_infos/final/end_effector_loc Std          0.239775
exploration/env_infos/final/end_effector_loc Max          0.222865
exploration/env_infos/final/end_effector_loc Min         -0.500138
exploration/env_infos/initial/end_effector_loc Mean       0.000981763
exploration/env_infos/initial/end_effector_loc Std        0.0122363
exploration/env_infos/initial/end_effector_loc Max        0.0208198
exploration/env_infos/initial/end_effector_loc Min       -0.0226357
exploration/env_infos/end_effector_loc Mean              -0.076609
exploration/env_infos/end_effector_loc Std                0.165461
exploration/env_infos/end_effector_loc Max                0.222865
exploration/env_infos/end_effector_loc Min               -0.500138
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0306226
exploration/env_infos/final/reward_dist Std               0.0540457
exploration/env_infos/final/reward_dist Max               0.13812
exploration/env_infos/final/reward_dist Min               4.36034e-10
exploration/env_infos/initial/reward_dist Mean            0.00491202
exploration/env_infos/initial/reward_dist Std             0.00751404
exploration/env_infos/initial/reward_dist Max             0.0197605
exploration/env_infos/initial/reward_dist Min             1.09685e-06
exploration/env_infos/reward_dist Mean                    0.138501
exploration/env_infos/reward_dist Std                     0.236884
exploration/env_infos/reward_dist Max                     0.951997
exploration/env_infos/reward_dist Min                     4.36034e-10
evaluation/num steps total                           250000
evaluation/num paths total                            12500
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0666294
evaluation/Rewards Std                                    0.0876226
evaluation/Rewards Max                                    0.141524
evaluation/Rewards Min                                   -0.633971
evaluation/Returns Mean                                  -1.33259
evaluation/Returns Std                                    1.33121
evaluation/Returns Max                                    1.2805
evaluation/Returns Min                                   -5.99894
evaluation/Actions Mean                                  -0.00298881
evaluation/Actions Std                                    0.113332
evaluation/Actions Max                                    0.927375
evaluation/Actions Min                                   -0.973004
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.33259
evaluation/env_infos/final/reward_energy Mean            -0.063829
evaluation/env_infos/final/reward_energy Std              0.05763
evaluation/env_infos/final/reward_energy Max             -0.00404059
evaluation/env_infos/final/reward_energy Min             -0.255239
evaluation/env_infos/initial/reward_energy Mean          -0.311736
evaluation/env_infos/initial/reward_energy Std            0.287147
evaluation/env_infos/initial/reward_energy Max           -0.0087064
evaluation/env_infos/initial/reward_energy Min           -1.22833
evaluation/env_infos/reward_energy Mean                  -0.099428
evaluation/env_infos/reward_energy Std                    0.125778
evaluation/env_infos/reward_energy Max                   -0.00404059
evaluation/env_infos/reward_energy Min                   -1.22833
evaluation/env_infos/final/end_effector_loc Mean         -0.0628783
evaluation/env_infos/final/end_effector_loc Std           0.309316
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000208588
evaluation/env_infos/initial/end_effector_loc Std         0.0149832
evaluation/env_infos/initial/end_effector_loc Max         0.0463688
evaluation/env_infos/initial/end_effector_loc Min        -0.0486502
evaluation/env_infos/end_effector_loc Mean               -0.030581
evaluation/env_infos/end_effector_loc Std                 0.208399
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.103121
evaluation/env_infos/final/reward_dist Std                0.222012
evaluation/env_infos/final/reward_dist Max                0.980754
evaluation/env_infos/final/reward_dist Min                6.97091e-106
evaluation/env_infos/initial/reward_dist Mean             0.00877048
evaluation/env_infos/initial/reward_dist Std              0.0257407
evaluation/env_infos/initial/reward_dist Max              0.152985
evaluation/env_infos/initial/reward_dist Min              1.30159e-06
evaluation/env_infos/reward_dist Mean                     0.125453
evaluation/env_infos/reward_dist Std                      0.228698
evaluation/env_infos/reward_dist Max                      0.999991
evaluation/env_infos/reward_dist Min                      6.97091e-106
time/data storing (s)                                    38.2745
time/evaluation sampling (s)                              0.630893
time/exploration sampling (s)                             0.09079
time/logging (s)                                          0.0145002
time/saving (s)                                           0.799063
time/training (s)                                        39.4153
time/epoch (s)                                           79.2251
time/total (s)                                        18835.3
Epoch                                                   249
---------------------------------------------------  -----------------
2021-05-29 05:11:12.484847 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 250 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00314337
trainer/QF2 Loss                                          0.00351218
trainer/Policy Loss                                       3.15553
trainer/Q1 Predictions Mean                              -0.979998
trainer/Q1 Predictions Std                                0.979259
trainer/Q1 Predictions Max                                1.5703
trainer/Q1 Predictions Min                               -3.10795
trainer/Q2 Predictions Mean                              -0.986952
trainer/Q2 Predictions Std                                0.982958
trainer/Q2 Predictions Max                                1.55884
trainer/Q2 Predictions Min                               -3.11901
trainer/Q Targets Mean                                   -0.986353
trainer/Q Targets Std                                     0.980078
trainer/Q Targets Max                                     1.56632
trainer/Q Targets Min                                    -3.14873
trainer/Log Pis Mean                                      2.17536
trainer/Log Pis Std                                       1.04478
trainer/Log Pis Max                                       3.7594
trainer/Log Pis Min                                      -1.77323
trainer/Policy mu Mean                                    0.00776792
trainer/Policy mu Std                                     0.320551
trainer/Policy mu Max                                     1.31911
trainer/Policy mu Min                                    -1.78682
trainer/Policy log std Mean                              -2.35329
trainer/Policy log std Std                                0.416663
trainer/Policy log std Max                               -0.723875
trainer/Policy log std Min                               -2.87727
trainer/Alpha                                             0.0212023
trainer/Alpha Loss                                        0.675917
exploration/num steps total                           26100
exploration/num paths total                            1305
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0896909
exploration/Rewards Std                                   0.0703406
exploration/Rewards Max                                   0.0777918
exploration/Rewards Min                                  -0.283285
exploration/Returns Mean                                 -1.79382
exploration/Returns Std                                   0.753789
exploration/Returns Max                                  -0.528787
exploration/Returns Min                                  -2.58569
exploration/Actions Mean                                 -0.00754246
exploration/Actions Std                                   0.0814108
exploration/Actions Max                                   0.391275
exploration/Actions Min                                  -0.338482
exploration/Num Paths                                     5
exploration/Average Returns                              -1.79382
exploration/env_infos/final/reward_energy Mean           -0.0644089
exploration/env_infos/final/reward_energy Std             0.0202817
exploration/env_infos/final/reward_energy Max            -0.039267
exploration/env_infos/final/reward_energy Min            -0.0939726
exploration/env_infos/initial/reward_energy Mean         -0.198819
exploration/env_infos/initial/reward_energy Std           0.139564
exploration/env_infos/initial/reward_energy Max          -0.0370169
exploration/env_infos/initial/reward_energy Min          -0.391516
exploration/env_infos/reward_energy Mean                 -0.0951598
exploration/env_infos/reward_energy Std                   0.0656797
exploration/env_infos/reward_energy Max                  -0.00681294
exploration/env_infos/reward_energy Min                  -0.391516
exploration/env_infos/final/end_effector_loc Mean        -0.0982572
exploration/env_infos/final/end_effector_loc Std          0.22871
exploration/env_infos/final/end_effector_loc Max          0.52005
exploration/env_infos/final/end_effector_loc Min         -0.340547
exploration/env_infos/initial/end_effector_loc Mean      -0.000920147
exploration/env_infos/initial/end_effector_loc Std        0.00853886
exploration/env_infos/initial/end_effector_loc Max        0.0195637
exploration/env_infos/initial/end_effector_loc Min       -0.0169241
exploration/env_infos/end_effector_loc Mean              -0.0449741
exploration/env_infos/end_effector_loc Std                0.138115
exploration/env_infos/end_effector_loc Max                0.52005
exploration/env_infos/end_effector_loc Min               -0.340547
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0963836
exploration/env_infos/final/reward_dist Std               0.176889
exploration/env_infos/final/reward_dist Max               0.44926
exploration/env_infos/final/reward_dist Min               6.24727e-11
exploration/env_infos/initial/reward_dist Mean            0.0067128
exploration/env_infos/initial/reward_dist Std             0.00547218
exploration/env_infos/initial/reward_dist Max             0.0123276
exploration/env_infos/initial/reward_dist Min             7.07515e-06
exploration/env_infos/reward_dist Mean                    0.131862
exploration/env_infos/reward_dist Std                     0.225649
exploration/env_infos/reward_dist Max                     0.99085
exploration/env_infos/reward_dist Min                     6.24727e-11
evaluation/num steps total                           251000
evaluation/num paths total                            12550
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0835402
evaluation/Rewards Std                                    0.100522
evaluation/Rewards Max                                    0.157836
evaluation/Rewards Min                                   -0.745935
evaluation/Returns Mean                                  -1.6708
evaluation/Returns Std                                    1.51141
evaluation/Returns Max                                    1.2787
evaluation/Returns Min                                   -7.87716
evaluation/Actions Mean                                  -0.000896289
evaluation/Actions Std                                    0.117835
evaluation/Actions Max                                    0.902055
evaluation/Actions Min                                   -0.931704
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.6708
evaluation/env_infos/final/reward_energy Mean            -0.0617165
evaluation/env_infos/final/reward_energy Std              0.0542221
evaluation/env_infos/final/reward_energy Max             -0.00846445
evaluation/env_infos/final/reward_energy Min             -0.224943
evaluation/env_infos/initial/reward_energy Mean          -0.321446
evaluation/env_infos/initial/reward_energy Std            0.287852
evaluation/env_infos/initial/reward_energy Max           -0.017148
evaluation/env_infos/initial/reward_energy Min           -1.05925
evaluation/env_infos/reward_energy Mean                  -0.0982319
evaluation/env_infos/reward_energy Std                    0.134619
evaluation/env_infos/reward_energy Max                   -0.00250133
evaluation/env_infos/reward_energy Min                   -1.05925
evaluation/env_infos/final/end_effector_loc Mean          0.0112513
evaluation/env_infos/final/end_effector_loc Std           0.35558
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000592628
evaluation/env_infos/initial/end_effector_loc Std         0.0152441
evaluation/env_infos/initial/end_effector_loc Max         0.0451027
evaluation/env_infos/initial/end_effector_loc Min        -0.0465852
evaluation/env_infos/end_effector_loc Mean                0.00482563
evaluation/env_infos/end_effector_loc Std                 0.236126
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.047246
evaluation/env_infos/final/reward_dist Std                0.0976249
evaluation/env_infos/final/reward_dist Max                0.452069
evaluation/env_infos/final/reward_dist Min                5.66324e-66
evaluation/env_infos/initial/reward_dist Mean             0.00581003
evaluation/env_infos/initial/reward_dist Std              0.0155084
evaluation/env_infos/initial/reward_dist Max              0.104257
evaluation/env_infos/initial/reward_dist Min              6.41494e-08
evaluation/env_infos/reward_dist Mean                     0.124624
evaluation/env_infos/reward_dist Std                      0.226708
evaluation/env_infos/reward_dist Max                      0.991399
evaluation/env_infos/reward_dist Min                      7.94863e-78
time/data storing (s)                                    38.3384
time/evaluation sampling (s)                              0.532047
time/exploration sampling (s)                             0.0869435
time/logging (s)                                          0.0169632
time/saving (s)                                           1.63508
time/training (s)                                        40.036
time/epoch (s)                                           80.6455
time/total (s)                                        18918.5
Epoch                                                   250
---------------------------------------------------  ----------------
2021-05-29 05:12:35.040731 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 251 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00315602
trainer/QF2 Loss                                          0.00343386
trainer/Policy Loss                                       2.87843
trainer/Q1 Predictions Mean                              -0.976178
trainer/Q1 Predictions Std                                0.965334
trainer/Q1 Predictions Max                                1.48162
trainer/Q1 Predictions Min                               -3.34836
trainer/Q2 Predictions Mean                              -0.99673
trainer/Q2 Predictions Std                                0.963557
trainer/Q2 Predictions Max                                1.48492
trainer/Q2 Predictions Min                               -3.39745
trainer/Q Targets Mean                                   -0.990524
trainer/Q Targets Std                                     0.977481
trainer/Q Targets Max                                     1.44224
trainer/Q Targets Min                                    -3.40373
trainer/Log Pis Mean                                      1.89155
trainer/Log Pis Std                                       1.09096
trainer/Log Pis Max                                       4.81891
trainer/Log Pis Min                                      -2.454
trainer/Policy mu Mean                                   -0.0175115
trainer/Policy mu Std                                     0.393663
trainer/Policy mu Max                                     2.21825
trainer/Policy mu Min                                    -2.56385
trainer/Policy log std Mean                              -2.21845
trainer/Policy log std Std                                0.481773
trainer/Policy log std Max                               -0.151526
trainer/Policy log std Min                               -2.83134
trainer/Alpha                                             0.0230697
trainer/Alpha Loss                                       -0.408664
exploration/num steps total                           26200
exploration/num paths total                            1310
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.096435
exploration/Rewards Std                                   0.0778569
exploration/Rewards Max                                   0.0801223
exploration/Rewards Min                                  -0.334295
exploration/Returns Mean                                 -1.9287
exploration/Returns Std                                   0.771122
exploration/Returns Max                                  -0.936806
exploration/Returns Min                                  -2.83063
exploration/Actions Mean                                 -0.00654924
exploration/Actions Std                                   0.155075
exploration/Actions Max                                   0.558416
exploration/Actions Min                                  -0.678
exploration/Num Paths                                     5
exploration/Average Returns                              -1.9287
exploration/env_infos/final/reward_energy Mean           -0.0951171
exploration/env_infos/final/reward_energy Std             0.0224356
exploration/env_infos/final/reward_energy Max            -0.0514409
exploration/env_infos/final/reward_energy Min            -0.113517
exploration/env_infos/initial/reward_energy Mean         -0.442667
exploration/env_infos/initial/reward_energy Std           0.263428
exploration/env_infos/initial/reward_energy Max          -0.148849
exploration/env_infos/initial/reward_energy Min          -0.856332
exploration/env_infos/reward_energy Mean                 -0.171016
exploration/env_infos/reward_energy Std                   0.137609
exploration/env_infos/reward_energy Max                  -0.0216513
exploration/env_infos/reward_energy Min                  -0.856332
exploration/env_infos/final/end_effector_loc Mean        -0.129342
exploration/env_infos/final/end_effector_loc Std          0.282453
exploration/env_infos/final/end_effector_loc Max          0.331533
exploration/env_infos/final/end_effector_loc Min         -0.535129
exploration/env_infos/initial/end_effector_loc Mean      -0.0029892
exploration/env_infos/initial/end_effector_loc Std        0.0179652
exploration/env_infos/initial/end_effector_loc Max        0.0279208
exploration/env_infos/initial/end_effector_loc Min       -0.0329827
exploration/env_infos/end_effector_loc Mean              -0.0645395
exploration/env_infos/end_effector_loc Std                0.197409
exploration/env_infos/end_effector_loc Max                0.33404
exploration/env_infos/end_effector_loc Min               -0.535129
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0109391
exploration/env_infos/final/reward_dist Std               0.0183421
exploration/env_infos/final/reward_dist Max               0.0471554
exploration/env_infos/final/reward_dist Min               9.58453e-23
exploration/env_infos/initial/reward_dist Mean            0.00841724
exploration/env_infos/initial/reward_dist Std             0.00684343
exploration/env_infos/initial/reward_dist Max             0.0145286
exploration/env_infos/initial/reward_dist Min             4.57809e-05
exploration/env_infos/reward_dist Mean                    0.144425
exploration/env_infos/reward_dist Std                     0.261114
exploration/env_infos/reward_dist Max                     0.984026
exploration/env_infos/reward_dist Min                     9.58453e-23
evaluation/num steps total                           252000
evaluation/num paths total                            12600
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.060922
evaluation/Rewards Std                                    0.0786291
evaluation/Rewards Max                                    0.140167
evaluation/Rewards Min                                   -0.403842
evaluation/Returns Mean                                  -1.21844
evaluation/Returns Std                                    1.19743
evaluation/Returns Max                                    1.39252
evaluation/Returns Min                                   -4.25191
evaluation/Actions Mean                                  -0.00544334
evaluation/Actions Std                                    0.105746
evaluation/Actions Max                                    0.947108
evaluation/Actions Min                                   -0.752968
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.21844
evaluation/env_infos/final/reward_energy Mean            -0.0633751
evaluation/env_infos/final/reward_energy Std              0.0421347
evaluation/env_infos/final/reward_energy Max             -0.0133448
evaluation/env_infos/final/reward_energy Min             -0.178068
evaluation/env_infos/initial/reward_energy Mean          -0.318597
evaluation/env_infos/initial/reward_energy Std            0.261696
evaluation/env_infos/initial/reward_energy Max           -0.00926775
evaluation/env_infos/initial/reward_energy Min           -1.06717
evaluation/env_infos/reward_energy Mean                  -0.0969815
evaluation/env_infos/reward_energy Std                    0.114097
evaluation/env_infos/reward_energy Max                   -0.00098136
evaluation/env_infos/reward_energy Min                   -1.06717
evaluation/env_infos/final/end_effector_loc Mean         -0.0752775
evaluation/env_infos/final/end_effector_loc Std           0.327
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.915549
evaluation/env_infos/initial/end_effector_loc Mean       -0.00098645
evaluation/env_infos/initial/end_effector_loc Std         0.0145435
evaluation/env_infos/initial/end_effector_loc Max         0.0473554
evaluation/env_infos/initial/end_effector_loc Min        -0.0376484
evaluation/env_infos/end_effector_loc Mean               -0.030369
evaluation/env_infos/end_effector_loc Std                 0.203549
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.915549
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0663781
evaluation/env_infos/final/reward_dist Std                0.143729
evaluation/env_infos/final/reward_dist Max                0.540653
evaluation/env_infos/final/reward_dist Min                2.32874e-74
evaluation/env_infos/initial/reward_dist Mean             0.00788902
evaluation/env_infos/initial/reward_dist Std              0.0173712
evaluation/env_infos/initial/reward_dist Max              0.0903149
evaluation/env_infos/initial/reward_dist Min              1.69505e-06
evaluation/env_infos/reward_dist Mean                     0.14098
evaluation/env_infos/reward_dist Std                      0.221706
evaluation/env_infos/reward_dist Max                      0.992512
evaluation/env_infos/reward_dist Min                      2.32874e-74
time/data storing (s)                                    38.1624
time/evaluation sampling (s)                              0.660947
time/exploration sampling (s)                             0.0900774
time/logging (s)                                          0.0159817
time/saving (s)                                           0.795331
time/training (s)                                        40.0934
time/epoch (s)                                           79.8182
time/total (s)                                        19001.1
Epoch                                                   251
---------------------------------------------------  ----------------
2021-05-29 05:13:58.077609 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 252 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00444813
trainer/QF2 Loss                                          0.00482927
trainer/Policy Loss                                       2.77838
trainer/Q1 Predictions Mean                              -0.890785
trainer/Q1 Predictions Std                                0.86619
trainer/Q1 Predictions Max                                1.37654
trainer/Q1 Predictions Min                               -3.01586
trainer/Q2 Predictions Mean                              -0.875305
trainer/Q2 Predictions Std                                0.879502
trainer/Q2 Predictions Max                                1.43266
trainer/Q2 Predictions Min                               -3.00768
trainer/Q Targets Mean                                   -0.878908
trainer/Q Targets Std                                     0.875765
trainer/Q Targets Max                                     1.50776
trainer/Q Targets Min                                    -3.02735
trainer/Log Pis Mean                                      1.91127
trainer/Log Pis Std                                       1.25985
trainer/Log Pis Max                                       4.99556
trainer/Log Pis Min                                      -6.9882
trainer/Policy mu Mean                                   -0.00280804
trainer/Policy mu Std                                     0.436226
trainer/Policy mu Max                                     2.1285
trainer/Policy mu Min                                    -2.42372
trainer/Policy log std Mean                              -2.23819
trainer/Policy log std Std                                0.485945
trainer/Policy log std Max                               -0.446131
trainer/Policy log std Min                               -2.89975
trainer/Alpha                                             0.0221325
trainer/Alpha Loss                                       -0.338233
exploration/num steps total                           26300
exploration/num paths total                            1315
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0708062
exploration/Rewards Std                                   0.0756315
exploration/Rewards Max                                   0.0939297
exploration/Rewards Min                                  -0.253941
exploration/Returns Mean                                 -1.41612
exploration/Returns Std                                   1.09058
exploration/Returns Max                                  -0.113215
exploration/Returns Min                                  -3.02932
exploration/Actions Mean                                 -0.00478879
exploration/Actions Std                                   0.137567
exploration/Actions Max                                   0.631822
exploration/Actions Min                                  -0.959018
exploration/Num Paths                                     5
exploration/Average Returns                              -1.41612
exploration/env_infos/final/reward_energy Mean           -0.114327
exploration/env_infos/final/reward_energy Std             0.0680549
exploration/env_infos/final/reward_energy Max            -0.0310746
exploration/env_infos/final/reward_energy Min            -0.225459
exploration/env_infos/initial/reward_energy Mean         -0.372106
exploration/env_infos/initial/reward_energy Std           0.32652
exploration/env_infos/initial/reward_energy Max          -0.12961
exploration/env_infos/initial/reward_energy Min          -0.99097
exploration/env_infos/reward_energy Mean                 -0.142486
exploration/env_infos/reward_energy Std                   0.132638
exploration/env_infos/reward_energy Max                  -0.0135719
exploration/env_infos/reward_energy Min                  -0.99097
exploration/env_infos/final/end_effector_loc Mean        -0.128701
exploration/env_infos/final/end_effector_loc Std          0.159184
exploration/env_infos/final/end_effector_loc Max          0.138115
exploration/env_infos/final/end_effector_loc Min         -0.381155
exploration/env_infos/initial/end_effector_loc Mean      -0.00709697
exploration/env_infos/initial/end_effector_loc Std        0.0159994
exploration/env_infos/initial/end_effector_loc Max        0.0124807
exploration/env_infos/initial/end_effector_loc Min       -0.0479509
exploration/env_infos/end_effector_loc Mean              -0.0763163
exploration/env_infos/end_effector_loc Std                0.122224
exploration/env_infos/end_effector_loc Max                0.138115
exploration/env_infos/end_effector_loc Min               -0.381155
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.100023
exploration/env_infos/final/reward_dist Std               0.132795
exploration/env_infos/final/reward_dist Max               0.336268
exploration/env_infos/final/reward_dist Min               0.000130538
exploration/env_infos/initial/reward_dist Mean            0.0324512
exploration/env_infos/initial/reward_dist Std             0.0364004
exploration/env_infos/initial/reward_dist Max             0.10012
exploration/env_infos/initial/reward_dist Min             6.80362e-05
exploration/env_infos/reward_dist Mean                    0.196869
exploration/env_infos/reward_dist Std                     0.227267
exploration/env_infos/reward_dist Max                     0.924753
exploration/env_infos/reward_dist Min                     6.80362e-05
evaluation/num steps total                           253000
evaluation/num paths total                            12650
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.100648
evaluation/Rewards Std                                    0.128363
evaluation/Rewards Max                                    0.115108
evaluation/Rewards Min                                   -0.840663
evaluation/Returns Mean                                  -2.01295
evaluation/Returns Std                                    2.2356
evaluation/Returns Max                                    0.378699
evaluation/Returns Min                                  -13.7916
evaluation/Actions Mean                                  -0.0183807
evaluation/Actions Std                                    0.169775
evaluation/Actions Max                                    0.990651
evaluation/Actions Min                                   -0.974339
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.01295
evaluation/env_infos/final/reward_energy Mean            -0.0987862
evaluation/env_infos/final/reward_energy Std              0.190209
evaluation/env_infos/final/reward_energy Max             -0.00318339
evaluation/env_infos/final/reward_energy Min             -0.996769
evaluation/env_infos/initial/reward_energy Mean          -0.376693
evaluation/env_infos/initial/reward_energy Std            0.326046
evaluation/env_infos/initial/reward_energy Max           -0.0174764
evaluation/env_infos/initial/reward_energy Min           -1.25487
evaluation/env_infos/reward_energy Mean                  -0.127597
evaluation/env_infos/reward_energy Std                    0.205041
evaluation/env_infos/reward_energy Max                   -0.00266125
evaluation/env_infos/reward_energy Min                   -1.26659
evaluation/env_infos/final/end_effector_loc Mean         -0.0498504
evaluation/env_infos/final/end_effector_loc Std           0.339186
evaluation/env_infos/final/end_effector_loc Max           0.588558
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000616728
evaluation/env_infos/initial/end_effector_loc Std         0.0176033
evaluation/env_infos/initial/end_effector_loc Max         0.0495326
evaluation/env_infos/initial/end_effector_loc Min        -0.0469053
evaluation/env_infos/end_effector_loc Mean               -0.0240256
evaluation/env_infos/end_effector_loc Std                 0.25225
evaluation/env_infos/end_effector_loc Max                 0.588558
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.131625
evaluation/env_infos/final/reward_dist Std                0.250609
evaluation/env_infos/final/reward_dist Max                0.981716
evaluation/env_infos/final/reward_dist Min                6.96709e-91
evaluation/env_infos/initial/reward_dist Mean             0.0097579
evaluation/env_infos/initial/reward_dist Std              0.0322457
evaluation/env_infos/initial/reward_dist Max              0.216658
evaluation/env_infos/initial/reward_dist Min              1.22831e-06
evaluation/env_infos/reward_dist Mean                     0.135371
evaluation/env_infos/reward_dist Std                      0.24458
evaluation/env_infos/reward_dist Max                      0.993107
evaluation/env_infos/reward_dist Min                      8.36274e-93
time/data storing (s)                                    38.689
time/evaluation sampling (s)                              0.657689
time/exploration sampling (s)                             0.0867438
time/logging (s)                                          0.0162487
time/saving (s)                                           0.798162
time/training (s)                                        39.6829
time/epoch (s)                                           79.9307
time/total (s)                                        19084.1
Epoch                                                   252
---------------------------------------------------  ----------------
2021-05-29 05:15:20.332472 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 253 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00529785
trainer/QF2 Loss                                          0.00388105
trainer/Policy Loss                                       2.86912
trainer/Q1 Predictions Mean                              -1.02537
trainer/Q1 Predictions Std                                0.865647
trainer/Q1 Predictions Max                                2.0514
trainer/Q1 Predictions Min                               -3.0075
trainer/Q2 Predictions Mean                              -1.02646
trainer/Q2 Predictions Std                                0.871852
trainer/Q2 Predictions Max                                2.1172
trainer/Q2 Predictions Min                               -2.98263
trainer/Q Targets Mean                                   -1.02885
trainer/Q Targets Std                                     0.875715
trainer/Q Targets Max                                     2.13202
trainer/Q Targets Min                                    -3.06315
trainer/Log Pis Mean                                      1.85258
trainer/Log Pis Std                                       1.32587
trainer/Log Pis Max                                       6.50033
trainer/Log Pis Min                                      -3.50712
trainer/Policy mu Mean                                   -0.00562894
trainer/Policy mu Std                                     0.428436
trainer/Policy mu Max                                     3.04391
trainer/Policy mu Min                                    -2.71494
trainer/Policy log std Mean                              -2.25346
trainer/Policy log std Std                                0.509265
trainer/Policy log std Max                                0.100812
trainer/Policy log std Min                               -2.95173
trainer/Alpha                                             0.0234673
trainer/Alpha Loss                                       -0.552957
exploration/num steps total                           26400
exploration/num paths total                            1320
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.112722
exploration/Rewards Std                                   0.0779981
exploration/Rewards Max                                   0.0483349
exploration/Rewards Min                                  -0.474923
exploration/Returns Mean                                 -2.25445
exploration/Returns Std                                   0.912459
exploration/Returns Max                                  -1.21685
exploration/Returns Min                                  -3.70618
exploration/Actions Mean                                 -0.011557
exploration/Actions Std                                   0.107342
exploration/Actions Max                                   0.445297
exploration/Actions Min                                  -0.36619
exploration/Num Paths                                     5
exploration/Average Returns                              -2.25445
exploration/env_infos/final/reward_energy Mean           -0.117474
exploration/env_infos/final/reward_energy Std             0.0445586
exploration/env_infos/final/reward_energy Max            -0.0586152
exploration/env_infos/final/reward_energy Min            -0.195219
exploration/env_infos/initial/reward_energy Mean         -0.255148
exploration/env_infos/initial/reward_energy Std           0.193173
exploration/env_infos/initial/reward_energy Max          -0.0337338
exploration/env_infos/initial/reward_energy Min          -0.500105
exploration/env_infos/reward_energy Mean                 -0.124155
exploration/env_infos/reward_energy Std                   0.088867
exploration/env_infos/reward_energy Max                  -0.013164
exploration/env_infos/reward_energy Min                  -0.500105
exploration/env_infos/final/end_effector_loc Mean        -0.0948641
exploration/env_infos/final/end_effector_loc Std          0.307618
exploration/env_infos/final/end_effector_loc Max          0.20598
exploration/env_infos/final/end_effector_loc Min         -0.854135
exploration/env_infos/initial/end_effector_loc Mean       0.003209
exploration/env_infos/initial/end_effector_loc Std        0.01085
exploration/env_infos/initial/end_effector_loc Max        0.0222648
exploration/env_infos/initial/end_effector_loc Min       -0.0183095
exploration/env_infos/end_effector_loc Mean              -0.0207807
exploration/env_infos/end_effector_loc Std                0.168999
exploration/env_infos/end_effector_loc Max                0.20598
exploration/env_infos/end_effector_loc Min               -0.854135
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.291012
exploration/env_infos/final/reward_dist Std               0.380576
exploration/env_infos/final/reward_dist Max               0.938533
exploration/env_infos/final/reward_dist Min               1.72627e-34
exploration/env_infos/initial/reward_dist Mean            0.0022366
exploration/env_infos/initial/reward_dist Std             0.00296121
exploration/env_infos/initial/reward_dist Max             0.00784029
exploration/env_infos/initial/reward_dist Min             1.24174e-05
exploration/env_infos/reward_dist Mean                    0.0537403
exploration/env_infos/reward_dist Std                     0.162995
exploration/env_infos/reward_dist Max                     0.938533
exploration/env_infos/reward_dist Min                     1.72627e-34
evaluation/num steps total                           254000
evaluation/num paths total                            12700
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.101755
evaluation/Rewards Std                                    0.140918
evaluation/Rewards Max                                    0.121638
evaluation/Rewards Min                                   -1.00526
evaluation/Returns Mean                                  -2.03509
evaluation/Returns Std                                    2.38643
evaluation/Returns Max                                    0.995377
evaluation/Returns Min                                  -14.3588
evaluation/Actions Mean                                  -0.0266724
evaluation/Actions Std                                    0.161209
evaluation/Actions Max                                    0.846282
evaluation/Actions Min                                   -0.995334
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.03509
evaluation/env_infos/final/reward_energy Mean            -0.0929805
evaluation/env_infos/final/reward_energy Std              0.174766
evaluation/env_infos/final/reward_energy Max             -0.00450107
evaluation/env_infos/final/reward_energy Min             -0.961184
evaluation/env_infos/initial/reward_energy Mean          -0.360043
evaluation/env_infos/initial/reward_energy Std            0.322752
evaluation/env_infos/initial/reward_energy Max           -0.0185973
evaluation/env_infos/initial/reward_energy Min           -1.28054
evaluation/env_infos/reward_energy Mean                  -0.121986
evaluation/env_infos/reward_energy Std                    0.196263
evaluation/env_infos/reward_energy Max                   -0.00311498
evaluation/env_infos/reward_energy Min                   -1.28054
evaluation/env_infos/final/end_effector_loc Mean         -0.109519
evaluation/env_infos/final/end_effector_loc Std           0.324387
evaluation/env_infos/final/end_effector_loc Max           0.595044
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00182006
evaluation/env_infos/initial/end_effector_loc Std         0.0169982
evaluation/env_infos/initial/end_effector_loc Max         0.0423141
evaluation/env_infos/initial/end_effector_loc Min        -0.0497667
evaluation/env_infos/end_effector_loc Mean               -0.0507057
evaluation/env_infos/end_effector_loc Std                 0.226915
evaluation/env_infos/end_effector_loc Max                 0.595044
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0399917
evaluation/env_infos/final/reward_dist Std                0.117238
evaluation/env_infos/final/reward_dist Max                0.721134
evaluation/env_infos/final/reward_dist Min                6.75729e-128
evaluation/env_infos/initial/reward_dist Mean             0.00350164
evaluation/env_infos/initial/reward_dist Std              0.00603129
evaluation/env_infos/initial/reward_dist Max              0.0231948
evaluation/env_infos/initial/reward_dist Min              1.96539e-06
evaluation/env_infos/reward_dist Mean                     0.0991837
evaluation/env_infos/reward_dist Std                      0.215245
evaluation/env_infos/reward_dist Max                      0.988566
evaluation/env_infos/reward_dist Min                      6.75729e-128
time/data storing (s)                                    38.1455
time/evaluation sampling (s)                              0.659517
time/exploration sampling (s)                             0.0815411
time/logging (s)                                          0.0145989
time/saving (s)                                           0.790446
time/training (s)                                        39.8674
time/epoch (s)                                           79.559
time/total (s)                                        19166.4
Epoch                                                   253
---------------------------------------------------  -----------------
2021-05-29 05:16:41.804465 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 254 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00353899
trainer/QF2 Loss                                          0.00338095
trainer/Policy Loss                                       2.85785
trainer/Q1 Predictions Mean                              -0.870995
trainer/Q1 Predictions Std                                0.900613
trainer/Q1 Predictions Max                                1.28591
trainer/Q1 Predictions Min                               -3.19665
trainer/Q2 Predictions Mean                              -0.892647
trainer/Q2 Predictions Std                                0.899582
trainer/Q2 Predictions Max                                1.32408
trainer/Q2 Predictions Min                               -3.40871
trainer/Q Targets Mean                                   -0.878325
trainer/Q Targets Std                                     0.90553
trainer/Q Targets Max                                     1.34983
trainer/Q Targets Min                                    -3.39062
trainer/Log Pis Mean                                      1.97339
trainer/Log Pis Std                                       1.22573
trainer/Log Pis Max                                       4.07541
trainer/Log Pis Min                                      -4.74908
trainer/Policy mu Mean                                   -0.00484901
trainer/Policy mu Std                                     0.340502
trainer/Policy mu Max                                     1.8386
trainer/Policy mu Min                                    -2.22959
trainer/Policy log std Mean                              -2.32541
trainer/Policy log std Std                                0.42289
trainer/Policy log std Max                               -0.512823
trainer/Policy log std Min                               -2.78005
trainer/Alpha                                             0.0249615
trainer/Alpha Loss                                       -0.0981945
exploration/num steps total                           26500
exploration/num paths total                            1325
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.131114
exploration/Rewards Std                                   0.195136
exploration/Rewards Max                                   0.0912142
exploration/Rewards Min                                  -0.913502
exploration/Returns Mean                                 -2.62227
exploration/Returns Std                                   2.96779
exploration/Returns Max                                   0.218561
exploration/Returns Min                                  -8.05616
exploration/Actions Mean                                 -0.0176355
exploration/Actions Std                                   0.163813
exploration/Actions Max                                   0.577963
exploration/Actions Min                                  -0.52205
exploration/Num Paths                                     5
exploration/Average Returns                              -2.62227
exploration/env_infos/final/reward_energy Mean           -0.174027
exploration/env_infos/final/reward_energy Std             0.157821
exploration/env_infos/final/reward_energy Max            -0.0337157
exploration/env_infos/final/reward_energy Min            -0.457292
exploration/env_infos/initial/reward_energy Mean         -0.427454
exploration/env_infos/initial/reward_energy Std           0.160019
exploration/env_infos/initial/reward_energy Max          -0.145233
exploration/env_infos/initial/reward_energy Min          -0.593408
exploration/env_infos/reward_energy Mean                 -0.183005
exploration/env_infos/reward_energy Std                   0.144225
exploration/env_infos/reward_energy Max                  -0.00250913
exploration/env_infos/reward_energy Min                  -0.593408
exploration/env_infos/final/end_effector_loc Mean        -0.0931253
exploration/env_infos/final/end_effector_loc Std          0.340407
exploration/env_infos/final/end_effector_loc Max          0.31803
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00303713
exploration/env_infos/initial/end_effector_loc Std        0.0158487
exploration/env_infos/initial/end_effector_loc Max        0.0288982
exploration/env_infos/initial/end_effector_loc Min       -0.0220329
exploration/env_infos/end_effector_loc Mean              -0.0336447
exploration/env_infos/end_effector_loc Std                0.21843
exploration/env_infos/end_effector_loc Max                0.31803
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.177978
exploration/env_infos/final/reward_dist Std               0.240322
exploration/env_infos/final/reward_dist Max               0.645195
exploration/env_infos/final/reward_dist Min               1.88132e-67
exploration/env_infos/initial/reward_dist Mean            0.00376222
exploration/env_infos/initial/reward_dist Std             0.00360732
exploration/env_infos/initial/reward_dist Max             0.00972347
exploration/env_infos/initial/reward_dist Min             8.85197e-05
exploration/env_infos/reward_dist Mean                    0.268675
exploration/env_infos/reward_dist Std                     0.321415
exploration/env_infos/reward_dist Max                     0.977669
exploration/env_infos/reward_dist Min                     1.88132e-67
evaluation/num steps total                           255000
evaluation/num paths total                            12750
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0954441
evaluation/Rewards Std                                    0.156468
evaluation/Rewards Max                                    0.156012
evaluation/Rewards Min                                   -1.01355
evaluation/Returns Mean                                  -1.90888
evaluation/Returns Std                                    2.77894
evaluation/Returns Max                                    1.87647
evaluation/Returns Min                                  -15.2853
evaluation/Actions Mean                                  -0.0255045
evaluation/Actions Std                                    0.143601
evaluation/Actions Max                                    0.927322
evaluation/Actions Min                                   -0.999267
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.90888
evaluation/env_infos/final/reward_energy Mean            -0.10562
evaluation/env_infos/final/reward_energy Std              0.176834
evaluation/env_infos/final/reward_energy Max             -0.010605
evaluation/env_infos/final/reward_energy Min             -0.852771
evaluation/env_infos/initial/reward_energy Mean          -0.300486
evaluation/env_infos/initial/reward_energy Std            0.300277
evaluation/env_infos/initial/reward_energy Max           -0.0182219
evaluation/env_infos/initial/reward_energy Min           -1.17892
evaluation/env_infos/reward_energy Mean                  -0.109382
evaluation/env_infos/reward_energy Std                    0.174869
evaluation/env_infos/reward_energy Max                   -0.000956124
evaluation/env_infos/reward_energy Min                   -1.3011
evaluation/env_infos/final/end_effector_loc Mean         -0.131818
evaluation/env_infos/final/end_effector_loc Std           0.300513
evaluation/env_infos/final/end_effector_loc Max           0.429479
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00146814
evaluation/env_infos/initial/end_effector_loc Std         0.0149471
evaluation/env_infos/initial/end_effector_loc Max         0.0463661
evaluation/env_infos/initial/end_effector_loc Min        -0.0499633
evaluation/env_infos/end_effector_loc Mean               -0.0584976
evaluation/env_infos/end_effector_loc Std                 0.214696
evaluation/env_infos/end_effector_loc Max                 0.440145
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.108508
evaluation/env_infos/final/reward_dist Std                0.190158
evaluation/env_infos/final/reward_dist Max                0.761876
evaluation/env_infos/final/reward_dist Min                7.56076e-156
evaluation/env_infos/initial/reward_dist Mean             0.0146841
evaluation/env_infos/initial/reward_dist Std              0.0299199
evaluation/env_infos/initial/reward_dist Max              0.181355
evaluation/env_infos/initial/reward_dist Min              4.88524e-08
evaluation/env_infos/reward_dist Mean                     0.108014
evaluation/env_infos/reward_dist Std                      0.205606
evaluation/env_infos/reward_dist Max                      0.966946
evaluation/env_infos/reward_dist Min                      7.56076e-156
time/data storing (s)                                    38.0837
time/evaluation sampling (s)                              0.53782
time/exploration sampling (s)                             0.088772
time/logging (s)                                          0.0141154
time/saving (s)                                           0.774339
time/training (s)                                        39.329
time/epoch (s)                                           78.8278
time/total (s)                                        19247.8
Epoch                                                   254
---------------------------------------------------  -----------------
2021-05-29 05:18:03.509978 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 255 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0039973
trainer/QF2 Loss                                          0.00550758
trainer/Policy Loss                                       3.03943
trainer/Q1 Predictions Mean                              -0.906816
trainer/Q1 Predictions Std                                0.874785
trainer/Q1 Predictions Max                                3.5803
trainer/Q1 Predictions Min                               -3.03377
trainer/Q2 Predictions Mean                              -0.899849
trainer/Q2 Predictions Std                                0.870856
trainer/Q2 Predictions Max                                3.56656
trainer/Q2 Predictions Min                               -2.99959
trainer/Q Targets Mean                                   -0.900306
trainer/Q Targets Std                                     0.877374
trainer/Q Targets Max                                     3.64057
trainer/Q Targets Min                                    -2.98903
trainer/Log Pis Mean                                      2.13914
trainer/Log Pis Std                                       1.19849
trainer/Log Pis Max                                       6.09535
trainer/Log Pis Min                                      -3.17522
trainer/Policy mu Mean                                    0.0367668
trainer/Policy mu Std                                     0.417838
trainer/Policy mu Max                                     4.35435
trainer/Policy mu Min                                    -1.72814
trainer/Policy log std Mean                              -2.32758
trainer/Policy log std Std                                0.506876
trainer/Policy log std Max                                0.313169
trainer/Policy log std Min                               -2.92131
trainer/Alpha                                             0.0249777
trainer/Alpha Loss                                        0.513627
exploration/num steps total                           26600
exploration/num paths total                            1330
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0696889
exploration/Rewards Std                                   0.0866555
exploration/Rewards Max                                   0.132265
exploration/Rewards Min                                  -0.307791
exploration/Returns Mean                                 -1.39378
exploration/Returns Std                                   1.27222
exploration/Returns Max                                   0.518722
exploration/Returns Min                                  -3.26263
exploration/Actions Mean                                 -0.00511803
exploration/Actions Std                                   0.148704
exploration/Actions Max                                   0.495529
exploration/Actions Min                                  -0.486232
exploration/Num Paths                                     5
exploration/Average Returns                              -1.39378
exploration/env_infos/final/reward_energy Mean           -0.0677998
exploration/env_infos/final/reward_energy Std             0.0199653
exploration/env_infos/final/reward_energy Max            -0.0409427
exploration/env_infos/final/reward_energy Min            -0.0979919
exploration/env_infos/initial/reward_energy Mean         -0.2187
exploration/env_infos/initial/reward_energy Std           0.130932
exploration/env_infos/initial/reward_energy Max          -0.0214461
exploration/env_infos/initial/reward_energy Min          -0.407989
exploration/env_infos/reward_energy Mean                 -0.170571
exploration/env_infos/reward_energy Std                   0.123222
exploration/env_infos/reward_energy Max                  -0.0162579
exploration/env_infos/reward_energy Min                  -0.568116
exploration/env_infos/final/end_effector_loc Mean         0.0687629
exploration/env_infos/final/end_effector_loc Std          0.26857
exploration/env_infos/final/end_effector_loc Max          0.59457
exploration/env_infos/final/end_effector_loc Min         -0.306868
exploration/env_infos/initial/end_effector_loc Mean       0.000243314
exploration/env_infos/initial/end_effector_loc Std        0.0090087
exploration/env_infos/initial/end_effector_loc Max        0.0151238
exploration/env_infos/initial/end_effector_loc Min       -0.0155813
exploration/env_infos/end_effector_loc Mean               0.0551026
exploration/env_infos/end_effector_loc Std                0.198765
exploration/env_infos/end_effector_loc Max                0.601159
exploration/env_infos/end_effector_loc Min               -0.420595
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0753635
exploration/env_infos/final/reward_dist Std               0.141531
exploration/env_infos/final/reward_dist Max               0.358337
exploration/env_infos/final/reward_dist Min               7.90439e-10
exploration/env_infos/initial/reward_dist Mean            0.00184905
exploration/env_infos/initial/reward_dist Std             0.002944
exploration/env_infos/initial/reward_dist Max             0.00764431
exploration/env_infos/initial/reward_dist Min             1.33829e-06
exploration/env_infos/reward_dist Mean                    0.0962307
exploration/env_infos/reward_dist Std                     0.182281
exploration/env_infos/reward_dist Max                     0.894856
exploration/env_infos/reward_dist Min                     4.96963e-10
evaluation/num steps total                           256000
evaluation/num paths total                            12800
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0683345
evaluation/Rewards Std                                    0.118751
evaluation/Rewards Max                                    0.133124
evaluation/Rewards Min                                   -0.789139
evaluation/Returns Mean                                  -1.36669
evaluation/Returns Std                                    1.96931
evaluation/Returns Max                                    1.38226
evaluation/Returns Min                                  -10.409
evaluation/Actions Mean                                  -0.0116563
evaluation/Actions Std                                    0.138551
evaluation/Actions Max                                    0.814527
evaluation/Actions Min                                   -0.98658
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.36669
evaluation/env_infos/final/reward_energy Mean            -0.0651138
evaluation/env_infos/final/reward_energy Std              0.102768
evaluation/env_infos/final/reward_energy Max             -0.00191472
evaluation/env_infos/final/reward_energy Min             -0.692025
evaluation/env_infos/initial/reward_energy Mean          -0.333352
evaluation/env_infos/initial/reward_energy Std            0.274229
evaluation/env_infos/initial/reward_energy Max           -0.0180504
evaluation/env_infos/initial/reward_energy Min           -1.32307
evaluation/env_infos/reward_energy Mean                  -0.102762
evaluation/env_infos/reward_energy Std                    0.167643
evaluation/env_infos/reward_energy Max                   -0.00191472
evaluation/env_infos/reward_energy Min                   -1.38916
evaluation/env_infos/final/end_effector_loc Mean          0.00989729
evaluation/env_infos/final/end_effector_loc Std           0.329158
evaluation/env_infos/final/end_effector_loc Max           0.634773
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000591622
evaluation/env_infos/initial/end_effector_loc Std         0.0152498
evaluation/env_infos/initial/end_effector_loc Max         0.0389023
evaluation/env_infos/initial/end_effector_loc Min        -0.0480187
evaluation/env_infos/end_effector_loc Mean                0.00834153
evaluation/env_infos/end_effector_loc Std                 0.221923
evaluation/env_infos/end_effector_loc Max                 0.634773
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.11698
evaluation/env_infos/final/reward_dist Std                0.233378
evaluation/env_infos/final/reward_dist Max                0.874453
evaluation/env_infos/final/reward_dist Min                1.16311e-169
evaluation/env_infos/initial/reward_dist Mean             0.0090364
evaluation/env_infos/initial/reward_dist Std              0.0142794
evaluation/env_infos/initial/reward_dist Max              0.0540788
evaluation/env_infos/initial/reward_dist Min              1.26354e-06
evaluation/env_infos/reward_dist Mean                     0.177275
evaluation/env_infos/reward_dist Std                      0.269382
evaluation/env_infos/reward_dist Max                      0.995725
evaluation/env_infos/reward_dist Min                      1.16311e-169
time/data storing (s)                                    37.9193
time/evaluation sampling (s)                              0.645384
time/exploration sampling (s)                             0.0848728
time/logging (s)                                          0.014505
time/saving (s)                                           0.808905
time/training (s)                                        39.4841
time/epoch (s)                                           78.9571
time/total (s)                                        19329.5
Epoch                                                   255
---------------------------------------------------  -----------------
2021-05-29 05:19:25.321074 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 256 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00337039
trainer/QF2 Loss                                          0.00430624
trainer/Policy Loss                                       2.90453
trainer/Q1 Predictions Mean                              -0.890151
trainer/Q1 Predictions Std                                0.85595
trainer/Q1 Predictions Max                                2.10735
trainer/Q1 Predictions Min                               -3.17955
trainer/Q2 Predictions Mean                              -0.902389
trainer/Q2 Predictions Std                                0.860407
trainer/Q2 Predictions Max                                2.16314
trainer/Q2 Predictions Min                               -3.15693
trainer/Q Targets Mean                                   -0.895298
trainer/Q Targets Std                                     0.864526
trainer/Q Targets Max                                     2.12744
trainer/Q Targets Min                                    -3.16571
trainer/Log Pis Mean                                      2.01978
trainer/Log Pis Std                                       1.13869
trainer/Log Pis Max                                       5.27511
trainer/Log Pis Min                                      -3.35197
trainer/Policy mu Mean                                   -0.0160076
trainer/Policy mu Std                                     0.478895
trainer/Policy mu Max                                     2.3957
trainer/Policy mu Min                                    -2.57275
trainer/Policy log std Mean                              -2.25033
trainer/Policy log std Std                                0.514017
trainer/Policy log std Max                               -0.112977
trainer/Policy log std Min                               -2.78667
trainer/Alpha                                             0.0239621
trainer/Alpha Loss                                        0.0738112
exploration/num steps total                           26700
exploration/num paths total                            1335
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.103557
exploration/Rewards Std                                   0.0725981
exploration/Rewards Max                                   0.0335797
exploration/Rewards Min                                  -0.292639
exploration/Returns Mean                                 -2.07114
exploration/Returns Std                                   1.07301
exploration/Returns Max                                  -0.253771
exploration/Returns Min                                  -3.38257
exploration/Actions Mean                                  0.00684074
exploration/Actions Std                                   0.10806
exploration/Actions Max                                   0.405395
exploration/Actions Min                                  -0.273636
exploration/Num Paths                                     5
exploration/Average Returns                              -2.07114
exploration/env_infos/final/reward_energy Mean           -0.097607
exploration/env_infos/final/reward_energy Std             0.0311351
exploration/env_infos/final/reward_energy Max            -0.0432891
exploration/env_infos/final/reward_energy Min            -0.130552
exploration/env_infos/initial/reward_energy Mean         -0.173134
exploration/env_infos/initial/reward_energy Std           0.0985881
exploration/env_infos/initial/reward_energy Max          -0.0400956
exploration/env_infos/initial/reward_energy Min          -0.299659
exploration/env_infos/reward_energy Mean                 -0.126327
exploration/env_infos/reward_energy Std                   0.0865382
exploration/env_infos/reward_energy Max                  -0.00761422
exploration/env_infos/reward_energy Min                  -0.417295
exploration/env_infos/final/end_effector_loc Mean         0.0782216
exploration/env_infos/final/end_effector_loc Std          0.159802
exploration/env_infos/final/end_effector_loc Max          0.32196
exploration/env_infos/final/end_effector_loc Min         -0.150353
exploration/env_infos/initial/end_effector_loc Mean       0.00117459
exploration/env_infos/initial/end_effector_loc Std        0.00694544
exploration/env_infos/initial/end_effector_loc Max        0.0143922
exploration/env_infos/initial/end_effector_loc Min       -0.0134348
exploration/env_infos/end_effector_loc Mean               0.0301346
exploration/env_infos/end_effector_loc Std                0.117891
exploration/env_infos/end_effector_loc Max                0.32196
exploration/env_infos/end_effector_loc Min               -0.201
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0304455
exploration/env_infos/final/reward_dist Std               0.0371454
exploration/env_infos/final/reward_dist Max               0.0995764
exploration/env_infos/final/reward_dist Min               5.83375e-07
exploration/env_infos/initial/reward_dist Mean            0.00131693
exploration/env_infos/initial/reward_dist Std             0.00161625
exploration/env_infos/initial/reward_dist Max             0.00410567
exploration/env_infos/initial/reward_dist Min             1.50136e-05
exploration/env_infos/reward_dist Mean                    0.0718887
exploration/env_infos/reward_dist Std                     0.14193
exploration/env_infos/reward_dist Max                     0.697942
exploration/env_infos/reward_dist Min                     5.83375e-07
evaluation/num steps total                           257000
evaluation/num paths total                            12850
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0882261
evaluation/Rewards Std                                    0.14417
evaluation/Rewards Max                                    0.136314
evaluation/Rewards Min                                   -1.20119
evaluation/Returns Mean                                  -1.76452
evaluation/Returns Std                                    2.43447
evaluation/Returns Max                                    1.31101
evaluation/Returns Min                                  -13.8324
evaluation/Actions Mean                                  -0.0157757
evaluation/Actions Std                                    0.151164
evaluation/Actions Max                                    0.768969
evaluation/Actions Min                                   -0.990049
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.76452
evaluation/env_infos/final/reward_energy Mean            -0.0783141
evaluation/env_infos/final/reward_energy Std              0.115474
evaluation/env_infos/final/reward_energy Max             -0.00550061
evaluation/env_infos/final/reward_energy Min             -0.599851
evaluation/env_infos/initial/reward_energy Mean          -0.368132
evaluation/env_infos/initial/reward_energy Std            0.296025
evaluation/env_infos/initial/reward_energy Max           -0.0201979
evaluation/env_infos/initial/reward_energy Min           -1.19546
evaluation/env_infos/reward_energy Mean                  -0.116617
evaluation/env_infos/reward_energy Std                    0.180553
evaluation/env_infos/reward_energy Max                   -0.00433351
evaluation/env_infos/reward_energy Min                   -1.38911
evaluation/env_infos/final/end_effector_loc Mean          0.00606261
evaluation/env_infos/final/end_effector_loc Std           0.359633
evaluation/env_infos/final/end_effector_loc Max           0.720442
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00179376
evaluation/env_infos/initial/end_effector_loc Std         0.0166049
evaluation/env_infos/initial/end_effector_loc Max         0.0384484
evaluation/env_infos/initial/end_effector_loc Min        -0.0488782
evaluation/env_infos/end_effector_loc Mean               -0.00054812
evaluation/env_infos/end_effector_loc Std                 0.245512
evaluation/env_infos/end_effector_loc Max                 0.720442
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0644201
evaluation/env_infos/final/reward_dist Std                0.156017
evaluation/env_infos/final/reward_dist Max                0.738772
evaluation/env_infos/final/reward_dist Min                4.0969e-161
evaluation/env_infos/initial/reward_dist Mean             0.008005
evaluation/env_infos/initial/reward_dist Std              0.0157404
evaluation/env_infos/initial/reward_dist Max              0.0652232
evaluation/env_infos/initial/reward_dist Min              3.54992e-06
evaluation/env_infos/reward_dist Mean                     0.144181
evaluation/env_infos/reward_dist Std                      0.246268
evaluation/env_infos/reward_dist Max                      0.993119
evaluation/env_infos/reward_dist Min                      4.0969e-161
time/data storing (s)                                    38.1164
time/evaluation sampling (s)                              0.830963
time/exploration sampling (s)                             0.0884009
time/logging (s)                                          0.0173214
time/saving (s)                                           0.798449
time/training (s)                                        39.1862
time/epoch (s)                                           79.0377
time/total (s)                                        19411.3
Epoch                                                   256
---------------------------------------------------  ----------------
2021-05-29 05:20:46.797508 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 257 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00344132
trainer/QF2 Loss                                          0.00345728
trainer/Policy Loss                                       2.76487
trainer/Q1 Predictions Mean                              -0.923021
trainer/Q1 Predictions Std                                0.837085
trainer/Q1 Predictions Max                                1.00053
trainer/Q1 Predictions Min                               -2.99165
trainer/Q2 Predictions Mean                              -0.923435
trainer/Q2 Predictions Std                                0.83604
trainer/Q2 Predictions Max                                1.03944
trainer/Q2 Predictions Min                               -3.01794
trainer/Q Targets Mean                                   -0.923893
trainer/Q Targets Std                                     0.842749
trainer/Q Targets Max                                     1.02706
trainer/Q Targets Min                                    -3.00034
trainer/Log Pis Mean                                      1.82874
trainer/Log Pis Std                                       1.30674
trainer/Log Pis Max                                       5.22401
trainer/Log Pis Min                                      -3.22389
trainer/Policy mu Mean                                   -0.043139
trainer/Policy mu Std                                     0.369908
trainer/Policy mu Max                                     1.54587
trainer/Policy mu Min                                    -2.22613
trainer/Policy log std Mean                              -2.27261
trainer/Policy log std Std                                0.468957
trainer/Policy log std Max                               -0.390796
trainer/Policy log std Min                               -2.84323
trainer/Alpha                                             0.0256364
trainer/Alpha Loss                                       -0.627527
exploration/num steps total                           26800
exploration/num paths total                            1340
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.117767
exploration/Rewards Std                                   0.067126
exploration/Rewards Max                                   0.0220987
exploration/Rewards Min                                  -0.270637
exploration/Returns Mean                                 -2.35533
exploration/Returns Std                                   0.899167
exploration/Returns Max                                  -1.11903
exploration/Returns Min                                  -3.29474
exploration/Actions Mean                                  0.00848465
exploration/Actions Std                                   0.10421
exploration/Actions Max                                   0.298968
exploration/Actions Min                                  -0.281071
exploration/Num Paths                                     5
exploration/Average Returns                              -2.35533
exploration/env_infos/final/reward_energy Mean           -0.0855647
exploration/env_infos/final/reward_energy Std             0.0680675
exploration/env_infos/final/reward_energy Max            -0.0292065
exploration/env_infos/final/reward_energy Min            -0.217507
exploration/env_infos/initial/reward_energy Mean         -0.142507
exploration/env_infos/initial/reward_energy Std           0.0848269
exploration/env_infos/initial/reward_energy Max          -0.04732
exploration/env_infos/initial/reward_energy Min          -0.294751
exploration/env_infos/reward_energy Mean                 -0.125258
exploration/env_infos/reward_energy Std                   0.0785733
exploration/env_infos/reward_energy Max                  -0.0222831
exploration/env_infos/reward_energy Min                  -0.366147
exploration/env_infos/final/end_effector_loc Mean         0.141573
exploration/env_infos/final/end_effector_loc Std          0.233411
exploration/env_infos/final/end_effector_loc Max          0.534327
exploration/env_infos/final/end_effector_loc Min         -0.165162
exploration/env_infos/initial/end_effector_loc Mean       0.000672241
exploration/env_infos/initial/end_effector_loc Std        0.00582476
exploration/env_infos/initial/end_effector_loc Max        0.0114302
exploration/env_infos/initial/end_effector_loc Min       -0.00930297
exploration/env_infos/end_effector_loc Mean               0.067834
exploration/env_infos/end_effector_loc Std                0.149879
exploration/env_infos/end_effector_loc Max                0.534327
exploration/env_infos/end_effector_loc Min               -0.16724
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0473566
exploration/env_infos/final/reward_dist Std               0.0939172
exploration/env_infos/final/reward_dist Max               0.235187
exploration/env_infos/final/reward_dist Min               1.74718e-34
exploration/env_infos/initial/reward_dist Mean            0.0043478
exploration/env_infos/initial/reward_dist Std             0.00797737
exploration/env_infos/initial/reward_dist Max             0.0202654
exploration/env_infos/initial/reward_dist Min             3.12252e-06
exploration/env_infos/reward_dist Mean                    0.059368
exploration/env_infos/reward_dist Std                     0.13008
exploration/env_infos/reward_dist Max                     0.553446
exploration/env_infos/reward_dist Min                     1.74718e-34
evaluation/num steps total                           258000
evaluation/num paths total                            12900
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.085308
evaluation/Rewards Std                                    0.139088
evaluation/Rewards Max                                    0.140693
evaluation/Rewards Min                                   -0.845169
evaluation/Returns Mean                                  -1.70616
evaluation/Returns Std                                    2.55754
evaluation/Returns Max                                    1.80374
evaluation/Returns Min                                  -14.3582
evaluation/Actions Mean                                  -0.0373717
evaluation/Actions Std                                    0.206237
evaluation/Actions Max                                    0.994431
evaluation/Actions Min                                   -0.999763
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.70616
evaluation/env_infos/final/reward_energy Mean            -0.105388
evaluation/env_infos/final/reward_energy Std              0.200841
evaluation/env_infos/final/reward_energy Max             -0.00186896
evaluation/env_infos/final/reward_energy Min             -0.996601
evaluation/env_infos/initial/reward_energy Mean          -0.369577
evaluation/env_infos/initial/reward_energy Std            0.309081
evaluation/env_infos/initial/reward_energy Max           -0.0152664
evaluation/env_infos/initial/reward_energy Min           -1.34951
evaluation/env_infos/reward_energy Mean                  -0.146691
evaluation/env_infos/reward_energy Std                    0.257571
evaluation/env_infos/reward_energy Max                   -0.00186896
evaluation/env_infos/reward_energy Min                   -1.40188
evaluation/env_infos/final/end_effector_loc Mean         -0.0571398
evaluation/env_infos/final/end_effector_loc Std           0.37432
evaluation/env_infos/final/end_effector_loc Max           0.763138
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000597344
evaluation/env_infos/initial/end_effector_loc Std         0.0170233
evaluation/env_infos/initial/end_effector_loc Max         0.0284914
evaluation/env_infos/initial/end_effector_loc Min        -0.0496917
evaluation/env_infos/end_effector_loc Mean               -0.0385608
evaluation/env_infos/end_effector_loc Std                 0.289776
evaluation/env_infos/end_effector_loc Max                 0.763138
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0910289
evaluation/env_infos/final/reward_dist Std                0.181523
evaluation/env_infos/final/reward_dist Max                0.721836
evaluation/env_infos/final/reward_dist Min                1.02113e-124
evaluation/env_infos/initial/reward_dist Mean             0.0179065
evaluation/env_infos/initial/reward_dist Std              0.0392379
evaluation/env_infos/initial/reward_dist Max              0.169431
evaluation/env_infos/initial/reward_dist Min              1.11529e-06
evaluation/env_infos/reward_dist Mean                     0.144893
evaluation/env_infos/reward_dist Std                      0.24899
evaluation/env_infos/reward_dist Max                      0.999604
evaluation/env_infos/reward_dist Min                      1.02113e-124
time/data storing (s)                                    37.8014
time/evaluation sampling (s)                              0.520603
time/exploration sampling (s)                             0.077854
time/logging (s)                                          0.0159759
time/saving (s)                                           0.781831
time/training (s)                                        39.5997
time/epoch (s)                                           78.7974
time/total (s)                                        19492.8
Epoch                                                   257
---------------------------------------------------  -----------------
2021-05-29 05:22:08.185409 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 258 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0189272
trainer/QF2 Loss                                          0.00546776
trainer/Policy Loss                                       3.09066
trainer/Q1 Predictions Mean                              -1.0057
trainer/Q1 Predictions Std                                0.878813
trainer/Q1 Predictions Max                                1.20443
trainer/Q1 Predictions Min                               -3.7151
trainer/Q2 Predictions Mean                              -1.02513
trainer/Q2 Predictions Std                                0.868828
trainer/Q2 Predictions Max                                1.16489
trainer/Q2 Predictions Min                               -3.70562
trainer/Q Targets Mean                                   -1.03914
trainer/Q Targets Std                                     0.86486
trainer/Q Targets Max                                     1.1316
trainer/Q Targets Min                                    -3.64995
trainer/Log Pis Mean                                      2.05616
trainer/Log Pis Std                                       1.02027
trainer/Log Pis Max                                       3.54351
trainer/Log Pis Min                                      -3.19253
trainer/Policy mu Mean                                   -0.00768548
trainer/Policy mu Std                                     0.312653
trainer/Policy mu Max                                     1.67012
trainer/Policy mu Min                                    -2.82381
trainer/Policy log std Mean                              -2.32112
trainer/Policy log std Std                                0.432376
trainer/Policy log std Max                               -0.238408
trainer/Policy log std Min                               -2.84495
trainer/Alpha                                             0.0261707
trainer/Alpha Loss                                        0.204549
exploration/num steps total                           26900
exploration/num paths total                            1345
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.124472
exploration/Rewards Std                                   0.0793357
exploration/Rewards Max                                   0.0945466
exploration/Rewards Min                                  -0.474788
exploration/Returns Mean                                 -2.48945
exploration/Returns Std                                   0.840053
exploration/Returns Max                                  -1.32603
exploration/Returns Min                                  -3.83361
exploration/Actions Mean                                 -0.0199956
exploration/Actions Std                                   0.277789
exploration/Actions Max                                   0.998838
exploration/Actions Min                                  -0.999105
exploration/Num Paths                                     5
exploration/Average Returns                              -2.48945
exploration/env_infos/final/reward_energy Mean           -0.110574
exploration/env_infos/final/reward_energy Std             0.0833218
exploration/env_infos/final/reward_energy Max            -0.0396742
exploration/env_infos/final/reward_energy Min            -0.269268
exploration/env_infos/initial/reward_energy Mean         -0.488746
exploration/env_infos/initial/reward_energy Std           0.381697
exploration/env_infos/initial/reward_energy Max          -0.168365
exploration/env_infos/initial/reward_energy Min          -1.19211
exploration/env_infos/reward_energy Mean                 -0.258406
exploration/env_infos/reward_energy Std                   0.297253
exploration/env_infos/reward_energy Max                  -0.0120381
exploration/env_infos/reward_energy Min                  -1.38334
exploration/env_infos/final/end_effector_loc Mean        -0.258452
exploration/env_infos/final/end_effector_loc Std          0.492467
exploration/env_infos/final/end_effector_loc Max          0.667836
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00333289
exploration/env_infos/initial/end_effector_loc Std        0.0216702
exploration/env_infos/initial/end_effector_loc Max        0.0287036
exploration/env_infos/initial/end_effector_loc Min       -0.0483627
exploration/env_infos/end_effector_loc Mean              -0.176597
exploration/env_infos/end_effector_loc Std                0.385429
exploration/env_infos/end_effector_loc Max                0.667836
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.150189
exploration/env_infos/final/reward_dist Std               0.285742
exploration/env_infos/final/reward_dist Max               0.721347
exploration/env_infos/final/reward_dist Min               2.40006e-86
exploration/env_infos/initial/reward_dist Mean            0.00582322
exploration/env_infos/initial/reward_dist Std             0.00978244
exploration/env_infos/initial/reward_dist Max             0.0251811
exploration/env_infos/initial/reward_dist Min             4.90085e-06
exploration/env_infos/reward_dist Mean                    0.0889934
exploration/env_infos/reward_dist Std                     0.215047
exploration/env_infos/reward_dist Max                     0.963856
exploration/env_infos/reward_dist Min                     2.40006e-86
evaluation/num steps total                           259000
evaluation/num paths total                            12950
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0998236
evaluation/Rewards Std                                    0.154588
evaluation/Rewards Max                                    0.116748
evaluation/Rewards Min                                   -0.961081
evaluation/Returns Mean                                  -1.99647
evaluation/Returns Std                                    2.73828
evaluation/Returns Max                                    0.746474
evaluation/Returns Min                                  -13.1467
evaluation/Actions Mean                                  -0.0367225
evaluation/Actions Std                                    0.20751
evaluation/Actions Max                                    0.838043
evaluation/Actions Min                                   -0.999905
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.99647
evaluation/env_infos/final/reward_energy Mean            -0.116888
evaluation/env_infos/final/reward_energy Std              0.235119
evaluation/env_infos/final/reward_energy Max             -0.00539162
evaluation/env_infos/final/reward_energy Min             -1.29788
evaluation/env_infos/initial/reward_energy Mean          -0.425212
evaluation/env_infos/initial/reward_energy Std            0.323077
evaluation/env_infos/initial/reward_energy Max           -0.0105294
evaluation/env_infos/initial/reward_energy Min           -1.04937
evaluation/env_infos/reward_energy Mean                  -0.157251
evaluation/env_infos/reward_energy Std                    0.253159
evaluation/env_infos/reward_energy Max                   -0.00243097
evaluation/env_infos/reward_energy Min                   -1.4116
evaluation/env_infos/final/end_effector_loc Mean         -0.0629172
evaluation/env_infos/final/end_effector_loc Std           0.373205
evaluation/env_infos/final/end_effector_loc Max           0.640133
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.001591
evaluation/env_infos/initial/end_effector_loc Std         0.0188135
evaluation/env_infos/initial/end_effector_loc Max         0.0419021
evaluation/env_infos/initial/end_effector_loc Min        -0.0499295
evaluation/env_infos/end_effector_loc Mean               -0.0336003
evaluation/env_infos/end_effector_loc Std                 0.270574
evaluation/env_infos/end_effector_loc Max                 0.640133
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.119306
evaluation/env_infos/final/reward_dist Std                0.21337
evaluation/env_infos/final/reward_dist Max                0.963165
evaluation/env_infos/final/reward_dist Min                6.92306e-124
evaluation/env_infos/initial/reward_dist Mean             0.0188644
evaluation/env_infos/initial/reward_dist Std              0.0387545
evaluation/env_infos/initial/reward_dist Max              0.191566
evaluation/env_infos/initial/reward_dist Min              9.77339e-07
evaluation/env_infos/reward_dist Mean                     0.157559
evaluation/env_infos/reward_dist Std                      0.253723
evaluation/env_infos/reward_dist Max                      0.999159
evaluation/env_infos/reward_dist Min                      6.92306e-124
time/data storing (s)                                    37.6286
time/evaluation sampling (s)                              0.694209
time/exploration sampling (s)                             0.0842487
time/logging (s)                                          0.0166265
time/saving (s)                                           0.786919
time/training (s)                                        39.4564
time/epoch (s)                                           78.667
time/total (s)                                        19574.2
Epoch                                                   258
---------------------------------------------------  -----------------
2021-05-29 05:23:30.136040 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 259 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0025132
trainer/QF2 Loss                                          0.00336617
trainer/Policy Loss                                       3.07984
trainer/Q1 Predictions Mean                              -1.06115
trainer/Q1 Predictions Std                                0.938759
trainer/Q1 Predictions Max                                1.11801
trainer/Q1 Predictions Min                               -3.66885
trainer/Q2 Predictions Mean                              -1.06016
trainer/Q2 Predictions Std                                0.931638
trainer/Q2 Predictions Max                                1.12915
trainer/Q2 Predictions Min                               -3.68529
trainer/Q Targets Mean                                   -1.06779
trainer/Q Targets Std                                     0.93314
trainer/Q Targets Max                                     1.08587
trainer/Q Targets Min                                    -3.72402
trainer/Log Pis Mean                                      2.01759
trainer/Log Pis Std                                       1.15293
trainer/Log Pis Max                                       3.77909
trainer/Log Pis Min                                      -2.91502
trainer/Policy mu Mean                                   -0.0189722
trainer/Policy mu Std                                     0.260128
trainer/Policy mu Max                                     1.16989
trainer/Policy mu Min                                    -1.74608
trainer/Policy log std Mean                              -2.33318
trainer/Policy log std Std                                0.430586
trainer/Policy log std Max                               -0.834461
trainer/Policy log std Min                               -2.88007
trainer/Alpha                                             0.0257583
trainer/Alpha Loss                                        0.0643583
exploration/num steps total                           27000
exploration/num paths total                            1350
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.114069
exploration/Rewards Std                                   0.0610882
exploration/Rewards Max                                  -0.00346561
exploration/Rewards Min                                  -0.335258
exploration/Returns Mean                                 -2.28138
exploration/Returns Std                                   0.502479
exploration/Returns Max                                  -1.56807
exploration/Returns Min                                  -2.93157
exploration/Actions Mean                                 -0.00870363
exploration/Actions Std                                   0.131229
exploration/Actions Max                                   0.849645
exploration/Actions Min                                  -0.341176
exploration/Num Paths                                     5
exploration/Average Returns                              -2.28138
exploration/env_infos/final/reward_energy Mean           -0.118563
exploration/env_infos/final/reward_energy Std             0.067034
exploration/env_infos/final/reward_energy Max            -0.0390917
exploration/env_infos/final/reward_energy Min            -0.233139
exploration/env_infos/initial/reward_energy Mean         -0.348797
exploration/env_infos/initial/reward_energy Std           0.315196
exploration/env_infos/initial/reward_energy Max          -0.0272679
exploration/env_infos/initial/reward_energy Min          -0.900378
exploration/env_infos/reward_energy Mean                 -0.145355
exploration/env_infos/reward_energy Std                   0.116041
exploration/env_infos/reward_energy Max                  -0.0105029
exploration/env_infos/reward_energy Min                  -0.900378
exploration/env_infos/final/end_effector_loc Mean         0.0282123
exploration/env_infos/final/end_effector_loc Std          0.217011
exploration/env_infos/final/end_effector_loc Max          0.363719
exploration/env_infos/final/end_effector_loc Min         -0.327358
exploration/env_infos/initial/end_effector_loc Mean       0.00432804
exploration/env_infos/initial/end_effector_loc Std        0.0160477
exploration/env_infos/initial/end_effector_loc Max        0.0424822
exploration/env_infos/initial/end_effector_loc Min       -0.0148983
exploration/env_infos/end_effector_loc Mean               0.039996
exploration/env_infos/end_effector_loc Std                0.184693
exploration/env_infos/end_effector_loc Max                0.416496
exploration/env_infos/end_effector_loc Min               -0.330473
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.223463
exploration/env_infos/final/reward_dist Std               0.235947
exploration/env_infos/final/reward_dist Max               0.511025
exploration/env_infos/final/reward_dist Min               1.37511e-11
exploration/env_infos/initial/reward_dist Mean            0.00789213
exploration/env_infos/initial/reward_dist Std             0.00771356
exploration/env_infos/initial/reward_dist Max             0.0175028
exploration/env_infos/initial/reward_dist Min             8.58434e-06
exploration/env_infos/reward_dist Mean                    0.175441
exploration/env_infos/reward_dist Std                     0.233276
exploration/env_infos/reward_dist Max                     0.966749
exploration/env_infos/reward_dist Min                     3.87947e-13
evaluation/num steps total                           260000
evaluation/num paths total                            13000
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0669785
evaluation/Rewards Std                                    0.0950517
evaluation/Rewards Max                                    0.177411
evaluation/Rewards Min                                   -0.566211
evaluation/Returns Mean                                  -1.33957
evaluation/Returns Std                                    1.41475
evaluation/Returns Max                                    1.88473
evaluation/Returns Min                                   -4.51255
evaluation/Actions Mean                                  -0.00216679
evaluation/Actions Std                                    0.114683
evaluation/Actions Max                                    0.767562
evaluation/Actions Min                                   -0.874377
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.33957
evaluation/env_infos/final/reward_energy Mean            -0.0704173
evaluation/env_infos/final/reward_energy Std              0.123453
evaluation/env_infos/final/reward_energy Max             -0.00481388
evaluation/env_infos/final/reward_energy Min             -0.843091
evaluation/env_infos/initial/reward_energy Mean          -0.373469
evaluation/env_infos/initial/reward_energy Std            0.263007
evaluation/env_infos/initial/reward_energy Max           -0.0193026
evaluation/env_infos/initial/reward_energy Min           -0.923689
evaluation/env_infos/reward_energy Mean                  -0.102879
evaluation/env_infos/reward_energy Std                    0.125418
evaluation/env_infos/reward_energy Max                   -0.000906439
evaluation/env_infos/reward_energy Min                   -0.923689
evaluation/env_infos/final/end_effector_loc Mean         -0.0166995
evaluation/env_infos/final/end_effector_loc Std           0.262833
evaluation/env_infos/final/end_effector_loc Max           0.882052
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00219165
evaluation/env_infos/initial/end_effector_loc Std         0.0160004
evaluation/env_infos/initial/end_effector_loc Max         0.0383781
evaluation/env_infos/initial/end_effector_loc Min        -0.0437189
evaluation/env_infos/end_effector_loc Mean               -0.0123612
evaluation/env_infos/end_effector_loc Std                 0.17736
evaluation/env_infos/end_effector_loc Max                 0.882052
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0909237
evaluation/env_infos/final/reward_dist Std                0.134597
evaluation/env_infos/final/reward_dist Max                0.480282
evaluation/env_infos/final/reward_dist Min                1.29919e-57
evaluation/env_infos/initial/reward_dist Mean             0.00703286
evaluation/env_infos/initial/reward_dist Std              0.011736
evaluation/env_infos/initial/reward_dist Max              0.03964
evaluation/env_infos/initial/reward_dist Min              1.70608e-06
evaluation/env_infos/reward_dist Mean                     0.165775
evaluation/env_infos/reward_dist Std                      0.245498
evaluation/env_infos/reward_dist Max                      0.993004
evaluation/env_infos/reward_dist Min                      9.24795e-58
time/data storing (s)                                    38.2896
time/evaluation sampling (s)                              0.646852
time/exploration sampling (s)                             0.0886833
time/logging (s)                                          0.0152664
time/saving (s)                                           0.773578
time/training (s)                                        39.4365
time/epoch (s)                                           79.2505
time/total (s)                                        19656.1
Epoch                                                   259
---------------------------------------------------  ----------------
2021-05-29 05:24:51.626176 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 260 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0224349
trainer/QF2 Loss                                          0.0123396
trainer/Policy Loss                                       3.12891
trainer/Q1 Predictions Mean                              -1.01896
trainer/Q1 Predictions Std                                0.884864
trainer/Q1 Predictions Max                                1.18993
trainer/Q1 Predictions Min                               -3.27351
trainer/Q2 Predictions Mean                              -1.02139
trainer/Q2 Predictions Std                                0.886818
trainer/Q2 Predictions Max                                1.15577
trainer/Q2 Predictions Min                               -3.29152
trainer/Q Targets Mean                                   -1.02799
trainer/Q Targets Std                                     0.878074
trainer/Q Targets Max                                     1.22944
trainer/Q Targets Min                                    -3.37479
trainer/Log Pis Mean                                      2.09813
trainer/Log Pis Std                                       1.15305
trainer/Log Pis Max                                       3.79096
trainer/Log Pis Min                                      -2.08338
trainer/Policy mu Mean                                    0.0395708
trainer/Policy mu Std                                     0.284083
trainer/Policy mu Max                                     2.11366
trainer/Policy mu Min                                    -1.52823
trainer/Policy log std Mean                              -2.34194
trainer/Policy log std Std                                0.458605
trainer/Policy log std Max                               -0.51558
trainer/Policy log std Min                               -2.85981
trainer/Alpha                                             0.0250309
trainer/Alpha Loss                                        0.361954
exploration/num steps total                           27100
exploration/num paths total                            1355
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.185541
exploration/Rewards Std                                   0.245339
exploration/Rewards Max                                   0.0575885
exploration/Rewards Min                                  -1.08448
exploration/Returns Mean                                 -3.71083
exploration/Returns Std                                   3.79917
exploration/Returns Max                                  -0.526113
exploration/Returns Min                                 -11.1773
exploration/Actions Mean                                 -0.0716254
exploration/Actions Std                                   0.274962
exploration/Actions Max                                   0.778848
exploration/Actions Min                                  -0.98734
exploration/Num Paths                                     5
exploration/Average Returns                              -3.71083
exploration/env_infos/final/reward_energy Mean           -0.146675
exploration/env_infos/final/reward_energy Std             0.169219
exploration/env_infos/final/reward_energy Max            -0.0231806
exploration/env_infos/final/reward_energy Min            -0.481222
exploration/env_infos/initial/reward_energy Mean         -0.615401
exploration/env_infos/initial/reward_energy Std           0.385247
exploration/env_infos/initial/reward_energy Max          -0.165889
exploration/env_infos/initial/reward_energy Min          -1.19545
exploration/env_infos/reward_energy Mean                 -0.261279
exploration/env_infos/reward_energy Std                   0.30529
exploration/env_infos/reward_energy Max                  -0.0113583
exploration/env_infos/reward_energy Min                  -1.38722
exploration/env_infos/final/end_effector_loc Mean        -0.220414
exploration/env_infos/final/end_effector_loc Std          0.428707
exploration/env_infos/final/end_effector_loc Max          0.280538
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00134872
exploration/env_infos/initial/end_effector_loc Std        0.0256339
exploration/env_infos/initial/end_effector_loc Max        0.0389424
exploration/env_infos/initial/end_effector_loc Min       -0.0477032
exploration/env_infos/end_effector_loc Mean              -0.127405
exploration/env_infos/end_effector_loc Std                0.330357
exploration/env_infos/end_effector_loc Max                0.285614
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0440876
exploration/env_infos/final/reward_dist Std               0.0708051
exploration/env_infos/final/reward_dist Max               0.183181
exploration/env_infos/final/reward_dist Min               1.79691e-106
exploration/env_infos/initial/reward_dist Mean            0.00468032
exploration/env_infos/initial/reward_dist Std             0.00736239
exploration/env_infos/initial/reward_dist Max             0.0191469
exploration/env_infos/initial/reward_dist Min             2.21226e-05
exploration/env_infos/reward_dist Mean                    0.0453511
exploration/env_infos/reward_dist Std                     0.0855669
exploration/env_infos/reward_dist Max                     0.476197
exploration/env_infos/reward_dist Min                     1.79691e-106
evaluation/num steps total                           261000
evaluation/num paths total                            13050
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0827518
evaluation/Rewards Std                                    0.0974683
evaluation/Rewards Max                                    0.142573
evaluation/Rewards Min                                   -0.626701
evaluation/Returns Mean                                  -1.65504
evaluation/Returns Std                                    1.40059
evaluation/Returns Max                                    1.53029
evaluation/Returns Min                                   -7.19224
evaluation/Actions Mean                                  -0.0136308
evaluation/Actions Std                                    0.113202
evaluation/Actions Max                                    0.829746
evaluation/Actions Min                                   -0.807337
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.65504
evaluation/env_infos/final/reward_energy Mean            -0.0718164
evaluation/env_infos/final/reward_energy Std              0.0698567
evaluation/env_infos/final/reward_energy Max             -0.0115879
evaluation/env_infos/final/reward_energy Min             -0.357491
evaluation/env_infos/initial/reward_energy Mean          -0.31976
evaluation/env_infos/initial/reward_energy Std            0.272094
evaluation/env_infos/initial/reward_energy Max           -0.0177599
evaluation/env_infos/initial/reward_energy Min           -0.897504
evaluation/env_infos/reward_energy Mean                  -0.0957674
evaluation/env_infos/reward_energy Std                    0.12973
evaluation/env_infos/reward_energy Max                   -0.000712934
evaluation/env_infos/reward_energy Min                   -0.897504
evaluation/env_infos/final/end_effector_loc Mean         -0.0805086
evaluation/env_infos/final/end_effector_loc Std           0.33865
evaluation/env_infos/final/end_effector_loc Max           0.75521
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00168842
evaluation/env_infos/initial/end_effector_loc Std         0.0147479
evaluation/env_infos/initial/end_effector_loc Max         0.0414873
evaluation/env_infos/initial/end_effector_loc Min        -0.0403669
evaluation/env_infos/end_effector_loc Mean               -0.0379584
evaluation/env_infos/end_effector_loc Std                 0.227703
evaluation/env_infos/end_effector_loc Max                 0.813675
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.107354
evaluation/env_infos/final/reward_dist Std                0.24294
evaluation/env_infos/final/reward_dist Max                0.99776
evaluation/env_infos/final/reward_dist Min                1.69491e-95
evaluation/env_infos/initial/reward_dist Mean             0.00392177
evaluation/env_infos/initial/reward_dist Std              0.006554
evaluation/env_infos/initial/reward_dist Max              0.0231161
evaluation/env_infos/initial/reward_dist Min              2.34295e-06
evaluation/env_infos/reward_dist Mean                     0.135285
evaluation/env_infos/reward_dist Std                      0.256868
evaluation/env_infos/reward_dist Max                      0.99776
evaluation/env_infos/reward_dist Min                      1.69491e-95
time/data storing (s)                                    37.6008
time/evaluation sampling (s)                              0.628039
time/exploration sampling (s)                             0.0853366
time/logging (s)                                          0.0142176
time/saving (s)                                           0.778801
time/training (s)                                        39.6708
time/epoch (s)                                           78.778
time/total (s)                                        19737.6
Epoch                                                   260
---------------------------------------------------  -----------------
2021-05-29 05:26:12.981517 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 261 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00298435
trainer/QF2 Loss                                          0.00545711
trainer/Policy Loss                                       2.92295
trainer/Q1 Predictions Mean                              -0.952834
trainer/Q1 Predictions Std                                0.899236
trainer/Q1 Predictions Max                                1.19425
trainer/Q1 Predictions Min                               -3.09884
trainer/Q2 Predictions Mean                              -0.964118
trainer/Q2 Predictions Std                                0.889592
trainer/Q2 Predictions Max                                1.16608
trainer/Q2 Predictions Min                               -3.08075
trainer/Q Targets Mean                                   -0.956139
trainer/Q Targets Std                                     0.899059
trainer/Q Targets Max                                     1.20661
trainer/Q Targets Min                                    -3.1189
trainer/Log Pis Mean                                      1.96311
trainer/Log Pis Std                                       1.21336
trainer/Log Pis Max                                       3.89868
trainer/Log Pis Min                                      -2.40213
trainer/Policy mu Mean                                    0.00631107
trainer/Policy mu Std                                     0.316152
trainer/Policy mu Max                                     1.81039
trainer/Policy mu Min                                    -2.00075
trainer/Policy log std Mean                              -2.33064
trainer/Policy log std Std                                0.473692
trainer/Policy log std Max                               -0.181553
trainer/Policy log std Min                               -3.03006
trainer/Alpha                                             0.0240111
trainer/Alpha Loss                                       -0.137567
exploration/num steps total                           27200
exploration/num paths total                            1360
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.129592
exploration/Rewards Std                                   0.104007
exploration/Rewards Max                                   0.0175378
exploration/Rewards Min                                  -0.526918
exploration/Returns Mean                                 -2.59184
exploration/Returns Std                                   1.21948
exploration/Returns Max                                  -0.750596
exploration/Returns Min                                  -4.08045
exploration/Actions Mean                                 -0.00658501
exploration/Actions Std                                   0.134692
exploration/Actions Max                                   0.537346
exploration/Actions Min                                  -0.566563
exploration/Num Paths                                     5
exploration/Average Returns                              -2.59184
exploration/env_infos/final/reward_energy Mean           -0.117311
exploration/env_infos/final/reward_energy Std             0.0648901
exploration/env_infos/final/reward_energy Max            -0.0501058
exploration/env_infos/final/reward_energy Min            -0.234621
exploration/env_infos/initial/reward_energy Mean         -0.416461
exploration/env_infos/initial/reward_energy Std           0.154325
exploration/env_infos/initial/reward_energy Max          -0.133483
exploration/env_infos/initial/reward_energy Min          -0.538532
exploration/env_infos/reward_energy Mean                 -0.149442
exploration/env_infos/reward_energy Std                   0.11848
exploration/env_infos/reward_energy Max                  -0.00396326
exploration/env_infos/reward_energy Min                  -0.610208
exploration/env_infos/final/end_effector_loc Mean         0.0291057
exploration/env_infos/final/end_effector_loc Std          0.46209
exploration/env_infos/final/end_effector_loc Max          0.878561
exploration/env_infos/final/end_effector_loc Min         -0.773649
exploration/env_infos/initial/end_effector_loc Mean       0.00683873
exploration/env_infos/initial/end_effector_loc Std        0.0141351
exploration/env_infos/initial/end_effector_loc Max        0.0268673
exploration/env_infos/initial/end_effector_loc Min       -0.0178379
exploration/env_infos/end_effector_loc Mean               0.0346388
exploration/env_infos/end_effector_loc Std                0.281969
exploration/env_infos/end_effector_loc Max                0.878561
exploration/env_infos/end_effector_loc Min               -0.773649
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0827279
exploration/env_infos/final/reward_dist Std               0.165456
exploration/env_infos/final/reward_dist Max               0.413639
exploration/env_infos/final/reward_dist Min               9.33895e-36
exploration/env_infos/initial/reward_dist Mean            0.00471411
exploration/env_infos/initial/reward_dist Std             0.00418474
exploration/env_infos/initial/reward_dist Max             0.0127205
exploration/env_infos/initial/reward_dist Min             0.000384682
exploration/env_infos/reward_dist Mean                    0.156068
exploration/env_infos/reward_dist Std                     0.254696
exploration/env_infos/reward_dist Max                     0.915727
exploration/env_infos/reward_dist Min                     9.33895e-36
evaluation/num steps total                           262000
evaluation/num paths total                            13100
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0760692
evaluation/Rewards Std                                    0.115708
evaluation/Rewards Max                                    0.146358
evaluation/Rewards Min                                   -0.845395
evaluation/Returns Mean                                  -1.52138
evaluation/Returns Std                                    1.8373
evaluation/Returns Max                                    1.51789
evaluation/Returns Min                                  -10.1606
evaluation/Actions Mean                                  -0.00496217
evaluation/Actions Std                                    0.120234
evaluation/Actions Max                                    0.830981
evaluation/Actions Min                                   -0.963671
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.52138
evaluation/env_infos/final/reward_energy Mean            -0.0514043
evaluation/env_infos/final/reward_energy Std              0.0571975
evaluation/env_infos/final/reward_energy Max             -0.00853614
evaluation/env_infos/final/reward_energy Min             -0.422969
evaluation/env_infos/initial/reward_energy Mean          -0.395243
evaluation/env_infos/initial/reward_energy Std            0.308122
evaluation/env_infos/initial/reward_energy Max           -0.0293694
evaluation/env_infos/initial/reward_energy Min           -1.18035
evaluation/env_infos/reward_energy Mean                  -0.0996056
evaluation/env_infos/reward_energy Std                    0.137986
evaluation/env_infos/reward_energy Max                   -0.00329488
evaluation/env_infos/reward_energy Min                   -1.18035
evaluation/env_infos/final/end_effector_loc Mean         -0.0245524
evaluation/env_infos/final/end_effector_loc Std           0.283958
evaluation/env_infos/final/end_effector_loc Max           0.881305
evaluation/env_infos/final/end_effector_loc Min          -0.631876
evaluation/env_infos/initial/end_effector_loc Mean        0.000880069
evaluation/env_infos/initial/end_effector_loc Std         0.0176966
evaluation/env_infos/initial/end_effector_loc Max         0.041549
evaluation/env_infos/initial/end_effector_loc Min        -0.0481836
evaluation/env_infos/end_effector_loc Mean               -0.0025984
evaluation/env_infos/end_effector_loc Std                 0.192436
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.631876
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.13228
evaluation/env_infos/final/reward_dist Std                0.234417
evaluation/env_infos/final/reward_dist Max                0.964397
evaluation/env_infos/final/reward_dist Min                2.65672e-43
evaluation/env_infos/initial/reward_dist Mean             0.00603101
evaluation/env_infos/initial/reward_dist Std              0.0134987
evaluation/env_infos/initial/reward_dist Max              0.0721999
evaluation/env_infos/initial/reward_dist Min              5.19005e-07
evaluation/env_infos/reward_dist Mean                     0.153335
evaluation/env_infos/reward_dist Std                      0.258678
evaluation/env_infos/reward_dist Max                      0.985239
evaluation/env_infos/reward_dist Min                      5.53354e-60
time/data storing (s)                                    38.0581
time/evaluation sampling (s)                              0.562313
time/exploration sampling (s)                             0.0830555
time/logging (s)                                          0.0158008
time/saving (s)                                           0.777612
time/training (s)                                        39.0759
time/epoch (s)                                           78.5729
time/total (s)                                        19818.9
Epoch                                                   261
---------------------------------------------------  ----------------
2021-05-29 05:27:34.514570 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 262 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00652186
trainer/QF2 Loss                                          0.00362495
trainer/Policy Loss                                       3.08595
trainer/Q1 Predictions Mean                              -1.03564
trainer/Q1 Predictions Std                                0.961151
trainer/Q1 Predictions Max                                1.00908
trainer/Q1 Predictions Min                               -3.70161
trainer/Q2 Predictions Mean                              -1.04116
trainer/Q2 Predictions Std                                0.956969
trainer/Q2 Predictions Max                                0.981365
trainer/Q2 Predictions Min                               -3.44656
trainer/Q Targets Mean                                   -1.03772
trainer/Q Targets Std                                     0.95778
trainer/Q Targets Max                                     0.982058
trainer/Q Targets Min                                    -3.52698
trainer/Log Pis Mean                                      2.05349
trainer/Log Pis Std                                       1.13602
trainer/Log Pis Max                                       4.06996
trainer/Log Pis Min                                      -3.0429
trainer/Policy mu Mean                                    0.00784418
trainer/Policy mu Std                                     0.299119
trainer/Policy mu Max                                     1.58949
trainer/Policy mu Min                                    -1.75405
trainer/Policy log std Mean                              -2.34597
trainer/Policy log std Std                                0.416588
trainer/Policy log std Max                               -0.584216
trainer/Policy log std Min                               -3.04835
trainer/Alpha                                             0.0243628
trainer/Alpha Loss                                        0.198651
exploration/num steps total                           27300
exploration/num paths total                            1365
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0560393
exploration/Rewards Std                                   0.0800969
exploration/Rewards Max                                   0.0954079
exploration/Rewards Min                                  -0.335751
exploration/Returns Mean                                 -1.12079
exploration/Returns Std                                   0.827895
exploration/Returns Max                                  -0.561376
exploration/Returns Min                                  -2.74019
exploration/Actions Mean                                  0.00231305
exploration/Actions Std                                   0.109211
exploration/Actions Max                                   0.390401
exploration/Actions Min                                  -0.422594
exploration/Num Paths                                     5
exploration/Average Returns                              -1.12079
exploration/env_infos/final/reward_energy Mean           -0.156333
exploration/env_infos/final/reward_energy Std             0.0689164
exploration/env_infos/final/reward_energy Max            -0.0500412
exploration/env_infos/final/reward_energy Min            -0.245335
exploration/env_infos/initial/reward_energy Mean         -0.260731
exploration/env_infos/initial/reward_energy Std           0.133837
exploration/env_infos/initial/reward_energy Max          -0.0857552
exploration/env_infos/initial/reward_energy Min          -0.431606
exploration/env_infos/reward_energy Mean                 -0.129748
exploration/env_infos/reward_energy Std                   0.0838478
exploration/env_infos/reward_energy Max                  -0.0113732
exploration/env_infos/reward_energy Min                  -0.431606
exploration/env_infos/final/end_effector_loc Mean         0.157608
exploration/env_infos/final/end_effector_loc Std          0.145996
exploration/env_infos/final/end_effector_loc Max          0.382765
exploration/env_infos/final/end_effector_loc Min         -0.0878625
exploration/env_infos/initial/end_effector_loc Mean       0.00140267
exploration/env_infos/initial/end_effector_loc Std        0.0102664
exploration/env_infos/initial/end_effector_loc Max        0.01952
exploration/env_infos/initial/end_effector_loc Min       -0.0211297
exploration/env_infos/end_effector_loc Mean               0.0895687
exploration/env_infos/end_effector_loc Std                0.115571
exploration/env_infos/end_effector_loc Max                0.382765
exploration/env_infos/end_effector_loc Min               -0.17998
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0675884
exploration/env_infos/final/reward_dist Std               0.0652982
exploration/env_infos/final/reward_dist Max               0.186351
exploration/env_infos/final/reward_dist Min               6.69858e-05
exploration/env_infos/initial/reward_dist Mean            0.00201306
exploration/env_infos/initial/reward_dist Std             0.00365245
exploration/env_infos/initial/reward_dist Max             0.00931117
exploration/env_infos/initial/reward_dist Min             3.27966e-06
exploration/env_infos/reward_dist Mean                    0.20868
exploration/env_infos/reward_dist Std                     0.26623
exploration/env_infos/reward_dist Max                     0.946813
exploration/env_infos/reward_dist Min                     3.27966e-06
evaluation/num steps total                           263000
evaluation/num paths total                            13150
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0756557
evaluation/Rewards Std                                    0.0786089
evaluation/Rewards Max                                    0.111869
evaluation/Rewards Min                                   -0.572838
evaluation/Returns Mean                                  -1.51311
evaluation/Returns Std                                    1.05153
evaluation/Returns Max                                    1.21487
evaluation/Returns Min                                   -4.27208
evaluation/Actions Mean                                   0.000276767
evaluation/Actions Std                                    0.103795
evaluation/Actions Max                                    0.922417
evaluation/Actions Min                                   -0.89475
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.51311
evaluation/env_infos/final/reward_energy Mean            -0.0495507
evaluation/env_infos/final/reward_energy Std              0.0362141
evaluation/env_infos/final/reward_energy Max             -0.00438789
evaluation/env_infos/final/reward_energy Min             -0.205866
evaluation/env_infos/initial/reward_energy Mean          -0.361143
evaluation/env_infos/initial/reward_energy Std            0.311519
evaluation/env_infos/initial/reward_energy Max           -0.0225688
evaluation/env_infos/initial/reward_energy Min           -1.10388
evaluation/env_infos/reward_energy Mean                  -0.0852531
evaluation/env_infos/reward_energy Std                    0.119495
evaluation/env_infos/reward_energy Max                   -0.00145689
evaluation/env_infos/reward_energy Min                   -1.10388
evaluation/env_infos/final/end_effector_loc Mean          0.019019
evaluation/env_infos/final/end_effector_loc Std           0.29555
evaluation/env_infos/final/end_effector_loc Max           0.919809
evaluation/env_infos/final/end_effector_loc Min          -0.756274
evaluation/env_infos/initial/end_effector_loc Mean        0.00209528
evaluation/env_infos/initial/end_effector_loc Std         0.0167315
evaluation/env_infos/initial/end_effector_loc Max         0.0461209
evaluation/env_infos/initial/end_effector_loc Min        -0.0447375
evaluation/env_infos/end_effector_loc Mean                0.0104064
evaluation/env_infos/end_effector_loc Std                 0.192512
evaluation/env_infos/end_effector_loc Max                 0.951435
evaluation/env_infos/end_effector_loc Min                -0.756274
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0828624
evaluation/env_infos/final/reward_dist Std                0.198709
evaluation/env_infos/final/reward_dist Max                0.972642
evaluation/env_infos/final/reward_dist Min                1.26042e-63
evaluation/env_infos/initial/reward_dist Mean             0.00603157
evaluation/env_infos/initial/reward_dist Std              0.0106736
evaluation/env_infos/initial/reward_dist Max              0.0449276
evaluation/env_infos/initial/reward_dist Min              1.29226e-06
evaluation/env_infos/reward_dist Mean                     0.123924
evaluation/env_infos/reward_dist Std                      0.226737
evaluation/env_infos/reward_dist Max                      0.998549
evaluation/env_infos/reward_dist Min                      1.26042e-63
time/data storing (s)                                    37.8756
time/evaluation sampling (s)                              0.644872
time/exploration sampling (s)                             0.0915856
time/logging (s)                                          0.014993
time/saving (s)                                           0.791886
time/training (s)                                        39.3398
time/epoch (s)                                           78.7588
time/total (s)                                        19900.5
Epoch                                                   262
---------------------------------------------------  ----------------
2021-05-29 05:28:56.888968 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 263 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00322528
trainer/QF2 Loss                                          0.00295844
trainer/Policy Loss                                       2.79041
trainer/Q1 Predictions Mean                              -0.898244
trainer/Q1 Predictions Std                                0.854474
trainer/Q1 Predictions Max                                1.31643
trainer/Q1 Predictions Min                               -3.63492
trainer/Q2 Predictions Mean                              -0.906991
trainer/Q2 Predictions Std                                0.844999
trainer/Q2 Predictions Max                                1.23472
trainer/Q2 Predictions Min                               -3.46842
trainer/Q Targets Mean                                   -0.896317
trainer/Q Targets Std                                     0.848431
trainer/Q Targets Max                                     1.25357
trainer/Q Targets Min                                    -3.58284
trainer/Log Pis Mean                                      1.8917
trainer/Log Pis Std                                       1.09665
trainer/Log Pis Max                                       3.65221
trainer/Log Pis Min                                      -2.3812
trainer/Policy mu Mean                                    0.00476381
trainer/Policy mu Std                                     0.218393
trainer/Policy mu Max                                     1.16042
trainer/Policy mu Min                                    -1.52378
trainer/Policy log std Mean                              -2.31856
trainer/Policy log std Std                                0.40764
trainer/Policy log std Max                               -0.491267
trainer/Policy log std Min                               -2.95064
trainer/Alpha                                             0.0248661
trainer/Alpha Loss                                       -0.399965
exploration/num steps total                           27400
exploration/num paths total                            1370
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0445418
exploration/Rewards Std                                   0.110885
exploration/Rewards Max                                   0.091445
exploration/Rewards Min                                  -0.522196
exploration/Returns Mean                                 -0.890836
exploration/Returns Std                                   1.26624
exploration/Returns Max                                   0.306683
exploration/Returns Min                                  -2.88845
exploration/Actions Mean                                 -0.00680936
exploration/Actions Std                                   0.164244
exploration/Actions Max                                   0.625553
exploration/Actions Min                                  -0.926901
exploration/Num Paths                                     5
exploration/Average Returns                              -0.890836
exploration/env_infos/final/reward_energy Mean           -0.175616
exploration/env_infos/final/reward_energy Std             0.102069
exploration/env_infos/final/reward_energy Max            -0.0316813
exploration/env_infos/final/reward_energy Min            -0.323596
exploration/env_infos/initial/reward_energy Mean         -0.362833
exploration/env_infos/initial/reward_energy Std           0.338561
exploration/env_infos/initial/reward_energy Max          -0.022986
exploration/env_infos/initial/reward_energy Min          -0.974046
exploration/env_infos/reward_energy Mean                 -0.170734
exploration/env_infos/reward_energy Std                   0.157781
exploration/env_infos/reward_energy Max                  -0.0189945
exploration/env_infos/reward_energy Min                  -0.974046
exploration/env_infos/final/end_effector_loc Mean        -0.179258
exploration/env_infos/final/end_effector_loc Std          0.244789
exploration/env_infos/final/end_effector_loc Max          0.187311
exploration/env_infos/final/end_effector_loc Min         -0.728274
exploration/env_infos/initial/end_effector_loc Mean      -0.0089073
exploration/env_infos/initial/end_effector_loc Std        0.0151162
exploration/env_infos/initial/end_effector_loc Max        0.0149683
exploration/env_infos/initial/end_effector_loc Min       -0.046345
exploration/env_infos/end_effector_loc Mean              -0.0941954
exploration/env_infos/end_effector_loc Std                0.164063
exploration/env_infos/end_effector_loc Max                0.197331
exploration/env_infos/end_effector_loc Min               -0.728274
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.279854
exploration/env_infos/final/reward_dist Std               0.254164
exploration/env_infos/final/reward_dist Max               0.6332
exploration/env_infos/final/reward_dist Min               2.1772e-28
exploration/env_infos/initial/reward_dist Mean            0.00189639
exploration/env_infos/initial/reward_dist Std             0.00184904
exploration/env_infos/initial/reward_dist Max             0.00518062
exploration/env_infos/initial/reward_dist Min             0.000157277
exploration/env_infos/reward_dist Mean                    0.168913
exploration/env_infos/reward_dist Std                     0.23295
exploration/env_infos/reward_dist Max                     0.868236
exploration/env_infos/reward_dist Min                     2.1772e-28
evaluation/num steps total                           264000
evaluation/num paths total                            13200
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0761904
evaluation/Rewards Std                                    0.0909333
evaluation/Rewards Max                                    0.171163
evaluation/Rewards Min                                   -0.508957
evaluation/Returns Mean                                  -1.52381
evaluation/Returns Std                                    1.39182
evaluation/Returns Max                                    2.26394
evaluation/Returns Min                                   -4.51368
evaluation/Actions Mean                                  -0.00320086
evaluation/Actions Std                                    0.0970303
evaluation/Actions Max                                    0.864743
evaluation/Actions Min                                   -0.744547
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.52381
evaluation/env_infos/final/reward_energy Mean            -0.0579207
evaluation/env_infos/final/reward_energy Std              0.0608265
evaluation/env_infos/final/reward_energy Max             -0.00847586
evaluation/env_infos/final/reward_energy Min             -0.277643
evaluation/env_infos/initial/reward_energy Mean          -0.297827
evaluation/env_infos/initial/reward_energy Std            0.238644
evaluation/env_infos/initial/reward_energy Max           -0.00590865
evaluation/env_infos/initial/reward_energy Min           -0.879737
evaluation/env_infos/reward_energy Mean                  -0.084656
evaluation/env_infos/reward_energy Std                    0.108091
evaluation/env_infos/reward_energy Max                   -0.000881381
evaluation/env_infos/reward_energy Min                   -0.879737
evaluation/env_infos/final/end_effector_loc Mean         -0.0212878
evaluation/env_infos/final/end_effector_loc Std           0.307382
evaluation/env_infos/final/end_effector_loc Max           0.692449
evaluation/env_infos/final/end_effector_loc Min          -0.757469
evaluation/env_infos/initial/end_effector_loc Mean        0.00118678
evaluation/env_infos/initial/end_effector_loc Std         0.0134409
evaluation/env_infos/initial/end_effector_loc Max         0.0432371
evaluation/env_infos/initial/end_effector_loc Min        -0.0372273
evaluation/env_infos/end_effector_loc Mean               -0.00158284
evaluation/env_infos/end_effector_loc Std                 0.195132
evaluation/env_infos/end_effector_loc Max                 0.692898
evaluation/env_infos/end_effector_loc Min                -0.757469
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0953513
evaluation/env_infos/final/reward_dist Std                0.184925
evaluation/env_infos/final/reward_dist Max                0.689731
evaluation/env_infos/final/reward_dist Min                6.78356e-58
evaluation/env_infos/initial/reward_dist Mean             0.00373163
evaluation/env_infos/initial/reward_dist Std              0.00705607
evaluation/env_infos/initial/reward_dist Max              0.034665
evaluation/env_infos/initial/reward_dist Min              1.91399e-06
evaluation/env_infos/reward_dist Mean                     0.122738
evaluation/env_infos/reward_dist Std                      0.233342
evaluation/env_infos/reward_dist Max                      0.9973
evaluation/env_infos/reward_dist Min                      6.78356e-58
time/data storing (s)                                    38.0573
time/evaluation sampling (s)                              0.597568
time/exploration sampling (s)                             0.0801494
time/logging (s)                                          0.0161558
time/saving (s)                                           0.778331
time/training (s)                                        39.684
time/epoch (s)                                           79.2136
time/total (s)                                        19982.8
Epoch                                                   263
---------------------------------------------------  ----------------
2021-05-29 05:30:18.537579 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 264 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00407743
trainer/QF2 Loss                                          0.00464085
trainer/Policy Loss                                       2.93118
trainer/Q1 Predictions Mean                              -0.94267
trainer/Q1 Predictions Std                                0.893094
trainer/Q1 Predictions Max                                0.882343
trainer/Q1 Predictions Min                               -3.37368
trainer/Q2 Predictions Mean                              -0.955087
trainer/Q2 Predictions Std                                0.890489
trainer/Q2 Predictions Max                                0.81879
trainer/Q2 Predictions Min                               -3.39022
trainer/Q Targets Mean                                   -0.953406
trainer/Q Targets Std                                     0.89253
trainer/Q Targets Max                                     0.858701
trainer/Q Targets Min                                    -3.41083
trainer/Log Pis Mean                                      1.98355
trainer/Log Pis Std                                       1.16958
trainer/Log Pis Max                                       3.94239
trainer/Log Pis Min                                      -3.40479
trainer/Policy mu Mean                                    0.00172849
trainer/Policy mu Std                                     0.301558
trainer/Policy mu Max                                     1.442
trainer/Policy mu Min                                    -3.02136
trainer/Policy log std Mean                              -2.31811
trainer/Policy log std Std                                0.434571
trainer/Policy log std Max                               -0.484462
trainer/Policy log std Min                               -3.04606
trainer/Alpha                                             0.0237807
trainer/Alpha Loss                                       -0.061489
exploration/num steps total                           27500
exploration/num paths total                            1375
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0859386
exploration/Rewards Std                                   0.0879702
exploration/Rewards Max                                   0.0962437
exploration/Rewards Min                                  -0.486538
exploration/Returns Mean                                 -1.71877
exploration/Returns Std                                   1.03519
exploration/Returns Max                                  -0.713899
exploration/Returns Min                                  -3.52043
exploration/Actions Mean                                  0.00473922
exploration/Actions Std                                   0.165298
exploration/Actions Max                                   0.857743
exploration/Actions Min                                  -0.594591
exploration/Num Paths                                     5
exploration/Average Returns                              -1.71877
exploration/env_infos/final/reward_energy Mean           -0.174972
exploration/env_infos/final/reward_energy Std             0.184984
exploration/env_infos/final/reward_energy Max            -0.0385264
exploration/env_infos/final/reward_energy Min            -0.534988
exploration/env_infos/initial/reward_energy Mean         -0.487262
exploration/env_infos/initial/reward_energy Std           0.254629
exploration/env_infos/initial/reward_energy Max          -0.155107
exploration/env_infos/initial/reward_energy Min          -0.875931
exploration/env_infos/reward_energy Mean                 -0.1795
exploration/env_infos/reward_energy Std                   0.149905
exploration/env_infos/reward_energy Max                  -0.0264758
exploration/env_infos/reward_energy Min                  -0.875931
exploration/env_infos/final/end_effector_loc Mean        -0.0215121
exploration/env_infos/final/end_effector_loc Std          0.176708
exploration/env_infos/final/end_effector_loc Max          0.236563
exploration/env_infos/final/end_effector_loc Min         -0.242016
exploration/env_infos/initial/end_effector_loc Mean       0.00457375
exploration/env_infos/initial/end_effector_loc Std        0.018892
exploration/env_infos/initial/end_effector_loc Max        0.0428871
exploration/env_infos/initial/end_effector_loc Min       -0.0297296
exploration/env_infos/end_effector_loc Mean              -0.0280473
exploration/env_infos/end_effector_loc Std                0.149199
exploration/env_infos/end_effector_loc Max                0.293306
exploration/env_infos/end_effector_loc Min               -0.256165
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0575291
exploration/env_infos/final/reward_dist Std               0.107565
exploration/env_infos/final/reward_dist Max               0.272333
exploration/env_infos/final/reward_dist Min               2.04477e-18
exploration/env_infos/initial/reward_dist Mean            0.00398667
exploration/env_infos/initial/reward_dist Std             0.00772526
exploration/env_infos/initial/reward_dist Max             0.0194365
exploration/env_infos/initial/reward_dist Min             3.09302e-05
exploration/env_infos/reward_dist Mean                    0.0960479
exploration/env_infos/reward_dist Std                     0.191522
exploration/env_infos/reward_dist Max                     0.887106
exploration/env_infos/reward_dist Min                     2.49527e-19
evaluation/num steps total                           265000
evaluation/num paths total                            13250
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0466294
evaluation/Rewards Std                                    0.0743919
evaluation/Rewards Max                                    0.155652
evaluation/Rewards Min                                   -0.606121
evaluation/Returns Mean                                  -0.932588
evaluation/Returns Std                                    1.08021
evaluation/Returns Max                                    2.35945
evaluation/Returns Min                                   -3.448
evaluation/Actions Mean                                   0.00372214
evaluation/Actions Std                                    0.0704696
evaluation/Actions Max                                    0.725973
evaluation/Actions Min                                   -0.838173
evaluation/Num Paths                                     50
evaluation/Average Returns                               -0.932588
evaluation/env_infos/final/reward_energy Mean            -0.0307427
evaluation/env_infos/final/reward_energy Std              0.0211236
evaluation/env_infos/final/reward_energy Max             -0.00339513
evaluation/env_infos/final/reward_energy Min             -0.107408
evaluation/env_infos/initial/reward_energy Mean          -0.231586
evaluation/env_infos/initial/reward_energy Std            0.206313
evaluation/env_infos/initial/reward_energy Max           -0.0149217
evaluation/env_infos/initial/reward_energy Min           -0.858625
evaluation/env_infos/reward_energy Mean                  -0.0598998
evaluation/env_infos/reward_energy Std                    0.0798226
evaluation/env_infos/reward_energy Max                   -0.00237521
evaluation/env_infos/reward_energy Min                   -0.858625
evaluation/env_infos/final/end_effector_loc Mean          0.045535
evaluation/env_infos/final/end_effector_loc Std           0.254659
evaluation/env_infos/final/end_effector_loc Max           0.437981
evaluation/env_infos/final/end_effector_loc Min          -0.938659
evaluation/env_infos/initial/end_effector_loc Mean        0.00108128
evaluation/env_infos/initial/end_effector_loc Std         0.0109123
evaluation/env_infos/initial/end_effector_loc Max         0.0362987
evaluation/env_infos/initial/end_effector_loc Min        -0.0419087
evaluation/env_infos/end_effector_loc Mean                0.0201551
evaluation/env_infos/end_effector_loc Std                 0.159683
evaluation/env_infos/end_effector_loc Max                 0.437981
evaluation/env_infos/end_effector_loc Min                -0.938659
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.142891
evaluation/env_infos/final/reward_dist Std                0.267471
evaluation/env_infos/final/reward_dist Max                0.97374
evaluation/env_infos/final/reward_dist Min                5.49334e-66
evaluation/env_infos/initial/reward_dist Mean             0.0051737
evaluation/env_infos/initial/reward_dist Std              0.00938756
evaluation/env_infos/initial/reward_dist Max              0.0379159
evaluation/env_infos/initial/reward_dist Min              1.0799e-06
evaluation/env_infos/reward_dist Mean                     0.157411
evaluation/env_infos/reward_dist Std                      0.250312
evaluation/env_infos/reward_dist Max                      0.996353
evaluation/env_infos/reward_dist Min                      5.49334e-66
time/data storing (s)                                    37.5665
time/evaluation sampling (s)                              0.666163
time/exploration sampling (s)                             0.0852999
time/logging (s)                                          0.0143402
time/saving (s)                                           0.791466
time/training (s)                                        39.7567
time/epoch (s)                                           78.8804
time/total (s)                                        20064.5
Epoch                                                   264
---------------------------------------------------  ----------------
2021-05-29 05:31:39.429701 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 265 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0034034
trainer/QF2 Loss                                          0.00312013
trainer/Policy Loss                                       2.86434
trainer/Q1 Predictions Mean                              -0.879537
trainer/Q1 Predictions Std                                0.937206
trainer/Q1 Predictions Max                                1.16403
trainer/Q1 Predictions Min                               -4.21113
trainer/Q2 Predictions Mean                              -0.880523
trainer/Q2 Predictions Std                                0.934663
trainer/Q2 Predictions Max                                1.13888
trainer/Q2 Predictions Min                               -4.17163
trainer/Q Targets Mean                                   -0.885935
trainer/Q Targets Std                                     0.939176
trainer/Q Targets Max                                     1.06625
trainer/Q Targets Min                                    -4.19783
trainer/Log Pis Mean                                      1.97357
trainer/Log Pis Std                                       1.10269
trainer/Log Pis Max                                       3.88762
trainer/Log Pis Min                                      -2.68748
trainer/Policy mu Mean                                   -0.00852679
trainer/Policy mu Std                                     0.239776
trainer/Policy mu Max                                     1.18049
trainer/Policy mu Min                                    -2.37961
trainer/Policy log std Mean                              -2.34911
trainer/Policy log std Std                                0.410701
trainer/Policy log std Max                               -0.0280213
trainer/Policy log std Min                               -2.97717
trainer/Alpha                                             0.0243657
trainer/Alpha Loss                                       -0.0981762
exploration/num steps total                           27600
exploration/num paths total                            1380
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0704204
exploration/Rewards Std                                   0.0771583
exploration/Rewards Max                                   0.120755
exploration/Rewards Min                                  -0.222222
exploration/Returns Mean                                 -1.40841
exploration/Returns Std                                   1.19082
exploration/Returns Max                                   0.66533
exploration/Returns Min                                  -2.91827
exploration/Actions Mean                                  0.00428748
exploration/Actions Std                                   0.1304
exploration/Actions Max                                   0.602059
exploration/Actions Min                                  -0.612399
exploration/Num Paths                                     5
exploration/Average Returns                              -1.40841
exploration/env_infos/final/reward_energy Mean           -0.0883594
exploration/env_infos/final/reward_energy Std             0.03802
exploration/env_infos/final/reward_energy Max            -0.033282
exploration/env_infos/final/reward_energy Min            -0.132034
exploration/env_infos/initial/reward_energy Mean         -0.381575
exploration/env_infos/initial/reward_energy Std           0.244211
exploration/env_infos/initial/reward_energy Max          -0.0403736
exploration/env_infos/initial/reward_energy Min          -0.644232
exploration/env_infos/reward_energy Mean                 -0.148532
exploration/env_infos/reward_energy Std                   0.109468
exploration/env_infos/reward_energy Max                  -0.0124973
exploration/env_infos/reward_energy Min                  -0.644232
exploration/env_infos/final/end_effector_loc Mean         0.0304134
exploration/env_infos/final/end_effector_loc Std          0.209472
exploration/env_infos/final/end_effector_loc Max          0.415486
exploration/env_infos/final/end_effector_loc Min         -0.347776
exploration/env_infos/initial/end_effector_loc Mean      -8.2174e-05
exploration/env_infos/initial/end_effector_loc Std        0.0160169
exploration/env_infos/initial/end_effector_loc Max        0.0301029
exploration/env_infos/initial/end_effector_loc Min       -0.03062
exploration/env_infos/end_effector_loc Mean               0.0092028
exploration/env_infos/end_effector_loc Std                0.158523
exploration/env_infos/end_effector_loc Max                0.415486
exploration/env_infos/end_effector_loc Min               -0.347776
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.162077
exploration/env_infos/final/reward_dist Std               0.198999
exploration/env_infos/final/reward_dist Max               0.507582
exploration/env_infos/final/reward_dist Min               1.28341e-06
exploration/env_infos/initial/reward_dist Mean            0.00906372
exploration/env_infos/initial/reward_dist Std             0.012954
exploration/env_infos/initial/reward_dist Max             0.033746
exploration/env_infos/initial/reward_dist Min             8.74181e-05
exploration/env_infos/reward_dist Mean                    0.227552
exploration/env_infos/reward_dist Std                     0.311072
exploration/env_infos/reward_dist Max                     0.977243
exploration/env_infos/reward_dist Min                     1.28341e-06
evaluation/num steps total                           266000
evaluation/num paths total                            13300
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0463622
evaluation/Rewards Std                                    0.0892921
evaluation/Rewards Max                                    0.166493
evaluation/Rewards Min                                   -0.62379
evaluation/Returns Mean                                  -0.927245
evaluation/Returns Std                                    1.24014
evaluation/Returns Max                                    2.12887
evaluation/Returns Min                                   -4.21036
evaluation/Actions Mean                                   0.00234284
evaluation/Actions Std                                    0.078404
evaluation/Actions Max                                    0.685575
evaluation/Actions Min                                   -0.757495
evaluation/Num Paths                                     50
evaluation/Average Returns                               -0.927245
evaluation/env_infos/final/reward_energy Mean            -0.0414167
evaluation/env_infos/final/reward_energy Std              0.0407795
evaluation/env_infos/final/reward_energy Max             -0.00483222
evaluation/env_infos/final/reward_energy Min             -0.197036
evaluation/env_infos/initial/reward_energy Mean          -0.262142
evaluation/env_infos/initial/reward_energy Std            0.237904
evaluation/env_infos/initial/reward_energy Max           -0.0106609
evaluation/env_infos/initial/reward_energy Min           -1.00167
evaluation/env_infos/reward_energy Mean                  -0.0620503
evaluation/env_infos/reward_energy Std                    0.0919517
evaluation/env_infos/reward_energy Max                   -0.00119642
evaluation/env_infos/reward_energy Min                   -1.00167
evaluation/env_infos/final/end_effector_loc Mean          0.0415828
evaluation/env_infos/final/end_effector_loc Std           0.267329
evaluation/env_infos/final/end_effector_loc Max           0.533484
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000893439
evaluation/env_infos/initial/end_effector_loc Std         0.0124839
evaluation/env_infos/initial/end_effector_loc Max         0.0336971
evaluation/env_infos/initial/end_effector_loc Min        -0.0378748
evaluation/env_infos/end_effector_loc Mean                0.0185777
evaluation/env_infos/end_effector_loc Std                 0.170604
evaluation/env_infos/end_effector_loc Max                 0.533484
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0961828
evaluation/env_infos/final/reward_dist Std                0.192397
evaluation/env_infos/final/reward_dist Max                0.852598
evaluation/env_infos/final/reward_dist Min                6.40068e-72
evaluation/env_infos/initial/reward_dist Mean             0.0081525
evaluation/env_infos/initial/reward_dist Std              0.0145741
evaluation/env_infos/initial/reward_dist Max              0.0626841
evaluation/env_infos/initial/reward_dist Min              1.14762e-06
evaluation/env_infos/reward_dist Mean                     0.156712
evaluation/env_infos/reward_dist Std                      0.258939
evaluation/env_infos/reward_dist Max                      0.991544
evaluation/env_infos/reward_dist Min                      6.40068e-72
time/data storing (s)                                    38.1401
time/evaluation sampling (s)                              0.651343
time/exploration sampling (s)                             0.0844892
time/logging (s)                                          0.0144038
time/saving (s)                                           0.777408
time/training (s)                                        38.463
time/epoch (s)                                           78.1308
time/total (s)                                        20145.3
Epoch                                                   265
---------------------------------------------------  ----------------
2021-05-29 05:33:01.349285 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 266 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00356693
trainer/QF2 Loss                                          0.00451537
trainer/Policy Loss                                       2.89079
trainer/Q1 Predictions Mean                              -0.91369
trainer/Q1 Predictions Std                                0.94948
trainer/Q1 Predictions Max                                1.06982
trainer/Q1 Predictions Min                               -3.60256
trainer/Q2 Predictions Mean                              -0.904573
trainer/Q2 Predictions Std                                0.953874
trainer/Q2 Predictions Max                                1.12167
trainer/Q2 Predictions Min                               -3.50094
trainer/Q Targets Mean                                   -0.917708
trainer/Q Targets Std                                     0.950661
trainer/Q Targets Max                                     0.986
trainer/Q Targets Min                                    -3.66622
trainer/Log Pis Mean                                      1.98227
trainer/Log Pis Std                                       1.02477
trainer/Log Pis Max                                       3.71028
trainer/Log Pis Min                                      -2.50727
trainer/Policy mu Mean                                   -0.00709417
trainer/Policy mu Std                                     0.258089
trainer/Policy mu Max                                     1.60629
trainer/Policy mu Min                                    -1.70961
trainer/Policy log std Mean                              -2.34799
trainer/Policy log std Std                                0.386275
trainer/Policy log std Max                               -0.447379
trainer/Policy log std Min                               -2.99763
trainer/Alpha                                             0.0232498
trainer/Alpha Loss                                       -0.0666921
exploration/num steps total                           27700
exploration/num paths total                            1385
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0957604
exploration/Rewards Std                                   0.170053
exploration/Rewards Max                                   0.143913
exploration/Rewards Min                                  -0.684238
exploration/Returns Mean                                 -1.91521
exploration/Returns Std                                   3.02703
exploration/Returns Max                                   0.594054
exploration/Returns Min                                  -7.48422
exploration/Actions Mean                                 -0.0474319
exploration/Actions Std                                   0.178292
exploration/Actions Max                                   0.472275
exploration/Actions Min                                  -0.920344
exploration/Num Paths                                     5
exploration/Average Returns                              -1.91521
exploration/env_infos/final/reward_energy Mean           -0.125059
exploration/env_infos/final/reward_energy Std             0.0740716
exploration/env_infos/final/reward_energy Max            -0.0315847
exploration/env_infos/final/reward_energy Min            -0.224919
exploration/env_infos/initial/reward_energy Mean         -0.476756
exploration/env_infos/initial/reward_energy Std           0.317098
exploration/env_infos/initial/reward_energy Max          -0.164575
exploration/env_infos/initial/reward_energy Min          -1.07548
exploration/env_infos/reward_energy Mean                 -0.202929
exploration/env_infos/reward_energy Std                   0.163998
exploration/env_infos/reward_energy Max                  -0.00834541
exploration/env_infos/reward_energy Min                  -1.07548
exploration/env_infos/final/end_effector_loc Mean        -0.0978313
exploration/env_infos/final/end_effector_loc Std          0.483448
exploration/env_infos/final/end_effector_loc Max          0.351401
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.000622518
exploration/env_infos/initial/end_effector_loc Std        0.0202342
exploration/env_infos/initial/end_effector_loc Max        0.0236137
exploration/env_infos/initial/end_effector_loc Min       -0.0460172
exploration/env_infos/end_effector_loc Mean              -0.0448984
exploration/env_infos/end_effector_loc Std                0.376753
exploration/env_infos/end_effector_loc Max                0.351401
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.107291
exploration/env_infos/final/reward_dist Std               0.111261
exploration/env_infos/final/reward_dist Max               0.308261
exploration/env_infos/final/reward_dist Min               1.50231e-97
exploration/env_infos/initial/reward_dist Mean            0.00467107
exploration/env_infos/initial/reward_dist Std             0.00609629
exploration/env_infos/initial/reward_dist Max             0.0166032
exploration/env_infos/initial/reward_dist Min             0.000303689
exploration/env_infos/reward_dist Mean                    0.23881
exploration/env_infos/reward_dist Std                     0.279614
exploration/env_infos/reward_dist Max                     0.968725
exploration/env_infos/reward_dist Min                     1.50231e-97
evaluation/num steps total                           267000
evaluation/num paths total                            13350
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0672989
evaluation/Rewards Std                                    0.100573
evaluation/Rewards Max                                    0.106314
evaluation/Rewards Min                                   -0.815543
evaluation/Returns Mean                                  -1.34598
evaluation/Returns Std                                    1.52424
evaluation/Returns Max                                    0.928534
evaluation/Returns Min                                   -6.20161
evaluation/Actions Mean                                  -0.0181148
evaluation/Actions Std                                    0.132558
evaluation/Actions Max                                    0.876354
evaluation/Actions Min                                   -0.997853
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.34598
evaluation/env_infos/final/reward_energy Mean            -0.0498939
evaluation/env_infos/final/reward_energy Std              0.0726853
evaluation/env_infos/final/reward_energy Max             -0.000868207
evaluation/env_infos/final/reward_energy Min             -0.368519
evaluation/env_infos/initial/reward_energy Mean          -0.406996
evaluation/env_infos/initial/reward_energy Std            0.341216
evaluation/env_infos/initial/reward_energy Max           -0.018491
evaluation/env_infos/initial/reward_energy Min           -1.36227
evaluation/env_infos/reward_energy Mean                  -0.097177
evaluation/env_infos/reward_energy Std                    0.162345
evaluation/env_infos/reward_energy Max                   -0.000868207
evaluation/env_infos/reward_energy Min                   -1.36227
evaluation/env_infos/final/end_effector_loc Mean         -0.0985384
evaluation/env_infos/final/end_effector_loc Std           0.354609
evaluation/env_infos/final/end_effector_loc Max           0.435916
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00197225
evaluation/env_infos/initial/end_effector_loc Std         0.0186736
evaluation/env_infos/initial/end_effector_loc Max         0.0438177
evaluation/env_infos/initial/end_effector_loc Min        -0.0498926
evaluation/env_infos/end_effector_loc Mean               -0.0527803
evaluation/env_infos/end_effector_loc Std                 0.248461
evaluation/env_infos/end_effector_loc Max                 0.435916
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.101664
evaluation/env_infos/final/reward_dist Std                0.213934
evaluation/env_infos/final/reward_dist Max                0.920154
evaluation/env_infos/final/reward_dist Min                9.39474e-115
evaluation/env_infos/initial/reward_dist Mean             0.00953096
evaluation/env_infos/initial/reward_dist Std              0.0193409
evaluation/env_infos/initial/reward_dist Max              0.110756
evaluation/env_infos/initial/reward_dist Min              1.4623e-06
evaluation/env_infos/reward_dist Mean                     0.143629
evaluation/env_infos/reward_dist Std                      0.235085
evaluation/env_infos/reward_dist Max                      0.990247
evaluation/env_infos/reward_dist Min                      9.39474e-115
time/data storing (s)                                    37.7525
time/evaluation sampling (s)                              0.656374
time/exploration sampling (s)                             0.082027
time/logging (s)                                          0.0168563
time/saving (s)                                           0.804905
time/training (s)                                        39.7596
time/epoch (s)                                           79.0723
time/total (s)                                        20227.3
Epoch                                                   266
---------------------------------------------------  -----------------
2021-05-29 05:34:22.773418 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 267 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00443529
trainer/QF2 Loss                                          0.00370159
trainer/Policy Loss                                       2.8802
trainer/Q1 Predictions Mean                              -0.771143
trainer/Q1 Predictions Std                                0.867102
trainer/Q1 Predictions Max                                0.931794
trainer/Q1 Predictions Min                               -3.33063
trainer/Q2 Predictions Mean                              -0.768038
trainer/Q2 Predictions Std                                0.869174
trainer/Q2 Predictions Max                                0.982668
trainer/Q2 Predictions Min                               -3.26433
trainer/Q Targets Mean                                   -0.778093
trainer/Q Targets Std                                     0.868986
trainer/Q Targets Max                                     0.947004
trainer/Q Targets Min                                    -3.21146
trainer/Log Pis Mean                                      2.10964
trainer/Log Pis Std                                       1.03263
trainer/Log Pis Max                                       5.66273
trainer/Log Pis Min                                      -4.31728
trainer/Policy mu Mean                                   -0.040536
trainer/Policy mu Std                                     0.410511
trainer/Policy mu Max                                     2.0227
trainer/Policy mu Min                                    -2.36957
trainer/Policy log std Mean                              -2.28713
trainer/Policy log std Std                                0.485804
trainer/Policy log std Max                                0.00736955
trainer/Policy log std Min                               -3.05187
trainer/Alpha                                             0.0211328
trainer/Alpha Loss                                        0.423027
exploration/num steps total                           27800
exploration/num paths total                            1390
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.174806
exploration/Rewards Std                                   0.283571
exploration/Rewards Max                                   0.142299
exploration/Rewards Min                                  -1.08267
exploration/Returns Mean                                 -3.49612
exploration/Returns Std                                   3.5658
exploration/Returns Max                                   0.234177
exploration/Returns Min                                 -10.2622
exploration/Actions Mean                                 -0.0226209
exploration/Actions Std                                   0.18201
exploration/Actions Max                                   0.676579
exploration/Actions Min                                  -0.87041
exploration/Num Paths                                     5
exploration/Average Returns                              -3.49612
exploration/env_infos/final/reward_energy Mean           -0.101183
exploration/env_infos/final/reward_energy Std             0.0725397
exploration/env_infos/final/reward_energy Max            -0.0175774
exploration/env_infos/final/reward_energy Min            -0.204574
exploration/env_infos/initial/reward_energy Mean         -0.502513
exploration/env_infos/initial/reward_energy Std           0.310054
exploration/env_infos/initial/reward_energy Max          -0.150234
exploration/env_infos/initial/reward_energy Min          -0.880831
exploration/env_infos/reward_energy Mean                 -0.19036
exploration/env_infos/reward_energy Std                   0.176186
exploration/env_infos/reward_energy Max                  -0.0175774
exploration/env_infos/reward_energy Min                  -0.880831
exploration/env_infos/final/end_effector_loc Mean        -0.214907
exploration/env_infos/final/end_effector_loc Std          0.537386
exploration/env_infos/final/end_effector_loc Max          0.462026
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.011891
exploration/env_infos/initial/end_effector_loc Std        0.0171587
exploration/env_infos/initial/end_effector_loc Max        0.00744923
exploration/env_infos/initial/end_effector_loc Min       -0.0435205
exploration/env_infos/end_effector_loc Mean              -0.123393
exploration/env_infos/end_effector_loc Std                0.340372
exploration/env_infos/end_effector_loc Max                0.462026
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.100052
exploration/env_infos/final/reward_dist Std               0.192381
exploration/env_infos/final/reward_dist Max               0.484623
exploration/env_infos/final/reward_dist Min               1.47649e-113
exploration/env_infos/initial/reward_dist Mean            0.0195509
exploration/env_infos/initial/reward_dist Std             0.0255575
exploration/env_infos/initial/reward_dist Max             0.0633753
exploration/env_infos/initial/reward_dist Min             6.9012e-06
exploration/env_infos/reward_dist Mean                    0.129411
exploration/env_infos/reward_dist Std                     0.254858
exploration/env_infos/reward_dist Max                     0.958611
exploration/env_infos/reward_dist Min                     1.47649e-113
evaluation/num steps total                           268000
evaluation/num paths total                            13400
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0787278
evaluation/Rewards Std                                    0.142292
evaluation/Rewards Max                                    0.160477
evaluation/Rewards Min                                   -1.03923
evaluation/Returns Mean                                  -1.57456
evaluation/Returns Std                                    2.25803
evaluation/Returns Max                                    1.96716
evaluation/Returns Min                                  -10.125
evaluation/Actions Mean                                  -0.0128358
evaluation/Actions Std                                    0.124441
evaluation/Actions Max                                    0.699219
evaluation/Actions Min                                   -0.912984
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.57456
evaluation/env_infos/final/reward_energy Mean            -0.0327043
evaluation/env_infos/final/reward_energy Std              0.0336
evaluation/env_infos/final/reward_energy Max             -0.0033939
evaluation/env_infos/final/reward_energy Min             -0.161254
evaluation/env_infos/initial/reward_energy Mean          -0.335631
evaluation/env_infos/initial/reward_energy Std            0.264064
evaluation/env_infos/initial/reward_energy Max           -0.0150084
evaluation/env_infos/initial/reward_energy Min           -0.913935
evaluation/env_infos/reward_energy Mean                  -0.0926509
evaluation/env_infos/reward_energy Std                    0.150721
evaluation/env_infos/reward_energy Max                   -0.000718308
evaluation/env_infos/reward_energy Min                   -1.04325
evaluation/env_infos/final/end_effector_loc Mean         -0.0972275
evaluation/env_infos/final/end_effector_loc Std           0.364291
evaluation/env_infos/final/end_effector_loc Max           0.879734
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00417481
evaluation/env_infos/initial/end_effector_loc Std         0.0145101
evaluation/env_infos/initial/end_effector_loc Max         0.0349609
evaluation/env_infos/initial/end_effector_loc Min        -0.0439964
evaluation/env_infos/end_effector_loc Mean               -0.0592963
evaluation/env_infos/end_effector_loc Std                 0.254425
evaluation/env_infos/end_effector_loc Max                 0.879734
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.144255
evaluation/env_infos/final/reward_dist Std                0.241678
evaluation/env_infos/final/reward_dist Max                0.946477
evaluation/env_infos/final/reward_dist Min                4.29766e-147
evaluation/env_infos/initial/reward_dist Mean             0.00767805
evaluation/env_infos/initial/reward_dist Std              0.0182554
evaluation/env_infos/initial/reward_dist Max              0.108153
evaluation/env_infos/initial/reward_dist Min              5.37316e-06
evaluation/env_infos/reward_dist Mean                     0.153524
evaluation/env_infos/reward_dist Std                      0.251167
evaluation/env_infos/reward_dist Max                      0.996431
evaluation/env_infos/reward_dist Min                      4.29766e-147
time/data storing (s)                                    38.1478
time/evaluation sampling (s)                              0.523807
time/exploration sampling (s)                             0.0836208
time/logging (s)                                          0.0146298
time/saving (s)                                           0.794986
time/training (s)                                        38.9891
time/epoch (s)                                           78.554
time/total (s)                                        20308.7
Epoch                                                   267
---------------------------------------------------  -----------------
2021-05-29 05:35:46.713412 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 268 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0042529
trainer/QF2 Loss                                          0.00583687
trainer/Policy Loss                                       2.73424
trainer/Q1 Predictions Mean                              -0.730301
trainer/Q1 Predictions Std                                0.823606
trainer/Q1 Predictions Max                                0.933107
trainer/Q1 Predictions Min                               -4.24963
trainer/Q2 Predictions Mean                              -0.715795
trainer/Q2 Predictions Std                                0.821354
trainer/Q2 Predictions Max                                0.89529
trainer/Q2 Predictions Min                               -4.27584
trainer/Q Targets Mean                                   -0.711086
trainer/Q Targets Std                                     0.832138
trainer/Q Targets Max                                     0.940587
trainer/Q Targets Min                                    -4.3063
trainer/Log Pis Mean                                      2.02003
trainer/Log Pis Std                                       1.15987
trainer/Log Pis Max                                       3.89136
trainer/Log Pis Min                                      -2.95637
trainer/Policy mu Mean                                   -0.0175708
trainer/Policy mu Std                                     0.353326
trainer/Policy mu Max                                     2.38551
trainer/Policy mu Min                                    -1.99139
trainer/Policy log std Mean                              -2.311
trainer/Policy log std Std                                0.502022
trainer/Policy log std Max                                0.600318
trainer/Policy log std Min                               -3.11952
trainer/Alpha                                             0.018317
trainer/Alpha Loss                                        0.0801114
exploration/num steps total                           27900
exploration/num paths total                            1395
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.195082
exploration/Rewards Std                                   0.218964
exploration/Rewards Max                                   0.0409597
exploration/Rewards Min                                  -1.02046
exploration/Returns Mean                                 -3.90164
exploration/Returns Std                                   3.95462
exploration/Returns Max                                  -1.26744
exploration/Returns Min                                 -11.7305
exploration/Actions Mean                                 -0.0617433
exploration/Actions Std                                   0.248221
exploration/Actions Max                                   0.655199
exploration/Actions Min                                  -0.989446
exploration/Num Paths                                     5
exploration/Average Returns                              -3.90164
exploration/env_infos/final/reward_energy Mean           -0.0793085
exploration/env_infos/final/reward_energy Std             0.0374289
exploration/env_infos/final/reward_energy Max            -0.010223
exploration/env_infos/final/reward_energy Min            -0.122016
exploration/env_infos/initial/reward_energy Mean         -0.462992
exploration/env_infos/initial/reward_energy Std           0.501655
exploration/env_infos/initial/reward_energy Max          -0.0319818
exploration/env_infos/initial/reward_energy Min          -1.16599
exploration/env_infos/reward_energy Mean                 -0.224127
exploration/env_infos/reward_energy Std                   0.283936
exploration/env_infos/reward_energy Max                  -0.000887967
exploration/env_infos/reward_energy Min                  -1.36836
exploration/env_infos/final/end_effector_loc Mean        -0.347558
exploration/env_infos/final/end_effector_loc Std          0.399972
exploration/env_infos/final/end_effector_loc Max          0.172155
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00816432
exploration/env_infos/initial/end_effector_loc Std        0.0227127
exploration/env_infos/initial/end_effector_loc Max        0.0327599
exploration/env_infos/initial/end_effector_loc Min       -0.0482247
exploration/env_infos/end_effector_loc Mean              -0.222792
exploration/env_infos/end_effector_loc Std                0.340228
exploration/env_infos/end_effector_loc Max                0.182875
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.136759
exploration/env_infos/final/reward_dist Std               0.210877
exploration/env_infos/final/reward_dist Max               0.544472
exploration/env_infos/final/reward_dist Min               2.11775e-100
exploration/env_infos/initial/reward_dist Mean            0.00871338
exploration/env_infos/initial/reward_dist Std             0.00998729
exploration/env_infos/initial/reward_dist Max             0.023795
exploration/env_infos/initial/reward_dist Min             6.57657e-06
exploration/env_infos/reward_dist Mean                    0.108525
exploration/env_infos/reward_dist Std                     0.223323
exploration/env_infos/reward_dist Max                     0.987817
exploration/env_infos/reward_dist Min                     2.11775e-100
evaluation/num steps total                           269000
evaluation/num paths total                            13450
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.077641
evaluation/Rewards Std                                    0.112326
evaluation/Rewards Max                                    0.146115
evaluation/Rewards Min                                   -0.640231
evaluation/Returns Mean                                  -1.55282
evaluation/Returns Std                                    1.79032
evaluation/Returns Max                                    1.64549
evaluation/Returns Min                                   -7.82726
evaluation/Actions Mean                                  -0.0194785
evaluation/Actions Std                                    0.146266
evaluation/Actions Max                                    0.828226
evaluation/Actions Min                                   -0.993553
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.55282
evaluation/env_infos/final/reward_energy Mean            -0.0454284
evaluation/env_infos/final/reward_energy Std              0.028101
evaluation/env_infos/final/reward_energy Max             -0.00385241
evaluation/env_infos/final/reward_energy Min             -0.146223
evaluation/env_infos/initial/reward_energy Mean          -0.401326
evaluation/env_infos/initial/reward_energy Std            0.31271
evaluation/env_infos/initial/reward_energy Max           -0.0411806
evaluation/env_infos/initial/reward_energy Min           -1.34664
evaluation/env_infos/reward_energy Mean                  -0.111139
evaluation/env_infos/reward_energy Std                    0.176619
evaluation/env_infos/reward_energy Max                   -0.0034406
evaluation/env_infos/reward_energy Min                   -1.37553
evaluation/env_infos/final/end_effector_loc Mean         -0.116874
evaluation/env_infos/final/end_effector_loc Std           0.368286
evaluation/env_infos/final/end_effector_loc Max           0.731167
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00237482
evaluation/env_infos/initial/end_effector_loc Std         0.0178304
evaluation/env_infos/initial/end_effector_loc Max         0.0414113
evaluation/env_infos/initial/end_effector_loc Min        -0.0496776
evaluation/env_infos/end_effector_loc Mean               -0.0565342
evaluation/env_infos/end_effector_loc Std                 0.258963
evaluation/env_infos/end_effector_loc Max                 0.86688
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0903971
evaluation/env_infos/final/reward_dist Std                0.197844
evaluation/env_infos/final/reward_dist Max                0.87911
evaluation/env_infos/final/reward_dist Min                2.46528e-111
evaluation/env_infos/initial/reward_dist Mean             0.0112974
evaluation/env_infos/initial/reward_dist Std              0.0248395
evaluation/env_infos/initial/reward_dist Max              0.135116
evaluation/env_infos/initial/reward_dist Min              1.70012e-06
evaluation/env_infos/reward_dist Mean                     0.16684
evaluation/env_infos/reward_dist Std                      0.261952
evaluation/env_infos/reward_dist Max                      0.998872
evaluation/env_infos/reward_dist Min                      2.46528e-111
time/data storing (s)                                    39.691
time/evaluation sampling (s)                              0.62704
time/exploration sampling (s)                             0.0873227
time/logging (s)                                          0.0186188
time/saving (s)                                           0.78176
time/training (s)                                        39.9108
time/epoch (s)                                           81.1166
time/total (s)                                        20392.6
Epoch                                                   268
---------------------------------------------------  -----------------
2021-05-29 05:37:12.127927 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 269 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0204035
trainer/QF2 Loss                                          0.0189563
trainer/Policy Loss                                       2.93282
trainer/Q1 Predictions Mean                              -0.769056
trainer/Q1 Predictions Std                                0.840139
trainer/Q1 Predictions Max                                0.765958
trainer/Q1 Predictions Min                               -3.16692
trainer/Q2 Predictions Mean                              -0.75126
trainer/Q2 Predictions Std                                0.879847
trainer/Q2 Predictions Max                                0.822253
trainer/Q2 Predictions Min                               -3.54591
trainer/Q Targets Mean                                   -0.769871
trainer/Q Targets Std                                     0.87274
trainer/Q Targets Max                                     0.920111
trainer/Q Targets Min                                    -3.7808
trainer/Log Pis Mean                                      2.16316
trainer/Log Pis Std                                       1.15572
trainer/Log Pis Max                                      10.0269
trainer/Log Pis Min                                      -3.51006
trainer/Policy mu Mean                                   -0.045119
trainer/Policy mu Std                                     0.338572
trainer/Policy mu Max                                     1.43246
trainer/Policy mu Min                                    -3.12526
trainer/Policy log std Mean                              -2.35077
trainer/Policy log std Std                                0.434855
trainer/Policy log std Max                                0.714751
trainer/Policy log std Min                               -3.06485
trainer/Alpha                                             0.0205137
trainer/Alpha Loss                                        0.634499
exploration/num steps total                           28000
exploration/num paths total                            1400
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.0890997
exploration/Rewards Std                                   0.0849447
exploration/Rewards Max                                   0.0962351
exploration/Rewards Min                                  -0.337671
exploration/Returns Mean                                 -1.78199
exploration/Returns Std                                   1.31088
exploration/Returns Max                                   0.789102
exploration/Returns Min                                  -2.81308
exploration/Actions Mean                                 -0.00527948
exploration/Actions Std                                   0.138569
exploration/Actions Max                                   0.434452
exploration/Actions Min                                  -0.480336
exploration/Num Paths                                     5
exploration/Average Returns                              -1.78199
exploration/env_infos/final/reward_energy Mean           -0.0697319
exploration/env_infos/final/reward_energy Std             0.0590015
exploration/env_infos/final/reward_energy Max            -0.0299401
exploration/env_infos/final/reward_energy Min            -0.186406
exploration/env_infos/initial/reward_energy Mean         -0.291604
exploration/env_infos/initial/reward_energy Std           0.167165
exploration/env_infos/initial/reward_energy Max          -0.0423531
exploration/env_infos/initial/reward_energy Min          -0.501056
exploration/env_infos/reward_energy Mean                 -0.162893
exploration/env_infos/reward_energy Std                   0.109198
exploration/env_infos/reward_energy Max                  -0.0275136
exploration/env_infos/reward_energy Min                  -0.504319
exploration/env_infos/final/end_effector_loc Mean         0.0412693
exploration/env_infos/final/end_effector_loc Std          0.274941
exploration/env_infos/final/end_effector_loc Max          0.316288
exploration/env_infos/final/end_effector_loc Min         -0.618001
exploration/env_infos/initial/end_effector_loc Mean       0.00215035
exploration/env_infos/initial/end_effector_loc Std        0.0116875
exploration/env_infos/initial/end_effector_loc Max        0.0217226
exploration/env_infos/initial/end_effector_loc Min       -0.0240168
exploration/env_infos/end_effector_loc Mean               0.0542169
exploration/env_infos/end_effector_loc Std                0.171645
exploration/env_infos/end_effector_loc Max                0.331818
exploration/env_infos/end_effector_loc Min               -0.618001
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.126645
exploration/env_infos/final/reward_dist Std               0.223916
exploration/env_infos/final/reward_dist Max               0.573655
exploration/env_infos/final/reward_dist Min               5.85701e-25
exploration/env_infos/initial/reward_dist Mean            0.00860144
exploration/env_infos/initial/reward_dist Std             0.0127736
exploration/env_infos/initial/reward_dist Max             0.0332315
exploration/env_infos/initial/reward_dist Min             2.29437e-05
exploration/env_infos/reward_dist Mean                    0.175119
exploration/env_infos/reward_dist Std                     0.257621
exploration/env_infos/reward_dist Max                     0.86876
exploration/env_infos/reward_dist Min                     5.85701e-25
evaluation/num steps total                           270000
evaluation/num paths total                            13500
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0840439
evaluation/Rewards Std                                    0.131068
evaluation/Rewards Max                                    0.156983
evaluation/Rewards Min                                   -0.955971
evaluation/Returns Mean                                  -1.68088
evaluation/Returns Std                                    1.86925
evaluation/Returns Max                                    1.63468
evaluation/Returns Min                                   -9.41922
evaluation/Actions Mean                                  -0.0165501
evaluation/Actions Std                                    0.107143
evaluation/Actions Max                                    0.892088
evaluation/Actions Min                                   -0.931245
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.68088
evaluation/env_infos/final/reward_energy Mean            -0.068459
evaluation/env_infos/final/reward_energy Std              0.138317
evaluation/env_infos/final/reward_energy Max             -0.0130741
evaluation/env_infos/final/reward_energy Min             -1.02622
evaluation/env_infos/initial/reward_energy Mean          -0.30144
evaluation/env_infos/initial/reward_energy Std            0.271881
evaluation/env_infos/initial/reward_energy Max           -0.0242054
evaluation/env_infos/initial/reward_energy Min           -1.3066
evaluation/env_infos/reward_energy Mean                  -0.0892219
evaluation/env_infos/reward_energy Std                    0.124686
evaluation/env_infos/reward_energy Max                   -0.00081305
evaluation/env_infos/reward_energy Min                   -1.3066
evaluation/env_infos/final/end_effector_loc Mean         -0.0984377
evaluation/env_infos/final/end_effector_loc Std           0.35158
evaluation/env_infos/final/end_effector_loc Max           0.676661
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000687264
evaluation/env_infos/initial/end_effector_loc Std         0.0143356
evaluation/env_infos/initial/end_effector_loc Max         0.0446044
evaluation/env_infos/initial/end_effector_loc Min        -0.0465622
evaluation/env_infos/end_effector_loc Mean               -0.0345153
evaluation/env_infos/end_effector_loc Std                 0.225818
evaluation/env_infos/end_effector_loc Max                 0.676661
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0880098
evaluation/env_infos/final/reward_dist Std                0.203278
evaluation/env_infos/final/reward_dist Max                0.806136
evaluation/env_infos/final/reward_dist Min                1.13548e-132
evaluation/env_infos/initial/reward_dist Mean             0.00490623
evaluation/env_infos/initial/reward_dist Std              0.00900266
evaluation/env_infos/initial/reward_dist Max              0.044639
evaluation/env_infos/initial/reward_dist Min              9.50449e-07
evaluation/env_infos/reward_dist Mean                     0.137541
evaluation/env_infos/reward_dist Std                      0.23507
evaluation/env_infos/reward_dist Max                      0.994929
evaluation/env_infos/reward_dist Min                      1.13548e-132
time/data storing (s)                                    40.8762
time/evaluation sampling (s)                              0.765784
time/exploration sampling (s)                             0.0889646
time/logging (s)                                          0.01666
time/saving (s)                                           0.794054
time/training (s)                                        39.9941
time/epoch (s)                                           82.5357
time/total (s)                                        20478
Epoch                                                   269
---------------------------------------------------  -----------------
2021-05-29 05:38:36.012695 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 270 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.018596
trainer/QF2 Loss                                          0.00989006
trainer/Policy Loss                                       2.8067
trainer/Q1 Predictions Mean                              -0.801497
trainer/Q1 Predictions Std                                0.96946
trainer/Q1 Predictions Max                                0.73916
trainer/Q1 Predictions Min                               -4.14162
trainer/Q2 Predictions Mean                              -0.770381
trainer/Q2 Predictions Std                                1.00491
trainer/Q2 Predictions Max                                1.02889
trainer/Q2 Predictions Min                               -3.85391
trainer/Q Targets Mean                                   -0.810948
trainer/Q Targets Std                                     0.99241
trainer/Q Targets Max                                     0.879332
trainer/Q Targets Min                                    -3.92123
trainer/Log Pis Mean                                      2.02204
trainer/Log Pis Std                                       1.17668
trainer/Log Pis Max                                       5.70916
trainer/Log Pis Min                                      -4.07796
trainer/Policy mu Mean                                   -0.0186524
trainer/Policy mu Std                                     0.359424
trainer/Policy mu Max                                     1.94046
trainer/Policy mu Min                                    -2.512
trainer/Policy log std Mean                              -2.30957
trainer/Policy log std Std                                0.422267
trainer/Policy log std Max                               -0.234684
trainer/Policy log std Min                               -3.18504
trainer/Alpha                                             0.0212499
trainer/Alpha Loss                                        0.0848965
exploration/num steps total                           28100
exploration/num paths total                            1405
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.152477
exploration/Rewards Std                                   0.091623
exploration/Rewards Max                                   0.030941
exploration/Rewards Min                                  -0.641027
exploration/Returns Mean                                 -3.04954
exploration/Returns Std                                   1.08144
exploration/Returns Max                                  -1.39495
exploration/Returns Min                                  -4.29217
exploration/Actions Mean                                  0.0124351
exploration/Actions Std                                   0.118178
exploration/Actions Max                                   0.788177
exploration/Actions Min                                  -0.426399
exploration/Num Paths                                     5
exploration/Average Returns                              -3.04954
exploration/env_infos/final/reward_energy Mean           -0.215359
exploration/env_infos/final/reward_energy Std             0.298812
exploration/env_infos/final/reward_energy Max            -0.0359842
exploration/env_infos/final/reward_energy Min            -0.810862
exploration/env_infos/initial/reward_energy Mean         -0.254031
exploration/env_infos/initial/reward_energy Std           0.161847
exploration/env_infos/initial/reward_energy Max          -0.0910208
exploration/env_infos/initial/reward_energy Min          -0.518224
exploration/env_infos/reward_energy Mean                 -0.129189
exploration/env_infos/reward_energy Std                   0.107477
exploration/env_infos/reward_energy Max                  -0.00592009
exploration/env_infos/reward_energy Min                  -0.810862
exploration/env_infos/final/end_effector_loc Mean         0.0443063
exploration/env_infos/final/end_effector_loc Std          0.354373
exploration/env_infos/final/end_effector_loc Max          0.736534
exploration/env_infos/final/end_effector_loc Min         -0.509835
exploration/env_infos/initial/end_effector_loc Mean       0.000219056
exploration/env_infos/initial/end_effector_loc Std        0.0106471
exploration/env_infos/initial/end_effector_loc Max        0.0156556
exploration/env_infos/initial/end_effector_loc Min       -0.02132
exploration/env_infos/end_effector_loc Mean               0.0106962
exploration/env_infos/end_effector_loc Std                0.183123
exploration/env_infos/end_effector_loc Max                0.736534
exploration/env_infos/end_effector_loc Min               -0.509835
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00431156
exploration/env_infos/final/reward_dist Std               0.00799557
exploration/env_infos/final/reward_dist Max               0.0202716
exploration/env_infos/final/reward_dist Min               5.8733e-20
exploration/env_infos/initial/reward_dist Mean            0.00108764
exploration/env_infos/initial/reward_dist Std             0.00133003
exploration/env_infos/initial/reward_dist Max             0.00318972
exploration/env_infos/initial/reward_dist Min             8.2634e-06
exploration/env_infos/reward_dist Mean                    0.0664902
exploration/env_infos/reward_dist Std                     0.139953
exploration/env_infos/reward_dist Max                     0.733655
exploration/env_infos/reward_dist Min                     5.8733e-20
evaluation/num steps total                           271000
evaluation/num paths total                            13550
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0916098
evaluation/Rewards Std                                    0.134408
evaluation/Rewards Max                                    0.11417
evaluation/Rewards Min                                   -1.0003
evaluation/Returns Mean                                  -1.8322
evaluation/Returns Std                                    1.88388
evaluation/Returns Max                                    0.865165
evaluation/Returns Min                                   -9.47482
evaluation/Actions Mean                                  -0.00796163
evaluation/Actions Std                                    0.103584
evaluation/Actions Max                                    0.591445
evaluation/Actions Min                                   -0.909086
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.8322
evaluation/env_infos/final/reward_energy Mean            -0.047186
evaluation/env_infos/final/reward_energy Std              0.0379421
evaluation/env_infos/final/reward_energy Max             -0.00543481
evaluation/env_infos/final/reward_energy Min             -0.159731
evaluation/env_infos/initial/reward_energy Mean          -0.240906
evaluation/env_infos/initial/reward_energy Std            0.206421
evaluation/env_infos/initial/reward_energy Max           -0.00138204
evaluation/env_infos/initial/reward_energy Min           -0.967701
evaluation/env_infos/reward_energy Mean                  -0.0855803
evaluation/env_infos/reward_energy Std                    0.119424
evaluation/env_infos/reward_energy Max                   -0.00138204
evaluation/env_infos/reward_energy Min                   -0.973356
evaluation/env_infos/final/end_effector_loc Mean         -0.00776637
evaluation/env_infos/final/end_effector_loc Std           0.342128
evaluation/env_infos/final/end_effector_loc Max           0.726029
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000278233
evaluation/env_infos/initial/end_effector_loc Std         0.0112129
evaluation/env_infos/initial/end_effector_loc Max         0.0295723
evaluation/env_infos/initial/end_effector_loc Min        -0.0357094
evaluation/env_infos/end_effector_loc Mean               -0.000255389
evaluation/env_infos/end_effector_loc Std                 0.223218
evaluation/env_infos/end_effector_loc Max                 0.726029
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.100672
evaluation/env_infos/final/reward_dist Std                0.211616
evaluation/env_infos/final/reward_dist Max                0.891783
evaluation/env_infos/final/reward_dist Min                1.86495e-99
evaluation/env_infos/initial/reward_dist Mean             0.0073163
evaluation/env_infos/initial/reward_dist Std              0.0121876
evaluation/env_infos/initial/reward_dist Max              0.0504487
evaluation/env_infos/initial/reward_dist Min              2.41398e-06
evaluation/env_infos/reward_dist Mean                     0.126745
evaluation/env_infos/reward_dist Std                      0.225788
evaluation/env_infos/reward_dist Max                      0.981546
evaluation/env_infos/reward_dist Min                      1.86495e-99
time/data storing (s)                                    38.4127
time/evaluation sampling (s)                              0.555129
time/exploration sampling (s)                             0.0818242
time/logging (s)                                          0.0167943
time/saving (s)                                           0.791519
time/training (s)                                        41.1121
time/epoch (s)                                           80.97
time/total (s)                                        20561.9
Epoch                                                   270
---------------------------------------------------  ----------------
2021-05-29 05:39:58.869533 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 271 finished
---------------------------------------------------  ----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00511477
trainer/QF2 Loss                                          0.00536967
trainer/Policy Loss                                       2.89496
trainer/Q1 Predictions Mean                              -0.817425
trainer/Q1 Predictions Std                                0.977689
trainer/Q1 Predictions Max                                1.02854
trainer/Q1 Predictions Min                               -3.74346
trainer/Q2 Predictions Mean                              -0.836021
trainer/Q2 Predictions Std                                0.973497
trainer/Q2 Predictions Max                                0.967978
trainer/Q2 Predictions Min                               -3.74059
trainer/Q Targets Mean                                   -0.823909
trainer/Q Targets Std                                     0.978886
trainer/Q Targets Max                                     0.962208
trainer/Q Targets Min                                    -3.68923
trainer/Log Pis Mean                                      2.08216
trainer/Log Pis Std                                       1.14243
trainer/Log Pis Max                                       5.03828
trainer/Log Pis Min                                      -4.33455
trainer/Policy mu Mean                                   -0.00831068
trainer/Policy mu Std                                     0.392651
trainer/Policy mu Max                                     2.34509
trainer/Policy mu Min                                    -2.61956
trainer/Policy log std Mean                              -2.31079
trainer/Policy log std Std                                0.416012
trainer/Policy log std Max                               -0.34194
trainer/Policy log std Min                               -3.06331
trainer/Alpha                                             0.0202858
trainer/Alpha Loss                                        0.32033
exploration/num steps total                           28200
exploration/num paths total                            1410
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.188502
exploration/Rewards Std                                   0.206062
exploration/Rewards Max                                   0.164005
exploration/Rewards Min                                  -0.911924
exploration/Returns Mean                                 -3.77004
exploration/Returns Std                                   3.08029
exploration/Returns Max                                   0.614115
exploration/Returns Min                                  -7.90263
exploration/Actions Mean                                 -0.0153881
exploration/Actions Std                                   0.210255
exploration/Actions Max                                   0.771301
exploration/Actions Min                                  -0.767487
exploration/Num Paths                                     5
exploration/Average Returns                              -3.77004
exploration/env_infos/final/reward_energy Mean           -0.155627
exploration/env_infos/final/reward_energy Std             0.0836355
exploration/env_infos/final/reward_energy Max            -0.0883797
exploration/env_infos/final/reward_energy Min            -0.318539
exploration/env_infos/initial/reward_energy Mean         -0.480763
exploration/env_infos/initial/reward_energy Std           0.215742
exploration/env_infos/initial/reward_energy Max          -0.211068
exploration/env_infos/initial/reward_energy Min          -0.785392
exploration/env_infos/reward_energy Mean                 -0.229236
exploration/env_infos/reward_energy Std                   0.190628
exploration/env_infos/reward_energy Max                  -0.00959856
exploration/env_infos/reward_energy Min                  -0.883578
exploration/env_infos/final/end_effector_loc Mean        -0.0377178
exploration/env_infos/final/end_effector_loc Std          0.320714
exploration/env_infos/final/end_effector_loc Max          0.444585
exploration/env_infos/final/end_effector_loc Min         -0.562142
exploration/env_infos/initial/end_effector_loc Mean      -0.00253522
exploration/env_infos/initial/end_effector_loc Std        0.0184573
exploration/env_infos/initial/end_effector_loc Max        0.0355059
exploration/env_infos/initial/end_effector_loc Min       -0.0258016
exploration/env_infos/end_effector_loc Mean               0.0186389
exploration/env_infos/end_effector_loc Std                0.242677
exploration/env_infos/end_effector_loc Max                0.631031
exploration/env_infos/end_effector_loc Min               -0.562142
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0156143
exploration/env_infos/final/reward_dist Std               0.0307334
exploration/env_infos/final/reward_dist Max               0.0770766
exploration/env_infos/final/reward_dist Min               2.93893e-53
exploration/env_infos/initial/reward_dist Mean            0.0145437
exploration/env_infos/initial/reward_dist Std             0.0233061
exploration/env_infos/initial/reward_dist Max             0.0608921
exploration/env_infos/initial/reward_dist Min             0.000132948
exploration/env_infos/reward_dist Mean                    0.105874
exploration/env_infos/reward_dist Std                     0.228022
exploration/env_infos/reward_dist Max                     0.97113
exploration/env_infos/reward_dist Min                     2.93893e-53
evaluation/num steps total                           272000
evaluation/num paths total                            13600
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.0677086
evaluation/Rewards Std                                    0.0933069
evaluation/Rewards Max                                    0.131724
evaluation/Rewards Min                                   -0.430161
evaluation/Returns Mean                                  -1.35417
evaluation/Returns Std                                    1.42341
evaluation/Returns Max                                    1.28698
evaluation/Returns Min                                   -6.41776
evaluation/Actions Mean                                   0.00425259
evaluation/Actions Std                                    0.0890729
evaluation/Actions Max                                    0.57553
evaluation/Actions Min                                   -0.778586
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.35417
evaluation/env_infos/final/reward_energy Mean            -0.0639472
evaluation/env_infos/final/reward_energy Std              0.0510929
evaluation/env_infos/final/reward_energy Max             -0.00700973
evaluation/env_infos/final/reward_energy Min             -0.268803
evaluation/env_infos/initial/reward_energy Mean          -0.27811
evaluation/env_infos/initial/reward_energy Std            0.236793
evaluation/env_infos/initial/reward_energy Max           -0.0218341
evaluation/env_infos/initial/reward_energy Min           -0.968211
evaluation/env_infos/reward_energy Mean                  -0.0827294
evaluation/env_infos/reward_energy Std                    0.095184
evaluation/env_infos/reward_energy Max                   -0.00214097
evaluation/env_infos/reward_energy Min                   -0.968211
evaluation/env_infos/final/end_effector_loc Mean          0.0652303
evaluation/env_infos/final/end_effector_loc Std           0.322292
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -0.709048
evaluation/env_infos/initial/end_effector_loc Mean       -0.000945821
evaluation/env_infos/initial/end_effector_loc Std         0.0128793
evaluation/env_infos/initial/end_effector_loc Max         0.0287765
evaluation/env_infos/initial/end_effector_loc Min        -0.0389293
evaluation/env_infos/end_effector_loc Mean                0.0308889
evaluation/env_infos/end_effector_loc Std                 0.20697
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -0.709048
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0707762
evaluation/env_infos/final/reward_dist Std                0.179295
evaluation/env_infos/final/reward_dist Max                0.810701
evaluation/env_infos/final/reward_dist Min                1.04491e-65
evaluation/env_infos/initial/reward_dist Mean             0.0081829
evaluation/env_infos/initial/reward_dist Std              0.0186375
evaluation/env_infos/initial/reward_dist Max              0.09597
evaluation/env_infos/initial/reward_dist Min              2.33486e-06
evaluation/env_infos/reward_dist Mean                     0.142507
evaluation/env_infos/reward_dist Std                      0.255806
evaluation/env_infos/reward_dist Max                      0.996902
evaluation/env_infos/reward_dist Min                      1.01044e-65
time/data storing (s)                                    38.7205
time/evaluation sampling (s)                              0.640269
time/exploration sampling (s)                             0.0934535
time/logging (s)                                          0.0153089
time/saving (s)                                           0.805373
time/training (s)                                        39.6638
time/epoch (s)                                           79.9387
time/total (s)                                        20644.7
Epoch                                                   271
---------------------------------------------------  ----------------
2021-05-29 05:41:22.035402 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 272 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00850618
trainer/QF2 Loss                                          0.00526775
trainer/Policy Loss                                       2.88943
trainer/Q1 Predictions Mean                              -0.822602
trainer/Q1 Predictions Std                                0.951668
trainer/Q1 Predictions Max                                1.05401
trainer/Q1 Predictions Min                               -3.54218
trainer/Q2 Predictions Mean                              -0.823627
trainer/Q2 Predictions Std                                0.963297
trainer/Q2 Predictions Max                                1.08238
trainer/Q2 Predictions Min                               -4.72354
trainer/Q Targets Mean                                   -0.823547
trainer/Q Targets Std                                     0.960517
trainer/Q Targets Max                                     1.12083
trainer/Q Targets Min                                    -4.47568
trainer/Log Pis Mean                                      2.06208
trainer/Log Pis Std                                       1.08294
trainer/Log Pis Max                                       5.61113
trainer/Log Pis Min                                      -1.37973
trainer/Policy mu Mean                                    0.00232818
trainer/Policy mu Std                                     0.289063
trainer/Policy mu Max                                     2.08794
trainer/Policy mu Min                                    -2.71326
trainer/Policy log std Mean                              -2.32873
trainer/Policy log std Std                                0.365299
trainer/Policy log std Max                               -0.311413
trainer/Policy log std Min                               -3.0552
trainer/Alpha                                             0.0204645
trainer/Alpha Loss                                        0.241366
exploration/num steps total                           28300
exploration/num paths total                            1415
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.120799
exploration/Rewards Std                                   0.0886573
exploration/Rewards Max                                   0.0211222
exploration/Rewards Min                                  -0.719323
exploration/Returns Mean                                 -2.41599
exploration/Returns Std                                   0.877313
exploration/Returns Max                                  -0.92974
exploration/Returns Min                                  -3.5755
exploration/Actions Mean                                 -0.00980469
exploration/Actions Std                                   0.127888
exploration/Actions Max                                   0.693252
exploration/Actions Min                                  -0.586505
exploration/Num Paths                                     5
exploration/Average Returns                              -2.41599
exploration/env_infos/final/reward_energy Mean           -0.112949
exploration/env_infos/final/reward_energy Std             0.0593809
exploration/env_infos/final/reward_energy Max            -0.0473003
exploration/env_infos/final/reward_energy Min            -0.225129
exploration/env_infos/initial/reward_energy Mean         -0.465895
exploration/env_infos/initial/reward_energy Std           0.238824
exploration/env_infos/initial/reward_energy Max          -0.236581
exploration/env_infos/initial/reward_energy Min          -0.825898
exploration/env_infos/reward_energy Mean                 -0.137042
exploration/env_infos/reward_energy Std                   0.118838
exploration/env_infos/reward_energy Max                  -0.00473911
exploration/env_infos/reward_energy Min                  -0.825898
exploration/env_infos/final/end_effector_loc Mean         0.0062763
exploration/env_infos/final/end_effector_loc Std          0.267664
exploration/env_infos/final/end_effector_loc Max          0.37282
exploration/env_infos/final/end_effector_loc Min         -0.450767
exploration/env_infos/initial/end_effector_loc Mean       0.00213877
exploration/env_infos/initial/end_effector_loc Std        0.018386
exploration/env_infos/initial/end_effector_loc Max        0.0346626
exploration/env_infos/initial/end_effector_loc Min       -0.0293253
exploration/env_infos/end_effector_loc Mean               0.0326912
exploration/env_infos/end_effector_loc Std                0.193525
exploration/env_infos/end_effector_loc Max                0.398613
exploration/env_infos/end_effector_loc Min               -0.450767
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0817172
exploration/env_infos/final/reward_dist Std               0.162973
exploration/env_infos/final/reward_dist Max               0.407663
exploration/env_infos/final/reward_dist Min               7.88574e-11
exploration/env_infos/initial/reward_dist Mean            0.00560145
exploration/env_infos/initial/reward_dist Std             0.0094931
exploration/env_infos/initial/reward_dist Max             0.0245199
exploration/env_infos/initial/reward_dist Min             4.79624e-06
exploration/env_infos/reward_dist Mean                    0.0366142
exploration/env_infos/reward_dist Std                     0.0751251
exploration/env_infos/reward_dist Max                     0.407663
exploration/env_infos/reward_dist Min                     1.78375e-11
evaluation/num steps total                           273000
evaluation/num paths total                            13650
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.075759
evaluation/Rewards Std                                    0.125794
evaluation/Rewards Max                                    0.170652
evaluation/Rewards Min                                   -1.0112
evaluation/Returns Mean                                  -1.51518
evaluation/Returns Std                                    1.99078
evaluation/Returns Max                                    1.98783
evaluation/Returns Min                                  -12.1783
evaluation/Actions Mean                                  -0.00623807
evaluation/Actions Std                                    0.138831
evaluation/Actions Max                                    0.992599
evaluation/Actions Min                                   -0.984496
evaluation/Num Paths                                     50
evaluation/Average Returns                               -1.51518
evaluation/env_infos/final/reward_energy Mean            -0.109567
evaluation/env_infos/final/reward_energy Std              0.192698
evaluation/env_infos/final/reward_energy Max             -0.0145364
evaluation/env_infos/final/reward_energy Min             -1.08967
evaluation/env_infos/initial/reward_energy Mean          -0.296313
evaluation/env_infos/initial/reward_energy Std            0.223183
evaluation/env_infos/initial/reward_energy Max           -0.018747
evaluation/env_infos/initial/reward_energy Min           -0.946633
evaluation/env_infos/reward_energy Mean                  -0.11071
evaluation/env_infos/reward_energy Std                    0.162386
evaluation/env_infos/reward_energy Max                   -0.00402208
evaluation/env_infos/reward_energy Min                   -1.35584
evaluation/env_infos/final/end_effector_loc Mean          0.0138968
evaluation/env_infos/final/end_effector_loc Std           0.294358
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00129786
evaluation/env_infos/initial/end_effector_loc Std         0.0130511
evaluation/env_infos/initial/end_effector_loc Max         0.0338196
evaluation/env_infos/initial/end_effector_loc Min        -0.0419031
evaluation/env_infos/end_effector_loc Mean                0.0196913
evaluation/env_infos/end_effector_loc Std                 0.196734
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0806119
evaluation/env_infos/final/reward_dist Std                0.170701
evaluation/env_infos/final/reward_dist Max                0.773687
evaluation/env_infos/final/reward_dist Min                3.01245e-102
evaluation/env_infos/initial/reward_dist Mean             0.00594691
evaluation/env_infos/initial/reward_dist Std              0.0122707
evaluation/env_infos/initial/reward_dist Max              0.0607621
evaluation/env_infos/initial/reward_dist Min              1.26288e-06
evaluation/env_infos/reward_dist Mean                     0.147764
evaluation/env_infos/reward_dist Std                      0.258169
evaluation/env_infos/reward_dist Max                      0.997002
evaluation/env_infos/reward_dist Min                      3.01245e-102
time/data storing (s)                                    38.6988
time/evaluation sampling (s)                              0.640914
time/exploration sampling (s)                             0.0844705
time/logging (s)                                          0.0173646
time/saving (s)                                           0.787287
time/training (s)                                        39.9891
time/epoch (s)                                           80.218
time/total (s)                                        20727.9
Epoch                                                   272
---------------------------------------------------  -----------------
2021-05-29 05:42:45.560132 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 273 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.00812595
trainer/QF2 Loss                                          0.00930723
trainer/Policy Loss                                       2.78679
trainer/Q1 Predictions Mean                              -0.88482
trainer/Q1 Predictions Std                                0.917878
trainer/Q1 Predictions Max                                1.14742
trainer/Q1 Predictions Min                               -3.64867
trainer/Q2 Predictions Mean                              -0.877222
trainer/Q2 Predictions Std                                0.907485
trainer/Q2 Predictions Max                                1.12574
trainer/Q2 Predictions Min                               -3.59389
trainer/Q Targets Mean                                   -0.882843
trainer/Q Targets Std                                     0.91472
trainer/Q Targets Max                                     1.12991
trainer/Q Targets Min                                    -3.69201
trainer/Log Pis Mean                                      1.94439
trainer/Log Pis Std                                       1.25469
trainer/Log Pis Max                                       9.30087
trainer/Log Pis Min                                      -2.086
trainer/Policy mu Mean                                   -0.0782852
trainer/Policy mu Std                                     0.610224
trainer/Policy mu Max                                     2.40201
trainer/Policy mu Min                                    -5.24762
trainer/Policy log std Mean                              -2.19514
trainer/Policy log std Std                                0.490457
trainer/Policy log std Max                                0.648761
trainer/Policy log std Min                               -2.99512
trainer/Alpha                                             0.0215439
trainer/Alpha Loss                                       -0.213323
exploration/num steps total                           28400
exploration/num paths total                            1420
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.179124
exploration/Rewards Std                                   0.106632
exploration/Rewards Max                                  -0.0424921
exploration/Rewards Min                                  -0.880094
exploration/Returns Mean                                 -3.58247
exploration/Returns Std                                   0.979916
exploration/Returns Max                                  -2.55166
exploration/Returns Min                                  -5.41081
exploration/Actions Mean                                 -0.0116664
exploration/Actions Std                                   0.230111
exploration/Actions Max                                   0.86974
exploration/Actions Min                                  -0.990337
exploration/Num Paths                                     5
exploration/Average Returns                              -3.58247
exploration/env_infos/final/reward_energy Mean           -0.193187
exploration/env_infos/final/reward_energy Std             0.130219
exploration/env_infos/final/reward_energy Max            -0.0822075
exploration/env_infos/final/reward_energy Min            -0.420276
exploration/env_infos/initial/reward_energy Mean         -0.651931
exploration/env_infos/initial/reward_energy Std           0.494919
exploration/env_infos/initial/reward_energy Max          -0.0591101
exploration/env_infos/initial/reward_energy Min          -1.31803
exploration/env_infos/reward_energy Mean                 -0.232706
exploration/env_infos/reward_energy Std                   0.228084
exploration/env_infos/reward_energy Max                  -0.0176788
exploration/env_infos/reward_energy Min                  -1.31803
exploration/env_infos/final/end_effector_loc Mean        -0.103227
exploration/env_infos/final/end_effector_loc Std          0.350865
exploration/env_infos/final/end_effector_loc Max          0.441254
exploration/env_infos/final/end_effector_loc Min         -0.615595
exploration/env_infos/initial/end_effector_loc Mean      -0.0126037
exploration/env_infos/initial/end_effector_loc Std        0.0260499
exploration/env_infos/initial/end_effector_loc Max        0.043487
exploration/env_infos/initial/end_effector_loc Min       -0.0495168
exploration/env_infos/end_effector_loc Mean              -0.0523196
exploration/env_infos/end_effector_loc Std                0.216865
exploration/env_infos/end_effector_loc Max                0.441254
exploration/env_infos/end_effector_loc Min               -0.615595
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              2.12743e-11
exploration/env_infos/final/reward_dist Std               3.42404e-11
exploration/env_infos/final/reward_dist Max               8.9312e-11
exploration/env_infos/final/reward_dist Min               5.01095e-58
exploration/env_infos/initial/reward_dist Mean            0.00550057
exploration/env_infos/initial/reward_dist Std             0.00491235
exploration/env_infos/initial/reward_dist Max             0.0113432
exploration/env_infos/initial/reward_dist Min             2.12378e-08
exploration/env_infos/reward_dist Mean                    0.00506144
exploration/env_infos/reward_dist Std                     0.011157
exploration/env_infos/reward_dist Max                     0.0606705
exploration/env_infos/reward_dist Min                     5.01095e-58
evaluation/num steps total                           274000
evaluation/num paths total                            13700
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.12076
evaluation/Rewards Std                                    0.192064
evaluation/Rewards Max                                    0.155915
evaluation/Rewards Min                                   -1.20966
evaluation/Returns Mean                                  -2.4152
evaluation/Returns Std                                    3.38305
evaluation/Returns Max                                    1.85053
evaluation/Returns Min                                  -14.8569
evaluation/Actions Mean                                  -0.0171428
evaluation/Actions Std                                    0.172517
evaluation/Actions Max                                    0.867624
evaluation/Actions Min                                   -0.999982
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.4152
evaluation/env_infos/final/reward_energy Mean            -0.0603815
evaluation/env_infos/final/reward_energy Std              0.0469301
evaluation/env_infos/final/reward_energy Max             -0.00852017
evaluation/env_infos/final/reward_energy Min             -0.289883
evaluation/env_infos/initial/reward_energy Mean          -0.368163
evaluation/env_infos/initial/reward_energy Std            0.321881
evaluation/env_infos/initial/reward_energy Max           -0.0124349
evaluation/env_infos/initial/reward_energy Min           -1.30124
evaluation/env_infos/reward_energy Mean                  -0.125471
evaluation/env_infos/reward_energy Std                    0.21064
evaluation/env_infos/reward_energy Max                   -0.00403836
evaluation/env_infos/reward_energy Min                   -1.35641
evaluation/env_infos/final/end_effector_loc Mean         -0.0208594
evaluation/env_infos/final/end_effector_loc Std           0.41108
evaluation/env_infos/final/end_effector_loc Max           0.971001
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.0022619
evaluation/env_infos/initial/end_effector_loc Std         0.0171413
evaluation/env_infos/initial/end_effector_loc Max         0.0433812
evaluation/env_infos/initial/end_effector_loc Min        -0.049998
evaluation/env_infos/end_effector_loc Mean               -0.0304971
evaluation/env_infos/end_effector_loc Std                 0.293586
evaluation/env_infos/end_effector_loc Max                 0.971001
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0757216
evaluation/env_infos/final/reward_dist Std                0.144956
evaluation/env_infos/final/reward_dist Max                0.587013
evaluation/env_infos/final/reward_dist Min                2.38587e-162
evaluation/env_infos/initial/reward_dist Mean             0.00471672
evaluation/env_infos/initial/reward_dist Std              0.00797098
evaluation/env_infos/initial/reward_dist Max              0.0356311
evaluation/env_infos/initial/reward_dist Min              4.05002e-09
evaluation/env_infos/reward_dist Mean                     0.131711
evaluation/env_infos/reward_dist Std                      0.241744
evaluation/env_infos/reward_dist Max                      0.993245
evaluation/env_infos/reward_dist Min                      2.38587e-162
time/data storing (s)                                    38.9514
time/evaluation sampling (s)                              0.614667
time/exploration sampling (s)                             0.0898356
time/logging (s)                                          0.0168534
time/saving (s)                                           0.805053
time/training (s)                                        40.2148
time/epoch (s)                                           80.6927
time/total (s)                                        20811.4
Epoch                                                   273
---------------------------------------------------  -----------------
2021-05-29 05:44:09.625132 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 274 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          1.21506
trainer/QF2 Loss                                          0.086416
trainer/Policy Loss                                       2.67527
trainer/Q1 Predictions Mean                              -0.549968
trainer/Q1 Predictions Std                                1.72765
trainer/Q1 Predictions Max                                8.59415
trainer/Q1 Predictions Min                               -4.08607
trainer/Q2 Predictions Mean                              -0.707437
trainer/Q2 Predictions Std                                1.16231
trainer/Q2 Predictions Max                                5.09342
trainer/Q2 Predictions Min                               -3.98583
trainer/Q Targets Mean                                   -0.750554
trainer/Q Targets Std                                     1.03206
trainer/Q Targets Max                                     2.80332
trainer/Q Targets Min                                    -4.33092
trainer/Log Pis Mean                                      2.06525
trainer/Log Pis Std                                       1.35199
trainer/Log Pis Max                                       7.34608
trainer/Log Pis Min                                      -3.17131
trainer/Policy mu Mean                                   -0.166905
trainer/Policy mu Std                                     0.681304
trainer/Policy mu Max                                     2.15013
trainer/Policy mu Min                                    -3.4004
trainer/Policy log std Mean                              -2.12972
trainer/Policy log std Std                                0.52913
trainer/Policy log std Max                                0.0775936
trainer/Policy log std Min                               -2.78582
trainer/Alpha                                             0.0229155
trainer/Alpha Loss                                        0.246421
exploration/num steps total                           28500
exploration/num paths total                            1425
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.160133
exploration/Rewards Std                                   0.107369
exploration/Rewards Max                                   0.101852
exploration/Rewards Min                                  -0.331078
exploration/Returns Mean                                 -3.20265
exploration/Returns Std                                   1.79886
exploration/Returns Max                                  -0.130609
exploration/Returns Min                                  -5.30877
exploration/Actions Mean                                 -0.116179
exploration/Actions Std                                   0.331197
exploration/Actions Max                                   0.643227
exploration/Actions Min                                  -1
exploration/Num Paths                                     5
exploration/Average Returns                              -3.20265
exploration/env_infos/final/reward_energy Mean           -0.279661
exploration/env_infos/final/reward_energy Std             0.351312
exploration/env_infos/final/reward_energy Max            -0.0653514
exploration/env_infos/final/reward_energy Min            -0.975062
exploration/env_infos/initial/reward_energy Mean         -0.474936
exploration/env_infos/initial/reward_energy Std           0.314106
exploration/env_infos/initial/reward_energy Max          -0.0840059
exploration/env_infos/initial/reward_energy Min          -0.858658
exploration/env_infos/reward_energy Mean                 -0.350282
exploration/env_infos/reward_energy Std                   0.351683
exploration/env_infos/reward_energy Max                  -0.0134874
exploration/env_infos/reward_energy Min                  -1.18807
exploration/env_infos/final/end_effector_loc Mean        -0.264384
exploration/env_infos/final/end_effector_loc Std          0.405408
exploration/env_infos/final/end_effector_loc Max          0.25875
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00666586
exploration/env_infos/initial/end_effector_loc Std        0.0189961
exploration/env_infos/initial/end_effector_loc Max        0.027621
exploration/env_infos/initial/end_effector_loc Min       -0.0415903
exploration/env_infos/end_effector_loc Mean              -0.138398
exploration/env_infos/end_effector_loc Std                0.342469
exploration/env_infos/end_effector_loc Max                0.266584
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0539519
exploration/env_infos/final/reward_dist Std               0.0845632
exploration/env_infos/final/reward_dist Max               0.21836
exploration/env_infos/final/reward_dist Min               1.41723e-96
exploration/env_infos/initial/reward_dist Mean            0.000249429
exploration/env_infos/initial/reward_dist Std             0.000376468
exploration/env_infos/initial/reward_dist Max             0.000998206
exploration/env_infos/initial/reward_dist Min             1.39263e-06
exploration/env_infos/reward_dist Mean                    0.0750486
exploration/env_infos/reward_dist Std                     0.142888
exploration/env_infos/reward_dist Max                     0.825887
exploration/env_infos/reward_dist Min                     1.41723e-96
evaluation/num steps total                           275000
evaluation/num paths total                            13750
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.210544
evaluation/Rewards Std                                    0.330621
evaluation/Rewards Max                                    0.16748
evaluation/Rewards Min                                   -1.5835
evaluation/Returns Mean                                  -4.21088
evaluation/Returns Std                                    5.9081
evaluation/Returns Max                                    2.0542
evaluation/Returns Min                                  -23.1692
evaluation/Actions Mean                                  -0.103463
evaluation/Actions Std                                    0.324306
evaluation/Actions Max                                    0.999929
evaluation/Actions Min                                   -0.999846
evaluation/Num Paths                                     50
evaluation/Average Returns                               -4.21088
evaluation/env_infos/final/reward_energy Mean            -0.195907
evaluation/env_infos/final/reward_energy Std              0.277212
evaluation/env_infos/final/reward_energy Max             -0.00380161
evaluation/env_infos/final/reward_energy Min             -0.984512
evaluation/env_infos/initial/reward_energy Mean          -0.488283
evaluation/env_infos/initial/reward_energy Std            0.349381
evaluation/env_infos/initial/reward_energy Max           -0.0265022
evaluation/env_infos/initial/reward_energy Min           -1.20199
evaluation/env_infos/reward_energy Mean                  -0.295395
evaluation/env_infos/reward_energy Std                    0.380131
evaluation/env_infos/reward_energy Max                   -0.00258407
evaluation/env_infos/reward_energy Min                   -1.41036
evaluation/env_infos/final/end_effector_loc Mean         -0.239965
evaluation/env_infos/final/end_effector_loc Std           0.477751
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00872034
evaluation/env_infos/initial/end_effector_loc Std         0.0193537
evaluation/env_infos/initial/end_effector_loc Max         0.0351882
evaluation/env_infos/initial/end_effector_loc Min        -0.0499417
evaluation/env_infos/end_effector_loc Mean               -0.144012
evaluation/env_infos/end_effector_loc Std                 0.384102
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.107408
evaluation/env_infos/final/reward_dist Std                0.244971
evaluation/env_infos/final/reward_dist Max                0.930459
evaluation/env_infos/final/reward_dist Min                2.08174e-187
evaluation/env_infos/initial/reward_dist Mean             0.00753731
evaluation/env_infos/initial/reward_dist Std              0.0127755
evaluation/env_infos/initial/reward_dist Max              0.0551207
evaluation/env_infos/initial/reward_dist Min              8.01907e-09
evaluation/env_infos/reward_dist Mean                     0.15584
evaluation/env_infos/reward_dist Std                      0.271375
evaluation/env_infos/reward_dist Max                      0.996886
evaluation/env_infos/reward_dist Min                      2.08174e-187
time/data storing (s)                                    38.6499
time/evaluation sampling (s)                              0.656549
time/exploration sampling (s)                             0.0860327
time/logging (s)                                          0.0168179
time/saving (s)                                           0.795193
time/training (s)                                        40.2859
time/epoch (s)                                           80.4904
time/total (s)                                        20895.5
Epoch                                                   274
---------------------------------------------------  -----------------
2021-05-29 05:45:33.851258 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 275 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0489805
trainer/QF2 Loss                                          0.16872
trainer/Policy Loss                                       2.68263
trainer/Q1 Predictions Mean                              -0.684539
trainer/Q1 Predictions Std                                1.02511
trainer/Q1 Predictions Max                                3.32583
trainer/Q1 Predictions Min                               -4.00615
trainer/Q2 Predictions Mean                              -0.720744
trainer/Q2 Predictions Std                                1.09058
trainer/Q2 Predictions Max                                5.15292
trainer/Q2 Predictions Min                               -3.95763
trainer/Q Targets Mean                                   -0.716213
trainer/Q Targets Std                                     0.99637
trainer/Q Targets Max                                     3.09123
trainer/Q Targets Min                                    -4.17341
trainer/Log Pis Mean                                      2.02673
trainer/Log Pis Std                                       1.39807
trainer/Log Pis Max                                       7.50266
trainer/Log Pis Min                                      -2.23514
trainer/Policy mu Mean                                   -0.079665
trainer/Policy mu Std                                     0.816141
trainer/Policy mu Max                                     2.75811
trainer/Policy mu Min                                    -4.74461
trainer/Policy log std Mean                              -1.9948
trainer/Policy log std Std                                0.657115
trainer/Policy log std Max                                1.56202
trainer/Policy log std Min                               -2.82602
trainer/Alpha                                             0.0221841
trainer/Alpha Loss                                        0.101824
exploration/num steps total                           28600
exploration/num paths total                            1430
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.429826
exploration/Rewards Std                                   0.320681
exploration/Rewards Max                                  -0.0269069
exploration/Rewards Min                                  -1.43173
exploration/Returns Mean                                 -8.59651
exploration/Returns Std                                   5.53706
exploration/Returns Max                                  -3.07414
exploration/Returns Min                                 -18.8943
exploration/Actions Mean                                 -0.137654
exploration/Actions Std                                   0.531494
exploration/Actions Max                                   0.965892
exploration/Actions Min                                  -0.966201
exploration/Num Paths                                     5
exploration/Average Returns                              -8.59651
exploration/env_infos/final/reward_energy Mean           -0.726738
exploration/env_infos/final/reward_energy Std             0.350333
exploration/env_infos/final/reward_energy Max            -0.044682
exploration/env_infos/final/reward_energy Min            -1.0506
exploration/env_infos/initial/reward_energy Mean         -0.70267
exploration/env_infos/initial/reward_energy Std           0.416894
exploration/env_infos/initial/reward_energy Max          -0.14611
exploration/env_infos/initial/reward_energy Min          -1.17485
exploration/env_infos/reward_energy Mean                 -0.639528
exploration/env_infos/reward_energy Std                   0.440311
exploration/env_infos/reward_energy Max                  -0.00537539
exploration/env_infos/reward_energy Min                  -1.34065
exploration/env_infos/final/end_effector_loc Mean        -0.0301177
exploration/env_infos/final/end_effector_loc Std          0.803578
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00833068
exploration/env_infos/initial/end_effector_loc Std        0.0276592
exploration/env_infos/initial/end_effector_loc Max        0.0344705
exploration/env_infos/initial/end_effector_loc Min       -0.0475653
exploration/env_infos/end_effector_loc Mean              -0.0555553
exploration/env_infos/end_effector_loc Std                0.613351
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              7.53091e-17
exploration/env_infos/final/reward_dist Std               1.50618e-16
exploration/env_infos/final/reward_dist Max               3.76546e-16
exploration/env_infos/final/reward_dist Min               8.10668e-193
exploration/env_infos/initial/reward_dist Mean            0.00780501
exploration/env_infos/initial/reward_dist Std             0.00838053
exploration/env_infos/initial/reward_dist Max             0.0180252
exploration/env_infos/initial/reward_dist Min             9.55879e-07
exploration/env_infos/reward_dist Mean                    0.0194652
exploration/env_infos/reward_dist Std                     0.0627263
exploration/env_infos/reward_dist Max                     0.313781
exploration/env_infos/reward_dist Min                     8.10668e-193
evaluation/num steps total                           276000
evaluation/num paths total                            13800
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.346002
evaluation/Rewards Std                                    0.375247
evaluation/Rewards Max                                    0.133365
evaluation/Rewards Min                                   -1.52692
evaluation/Returns Mean                                  -6.92003
evaluation/Returns Std                                    6.86094
evaluation/Returns Max                                    1.63338
evaluation/Returns Min                                  -22.0018
evaluation/Actions Mean                                  -0.0470352
evaluation/Actions Std                                    0.398473
evaluation/Actions Max                                    0.992191
evaluation/Actions Min                                   -0.999882
evaluation/Num Paths                                     50
evaluation/Average Returns                               -6.92003
evaluation/env_infos/final/reward_energy Mean            -0.277105
evaluation/env_infos/final/reward_energy Std              0.278633
evaluation/env_infos/final/reward_energy Max             -0.0125549
evaluation/env_infos/final/reward_energy Min             -1.28672
evaluation/env_infos/initial/reward_energy Mean          -0.638695
evaluation/env_infos/initial/reward_energy Std            0.33834
evaluation/env_infos/initial/reward_energy Max           -0.0655909
evaluation/env_infos/initial/reward_energy Min           -1.14253
evaluation/env_infos/reward_energy Mean                  -0.399118
evaluation/env_infos/reward_energy Std                    0.40335
evaluation/env_infos/reward_energy Max                   -0.0025909
evaluation/env_infos/reward_energy Min                   -1.39289
evaluation/env_infos/final/end_effector_loc Mean         -0.00839897
evaluation/env_infos/final/end_effector_loc Std           0.697202
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.013132
evaluation/env_infos/initial/end_effector_loc Std         0.0219216
evaluation/env_infos/initial/end_effector_loc Max         0.0407066
evaluation/env_infos/initial/end_effector_loc Min        -0.0499941
evaluation/env_infos/end_effector_loc Mean               -0.0908217
evaluation/env_infos/end_effector_loc Std                 0.528429
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.031495
evaluation/env_infos/final/reward_dist Std                0.121428
evaluation/env_infos/final/reward_dist Max                0.763123
evaluation/env_infos/final/reward_dist Min                8.85744e-200
evaluation/env_infos/initial/reward_dist Mean             0.00644453
evaluation/env_infos/initial/reward_dist Std              0.0143347
evaluation/env_infos/initial/reward_dist Max              0.0885965
evaluation/env_infos/initial/reward_dist Min              1.21156e-07
evaluation/env_infos/reward_dist Mean                     0.075122
evaluation/env_infos/reward_dist Std                      0.177707
evaluation/env_infos/reward_dist Max                      0.989867
evaluation/env_infos/reward_dist Min                      8.85744e-200
time/data storing (s)                                    39.4553
time/evaluation sampling (s)                              0.675819
time/exploration sampling (s)                             0.0906464
time/logging (s)                                          0.0168255
time/saving (s)                                           0.801445
time/training (s)                                        40.212
time/epoch (s)                                           81.252
time/total (s)                                        20979.7
Epoch                                                   275
---------------------------------------------------  -----------------
2021-05-29 05:46:57.549200 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 276 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.015662
trainer/QF2 Loss                                          0.0147547
trainer/Policy Loss                                       2.62002
trainer/Q1 Predictions Mean                              -0.771657
trainer/Q1 Predictions Std                                0.92209
trainer/Q1 Predictions Max                                2.30464
trainer/Q1 Predictions Min                               -4.0921
trainer/Q2 Predictions Mean                              -0.761357
trainer/Q2 Predictions Std                                0.901327
trainer/Q2 Predictions Max                                1.72834
trainer/Q2 Predictions Min                               -3.99359
trainer/Q Targets Mean                                   -0.760899
trainer/Q Targets Std                                     0.913118
trainer/Q Targets Max                                     2.23916
trainer/Q Targets Min                                    -4.20487
trainer/Log Pis Mean                                      1.90822
trainer/Log Pis Std                                       1.49082
trainer/Log Pis Max                                       7.91737
trainer/Log Pis Min                                      -4.45444
trainer/Policy mu Mean                                   -0.11455
trainer/Policy mu Std                                     0.707794
trainer/Policy mu Max                                     2.66177
trainer/Policy mu Min                                    -3.25361
trainer/Policy log std Mean                              -2.04727
trainer/Policy log std Std                                0.563073
trainer/Policy log std Max                                0.541641
trainer/Policy log std Min                               -2.85023
trainer/Alpha                                             0.021117
trainer/Alpha Loss                                       -0.354018
exploration/num steps total                           28700
exploration/num paths total                            1435
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.269608
exploration/Rewards Std                                   0.281862
exploration/Rewards Max                                   0.0392769
exploration/Rewards Min                                  -0.914667
exploration/Returns Mean                                 -5.39217
exploration/Returns Std                                   5.22788
exploration/Returns Max                                  -0.291446
exploration/Returns Min                                 -14.222
exploration/Actions Mean                                 -0.0808217
exploration/Actions Std                                   0.3678
exploration/Actions Max                                   0.98862
exploration/Actions Min                                  -0.990381
exploration/Num Paths                                     5
exploration/Average Returns                              -5.39217
exploration/env_infos/final/reward_energy Mean           -0.276125
exploration/env_infos/final/reward_energy Std             0.306363
exploration/env_infos/final/reward_energy Max            -0.061958
exploration/env_infos/final/reward_energy Min            -0.882029
exploration/env_infos/initial/reward_energy Mean         -0.887591
exploration/env_infos/initial/reward_energy Std           0.342265
exploration/env_infos/initial/reward_energy Max          -0.215747
exploration/env_infos/initial/reward_energy Min          -1.1492
exploration/env_infos/reward_energy Mean                 -0.387351
exploration/env_infos/reward_energy Std                   0.365483
exploration/env_infos/reward_energy Max                  -0.00991742
exploration/env_infos/reward_energy Min                  -1.2745
exploration/env_infos/final/end_effector_loc Mean        -0.0729899
exploration/env_infos/final/end_effector_loc Std          0.564854
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.0221
exploration/env_infos/initial/end_effector_loc Std        0.0253534
exploration/env_infos/initial/end_effector_loc Max        0.0210655
exploration/env_infos/initial/end_effector_loc Min       -0.0494441
exploration/env_infos/end_effector_loc Mean              -0.091829
exploration/env_infos/end_effector_loc Std                0.424687
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0491437
exploration/env_infos/final/reward_dist Std               0.063902
exploration/env_infos/final/reward_dist Max               0.156801
exploration/env_infos/final/reward_dist Min               1.23747e-110
exploration/env_infos/initial/reward_dist Mean            0.00458113
exploration/env_infos/initial/reward_dist Std             0.00565514
exploration/env_infos/initial/reward_dist Max             0.0156997
exploration/env_infos/initial/reward_dist Min             1.48237e-05
exploration/env_infos/reward_dist Mean                    0.185494
exploration/env_infos/reward_dist Std                     0.29151
exploration/env_infos/reward_dist Max                     0.955737
exploration/env_infos/reward_dist Min                     1.23747e-110
evaluation/num steps total                           277000
evaluation/num paths total                            13850
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.222272
evaluation/Rewards Std                                    0.287628
evaluation/Rewards Max                                    0.167636
evaluation/Rewards Min                                   -1.18698
evaluation/Returns Mean                                  -4.44544
evaluation/Returns Std                                    5.23904
evaluation/Returns Max                                    2.25379
evaluation/Returns Min                                  -17.6667
evaluation/Actions Mean                                  -0.018658
evaluation/Actions Std                                    0.351405
evaluation/Actions Max                                    0.999969
evaluation/Actions Min                                   -0.996507
evaluation/Num Paths                                     50
evaluation/Average Returns                               -4.44544
evaluation/env_infos/final/reward_energy Mean            -0.212559
evaluation/env_infos/final/reward_energy Std              0.299659
evaluation/env_infos/final/reward_energy Max             -0.0105746
evaluation/env_infos/final/reward_energy Min             -1.23592
evaluation/env_infos/initial/reward_energy Mean          -0.654001
evaluation/env_infos/initial/reward_energy Std            0.416696
evaluation/env_infos/initial/reward_energy Max           -0.00830052
evaluation/env_infos/initial/reward_energy Min           -1.3599
evaluation/env_infos/reward_energy Mean                  -0.324185
evaluation/env_infos/reward_energy Std                    0.377587
evaluation/env_infos/reward_energy Max                   -0.00756963
evaluation/env_infos/reward_energy Min                   -1.40511
evaluation/env_infos/final/end_effector_loc Mean         -0.0138514
evaluation/env_infos/final/end_effector_loc Std           0.572039
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.0093173
evaluation/env_infos/initial/end_effector_loc Std         0.0257853
evaluation/env_infos/initial/end_effector_loc Max         0.0479418
evaluation/env_infos/initial/end_effector_loc Min        -0.049798
evaluation/env_infos/end_effector_loc Mean               -0.0553508
evaluation/env_infos/end_effector_loc Std                 0.447189
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0809074
evaluation/env_infos/final/reward_dist Std                0.184795
evaluation/env_infos/final/reward_dist Max                0.869778
evaluation/env_infos/final/reward_dist Min                4.9247e-195
evaluation/env_infos/initial/reward_dist Mean             0.00614987
evaluation/env_infos/initial/reward_dist Std              0.0116638
evaluation/env_infos/initial/reward_dist Max              0.0451435
evaluation/env_infos/initial/reward_dist Min              6.18852e-09
evaluation/env_infos/reward_dist Mean                     0.12449
evaluation/env_infos/reward_dist Std                      0.241488
evaluation/env_infos/reward_dist Max                      0.995063
evaluation/env_infos/reward_dist Min                      4.9247e-195
time/data storing (s)                                    38.9545
time/evaluation sampling (s)                              0.540905
time/exploration sampling (s)                             0.081666
time/logging (s)                                          0.0154662
time/saving (s)                                           0.810315
time/training (s)                                        40.3865
time/epoch (s)                                           80.7894
time/total (s)                                        21063.4
Epoch                                                   276
---------------------------------------------------  -----------------
2021-05-29 05:48:21.493556 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 277 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0167697
trainer/QF2 Loss                                          0.0130286
trainer/Policy Loss                                       2.76826
trainer/Q1 Predictions Mean                              -0.775697
trainer/Q1 Predictions Std                                0.939742
trainer/Q1 Predictions Max                                2.18209
trainer/Q1 Predictions Min                               -4.20156
trainer/Q2 Predictions Mean                              -0.778509
trainer/Q2 Predictions Std                                0.949888
trainer/Q2 Predictions Max                                2.27811
trainer/Q2 Predictions Min                               -4.44765
trainer/Q Targets Mean                                   -0.758416
trainer/Q Targets Std                                     0.959214
trainer/Q Targets Max                                     2.20394
trainer/Q Targets Min                                    -4.52601
trainer/Log Pis Mean                                      2.04692
trainer/Log Pis Std                                       1.27498
trainer/Log Pis Max                                       8.77315
trainer/Log Pis Min                                      -2.22427
trainer/Policy mu Mean                                   -0.0380928
trainer/Policy mu Std                                     0.740253
trainer/Policy mu Max                                     3.88294
trainer/Policy mu Min                                    -2.95911
trainer/Policy log std Mean                              -2.0293
trainer/Policy log std Std                                0.514449
trainer/Policy log std Max                               -0.123246
trainer/Policy log std Min                               -2.79857
trainer/Alpha                                             0.0207523
trainer/Alpha Loss                                        0.18185
exploration/num steps total                           28800
exploration/num paths total                            1440
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.267261
exploration/Rewards Std                                   0.260747
exploration/Rewards Max                                   0.0841083
exploration/Rewards Min                                  -0.770571
exploration/Returns Mean                                 -5.34522
exploration/Returns Std                                   4.6596
exploration/Returns Max                                   0.239632
exploration/Returns Min                                 -10.9763
exploration/Actions Mean                                 -0.0283434
exploration/Actions Std                                   0.275233
exploration/Actions Max                                   0.696778
exploration/Actions Min                                  -0.991108
exploration/Num Paths                                     5
exploration/Average Returns                              -5.34522
exploration/env_infos/final/reward_energy Mean           -0.301857
exploration/env_infos/final/reward_energy Std             0.274672
exploration/env_infos/final/reward_energy Max            -0.0603981
exploration/env_infos/final/reward_energy Min            -0.746569
exploration/env_infos/initial/reward_energy Mean         -0.634365
exploration/env_infos/initial/reward_energy Std           0.437713
exploration/env_infos/initial/reward_energy Max          -0.156325
exploration/env_infos/initial/reward_energy Min          -1.19094
exploration/env_infos/reward_energy Mean                 -0.292612
exploration/env_infos/reward_energy Std                   0.259791
exploration/env_infos/reward_energy Max                  -0.0202014
exploration/env_infos/reward_energy Min                  -1.19094
exploration/env_infos/final/end_effector_loc Mean        -0.262029
exploration/env_infos/final/end_effector_loc Std          0.474117
exploration/env_infos/final/end_effector_loc Max          0.416364
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.0103754
exploration/env_infos/initial/end_effector_loc Std        0.0251965
exploration/env_infos/initial/end_effector_loc Max        0.0330164
exploration/env_infos/initial/end_effector_loc Min       -0.0495554
exploration/env_infos/end_effector_loc Mean              -0.17629
exploration/env_infos/end_effector_loc Std                0.355555
exploration/env_infos/end_effector_loc Max                0.416364
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0018461
exploration/env_infos/final/reward_dist Std               0.00334847
exploration/env_infos/final/reward_dist Max               0.00852053
exploration/env_infos/final/reward_dist Min               6.2847e-105
exploration/env_infos/initial/reward_dist Mean            0.0080924
exploration/env_infos/initial/reward_dist Std             0.0149768
exploration/env_infos/initial/reward_dist Max             0.0380293
exploration/env_infos/initial/reward_dist Min             4.16302e-05
exploration/env_infos/reward_dist Mean                    0.0553006
exploration/env_infos/reward_dist Std                     0.0988336
exploration/env_infos/reward_dist Max                     0.452053
exploration/env_infos/reward_dist Min                     6.2847e-105
evaluation/num steps total                           278000
evaluation/num paths total                            13900
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.222772
evaluation/Rewards Std                                    0.276743
evaluation/Rewards Max                                    0.129578
evaluation/Rewards Min                                   -1.11828
evaluation/Returns Mean                                  -4.45544
evaluation/Returns Std                                    4.93244
evaluation/Returns Max                                    1.41845
evaluation/Returns Min                                  -17.7163
evaluation/Actions Mean                                  -0.0292109
evaluation/Actions Std                                    0.303603
evaluation/Actions Max                                    1
evaluation/Actions Min                                   -0.999526
evaluation/Num Paths                                     50
evaluation/Average Returns                               -4.45544
evaluation/env_infos/final/reward_energy Mean            -0.273063
evaluation/env_infos/final/reward_energy Std              0.320374
evaluation/env_infos/final/reward_energy Max             -0.00575572
evaluation/env_infos/final/reward_energy Min             -1.40411
evaluation/env_infos/initial/reward_energy Mean          -0.638174
evaluation/env_infos/initial/reward_energy Std            0.365288
evaluation/env_infos/initial/reward_energy Max           -0.0295095
evaluation/env_infos/initial/reward_energy Min           -1.35206
evaluation/env_infos/reward_energy Mean                  -0.282105
evaluation/env_infos/reward_energy Std                    0.326303
evaluation/env_infos/reward_energy Max                   -0.000600975
evaluation/env_infos/reward_energy Min                   -1.41015
evaluation/env_infos/final/end_effector_loc Mean         -0.0681796
evaluation/env_infos/final/end_effector_loc Std           0.529829
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00258987
evaluation/env_infos/initial/end_effector_loc Std         0.0258683
evaluation/env_infos/initial/end_effector_loc Max         0.0462034
evaluation/env_infos/initial/end_effector_loc Min        -0.049749
evaluation/env_infos/end_effector_loc Mean               -0.075059
evaluation/env_infos/end_effector_loc Std                 0.420513
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0951089
evaluation/env_infos/final/reward_dist Std                0.229929
evaluation/env_infos/final/reward_dist Max                0.954523
evaluation/env_infos/final/reward_dist Min                2.38069e-157
evaluation/env_infos/initial/reward_dist Mean             0.00721656
evaluation/env_infos/initial/reward_dist Std              0.0146832
evaluation/env_infos/initial/reward_dist Max              0.0741541
evaluation/env_infos/initial/reward_dist Min              7.85511e-09
evaluation/env_infos/reward_dist Mean                     0.11686
evaluation/env_infos/reward_dist Std                      0.224436
evaluation/env_infos/reward_dist Max                      0.992401
evaluation/env_infos/reward_dist Min                      4.09605e-173
time/data storing (s)                                    38.7696
time/evaluation sampling (s)                              0.663909
time/exploration sampling (s)                             0.0911122
time/logging (s)                                          0.0156435
time/saving (s)                                           0.845031
time/training (s)                                        40.476
time/epoch (s)                                           80.8613
time/total (s)                                        21147.3
Epoch                                                   277
---------------------------------------------------  -----------------
2021-05-29 05:49:45.617588 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 278 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0196286
trainer/QF2 Loss                                          0.0190553
trainer/Policy Loss                                       2.88813
trainer/Q1 Predictions Mean                              -0.819318
trainer/Q1 Predictions Std                                1.00512
trainer/Q1 Predictions Max                                2.3158
trainer/Q1 Predictions Min                               -3.71276
trainer/Q2 Predictions Mean                              -0.809753
trainer/Q2 Predictions Std                                0.98577
trainer/Q2 Predictions Max                                2.28267
trainer/Q2 Predictions Min                               -3.65814
trainer/Q Targets Mean                                   -0.802161
trainer/Q Targets Std                                     1.00668
trainer/Q Targets Max                                     2.62737
trainer/Q Targets Min                                    -3.68423
trainer/Log Pis Mean                                      2.12955
trainer/Log Pis Std                                       1.30474
trainer/Log Pis Max                                       7.45216
trainer/Log Pis Min                                      -3.39589
trainer/Policy mu Mean                                   -0.0277886
trainer/Policy mu Std                                     0.686026
trainer/Policy mu Max                                     2.56258
trainer/Policy mu Min                                    -3.61957
trainer/Policy log std Mean                              -2.13443
trainer/Policy log std Std                                0.54047
trainer/Policy log std Max                               -0.00534534
trainer/Policy log std Min                               -2.8416
trainer/Alpha                                             0.0173024
trainer/Alpha Loss                                        0.525873
exploration/num steps total                           28900
exploration/num paths total                            1445
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.149441
exploration/Rewards Std                                   0.151935
exploration/Rewards Max                                   0.0974157
exploration/Rewards Min                                  -0.559384
exploration/Returns Mean                                 -2.98882
exploration/Returns Std                                   2.46621
exploration/Returns Max                                  -0.50506
exploration/Returns Min                                  -7.7306
exploration/Actions Mean                                 -0.00190041
exploration/Actions Std                                   0.284777
exploration/Actions Max                                   0.963264
exploration/Actions Min                                  -0.93349
exploration/Num Paths                                     5
exploration/Average Returns                              -2.98882
exploration/env_infos/final/reward_energy Mean           -0.242601
exploration/env_infos/final/reward_energy Std             0.272739
exploration/env_infos/final/reward_energy Max            -0.069339
exploration/env_infos/final/reward_energy Min            -0.781819
exploration/env_infos/initial/reward_energy Mean         -0.462803
exploration/env_infos/initial/reward_energy Std           0.300247
exploration/env_infos/initial/reward_energy Max          -0.175766
exploration/env_infos/initial/reward_energy Min          -0.935444
exploration/env_infos/reward_energy Mean                 -0.282082
exploration/env_infos/reward_energy Std                   0.287458
exploration/env_infos/reward_energy Max                  -0.0093124
exploration/env_infos/reward_energy Min                  -1.33794
exploration/env_infos/final/end_effector_loc Mean         0.0875929
exploration/env_infos/final/end_effector_loc Std          0.49955
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.00741658
exploration/env_infos/initial/end_effector_loc Std        0.0180392
exploration/env_infos/initial/end_effector_loc Max        0.0124309
exploration/env_infos/initial/end_effector_loc Min       -0.0465274
exploration/env_infos/end_effector_loc Mean              -0.00272557
exploration/env_infos/end_effector_loc Std                0.336416
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.191697
exploration/env_infos/final/reward_dist Std               0.381161
exploration/env_infos/final/reward_dist Max               0.954018
exploration/env_infos/final/reward_dist Min               2.2514e-111
exploration/env_infos/initial/reward_dist Mean            0.0254979
exploration/env_infos/initial/reward_dist Std             0.0498566
exploration/env_infos/initial/reward_dist Max             0.125207
exploration/env_infos/initial/reward_dist Min             5.78513e-05
exploration/env_infos/reward_dist Mean                    0.112227
exploration/env_infos/reward_dist Std                     0.218932
exploration/env_infos/reward_dist Max                     0.954018
exploration/env_infos/reward_dist Min                     2.2514e-111
evaluation/num steps total                           279000
evaluation/num paths total                            13950
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.238278
evaluation/Rewards Std                                    0.263222
evaluation/Rewards Max                                    0.1286
evaluation/Rewards Min                                   -1.15198
evaluation/Returns Mean                                  -4.76555
evaluation/Returns Std                                    4.68039
evaluation/Returns Max                                    1.09811
evaluation/Returns Min                                  -15.9676
evaluation/Actions Mean                                   0.0127629
evaluation/Actions Std                                    0.335056
evaluation/Actions Max                                    0.999999
evaluation/Actions Min                                   -0.999346
evaluation/Num Paths                                     50
evaluation/Average Returns                               -4.76555
evaluation/env_infos/final/reward_energy Mean            -0.273258
evaluation/env_infos/final/reward_energy Std              0.378699
evaluation/env_infos/final/reward_energy Max             -0.0136543
evaluation/env_infos/final/reward_energy Min             -1.4094
evaluation/env_infos/initial/reward_energy Mean          -0.603136
evaluation/env_infos/initial/reward_energy Std            0.401624
evaluation/env_infos/initial/reward_energy Max           -0.00485365
evaluation/env_infos/initial/reward_energy Min           -1.35995
evaluation/env_infos/reward_energy Mean                  -0.306245
evaluation/env_infos/reward_energy Std                    0.362029
evaluation/env_infos/reward_energy Max                   -0.00264169
evaluation/env_infos/reward_energy Min                   -1.41132
evaluation/env_infos/final/end_effector_loc Mean          0.0385136
evaluation/env_infos/final/end_effector_loc Std           0.52531
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00123137
evaluation/env_infos/initial/end_effector_loc Std         0.0255896
evaluation/env_infos/initial/end_effector_loc Max         0.049547
evaluation/env_infos/initial/end_effector_loc Min        -0.0481082
evaluation/env_infos/end_effector_loc Mean                0.00693297
evaluation/env_infos/end_effector_loc Std                 0.409508
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0635519
evaluation/env_infos/final/reward_dist Std                0.183523
evaluation/env_infos/final/reward_dist Max                0.920251
evaluation/env_infos/final/reward_dist Min                1.04542e-165
evaluation/env_infos/initial/reward_dist Mean             0.00998208
evaluation/env_infos/initial/reward_dist Std              0.0199448
evaluation/env_infos/initial/reward_dist Max              0.0883667
evaluation/env_infos/initial/reward_dist Min              2.09165e-06
evaluation/env_infos/reward_dist Mean                     0.0779442
evaluation/env_infos/reward_dist Std                      0.181288
evaluation/env_infos/reward_dist Max                      0.97911
evaluation/env_infos/reward_dist Min                      3.09464e-169
time/data storing (s)                                    39.2787
time/evaluation sampling (s)                              0.749589
time/exploration sampling (s)                             0.0893831
time/logging (s)                                          0.0169264
time/saving (s)                                           0.820593
time/training (s)                                        39.9268
time/epoch (s)                                           80.8819
time/total (s)                                        21231.4
Epoch                                                   278
---------------------------------------------------  -----------------
2021-05-29 05:51:11.747181 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 279 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0837632
trainer/QF2 Loss                                          0.0483654
trainer/Policy Loss                                       3.10497
trainer/Q1 Predictions Mean                              -1.02295
trainer/Q1 Predictions Std                                1.01584
trainer/Q1 Predictions Max                                1.77255
trainer/Q1 Predictions Min                               -4.10448
trainer/Q2 Predictions Mean                              -1.03096
trainer/Q2 Predictions Std                                1.0367
trainer/Q2 Predictions Max                                1.52041
trainer/Q2 Predictions Min                               -4.05344
trainer/Q Targets Mean                                   -1.06581
trainer/Q Targets Std                                     1.04664
trainer/Q Targets Max                                     1.58831
trainer/Q Targets Min                                    -4.35465
trainer/Log Pis Mean                                      2.12502
trainer/Log Pis Std                                       1.35372
trainer/Log Pis Max                                       7.31543
trainer/Log Pis Min                                      -3.53781
trainer/Policy mu Mean                                    0.120778
trainer/Policy mu Std                                     0.738205
trainer/Policy mu Max                                     4.10948
trainer/Policy mu Min                                    -2.31049
trainer/Policy log std Mean                              -2.07901
trainer/Policy log std Std                                0.524158
trainer/Policy log std Max                               -0.0204163
trainer/Policy log std Min                               -2.8646
trainer/Alpha                                             0.018025
trainer/Alpha Loss                                        0.502135
exploration/num steps total                           29000
exploration/num paths total                            1450
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.356372
exploration/Rewards Std                                   0.229358
exploration/Rewards Max                                  -0.0301426
exploration/Rewards Min                                  -1.28908
exploration/Returns Mean                                 -7.12744
exploration/Returns Std                                   3.16983
exploration/Returns Max                                  -1.97906
exploration/Returns Min                                  -9.97676
exploration/Actions Mean                                 -0.00234139
exploration/Actions Std                                   0.381369
exploration/Actions Max                                   0.998597
exploration/Actions Min                                  -0.983433
exploration/Num Paths                                     5
exploration/Average Returns                              -7.12744
exploration/env_infos/final/reward_energy Mean           -0.223519
exploration/env_infos/final/reward_energy Std             0.138647
exploration/env_infos/final/reward_energy Max            -0.0482508
exploration/env_infos/final/reward_energy Min            -0.472784
exploration/env_infos/initial/reward_energy Mean         -0.840896
exploration/env_infos/initial/reward_energy Std           0.357008
exploration/env_infos/initial/reward_energy Max          -0.410018
exploration/env_infos/initial/reward_energy Min          -1.37154
exploration/env_infos/reward_energy Mean                 -0.423892
exploration/env_infos/reward_energy Std                   0.333483
exploration/env_infos/reward_energy Max                  -0.0408361
exploration/env_infos/reward_energy Min                  -1.37154
exploration/env_infos/final/end_effector_loc Mean         0.0450236
exploration/env_infos/final/end_effector_loc Std          0.751996
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00160695
exploration/env_infos/initial/end_effector_loc Std        0.0322586
exploration/env_infos/initial/end_effector_loc Max        0.0478011
exploration/env_infos/initial/end_effector_loc Min       -0.0491717
exploration/env_infos/end_effector_loc Mean               0.0275914
exploration/env_infos/end_effector_loc Std                0.64585
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              6.22667e-10
exploration/env_infos/final/reward_dist Std               1.24533e-09
exploration/env_infos/final/reward_dist Max               3.11334e-09
exploration/env_infos/final/reward_dist Min               3.40335e-163
exploration/env_infos/initial/reward_dist Mean            0.000800914
exploration/env_infos/initial/reward_dist Std             0.00137567
exploration/env_infos/initial/reward_dist Max             0.0035424
exploration/env_infos/initial/reward_dist Min             1.79821e-06
exploration/env_infos/reward_dist Mean                    0.0187557
exploration/env_infos/reward_dist Std                     0.0866966
exploration/env_infos/reward_dist Max                     0.65216
exploration/env_infos/reward_dist Min                     2.30016e-180
evaluation/num steps total                           280000
evaluation/num paths total                            14000
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.213901
evaluation/Rewards Std                                    0.266667
evaluation/Rewards Max                                    0.140806
evaluation/Rewards Min                                   -1.46569
evaluation/Returns Mean                                  -4.27802
evaluation/Returns Std                                    4.46949
evaluation/Returns Max                                    1.26503
evaluation/Returns Min                                  -21.6024
evaluation/Actions Mean                                   0.0289065
evaluation/Actions Std                                    0.307979
evaluation/Actions Max                                    0.999991
evaluation/Actions Min                                   -0.977241
evaluation/Num Paths                                     50
evaluation/Average Returns                               -4.27802
evaluation/env_infos/final/reward_energy Mean            -0.317943
evaluation/env_infos/final/reward_energy Std              0.403587
evaluation/env_infos/final/reward_energy Max             -0.0130462
evaluation/env_infos/final/reward_energy Min             -1.35622
evaluation/env_infos/initial/reward_energy Mean          -0.672989
evaluation/env_infos/initial/reward_energy Std            0.396616
evaluation/env_infos/initial/reward_energy Max           -0.00858178
evaluation/env_infos/initial/reward_energy Min           -1.35624
evaluation/env_infos/reward_energy Mean                  -0.288176
evaluation/env_infos/reward_energy Std                    0.329133
evaluation/env_infos/reward_energy Max                   -0.00211085
evaluation/env_infos/reward_energy Min                   -1.38011
evaluation/env_infos/final/end_effector_loc Mean          0.108982
evaluation/env_infos/final/end_effector_loc Std           0.512687
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00395279
evaluation/env_infos/initial/end_effector_loc Std         0.027334
evaluation/env_infos/initial/end_effector_loc Max         0.0495909
evaluation/env_infos/initial/end_effector_loc Min        -0.047537
evaluation/env_infos/end_effector_loc Mean                0.0496451
evaluation/env_infos/end_effector_loc Std                 0.402085
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.114707
evaluation/env_infos/final/reward_dist Std                0.255993
evaluation/env_infos/final/reward_dist Max                0.981603
evaluation/env_infos/final/reward_dist Min                2.42084e-145
evaluation/env_infos/initial/reward_dist Mean             0.00543983
evaluation/env_infos/initial/reward_dist Std              0.0129832
evaluation/env_infos/initial/reward_dist Max              0.0767343
evaluation/env_infos/initial/reward_dist Min              1.9696e-08
evaluation/env_infos/reward_dist Mean                     0.102431
evaluation/env_infos/reward_dist Std                      0.230692
evaluation/env_infos/reward_dist Max                      0.99848
evaluation/env_infos/reward_dist Min                      4.54403e-194
time/data storing (s)                                    39.731
time/evaluation sampling (s)                              0.648987
time/exploration sampling (s)                             0.0929222
time/logging (s)                                          0.0182491
time/saving (s)                                           0.828022
time/training (s)                                        41.7774
time/epoch (s)                                           83.0966
time/total (s)                                        21317.5
Epoch                                                   279
---------------------------------------------------  -----------------
2021-05-29 05:52:34.777008 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 280 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0202871
trainer/QF2 Loss                                          0.0176059
trainer/Policy Loss                                       2.94548
trainer/Q1 Predictions Mean                              -1.03351
trainer/Q1 Predictions Std                                0.994656
trainer/Q1 Predictions Max                                1.16158
trainer/Q1 Predictions Min                               -4.61523
trainer/Q2 Predictions Mean                              -0.995877
trainer/Q2 Predictions Std                                1.0251
trainer/Q2 Predictions Max                                1.22231
trainer/Q2 Predictions Min                               -4.68762
trainer/Q Targets Mean                                   -1.029
trainer/Q Targets Std                                     1.01095
trainer/Q Targets Max                                     0.97041
trainer/Q Targets Min                                    -4.7787
trainer/Log Pis Mean                                      1.97418
trainer/Log Pis Std                                       1.1155
trainer/Log Pis Max                                       4.55283
trainer/Log Pis Min                                      -3.02119
trainer/Policy mu Mean                                   -0.00265914
trainer/Policy mu Std                                     0.473351
trainer/Policy mu Max                                     3.11676
trainer/Policy mu Min                                    -1.79337
trainer/Policy log std Mean                              -2.2349
trainer/Policy log std Std                                0.366137
trainer/Policy log std Max                               -0.385422
trainer/Policy log std Min                               -2.74919
trainer/Alpha                                             0.0157963
trainer/Alpha Loss                                       -0.1071
exploration/num steps total                           29100
exploration/num paths total                            1455
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.187187
exploration/Rewards Std                                   0.174274
exploration/Rewards Max                                   0.0772968
exploration/Rewards Min                                  -0.992525
exploration/Returns Mean                                 -3.74373
exploration/Returns Std                                   2.42679
exploration/Returns Max                                  -0.0135398
exploration/Returns Min                                  -7.32428
exploration/Actions Mean                                 -0.00288448
exploration/Actions Std                                   0.2054
exploration/Actions Max                                   0.675747
exploration/Actions Min                                  -0.83876
exploration/Num Paths                                     5
exploration/Average Returns                              -3.74373
exploration/env_infos/final/reward_energy Mean           -0.274933
exploration/env_infos/final/reward_energy Std             0.233503
exploration/env_infos/final/reward_energy Max            -0.0363387
exploration/env_infos/final/reward_energy Min            -0.585323
exploration/env_infos/initial/reward_energy Mean         -0.406799
exploration/env_infos/initial/reward_energy Std           0.272236
exploration/env_infos/initial/reward_energy Max          -0.127727
exploration/env_infos/initial/reward_energy Min          -0.865224
exploration/env_infos/reward_energy Mean                 -0.236084
exploration/env_infos/reward_energy Std                   0.16929
exploration/env_infos/reward_energy Max                  -0.0280741
exploration/env_infos/reward_energy Min                  -0.865224
exploration/env_infos/final/end_effector_loc Mean        -0.043679
exploration/env_infos/final/end_effector_loc Std          0.437485
exploration/env_infos/final/end_effector_loc Max          0.697988
exploration/env_infos/final/end_effector_loc Min         -0.869608
exploration/env_infos/initial/end_effector_loc Mean      -0.00274067
exploration/env_infos/initial/end_effector_loc Std        0.0170876
exploration/env_infos/initial/end_effector_loc Max        0.0220439
exploration/env_infos/initial/end_effector_loc Min       -0.041938
exploration/env_infos/end_effector_loc Mean              -0.0519858
exploration/env_infos/end_effector_loc Std                0.227487
exploration/env_infos/end_effector_loc Max                0.697988
exploration/env_infos/end_effector_loc Min               -0.869608
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0383082
exploration/env_infos/final/reward_dist Std               0.0744915
exploration/env_infos/final/reward_dist Max               0.187279
exploration/env_infos/final/reward_dist Min               9.58787e-86
exploration/env_infos/initial/reward_dist Mean            0.00355969
exploration/env_infos/initial/reward_dist Std             0.00480224
exploration/env_infos/initial/reward_dist Max             0.0129805
exploration/env_infos/initial/reward_dist Min             7.97201e-06
exploration/env_infos/reward_dist Mean                    0.11328
exploration/env_infos/reward_dist Std                     0.209652
exploration/env_infos/reward_dist Max                     0.724551
exploration/env_infos/reward_dist Min                     9.58787e-86
evaluation/num steps total                           281000
evaluation/num paths total                            14050
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.157571
evaluation/Rewards Std                                    0.177617
evaluation/Rewards Max                                    0.16165
evaluation/Rewards Min                                   -1.13922
evaluation/Returns Mean                                  -3.15142
evaluation/Returns Std                                    2.86273
evaluation/Returns Max                                    1.31566
evaluation/Returns Min                                  -14.2115
evaluation/Actions Mean                                  -0.0198194
evaluation/Actions Std                                    0.224086
evaluation/Actions Max                                    0.934033
evaluation/Actions Min                                   -0.936614
evaluation/Num Paths                                     50
evaluation/Average Returns                               -3.15142
evaluation/env_infos/final/reward_energy Mean            -0.177471
evaluation/env_infos/final/reward_energy Std              0.202619
evaluation/env_infos/final/reward_energy Max             -0.00883259
evaluation/env_infos/final/reward_energy Min             -0.756965
evaluation/env_infos/initial/reward_energy Mean          -0.496794
evaluation/env_infos/initial/reward_energy Std            0.299261
evaluation/env_infos/initial/reward_energy Max           -0.00865118
evaluation/env_infos/initial/reward_energy Min           -1.19665
evaluation/env_infos/reward_energy Mean                  -0.217056
evaluation/env_infos/reward_energy Std                    0.232596
evaluation/env_infos/reward_energy Max                   -0.00262466
evaluation/env_infos/reward_energy Min                   -1.20913
evaluation/env_infos/final/end_effector_loc Mean         -0.0120435
evaluation/env_infos/final/end_effector_loc Std           0.525494
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00074011
evaluation/env_infos/initial/end_effector_loc Std         0.0204916
evaluation/env_infos/initial/end_effector_loc Max         0.0388442
evaluation/env_infos/initial/end_effector_loc Min        -0.0460832
evaluation/env_infos/end_effector_loc Mean               -0.00841863
evaluation/env_infos/end_effector_loc Std                 0.368433
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0559689
evaluation/env_infos/final/reward_dist Std                0.170569
evaluation/env_infos/final/reward_dist Max                0.753265
evaluation/env_infos/final/reward_dist Min                5.46673e-170
evaluation/env_infos/initial/reward_dist Mean             0.00751094
evaluation/env_infos/initial/reward_dist Std              0.019013
evaluation/env_infos/initial/reward_dist Max              0.0888994
evaluation/env_infos/initial/reward_dist Min              2.71941e-06
evaluation/env_infos/reward_dist Mean                     0.104887
evaluation/env_infos/reward_dist Std                      0.217058
evaluation/env_infos/reward_dist Max                      0.99789
evaluation/env_infos/reward_dist Min                      6.10843e-171
time/data storing (s)                                    38.5003
time/evaluation sampling (s)                              0.612599
time/exploration sampling (s)                             0.0836591
time/logging (s)                                          0.0155781
time/saving (s)                                           0.789966
time/training (s)                                        39.6573
time/epoch (s)                                           79.6594
time/total (s)                                        21400.6
Epoch                                                   280
---------------------------------------------------  -----------------
2021-05-29 05:53:57.694570 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 281 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0123941
trainer/QF2 Loss                                          0.00927581
trainer/Policy Loss                                       3.02581
trainer/Q1 Predictions Mean                              -1.06353
trainer/Q1 Predictions Std                                1.13105
trainer/Q1 Predictions Max                                1.97341
trainer/Q1 Predictions Min                               -4.9365
trainer/Q2 Predictions Mean                              -1.0533
trainer/Q2 Predictions Std                                1.12561
trainer/Q2 Predictions Max                                1.98706
trainer/Q2 Predictions Min                               -4.95425
trainer/Q Targets Mean                                   -1.05139
trainer/Q Targets Std                                     1.13239
trainer/Q Targets Max                                     2.04377
trainer/Q Targets Min                                    -4.97568
trainer/Log Pis Mean                                      2.04374
trainer/Log Pis Std                                       1.22115
trainer/Log Pis Max                                       8.15887
trainer/Log Pis Min                                      -4.62259
trainer/Policy mu Mean                                   -0.0207447
trainer/Policy mu Std                                     0.535465
trainer/Policy mu Max                                     3.80999
trainer/Policy mu Min                                    -2.52688
trainer/Policy log std Mean                              -2.218
trainer/Policy log std Std                                0.402216
trainer/Policy log std Max                               -0.338994
trainer/Policy log std Min                               -2.78804
trainer/Alpha                                             0.0162394
trainer/Alpha Loss                                        0.180235
exploration/num steps total                           29200
exploration/num paths total                            1460
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.201783
exploration/Rewards Std                                   0.171385
exploration/Rewards Max                                  -0.0508158
exploration/Rewards Min                                  -0.891987
exploration/Returns Mean                                 -4.03566
exploration/Returns Std                                   2.18218
exploration/Returns Max                                  -2.4781
exploration/Returns Min                                  -8.17846
exploration/Actions Mean                                  0.0359227
exploration/Actions Std                                   0.207689
exploration/Actions Max                                   0.964929
exploration/Actions Min                                  -0.860993
exploration/Num Paths                                     5
exploration/Average Returns                              -4.03566
exploration/env_infos/final/reward_energy Mean           -0.19285
exploration/env_infos/final/reward_energy Std             0.101178
exploration/env_infos/final/reward_energy Max            -0.0614581
exploration/env_infos/final/reward_energy Min            -0.342257
exploration/env_infos/initial/reward_energy Mean         -0.226575
exploration/env_infos/initial/reward_energy Std           0.170816
exploration/env_infos/initial/reward_energy Max          -0.060009
exploration/env_infos/initial/reward_energy Min          -0.468438
exploration/env_infos/reward_energy Mean                 -0.197326
exploration/env_infos/reward_energy Std                   0.223412
exploration/env_infos/reward_energy Max                  -0.0224723
exploration/env_infos/reward_energy Min                  -1.18362
exploration/env_infos/final/end_effector_loc Mean         0.197086
exploration/env_infos/final/end_effector_loc Std          0.523763
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.710409
exploration/env_infos/initial/end_effector_loc Mean      -0.000530099
exploration/env_infos/initial/end_effector_loc Std        0.0100181
exploration/env_infos/initial/end_effector_loc Max        0.0231371
exploration/env_infos/initial/end_effector_loc Min       -0.0195215
exploration/env_infos/end_effector_loc Mean               0.0866768
exploration/env_infos/end_effector_loc Std                0.315492
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.710409
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00334954
exploration/env_infos/final/reward_dist Std               0.00669846
exploration/env_infos/final/reward_dist Max               0.0167465
exploration/env_infos/final/reward_dist Min               3.73184e-72
exploration/env_infos/initial/reward_dist Mean            0.00778667
exploration/env_infos/initial/reward_dist Std             0.010014
exploration/env_infos/initial/reward_dist Max             0.0254017
exploration/env_infos/initial/reward_dist Min             5.37051e-06
exploration/env_infos/reward_dist Mean                    0.0330525
exploration/env_infos/reward_dist Std                     0.0765022
exploration/env_infos/reward_dist Max                     0.399376
exploration/env_infos/reward_dist Min                     3.73184e-72
evaluation/num steps total                           282000
evaluation/num paths total                            14100
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.127631
evaluation/Rewards Std                                    0.12094
evaluation/Rewards Max                                    0.147524
evaluation/Rewards Min                                   -0.953234
evaluation/Returns Mean                                  -2.55261
evaluation/Returns Std                                    1.60819
evaluation/Returns Max                                    1.89751
evaluation/Returns Min                                   -6.83156
evaluation/Actions Mean                                  -0.0062712
evaluation/Actions Std                                    0.165543
evaluation/Actions Max                                    0.923806
evaluation/Actions Min                                   -0.993676
evaluation/Num Paths                                     50
evaluation/Average Returns                               -2.55261
evaluation/env_infos/final/reward_energy Mean            -0.0955778
evaluation/env_infos/final/reward_energy Std              0.092785
evaluation/env_infos/final/reward_energy Max             -0.00597955
evaluation/env_infos/final/reward_energy Min             -0.451559
evaluation/env_infos/initial/reward_energy Mean          -0.46084
evaluation/env_infos/initial/reward_energy Std            0.328642
evaluation/env_infos/initial/reward_energy Max           -0.0118718
evaluation/env_infos/initial/reward_energy Min           -1.32657
evaluation/env_infos/reward_energy Mean                  -0.150048
evaluation/env_infos/reward_energy Std                    0.179927
evaluation/env_infos/reward_energy Max                   -0.00400368
evaluation/env_infos/reward_energy Min                   -1.32657
evaluation/env_infos/final/end_effector_loc Mean         -0.0371922
evaluation/env_infos/final/end_effector_loc Std           0.456267
evaluation/env_infos/final/end_effector_loc Max           0.841169
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00342542
evaluation/env_infos/initial/end_effector_loc Std         0.0197165
evaluation/env_infos/initial/end_effector_loc Max         0.0348163
evaluation/env_infos/initial/end_effector_loc Min        -0.0495228
evaluation/env_infos/end_effector_loc Mean               -0.0262596
evaluation/env_infos/end_effector_loc Std                 0.301049
evaluation/env_infos/end_effector_loc Max                 0.841169
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0360535
evaluation/env_infos/final/reward_dist Std                0.132239
evaluation/env_infos/final/reward_dist Max                0.675458
evaluation/env_infos/final/reward_dist Min                3.45123e-137
evaluation/env_infos/initial/reward_dist Mean             0.00621275
evaluation/env_infos/initial/reward_dist Std              0.0113322
evaluation/env_infos/initial/reward_dist Max              0.0502905
evaluation/env_infos/initial/reward_dist Min              1.50015e-06
evaluation/env_infos/reward_dist Mean                     0.0621758
evaluation/env_infos/reward_dist Std                      0.154672
evaluation/env_infos/reward_dist Max                      0.951093
evaluation/env_infos/reward_dist Min                      3.45123e-137
time/data storing (s)                                    38.6151
time/evaluation sampling (s)                              0.644438
time/exploration sampling (s)                             0.0924327
time/logging (s)                                          0.0171624
time/saving (s)                                           0.785574
time/training (s)                                        39.8113
time/epoch (s)                                           79.966
time/total (s)                                        21483.5
Epoch                                                   281
---------------------------------------------------  -----------------
2021-05-29 05:55:19.612782 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 282 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0125352
trainer/QF2 Loss                                          0.0158539
trainer/Policy Loss                                       3.05549
trainer/Q1 Predictions Mean                              -1.08678
trainer/Q1 Predictions Std                                0.97051
trainer/Q1 Predictions Max                                0.850948
trainer/Q1 Predictions Min                               -3.69342
trainer/Q2 Predictions Mean                              -1.08857
trainer/Q2 Predictions Std                                0.95799
trainer/Q2 Predictions Max                                0.817188
trainer/Q2 Predictions Min                               -3.71536
trainer/Q Targets Mean                                   -1.09716
trainer/Q Targets Std                                     0.991782
trainer/Q Targets Max                                     0.881602
trainer/Q Targets Min                                    -3.8072
trainer/Log Pis Mean                                      2.02165
trainer/Log Pis Std                                       1.04615
trainer/Log Pis Max                                       4.07865
trainer/Log Pis Min                                      -2.46862
trainer/Policy mu Mean                                   -0.029806
trainer/Policy mu Std                                     0.425426
trainer/Policy mu Max                                     1.68974
trainer/Policy mu Min                                    -2.74343
trainer/Policy log std Mean                              -2.26451
trainer/Policy log std Std                                0.34088
trainer/Policy log std Max                               -0.409365
trainer/Policy log std Min                               -2.92806
trainer/Alpha                                             0.0161294
trainer/Alpha Loss                                        0.0893257
exploration/num steps total                           29300
exploration/num paths total                            1465
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.113282
exploration/Rewards Std                                   0.065466
exploration/Rewards Max                                   0.018555
exploration/Rewards Min                                  -0.351517
exploration/Returns Mean                                 -2.26564
exploration/Returns Std                                   0.584316
exploration/Returns Max                                  -1.20696
exploration/Returns Min                                  -2.82992
exploration/Actions Mean                                 -0.00555226
exploration/Actions Std                                   0.14467
exploration/Actions Max                                   0.612563
exploration/Actions Min                                  -0.776924
exploration/Num Paths                                     5
exploration/Average Returns                              -2.26564
exploration/env_infos/final/reward_energy Mean           -0.165654
exploration/env_infos/final/reward_energy Std             0.0738444
exploration/env_infos/final/reward_energy Max            -0.107425
exploration/env_infos/final/reward_energy Min            -0.307323
exploration/env_infos/initial/reward_energy Mean         -0.231664
exploration/env_infos/initial/reward_energy Std           0.280658
exploration/env_infos/initial/reward_energy Max          -0.0283824
exploration/env_infos/initial/reward_energy Min          -0.784355
exploration/env_infos/reward_energy Mean                 -0.146585
exploration/env_infos/reward_energy Std                   0.142944
exploration/env_infos/reward_energy Max                  -0.013058
exploration/env_infos/reward_energy Min                  -0.819964
exploration/env_infos/final/end_effector_loc Mean        -0.0210746
exploration/env_infos/final/end_effector_loc Std          0.234864
exploration/env_infos/final/end_effector_loc Max          0.332283
exploration/env_infos/final/end_effector_loc Min         -0.557385
exploration/env_infos/initial/end_effector_loc Mean      -0.00517051
exploration/env_infos/initial/end_effector_loc Std        0.0117819
exploration/env_infos/initial/end_effector_loc Max        0.00563923
exploration/env_infos/initial/end_effector_loc Min       -0.0388462
exploration/env_infos/end_effector_loc Mean              -0.00765868
exploration/env_infos/end_effector_loc Std                0.159981
exploration/env_infos/end_effector_loc Max                0.333388
exploration/env_infos/end_effector_loc Min               -0.557385
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0125537
exploration/env_infos/final/reward_dist Std               0.0221733
exploration/env_infos/final/reward_dist Max               0.0566462
exploration/env_infos/final/reward_dist Min               8.78711e-14
exploration/env_infos/initial/reward_dist Mean            0.00427583
exploration/env_infos/initial/reward_dist Std             0.00584769
exploration/env_infos/initial/reward_dist Max             0.0150584
exploration/env_infos/initial/reward_dist Min             2.18402e-06
exploration/env_infos/reward_dist Mean                    0.0540884
exploration/env_infos/reward_dist Std                     0.145072
exploration/env_infos/reward_dist Max                     0.988309
exploration/env_infos/reward_dist Min                     8.78711e-14
evaluation/num steps total                           283000
evaluation/num paths total                            14150
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.153515
evaluation/Rewards Std                                    0.202226
evaluation/Rewards Max                                    0.18524
evaluation/Rewards Min                                   -1.51925
evaluation/Returns Mean                                  -3.0703
evaluation/Returns Std                                    3.06673
evaluation/Returns Max                                    0.712794
evaluation/Returns Min                                  -12.2901
evaluation/Actions Mean                                   0.0103021
evaluation/Actions Std                                    0.21947
evaluation/Actions Max                                    0.998175
evaluation/Actions Min                                   -0.995874
evaluation/Num Paths                                     50
evaluation/Average Returns                               -3.0703
evaluation/env_infos/final/reward_energy Mean            -0.147003
evaluation/env_infos/final/reward_energy Std              0.230858
evaluation/env_infos/final/reward_energy Max             -0.0119088
evaluation/env_infos/final/reward_energy Min             -1.31164
evaluation/env_infos/initial/reward_energy Mean          -0.540362
evaluation/env_infos/initial/reward_energy Std            0.347272
evaluation/env_infos/initial/reward_energy Max           -0.0526122
evaluation/env_infos/initial/reward_energy Min           -1.35129
evaluation/env_infos/reward_energy Mean                  -0.199716
evaluation/env_infos/reward_energy Std                    0.238033
evaluation/env_infos/reward_energy Max                   -0.00717834
evaluation/env_infos/reward_energy Min                   -1.35129
evaluation/env_infos/final/end_effector_loc Mean          0.0930955
evaluation/env_infos/final/end_effector_loc Std           0.504188
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00404374
evaluation/env_infos/initial/end_effector_loc Std         0.0223469
evaluation/env_infos/initial/end_effector_loc Max         0.0483797
evaluation/env_infos/initial/end_effector_loc Min        -0.0497937
evaluation/env_infos/end_effector_loc Mean                0.0211604
evaluation/env_infos/end_effector_loc Std                 0.328519
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0593435
evaluation/env_infos/final/reward_dist Std                0.15793
evaluation/env_infos/final/reward_dist Max                0.772321
evaluation/env_infos/final/reward_dist Min                2.02979e-170
evaluation/env_infos/initial/reward_dist Mean             0.0146892
evaluation/env_infos/initial/reward_dist Std              0.025436
evaluation/env_infos/initial/reward_dist Max              0.111234
evaluation/env_infos/initial/reward_dist Min              1.47501e-06
evaluation/env_infos/reward_dist Mean                     0.100977
evaluation/env_infos/reward_dist Std                      0.205728
evaluation/env_infos/reward_dist Max                      0.998781
evaluation/env_infos/reward_dist Min                      2.02979e-170
time/data storing (s)                                    37.8565
time/evaluation sampling (s)                              0.533602
time/exploration sampling (s)                             0.0799611
time/logging (s)                                          0.0150658
time/saving (s)                                           0.776854
time/training (s)                                        39.7382
time/epoch (s)                                           79.0002
time/total (s)                                        21565.4
Epoch                                                   282
---------------------------------------------------  -----------------
2021-05-29 05:56:46.517986 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 283 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0127864
trainer/QF2 Loss                                          0.0472129
trainer/Policy Loss                                       3.12015
trainer/Q1 Predictions Mean                              -1.23403
trainer/Q1 Predictions Std                                1.1028
trainer/Q1 Predictions Max                                2.05117
trainer/Q1 Predictions Min                               -4.93778
trainer/Q2 Predictions Mean                              -1.2121
trainer/Q2 Predictions Std                                1.10329
trainer/Q2 Predictions Max                                2.10437
trainer/Q2 Predictions Min                               -5.06097
trainer/Q Targets Mean                                   -1.23907
trainer/Q Targets Std                                     1.11025
trainer/Q Targets Max                                     1.9537
trainer/Q Targets Min                                    -5.11192
trainer/Log Pis Mean                                      1.96474
trainer/Log Pis Std                                       1.04939
trainer/Log Pis Max                                       5.74153
trainer/Log Pis Min                                      -2.67127
trainer/Policy mu Mean                                   -0.0637149
trainer/Policy mu Std                                     0.523787
trainer/Policy mu Max                                     3.35189
trainer/Policy mu Min                                    -2.36434
trainer/Policy log std Mean                              -2.14874
trainer/Policy log std Std                                0.389348
trainer/Policy log std Max                               -0.16055
trainer/Policy log std Min                               -2.77544
trainer/Alpha                                             0.018861
trainer/Alpha Loss                                       -0.139972
exploration/num steps total                           29400
exploration/num paths total                            1470
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.171417
exploration/Rewards Std                                   0.131971
exploration/Rewards Max                                   0.076179
exploration/Rewards Min                                  -0.654451
exploration/Returns Mean                                 -3.42834
exploration/Returns Std                                   1.99168
exploration/Returns Max                                  -1.14505
exploration/Returns Min                                  -7.01192
exploration/Actions Mean                                 -0.00737844
exploration/Actions Std                                   0.165167
exploration/Actions Max                                   0.608748
exploration/Actions Min                                  -0.582492
exploration/Num Paths                                     5
exploration/Average Returns                              -3.42834
exploration/env_infos/final/reward_energy Mean           -0.163653
exploration/env_infos/final/reward_energy Std             0.126129
exploration/env_infos/final/reward_energy Max            -0.0734058
exploration/env_infos/final/reward_energy Min            -0.413345
exploration/env_infos/initial/reward_energy Mean         -0.236027
exploration/env_infos/initial/reward_energy Std           0.127887
exploration/env_infos/initial/reward_energy Max          -0.101323
exploration/env_infos/initial/reward_energy Min          -0.462476
exploration/env_infos/reward_energy Mean                 -0.19231
exploration/env_infos/reward_energy Std                   0.132988
exploration/env_infos/reward_energy Max                  -0.0136601
exploration/env_infos/reward_energy Min                  -0.72043
exploration/env_infos/final/end_effector_loc Mean        -0.132871
exploration/env_infos/final/end_effector_loc Std          0.213692
exploration/env_infos/final/end_effector_loc Max          0.240065
exploration/env_infos/final/end_effector_loc Min         -0.452095
exploration/env_infos/initial/end_effector_loc Mean      -0.00217415
exploration/env_infos/initial/end_effector_loc Std        0.00923865
exploration/env_infos/initial/end_effector_loc Max        0.0153776
exploration/env_infos/initial/end_effector_loc Min       -0.0172696
exploration/env_infos/end_effector_loc Mean              -0.0741249
exploration/env_infos/end_effector_loc Std                0.176912
exploration/env_infos/end_effector_loc Max                0.295674
exploration/env_infos/end_effector_loc Min               -0.452095
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00150461
exploration/env_infos/final/reward_dist Std               0.00297451
exploration/env_infos/final/reward_dist Max               0.00745339
exploration/env_infos/final/reward_dist Min               1.09108e-13
exploration/env_infos/initial/reward_dist Mean            0.00747238
exploration/env_infos/initial/reward_dist Std             0.00636738
exploration/env_infos/initial/reward_dist Max             0.0159486
exploration/env_infos/initial/reward_dist Min             7.49522e-06
exploration/env_infos/reward_dist Mean                    0.121162
exploration/env_infos/reward_dist Std                     0.228625
exploration/env_infos/reward_dist Max                     0.985468
exploration/env_infos/reward_dist Min                     1.3887e-26
evaluation/num steps total                           284000
evaluation/num paths total                            14200
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.317682
evaluation/Rewards Std                                    0.28577
evaluation/Rewards Max                                    0.0877304
evaluation/Rewards Min                                   -1.3667
evaluation/Returns Mean                                  -6.35364
evaluation/Returns Std                                    4.36279
evaluation/Returns Max                                   -0.467138
evaluation/Returns Min                                  -16.2412
evaluation/Actions Mean                                   0.00986267
evaluation/Actions Std                                    0.314888
evaluation/Actions Max                                    0.997915
evaluation/Actions Min                                   -0.981474
evaluation/Num Paths                                     50
evaluation/Average Returns                               -6.35364
evaluation/env_infos/final/reward_energy Mean            -0.246169
evaluation/env_infos/final/reward_energy Std              0.263766
evaluation/env_infos/final/reward_energy Max             -0.0300275
evaluation/env_infos/final/reward_energy Min             -1.04773
evaluation/env_infos/initial/reward_energy Mean          -0.545889
evaluation/env_infos/initial/reward_energy Std            0.384547
evaluation/env_infos/initial/reward_energy Max           -0.0249643
evaluation/env_infos/initial/reward_energy Min           -1.30164
evaluation/env_infos/reward_energy Mean                  -0.314539
evaluation/env_infos/reward_energy Std                    0.315546
evaluation/env_infos/reward_energy Max                   -0.00458036
evaluation/env_infos/reward_energy Min                   -1.38238
evaluation/env_infos/final/end_effector_loc Mean         -0.0549375
evaluation/env_infos/final/end_effector_loc Std           0.699931
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00563246
evaluation/env_infos/initial/end_effector_loc Std         0.0229263
evaluation/env_infos/initial/end_effector_loc Max         0.0482843
evaluation/env_infos/initial/end_effector_loc Min        -0.0490737
evaluation/env_infos/end_effector_loc Mean               -0.0220116
evaluation/env_infos/end_effector_loc Std                 0.473252
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.041031
evaluation/env_infos/final/reward_dist Std                0.184337
evaluation/env_infos/final/reward_dist Max                0.998529
evaluation/env_infos/final/reward_dist Min                9.24738e-175
evaluation/env_infos/initial/reward_dist Mean             0.00879294
evaluation/env_infos/initial/reward_dist Std              0.0332361
evaluation/env_infos/initial/reward_dist Max              0.235896
evaluation/env_infos/initial/reward_dist Min              3.14748e-06
evaluation/env_infos/reward_dist Mean                     0.0573214
evaluation/env_infos/reward_dist Std                      0.171818
evaluation/env_infos/reward_dist Max                      0.998529
evaluation/env_infos/reward_dist Min                      9.24738e-175
time/data storing (s)                                    39.8196
time/evaluation sampling (s)                              0.832967
time/exploration sampling (s)                             0.0923026
time/logging (s)                                          0.0173689
time/saving (s)                                           0.807178
time/training (s)                                        41.7659
time/epoch (s)                                           83.3354
time/total (s)                                        21652.1
Epoch                                                   283
---------------------------------------------------  -----------------
2021-05-29 05:58:11.232878 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 284 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0113585
trainer/QF2 Loss                                          0.0123086
trainer/Policy Loss                                       2.91614
trainer/Q1 Predictions Mean                              -1.03205
trainer/Q1 Predictions Std                                1.07747
trainer/Q1 Predictions Max                                3.31981
trainer/Q1 Predictions Min                               -4.32588
trainer/Q2 Predictions Mean                              -1.05841
trainer/Q2 Predictions Std                                1.07837
trainer/Q2 Predictions Max                                3.16562
trainer/Q2 Predictions Min                               -4.78638
trainer/Q Targets Mean                                   -1.03188
trainer/Q Targets Std                                     1.09478
trainer/Q Targets Max                                     3.30358
trainer/Q Targets Min                                    -4.72727
trainer/Log Pis Mean                                      1.95191
trainer/Log Pis Std                                       1.20595
trainer/Log Pis Max                                       7.65987
trainer/Log Pis Min                                      -3.17571
trainer/Policy mu Mean                                   -0.0266857
trainer/Policy mu Std                                     0.535989
trainer/Policy mu Max                                     2.95449
trainer/Policy mu Min                                    -1.85598
trainer/Policy log std Mean                              -2.11881
trainer/Policy log std Std                                0.434538
trainer/Policy log std Max                               -0.256534
trainer/Policy log std Min                               -2.88877
trainer/Alpha                                             0.0198194
trainer/Alpha Loss                                       -0.188573
exploration/num steps total                           29500
exploration/num paths total                            1475
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.130596
exploration/Rewards Std                                   0.0689052
exploration/Rewards Max                                   0.0212459
exploration/Rewards Min                                  -0.424033
exploration/Returns Mean                                 -2.61192
exploration/Returns Std                                   0.698242
exploration/Returns Max                                  -1.84521
exploration/Returns Min                                  -3.55955
exploration/Actions Mean                                  0.00123529
exploration/Actions Std                                   0.143046
exploration/Actions Max                                   0.496568
exploration/Actions Min                                  -0.737141
exploration/Num Paths                                     5
exploration/Average Returns                              -2.61192
exploration/env_infos/final/reward_energy Mean           -0.244529
exploration/env_infos/final/reward_energy Std             0.144512
exploration/env_infos/final/reward_energy Max            -0.0340296
exploration/env_infos/final/reward_energy Min            -0.45778
exploration/env_infos/initial/reward_energy Mean         -0.31315
exploration/env_infos/initial/reward_energy Std           0.258962
exploration/env_infos/initial/reward_energy Max          -0.0522084
exploration/env_infos/initial/reward_energy Min          -0.737473
exploration/env_infos/reward_energy Mean                 -0.162672
exploration/env_infos/reward_energy Std                   0.120271
exploration/env_infos/reward_energy Max                  -0.018123
exploration/env_infos/reward_energy Min                  -0.737473
exploration/env_infos/final/end_effector_loc Mean        -0.0437044
exploration/env_infos/final/end_effector_loc Std          0.206004
exploration/env_infos/final/end_effector_loc Max          0.327335
exploration/env_infos/final/end_effector_loc Min         -0.381047
exploration/env_infos/initial/end_effector_loc Mean      -0.00237677
exploration/env_infos/initial/end_effector_loc Std        0.0141689
exploration/env_infos/initial/end_effector_loc Max        0.0226533
exploration/env_infos/initial/end_effector_loc Min       -0.0368571
exploration/env_infos/end_effector_loc Mean              -0.0272782
exploration/env_infos/end_effector_loc Std                0.150244
exploration/env_infos/end_effector_loc Max                0.327335
exploration/env_infos/end_effector_loc Min               -0.387122
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.247012
exploration/env_infos/final/reward_dist Std               0.29636
exploration/env_infos/final/reward_dist Max               0.666966
exploration/env_infos/final/reward_dist Min               2.65359e-09
exploration/env_infos/initial/reward_dist Mean            0.00173496
exploration/env_infos/initial/reward_dist Std             0.00287338
exploration/env_infos/initial/reward_dist Max             0.00743483
exploration/env_infos/initial/reward_dist Min             1.93545e-06
exploration/env_infos/reward_dist Mean                    0.0803635
exploration/env_infos/reward_dist Std                     0.181675
exploration/env_infos/reward_dist Max                     0.896997
exploration/env_infos/reward_dist Min                     5.8848e-11
evaluation/num steps total                           285000
evaluation/num paths total                            14250
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.22421
evaluation/Rewards Std                                    0.294893
evaluation/Rewards Max                                    0.12019
evaluation/Rewards Min                                   -1.65974
evaluation/Returns Mean                                  -4.4842
evaluation/Returns Std                                    4.99245
evaluation/Returns Max                                    0.980844
evaluation/Returns Min                                  -22.0708
evaluation/Actions Mean                                   0.0458026
evaluation/Actions Std                                    0.310377
evaluation/Actions Max                                    1
evaluation/Actions Min                                   -0.999772
evaluation/Num Paths                                     50
evaluation/Average Returns                               -4.4842
evaluation/env_infos/final/reward_energy Mean            -0.230831
evaluation/env_infos/final/reward_energy Std              0.313611
evaluation/env_infos/final/reward_energy Max             -0.00737728
evaluation/env_infos/final/reward_energy Min             -1.36274
evaluation/env_infos/initial/reward_energy Mean          -0.439866
evaluation/env_infos/initial/reward_energy Std            0.323988
evaluation/env_infos/initial/reward_energy Max           -0.0239735
evaluation/env_infos/initial/reward_energy Min           -1.25869
evaluation/env_infos/reward_energy Mean                  -0.271951
evaluation/env_infos/reward_energy Std                    0.35058
evaluation/env_infos/reward_energy Max                   -0.00458893
evaluation/env_infos/reward_energy Min                   -1.41115
evaluation/env_infos/final/end_effector_loc Mean         -0.0342369
evaluation/env_infos/final/end_effector_loc Std           0.566198
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00361992
evaluation/env_infos/initial/end_effector_loc Std         0.0189726
evaluation/env_infos/initial/end_effector_loc Max         0.0464958
evaluation/env_infos/initial/end_effector_loc Min        -0.0499406
evaluation/env_infos/end_effector_loc Mean               -0.0041141
evaluation/env_infos/end_effector_loc Std                 0.391512
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0674008
evaluation/env_infos/final/reward_dist Std                0.204321
evaluation/env_infos/final/reward_dist Max                0.854629
evaluation/env_infos/final/reward_dist Min                3.35654e-144
evaluation/env_infos/initial/reward_dist Mean             0.0115703
evaluation/env_infos/initial/reward_dist Std              0.0177392
evaluation/env_infos/initial/reward_dist Max              0.0809513
evaluation/env_infos/initial/reward_dist Min              1.23045e-06
evaluation/env_infos/reward_dist Mean                     0.0894825
evaluation/env_infos/reward_dist Std                      0.217428
evaluation/env_infos/reward_dist Max                      0.998124
evaluation/env_infos/reward_dist Min                      3.35654e-144
time/data storing (s)                                    39.6963
time/evaluation sampling (s)                              0.804194
time/exploration sampling (s)                             0.0948786
time/logging (s)                                          0.0152094
time/saving (s)                                           0.779137
time/training (s)                                        39.8394
time/epoch (s)                                           81.2291
time/total (s)                                        21736.8
Epoch                                                   284
---------------------------------------------------  -----------------
2021-05-29 05:59:34.106781 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 285 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0446656
trainer/QF2 Loss                                          0.0295266
trainer/Policy Loss                                       2.9267
trainer/Q1 Predictions Mean                              -1.00295
trainer/Q1 Predictions Std                                1.1012
trainer/Q1 Predictions Max                                2.99428
trainer/Q1 Predictions Min                               -4.01678
trainer/Q2 Predictions Mean                              -0.966509
trainer/Q2 Predictions Std                                1.13635
trainer/Q2 Predictions Max                                2.88894
trainer/Q2 Predictions Min                               -3.90028
trainer/Q Targets Mean                                   -1.00038
trainer/Q Targets Std                                     1.14014
trainer/Q Targets Max                                     3.05275
trainer/Q Targets Min                                    -4.12423
trainer/Log Pis Mean                                      2.01047
trainer/Log Pis Std                                       1.57937
trainer/Log Pis Max                                       9.762
trainer/Log Pis Min                                      -3.12706
trainer/Policy mu Mean                                    0.0266501
trainer/Policy mu Std                                     0.749995
trainer/Policy mu Max                                     4.2024
trainer/Policy mu Min                                    -2.41307
trainer/Policy log std Mean                              -2.06553
trainer/Policy log std Std                                0.475513
trainer/Policy log std Max                                0.816588
trainer/Policy log std Min                               -3.19695
trainer/Alpha                                             0.0233407
trainer/Alpha Loss                                        0.0393644
exploration/num steps total                           29600
exploration/num paths total                            1480
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.68323
exploration/Rewards Std                                   0.522562
exploration/Rewards Max                                  -0.0574431
exploration/Rewards Min                                  -1.68149
exploration/Returns Mean                                -13.6646
exploration/Returns Std                                   8.56283
exploration/Returns Max                                  -3.29954
exploration/Returns Min                                 -25.7646
exploration/Actions Mean                                  0.21971
exploration/Actions Std                                   0.500689
exploration/Actions Max                                   1
exploration/Actions Min                                  -0.999602
exploration/Num Paths                                     5
exploration/Average Returns                             -13.6646
exploration/env_infos/final/reward_energy Mean           -0.567805
exploration/env_infos/final/reward_energy Std             0.507055
exploration/env_infos/final/reward_energy Max            -0.119031
exploration/env_infos/final/reward_energy Min            -1.38017
exploration/env_infos/initial/reward_energy Mean         -0.442904
exploration/env_infos/initial/reward_energy Std           0.274507
exploration/env_infos/initial/reward_energy Max          -0.171299
exploration/env_infos/initial/reward_energy Min          -0.962629
exploration/env_infos/reward_energy Mean                 -0.600102
exploration/env_infos/reward_energy Std                   0.487649
exploration/env_infos/reward_energy Max                  -0.0222195
exploration/env_infos/reward_energy Min                  -1.41143
exploration/env_infos/final/end_effector_loc Mean         0.295447
exploration/env_infos/final/end_effector_loc Std          0.674474
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00492492
exploration/env_infos/initial/end_effector_loc Std        0.0177522
exploration/env_infos/initial/end_effector_loc Max        0.0479373
exploration/env_infos/initial/end_effector_loc Min       -0.0129804
exploration/env_infos/end_effector_loc Mean               0.225923
exploration/env_infos/end_effector_loc Std                0.510771
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              8.51546e-12
exploration/env_infos/final/reward_dist Std               1.70309e-11
exploration/env_infos/final/reward_dist Max               4.25773e-11
exploration/env_infos/final/reward_dist Min               3.88354e-144
exploration/env_infos/initial/reward_dist Mean            0.00808438
exploration/env_infos/initial/reward_dist Std             0.0158121
exploration/env_infos/initial/reward_dist Max             0.0397075
exploration/env_infos/initial/reward_dist Min             3.80776e-05
exploration/env_infos/reward_dist Mean                    0.00113736
exploration/env_infos/reward_dist Std                     0.00557439
exploration/env_infos/reward_dist Max                     0.0397075
exploration/env_infos/reward_dist Min                     3.88354e-144
evaluation/num steps total                           286000
evaluation/num paths total                            14300
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.29036
evaluation/Rewards Std                                    0.318831
evaluation/Rewards Max                                    0.0967936
evaluation/Rewards Min                                   -1.32001
evaluation/Returns Mean                                  -5.8072
evaluation/Returns Std                                    5.60565
evaluation/Returns Max                                    0.380292
evaluation/Returns Min                                  -20.2573
evaluation/Actions Mean                                   0.0944612
evaluation/Actions Std                                    0.40853
evaluation/Actions Max                                    1
evaluation/Actions Min                                   -0.998688
evaluation/Num Paths                                     50
evaluation/Average Returns                               -5.8072
evaluation/env_infos/final/reward_energy Mean            -0.372098
evaluation/env_infos/final/reward_energy Std              0.397973
evaluation/env_infos/final/reward_energy Max             -0.00343082
evaluation/env_infos/final/reward_energy Min             -1.24793
evaluation/env_infos/initial/reward_energy Mean          -0.540701
evaluation/env_infos/initial/reward_energy Std            0.398992
evaluation/env_infos/initial/reward_energy Max           -0.0345489
evaluation/env_infos/initial/reward_energy Min           -1.32291
evaluation/env_infos/reward_energy Mean                  -0.404903
evaluation/env_infos/reward_energy Std                    0.433235
evaluation/env_infos/reward_energy Max                   -0.000965927
evaluation/env_infos/reward_energy Min                   -1.40993
evaluation/env_infos/final/end_effector_loc Mean          0.021701
evaluation/env_infos/final/end_effector_loc Std           0.588246
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00147411
evaluation/env_infos/initial/end_effector_loc Std         0.0237122
evaluation/env_infos/initial/end_effector_loc Max         0.0499967
evaluation/env_infos/initial/end_effector_loc Min        -0.0473799
evaluation/env_infos/end_effector_loc Mean                0.0369027
evaluation/env_infos/end_effector_loc Std                 0.450733
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0408067
evaluation/env_infos/final/reward_dist Std                0.143823
evaluation/env_infos/final/reward_dist Max                0.836831
evaluation/env_infos/final/reward_dist Min                1.12479e-194
evaluation/env_infos/initial/reward_dist Mean             0.00708867
evaluation/env_infos/initial/reward_dist Std              0.015984
evaluation/env_infos/initial/reward_dist Max              0.0907814
evaluation/env_infos/initial/reward_dist Min              9.70108e-07
evaluation/env_infos/reward_dist Mean                     0.0708026
evaluation/env_infos/reward_dist Std                      0.18221
evaluation/env_infos/reward_dist Max                      0.998166
evaluation/env_infos/reward_dist Min                      1.12479e-194
time/data storing (s)                                    38.829
time/evaluation sampling (s)                              0.651514
time/exploration sampling (s)                             0.0900526
time/logging (s)                                          0.016183
time/saving (s)                                           0.798348
time/training (s)                                        39.494
time/epoch (s)                                           79.8791
time/total (s)                                        21819.6
Epoch                                                   285
---------------------------------------------------  -----------------
2021-05-29 06:00:55.752002 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 286 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0517025
trainer/QF2 Loss                                          0.0433277
trainer/Policy Loss                                       2.84175
trainer/Q1 Predictions Mean                              -0.970687
trainer/Q1 Predictions Std                                1.50201
trainer/Q1 Predictions Max                                5.99479
trainer/Q1 Predictions Min                               -5.29373
trainer/Q2 Predictions Mean                              -0.977479
trainer/Q2 Predictions Std                                1.53807
trainer/Q2 Predictions Max                                6.42799
trainer/Q2 Predictions Min                               -5.30684
trainer/Q Targets Mean                                   -0.942288
trainer/Q Targets Std                                     1.54957
trainer/Q Targets Max                                     6.32014
trainer/Q Targets Min                                    -5.18372
trainer/Log Pis Mean                                      1.94241
trainer/Log Pis Std                                       1.20503
trainer/Log Pis Max                                       5.97273
trainer/Log Pis Min                                      -3.42305
trainer/Policy mu Mean                                    0.105737
trainer/Policy mu Std                                     0.548371
trainer/Policy mu Max                                     2.68828
trainer/Policy mu Min                                    -2.15135
trainer/Policy log std Mean                              -2.12865
trainer/Policy log std Std                                0.368224
trainer/Policy log std Max                               -0.950383
trainer/Policy log std Min                               -2.744
trainer/Alpha                                             0.0177497
trainer/Alpha Loss                                       -0.232109
exploration/num steps total                           29700
exploration/num paths total                            1485
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.227958
exploration/Rewards Std                                   0.313873
exploration/Rewards Max                                   0.0941245
exploration/Rewards Min                                  -1.20865
exploration/Returns Mean                                 -4.55917
exploration/Returns Std                                   5.48225
exploration/Returns Max                                   0.348949
exploration/Returns Min                                 -15.2385
exploration/Actions Mean                                  0.0339888
exploration/Actions Std                                   0.312214
exploration/Actions Max                                   0.954935
exploration/Actions Min                                  -0.932215
exploration/Num Paths                                     5
exploration/Average Returns                              -4.55917
exploration/env_infos/final/reward_energy Mean           -0.38551
exploration/env_infos/final/reward_energy Std             0.260929
exploration/env_infos/final/reward_energy Max            -0.127596
exploration/env_infos/final/reward_energy Min            -0.871552
exploration/env_infos/initial/reward_energy Mean         -0.515181
exploration/env_infos/initial/reward_energy Std           0.2892
exploration/env_infos/initial/reward_energy Max          -0.0800715
exploration/env_infos/initial/reward_energy Min          -0.887918
exploration/env_infos/reward_energy Mean                 -0.315148
exploration/env_infos/reward_energy Std                   0.312966
exploration/env_infos/reward_energy Max                  -0.0134562
exploration/env_infos/reward_energy Min                  -1.28502
exploration/env_infos/final/end_effector_loc Mean         0.0739721
exploration/env_infos/final/end_effector_loc Std          0.547035
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.0105953
exploration/env_infos/initial/end_effector_loc Std        0.0180014
exploration/env_infos/initial/end_effector_loc Max        0.017698
exploration/env_infos/initial/end_effector_loc Min       -0.0380693
exploration/env_infos/end_effector_loc Mean              -0.00317695
exploration/env_infos/end_effector_loc Std                0.386981
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.182972
exploration/env_infos/final/reward_dist Std               0.365944
exploration/env_infos/final/reward_dist Max               0.91486
exploration/env_infos/final/reward_dist Min               3.83567e-101
exploration/env_infos/initial/reward_dist Mean            0.00226556
exploration/env_infos/initial/reward_dist Std             0.00195078
exploration/env_infos/initial/reward_dist Max             0.00481165
exploration/env_infos/initial/reward_dist Min             4.96578e-07
exploration/env_infos/reward_dist Mean                    0.117485
exploration/env_infos/reward_dist Std                     0.22699
exploration/env_infos/reward_dist Max                     0.981479
exploration/env_infos/reward_dist Min                     3.83567e-101
evaluation/num steps total                           287000
evaluation/num paths total                            14350
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.164388
evaluation/Rewards Std                                    0.168356
evaluation/Rewards Max                                    0.125354
evaluation/Rewards Min                                   -0.90819
evaluation/Returns Mean                                  -3.28775
evaluation/Returns Std                                    2.85991
evaluation/Returns Max                                    1.69235
evaluation/Returns Min                                  -11.5901
evaluation/Actions Mean                                   0.0188713
evaluation/Actions Std                                    0.228663
evaluation/Actions Max                                    0.985135
evaluation/Actions Min                                   -0.997495
evaluation/Num Paths                                     50
evaluation/Average Returns                               -3.28775
evaluation/env_infos/final/reward_energy Mean            -0.179591
evaluation/env_infos/final/reward_energy Std              0.212663
evaluation/env_infos/final/reward_energy Max             -0.0101635
evaluation/env_infos/final/reward_energy Min             -1.08371
evaluation/env_infos/initial/reward_energy Mean          -0.390123
evaluation/env_infos/initial/reward_energy Std            0.351956
evaluation/env_infos/initial/reward_energy Max           -0.0092349
evaluation/env_infos/initial/reward_energy Min           -1.38991
evaluation/env_infos/reward_energy Mean                  -0.208108
evaluation/env_infos/reward_energy Std                    0.248952
evaluation/env_infos/reward_energy Max                   -0.0017002
evaluation/env_infos/reward_energy Min                   -1.38991
evaluation/env_infos/final/end_effector_loc Mean          0.178971
evaluation/env_infos/final/end_effector_loc Std           0.49373
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00181195
evaluation/env_infos/initial/end_effector_loc Std         0.0184879
evaluation/env_infos/initial/end_effector_loc Max         0.0492567
evaluation/env_infos/initial/end_effector_loc Min        -0.0490244
evaluation/env_infos/end_effector_loc Mean                0.0853187
evaluation/env_infos/end_effector_loc Std                 0.353907
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0772107
evaluation/env_infos/final/reward_dist Std                0.220581
evaluation/env_infos/final/reward_dist Max                0.929326
evaluation/env_infos/final/reward_dist Min                1.009e-150
evaluation/env_infos/initial/reward_dist Mean             0.00625528
evaluation/env_infos/initial/reward_dist Std              0.0151214
evaluation/env_infos/initial/reward_dist Max              0.0759344
evaluation/env_infos/initial/reward_dist Min              1.4375e-06
evaluation/env_infos/reward_dist Mean                     0.0609447
evaluation/env_infos/reward_dist Std                      0.159105
evaluation/env_infos/reward_dist Max                      0.966861
evaluation/env_infos/reward_dist Min                      2.50222e-152
time/data storing (s)                                    37.8728
time/evaluation sampling (s)                              0.530449
time/exploration sampling (s)                             0.089237
time/logging (s)                                          0.0143265
time/saving (s)                                           0.767538
time/training (s)                                        38.7837
time/epoch (s)                                           78.058
time/total (s)                                        21901.3
Epoch                                                   286
---------------------------------------------------  -----------------
2021-05-29 06:02:17.988623 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 287 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.121133
trainer/QF2 Loss                                          0.0306017
trainer/Policy Loss                                       3.17297
trainer/Q1 Predictions Mean                              -1.12868
trainer/Q1 Predictions Std                                1.44476
trainer/Q1 Predictions Max                                6.40486
trainer/Q1 Predictions Min                               -5.42154
trainer/Q2 Predictions Mean                              -1.12121
trainer/Q2 Predictions Std                                1.4774
trainer/Q2 Predictions Max                                6.22314
trainer/Q2 Predictions Min                               -4.99292
trainer/Q Targets Mean                                   -1.13269
trainer/Q Targets Std                                     1.46328
trainer/Q Targets Max                                     5.98681
trainer/Q Targets Min                                    -5.45738
trainer/Log Pis Mean                                      2.13839
trainer/Log Pis Std                                       1.33023
trainer/Log Pis Max                                       7.0885
trainer/Log Pis Min                                      -3.02069
trainer/Policy mu Mean                                    0.18921
trainer/Policy mu Std                                     0.68633
trainer/Policy mu Max                                     3.72129
trainer/Policy mu Min                                    -2.827
trainer/Policy log std Mean                              -2.12026
trainer/Policy log std Std                                0.425411
trainer/Policy log std Max                                0.277726
trainer/Policy log std Min                               -2.80223
trainer/Alpha                                             0.0201015
trainer/Alpha Loss                                        0.540925
exploration/num steps total                           29800
exploration/num paths total                            1490
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.237443
exploration/Rewards Std                                   0.129218
exploration/Rewards Max                                  -0.0323584
exploration/Rewards Min                                  -0.560235
exploration/Returns Mean                                 -4.74885
exploration/Returns Std                                   2.01505
exploration/Returns Max                                  -2.71902
exploration/Returns Min                                  -7.52623
exploration/Actions Mean                                  0.0265975
exploration/Actions Std                                   0.265456
exploration/Actions Max                                   0.908096
exploration/Actions Min                                  -0.983257
exploration/Num Paths                                     5
exploration/Average Returns                              -4.74885
exploration/env_infos/final/reward_energy Mean           -0.337344
exploration/env_infos/final/reward_energy Std             0.251631
exploration/env_infos/final/reward_energy Max            -0.0529091
exploration/env_infos/final/reward_energy Min            -0.716387
exploration/env_infos/initial/reward_energy Mean         -0.51521
exploration/env_infos/initial/reward_energy Std           0.397284
exploration/env_infos/initial/reward_energy Max          -0.0408425
exploration/env_infos/initial/reward_energy Min          -1.15703
exploration/env_infos/reward_energy Mean                 -0.28669
exploration/env_infos/reward_energy Std                   0.245271
exploration/env_infos/reward_energy Max                  -0.021214
exploration/env_infos/reward_energy Min                  -1.1845
exploration/env_infos/final/end_effector_loc Mean         0.205526
exploration/env_infos/final/end_effector_loc Std          0.729837
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.00287516
exploration/env_infos/initial/end_effector_loc Std        0.0228217
exploration/env_infos/initial/end_effector_loc Max        0.0304928
exploration/env_infos/initial/end_effector_loc Min       -0.0491629
exploration/env_infos/end_effector_loc Mean               0.119228
exploration/env_infos/end_effector_loc Std                0.549324
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              6.61637e-08
exploration/env_infos/final/reward_dist Std               1.32326e-07
exploration/env_infos/final/reward_dist Max               3.30816e-07
exploration/env_infos/final/reward_dist Min               1.6755e-178
exploration/env_infos/initial/reward_dist Mean            0.00753759
exploration/env_infos/initial/reward_dist Std             0.0108444
exploration/env_infos/initial/reward_dist Max             0.0280438
exploration/env_infos/initial/reward_dist Min             6.30377e-07
exploration/env_infos/reward_dist Mean                    0.02529
exploration/env_infos/reward_dist Std                     0.0795209
exploration/env_infos/reward_dist Max                     0.480313
exploration/env_infos/reward_dist Min                     1.6755e-178
evaluation/num steps total                           288000
evaluation/num paths total                            14400
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.170051
evaluation/Rewards Std                                    0.200703
evaluation/Rewards Max                                    0.117336
evaluation/Rewards Min                                   -1.17579
evaluation/Returns Mean                                  -3.40102
evaluation/Returns Std                                    3.16475
evaluation/Returns Max                                    0.801475
evaluation/Returns Min                                  -14.5837
evaluation/Actions Mean                                   0.037098
evaluation/Actions Std                                    0.219817
evaluation/Actions Max                                    0.981289
evaluation/Actions Min                                   -0.998728
evaluation/Num Paths                                     50
evaluation/Average Returns                               -3.40102
evaluation/env_infos/final/reward_energy Mean            -0.184763
evaluation/env_infos/final/reward_energy Std              0.296241
evaluation/env_infos/final/reward_energy Max             -0.00376586
evaluation/env_infos/final/reward_energy Min             -1.30797
evaluation/env_infos/initial/reward_energy Mean          -0.418096
evaluation/env_infos/initial/reward_energy Std            0.36019
evaluation/env_infos/initial/reward_energy Max           -0.0148356
evaluation/env_infos/initial/reward_energy Min           -1.28714
evaluation/env_infos/reward_energy Mean                  -0.197965
evaluation/env_infos/reward_energy Std                    0.245359
evaluation/env_infos/reward_energy Max                   -0.00174681
evaluation/env_infos/reward_energy Min                   -1.37505
evaluation/env_infos/final/end_effector_loc Mean          0.239976
evaluation/env_infos/final/end_effector_loc Std           0.479921
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00480265
evaluation/env_infos/initial/end_effector_loc Std         0.0189106
evaluation/env_infos/initial/end_effector_loc Max         0.0490644
evaluation/env_infos/initial/end_effector_loc Min        -0.0493318
evaluation/env_infos/end_effector_loc Mean                0.115065
evaluation/env_infos/end_effector_loc Std                 0.34538
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0481305
evaluation/env_infos/final/reward_dist Std                0.157665
evaluation/env_infos/final/reward_dist Max                0.947687
evaluation/env_infos/final/reward_dist Min                5.74028e-168
evaluation/env_infos/initial/reward_dist Mean             0.00348558
evaluation/env_infos/initial/reward_dist Std              0.00720914
evaluation/env_infos/initial/reward_dist Max              0.042299
evaluation/env_infos/initial/reward_dist Min              1.35258e-08
evaluation/env_infos/reward_dist Mean                     0.0578971
evaluation/env_infos/reward_dist Std                      0.164925
evaluation/env_infos/reward_dist Max                      0.996409
evaluation/env_infos/reward_dist Min                      5.74028e-168
time/data storing (s)                                    37.721
time/evaluation sampling (s)                              0.656315
time/exploration sampling (s)                             0.0897633
time/logging (s)                                          0.0164354
time/saving (s)                                           0.773951
time/training (s)                                        39.9141
time/epoch (s)                                           79.1716
time/total (s)                                        21983.5
Epoch                                                   287
---------------------------------------------------  -----------------
2021-05-29 06:03:39.558581 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 288 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0334144
trainer/QF2 Loss                                          0.0300345
trainer/Policy Loss                                       3.01625
trainer/Q1 Predictions Mean                              -1.02427
trainer/Q1 Predictions Std                                1.33305
trainer/Q1 Predictions Max                                3.00905
trainer/Q1 Predictions Min                               -5.82116
trainer/Q2 Predictions Mean                              -1.03298
trainer/Q2 Predictions Std                                1.33627
trainer/Q2 Predictions Max                                3.29539
trainer/Q2 Predictions Min                               -5.84771
trainer/Q Targets Mean                                   -0.995186
trainer/Q Targets Std                                     1.3393
trainer/Q Targets Max                                     3.07826
trainer/Q Targets Min                                    -5.60807
trainer/Log Pis Mean                                      2.04326
trainer/Log Pis Std                                       1.32323
trainer/Log Pis Max                                       6.87579
trainer/Log Pis Min                                      -3.51998
trainer/Policy mu Mean                                    0.0193051
trainer/Policy mu Std                                     0.601603
trainer/Policy mu Max                                     2.80989
trainer/Policy mu Min                                    -2.59242
trainer/Policy log std Mean                              -2.14973
trainer/Policy log std Std                                0.430429
trainer/Policy log std Max                                0.0150576
trainer/Policy log std Min                               -2.66633
trainer/Alpha                                             0.022391
trainer/Alpha Loss                                        0.164409
exploration/num steps total                           29900
exploration/num paths total                            1495
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.191423
exploration/Rewards Std                                   0.101056
exploration/Rewards Max                                  -0.0539498
exploration/Rewards Min                                  -0.635622
exploration/Returns Mean                                 -3.82846
exploration/Returns Std                                   1.46178
exploration/Returns Max                                  -2.61466
exploration/Returns Min                                  -6.68305
exploration/Actions Mean                                  9.33528e-05
exploration/Actions Std                                   0.148347
exploration/Actions Max                                   0.760157
exploration/Actions Min                                  -0.401702
exploration/Num Paths                                     5
exploration/Average Returns                              -3.82846
exploration/env_infos/final/reward_energy Mean           -0.118529
exploration/env_infos/final/reward_energy Std             0.0323655
exploration/env_infos/final/reward_energy Max            -0.0673259
exploration/env_infos/final/reward_energy Min            -0.159908
exploration/env_infos/initial/reward_energy Mean         -0.267469
exploration/env_infos/initial/reward_energy Std           0.100044
exploration/env_infos/initial/reward_energy Max          -0.113611
exploration/env_infos/initial/reward_energy Min          -0.378126
exploration/env_infos/reward_energy Mean                 -0.162311
exploration/env_infos/reward_energy Std                   0.132924
exploration/env_infos/reward_energy Max                  -0.0203639
exploration/env_infos/reward_energy Min                  -0.938245
exploration/env_infos/final/end_effector_loc Mean        -0.106402
exploration/env_infos/final/end_effector_loc Std          0.366831
exploration/env_infos/final/end_effector_loc Max          0.5449
exploration/env_infos/final/end_effector_loc Min         -0.970938
exploration/env_infos/initial/end_effector_loc Mean      -0.00332214
exploration/env_infos/initial/end_effector_loc Std        0.00953408
exploration/env_infos/initial/end_effector_loc Max        0.00971655
exploration/env_infos/initial/end_effector_loc Min       -0.0188032
exploration/env_infos/end_effector_loc Mean              -0.0897231
exploration/env_infos/end_effector_loc Std                0.211838
exploration/env_infos/end_effector_loc Max                0.5449
exploration/env_infos/end_effector_loc Min               -0.970938
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              9.19381e-05
exploration/env_infos/final/reward_dist Std               0.000155213
exploration/env_infos/final/reward_dist Max               0.000398756
exploration/env_infos/final/reward_dist Min               1.34319e-81
exploration/env_infos/initial/reward_dist Mean            7.44281e-05
exploration/env_infos/initial/reward_dist Std             0.000134025
exploration/env_infos/initial/reward_dist Max             0.000342363
exploration/env_infos/initial/reward_dist Min             1.48992e-06
exploration/env_infos/reward_dist Mean                    0.00419669
exploration/env_infos/reward_dist Std                     0.0110976
exploration/env_infos/reward_dist Max                     0.0642938
exploration/env_infos/reward_dist Min                     1.34319e-81
evaluation/num steps total                           289000
evaluation/num paths total                            14450
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.174944
evaluation/Rewards Std                                    0.196986
evaluation/Rewards Max                                    0.150756
evaluation/Rewards Min                                   -1.42656
evaluation/Returns Mean                                  -3.49888
evaluation/Returns Std                                    3.03192
evaluation/Returns Max                                    1.01896
evaluation/Returns Min                                  -13.0959
evaluation/Actions Mean                                   0.0109969
evaluation/Actions Std                                    0.201216
evaluation/Actions Max                                    0.985536
evaluation/Actions Min                                   -0.959589
evaluation/Num Paths                                     50
evaluation/Average Returns                               -3.49888
evaluation/env_infos/final/reward_energy Mean            -0.225748
evaluation/env_infos/final/reward_energy Std              0.260325
evaluation/env_infos/final/reward_energy Max             -0.0158086
evaluation/env_infos/final/reward_energy Min             -1.2149
evaluation/env_infos/initial/reward_energy Mean          -0.387707
evaluation/env_infos/initial/reward_energy Std            0.292339
evaluation/env_infos/initial/reward_energy Max           -0.0239136
evaluation/env_infos/initial/reward_energy Min           -1.1528
evaluation/env_infos/reward_energy Mean                  -0.202198
evaluation/env_infos/reward_energy Std                    0.200832
evaluation/env_infos/reward_energy Max                   -0.00597743
evaluation/env_infos/reward_energy Min                   -1.22668
evaluation/env_infos/final/end_effector_loc Mean          0.13987
evaluation/env_infos/final/end_effector_loc Std           0.522878
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.00102373
evaluation/env_infos/initial/end_effector_loc Std         0.017137
evaluation/env_infos/initial/end_effector_loc Max         0.0492768
evaluation/env_infos/initial/end_effector_loc Min        -0.040165
evaluation/env_infos/end_effector_loc Mean                0.0572299
evaluation/env_infos/end_effector_loc Std                 0.353298
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0306571
evaluation/env_infos/final/reward_dist Std                0.117736
evaluation/env_infos/final/reward_dist Max                0.745509
evaluation/env_infos/final/reward_dist Min                4.79885e-191
evaluation/env_infos/initial/reward_dist Mean             0.00504701
evaluation/env_infos/initial/reward_dist Std              0.00744858
evaluation/env_infos/initial/reward_dist Max              0.0277177
evaluation/env_infos/initial/reward_dist Min              4.4099e-07
evaluation/env_infos/reward_dist Mean                     0.0533261
evaluation/env_infos/reward_dist Std                      0.157548
evaluation/env_infos/reward_dist Max                      0.981851
evaluation/env_infos/reward_dist Min                      4.79885e-191
time/data storing (s)                                    38.1245
time/evaluation sampling (s)                              0.531901
time/exploration sampling (s)                             0.0792899
time/logging (s)                                          0.0144134
time/saving (s)                                           0.822124
time/training (s)                                        38.9971
time/epoch (s)                                           78.5693
time/total (s)                                        22065.1
Epoch                                                   288
---------------------------------------------------  -----------------
2021-05-29 06:05:00.922164 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 289 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0194971
trainer/QF2 Loss                                          0.0247547
trainer/Policy Loss                                       2.98572
trainer/Q1 Predictions Mean                              -1.06963
trainer/Q1 Predictions Std                                1.43602
trainer/Q1 Predictions Max                                2.67444
trainer/Q1 Predictions Min                               -6.2592
trainer/Q2 Predictions Mean                              -1.0762
trainer/Q2 Predictions Std                                1.43676
trainer/Q2 Predictions Max                                2.51226
trainer/Q2 Predictions Min                               -6.34462
trainer/Q Targets Mean                                   -1.09663
trainer/Q Targets Std                                     1.45156
trainer/Q Targets Max                                     2.65384
trainer/Q Targets Min                                    -6.45441
trainer/Log Pis Mean                                      2.02895
trainer/Log Pis Std                                       1.1946
trainer/Log Pis Max                                       9.24491
trainer/Log Pis Min                                      -4.3564
trainer/Policy mu Mean                                    0.0735454
trainer/Policy mu Std                                     0.61971
trainer/Policy mu Max                                     2.96518
trainer/Policy mu Min                                    -1.97347
trainer/Policy log std Mean                              -2.09474
trainer/Policy log std Std                                0.430442
trainer/Policy log std Max                                0.622693
trainer/Policy log std Min                               -2.6764
trainer/Alpha                                             0.0237018
trainer/Alpha Loss                                        0.108329
exploration/num steps total                           30000
exploration/num paths total                            1500
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.091523
exploration/Rewards Std                                   0.108036
exploration/Rewards Max                                   0.120503
exploration/Rewards Min                                  -0.379963
exploration/Returns Mean                                 -1.83046
exploration/Returns Std                                   1.78908
exploration/Returns Max                                   0.81636
exploration/Returns Min                                  -4.38123
exploration/Actions Mean                                 -0.00638981
exploration/Actions Std                                   0.151087
exploration/Actions Max                                   0.364352
exploration/Actions Min                                  -0.48737
exploration/Num Paths                                     5
exploration/Average Returns                              -1.83046
exploration/env_infos/final/reward_energy Mean           -0.227954
exploration/env_infos/final/reward_energy Std             0.0897096
exploration/env_infos/final/reward_energy Max            -0.148689
exploration/env_infos/final/reward_energy Min            -0.402922
exploration/env_infos/initial/reward_energy Mean         -0.339089
exploration/env_infos/initial/reward_energy Std           0.167124
exploration/env_infos/initial/reward_energy Max          -0.114999
exploration/env_infos/initial/reward_energy Min          -0.57851
exploration/env_infos/reward_energy Mean                 -0.185586
exploration/env_infos/reward_energy Std                   0.106275
exploration/env_infos/reward_energy Max                  -0.0126402
exploration/env_infos/reward_energy Min                  -0.57851
exploration/env_infos/final/end_effector_loc Mean        -0.0770783
exploration/env_infos/final/end_effector_loc Std          0.0827475
exploration/env_infos/final/end_effector_loc Max          0.102008
exploration/env_infos/final/end_effector_loc Min         -0.223532
exploration/env_infos/initial/end_effector_loc Mean      -0.00494581
exploration/env_infos/initial/end_effector_loc Std        0.0124169
exploration/env_infos/initial/end_effector_loc Max        0.0155839
exploration/env_infos/initial/end_effector_loc Min       -0.0243685
exploration/env_infos/end_effector_loc Mean              -0.0462468
exploration/env_infos/end_effector_loc Std                0.0835234
exploration/env_infos/end_effector_loc Max                0.124977
exploration/env_infos/end_effector_loc Min               -0.223532
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.151718
exploration/env_infos/final/reward_dist Std               0.278042
exploration/env_infos/final/reward_dist Max               0.706498
exploration/env_infos/final/reward_dist Min               2.00674e-05
exploration/env_infos/initial/reward_dist Mean            0.0173841
exploration/env_infos/initial/reward_dist Std             0.015492
exploration/env_infos/initial/reward_dist Max             0.0411104
exploration/env_infos/initial/reward_dist Min             0.00162624
exploration/env_infos/reward_dist Mean                    0.236519
exploration/env_infos/reward_dist Std                     0.296049
exploration/env_infos/reward_dist Max                     0.885666
exploration/env_infos/reward_dist Min                     2.21998e-06
evaluation/num steps total                           290000
evaluation/num paths total                            14500
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.163114
evaluation/Rewards Std                                    0.204203
evaluation/Rewards Max                                    0.153865
evaluation/Rewards Min                                   -1.60735
evaluation/Returns Mean                                  -3.26229
evaluation/Returns Std                                    2.96993
evaluation/Returns Max                                    1.41401
evaluation/Returns Min                                  -14.5118
evaluation/Actions Mean                                   0.00840299
evaluation/Actions Std                                    0.20091
evaluation/Actions Max                                    0.993787
evaluation/Actions Min                                   -0.956048
evaluation/Num Paths                                     50
evaluation/Average Returns                               -3.26229
evaluation/env_infos/final/reward_energy Mean            -0.196777
evaluation/env_infos/final/reward_energy Std              0.217103
evaluation/env_infos/final/reward_energy Max             -0.00813972
evaluation/env_infos/final/reward_energy Min             -1.01156
evaluation/env_infos/initial/reward_energy Mean          -0.367018
evaluation/env_infos/initial/reward_energy Std            0.280094
evaluation/env_infos/initial/reward_energy Max           -0.0149541
evaluation/env_infos/initial/reward_energy Min           -1.11009
evaluation/env_infos/reward_energy Mean                  -0.193386
evaluation/env_infos/reward_energy Std                    0.208501
evaluation/env_infos/reward_energy Max                   -0.00460891
evaluation/env_infos/reward_energy Min                   -1.16338
evaluation/env_infos/final/end_effector_loc Mean          0.0359566
evaluation/env_infos/final/end_effector_loc Std           0.476697
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00178995
evaluation/env_infos/initial/end_effector_loc Std         0.0162247
evaluation/env_infos/initial/end_effector_loc Max         0.0455513
evaluation/env_infos/initial/end_effector_loc Min        -0.0478024
evaluation/env_infos/end_effector_loc Mean               -0.0013392
evaluation/env_infos/end_effector_loc Std                 0.303766
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0391366
evaluation/env_infos/final/reward_dist Std                0.147549
evaluation/env_infos/final/reward_dist Max                0.787941
evaluation/env_infos/final/reward_dist Min                7.01472e-158
evaluation/env_infos/initial/reward_dist Mean             0.00631866
evaluation/env_infos/initial/reward_dist Std              0.0136062
evaluation/env_infos/initial/reward_dist Max              0.0743006
evaluation/env_infos/initial/reward_dist Min              3.26636e-06
evaluation/env_infos/reward_dist Mean                     0.0536347
evaluation/env_infos/reward_dist Std                      0.153732
evaluation/env_infos/reward_dist Max                      0.999208
evaluation/env_infos/reward_dist Min                      7.01472e-158
time/data storing (s)                                    37.4431
time/evaluation sampling (s)                              0.653799
time/exploration sampling (s)                             0.0900476
time/logging (s)                                          0.0153253
time/saving (s)                                           0.785344
time/training (s)                                        39.1831
time/epoch (s)                                           78.1708
time/total (s)                                        22146.4
Epoch                                                   289
---------------------------------------------------  -----------------
2021-05-29 06:06:21.757294 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 290 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0144028
trainer/QF2 Loss                                          0.0174904
trainer/Policy Loss                                       3.10866
trainer/Q1 Predictions Mean                              -1.14014
trainer/Q1 Predictions Std                                1.19859
trainer/Q1 Predictions Max                                3.54034
trainer/Q1 Predictions Min                               -4.31925
trainer/Q2 Predictions Mean                              -1.14329
trainer/Q2 Predictions Std                                1.19422
trainer/Q2 Predictions Max                                3.49739
trainer/Q2 Predictions Min                               -4.28051
trainer/Q Targets Mean                                   -1.15158
trainer/Q Targets Std                                     1.19696
trainer/Q Targets Max                                     3.57849
trainer/Q Targets Min                                    -4.27175
trainer/Log Pis Mean                                      2.02277
trainer/Log Pis Std                                       1.17537
trainer/Log Pis Max                                       5.76237
trainer/Log Pis Min                                      -2.30155
trainer/Policy mu Mean                                    0.0859279
trainer/Policy mu Std                                     0.596707
trainer/Policy mu Max                                     2.38846
trainer/Policy mu Min                                    -2.61382
trainer/Policy log std Mean                              -2.14656
trainer/Policy log std Std                                0.457645
trainer/Policy log std Max                                0.101748
trainer/Policy log std Min                               -2.72064
trainer/Alpha                                             0.0237248
trainer/Alpha Loss                                        0.0851782
exploration/num steps total                           30100
exploration/num paths total                            1505
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.206719
exploration/Rewards Std                                   0.139952
exploration/Rewards Max                                  -0.00847796
exploration/Rewards Min                                  -0.808373
exploration/Returns Mean                                 -4.13439
exploration/Returns Std                                   1.69262
exploration/Returns Max                                  -2.13699
exploration/Returns Min                                  -7.09094
exploration/Actions Mean                                  0.0688537
exploration/Actions Std                                   0.223054
exploration/Actions Max                                   0.79014
exploration/Actions Min                                  -0.4623
exploration/Num Paths                                     5
exploration/Average Returns                              -4.13439
exploration/env_infos/final/reward_energy Mean           -0.431599
exploration/env_infos/final/reward_energy Std             0.295381
exploration/env_infos/final/reward_energy Max            -0.0604594
exploration/env_infos/final/reward_energy Min            -0.744274
exploration/env_infos/initial/reward_energy Mean         -0.413917
exploration/env_infos/initial/reward_energy Std           0.108895
exploration/env_infos/initial/reward_energy Max          -0.25102
exploration/env_infos/initial/reward_energy Min          -0.553699
exploration/env_infos/reward_energy Mean                 -0.264437
exploration/env_infos/reward_energy Std                   0.197638
exploration/env_infos/reward_energy Max                  -0.0143505
exploration/env_infos/reward_energy Min                  -0.906312
exploration/env_infos/final/end_effector_loc Mean         0.337452
exploration/env_infos/final/end_effector_loc Std          0.423288
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.28444
exploration/env_infos/initial/end_effector_loc Mean       0.00023175
exploration/env_infos/initial/end_effector_loc Std        0.0151304
exploration/env_infos/initial/end_effector_loc Max        0.0229796
exploration/env_infos/initial/end_effector_loc Min       -0.0217319
exploration/env_infos/end_effector_loc Mean               0.123916
exploration/env_infos/end_effector_loc Std                0.27659
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.308659
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0433623
exploration/env_infos/final/reward_dist Std               0.0867246
exploration/env_infos/final/reward_dist Max               0.216812
exploration/env_infos/final/reward_dist Min               3.59547e-117
exploration/env_infos/initial/reward_dist Mean            0.00818316
exploration/env_infos/initial/reward_dist Std             0.00500093
exploration/env_infos/initial/reward_dist Max             0.0140142
exploration/env_infos/initial/reward_dist Min             0.00119836
exploration/env_infos/reward_dist Mean                    0.0784417
exploration/env_infos/reward_dist Std                     0.204666
exploration/env_infos/reward_dist Max                     0.988107
exploration/env_infos/reward_dist Min                     3.59547e-117
evaluation/num steps total                           291000
evaluation/num paths total                            14550
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.21101
evaluation/Rewards Std                                    0.232633
evaluation/Rewards Max                                    0.152242
evaluation/Rewards Min                                   -1.46867
evaluation/Returns Mean                                  -4.22019
evaluation/Returns Std                                    3.13135
evaluation/Returns Max                                    0.184692
evaluation/Returns Min                                  -13.7671
evaluation/Actions Mean                                   0.035052
evaluation/Actions Std                                    0.246018
evaluation/Actions Max                                    0.989873
evaluation/Actions Min                                   -0.986034
evaluation/Num Paths                                     50
evaluation/Average Returns                               -4.22019
evaluation/env_infos/final/reward_energy Mean            -0.297788
evaluation/env_infos/final/reward_energy Std              0.30228
evaluation/env_infos/final/reward_energy Max             -0.0190416
evaluation/env_infos/final/reward_energy Min             -1.03084
evaluation/env_infos/initial/reward_energy Mean          -0.360617
evaluation/env_infos/initial/reward_energy Std            0.297549
evaluation/env_infos/initial/reward_energy Max           -0.0412929
evaluation/env_infos/initial/reward_energy Min           -1.12078
evaluation/env_infos/reward_energy Mean                  -0.242125
evaluation/env_infos/reward_energy Std                    0.25472
evaluation/env_infos/reward_energy Max                   -0.00690648
evaluation/env_infos/reward_energy Min                   -1.35207
evaluation/env_infos/final/end_effector_loc Mean          0.161768
evaluation/env_infos/final/end_effector_loc Std           0.479956
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000365547
evaluation/env_infos/initial/end_effector_loc Std         0.0165255
evaluation/env_infos/initial/end_effector_loc Max         0.0439561
evaluation/env_infos/initial/end_effector_loc Min        -0.0427145
evaluation/env_infos/end_effector_loc Mean                0.0569901
evaluation/env_infos/end_effector_loc Std                 0.319141
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0757097
evaluation/env_infos/final/reward_dist Std                0.208496
evaluation/env_infos/final/reward_dist Max                0.846774
evaluation/env_infos/final/reward_dist Min                2.27676e-175
evaluation/env_infos/initial/reward_dist Mean             0.00587782
evaluation/env_infos/initial/reward_dist Std              0.0221391
evaluation/env_infos/initial/reward_dist Max              0.156016
evaluation/env_infos/initial/reward_dist Min              8.068e-07
evaluation/env_infos/reward_dist Mean                     0.0583714
evaluation/env_infos/reward_dist Std                      0.170178
evaluation/env_infos/reward_dist Max                      0.984073
evaluation/env_infos/reward_dist Min                      2.27676e-175
time/data storing (s)                                    37.8846
time/evaluation sampling (s)                              0.640765
time/exploration sampling (s)                             0.0847945
time/logging (s)                                          0.0141143
time/saving (s)                                           0.767518
time/training (s)                                        38.3221
time/epoch (s)                                           77.7139
time/total (s)                                        22227.2
Epoch                                                   290
---------------------------------------------------  -----------------
2021-05-29 06:07:44.119913 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 291 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.162312
trainer/QF2 Loss                                          0.129067
trainer/Policy Loss                                       2.9711
trainer/Q1 Predictions Mean                              -1.17457
trainer/Q1 Predictions Std                                1.29921
trainer/Q1 Predictions Max                                2.70501
trainer/Q1 Predictions Min                               -5.38025
trainer/Q2 Predictions Mean                              -1.19448
trainer/Q2 Predictions Std                                1.24114
trainer/Q2 Predictions Max                                1.27797
trainer/Q2 Predictions Min                               -5.47741
trainer/Q Targets Mean                                   -1.22704
trainer/Q Targets Std                                     1.29101
trainer/Q Targets Max                                     1.38922
trainer/Q Targets Min                                    -5.70825
trainer/Log Pis Mean                                      1.83282
trainer/Log Pis Std                                       1.32104
trainer/Log Pis Max                                       5.43464
trainer/Log Pis Min                                      -6.10814
trainer/Policy mu Mean                                   -0.0578323
trainer/Policy mu Std                                     0.556239
trainer/Policy mu Max                                     2.35606
trainer/Policy mu Min                                    -2.66247
trainer/Policy log std Mean                              -2.13413
trainer/Policy log std Std                                0.490905
trainer/Policy log std Max                                0.308489
trainer/Policy log std Min                               -2.92484
trainer/Alpha                                             0.023019
trainer/Alpha Loss                                       -0.630448
exploration/num steps total                           30200
exploration/num paths total                            1510
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.419147
exploration/Rewards Std                                   0.266131
exploration/Rewards Max                                  -0.0434261
exploration/Rewards Min                                  -1.0543
exploration/Returns Mean                                 -8.38294
exploration/Returns Std                                   4.44155
exploration/Returns Max                                  -3.26549
exploration/Returns Min                                 -14.0969
exploration/Actions Mean                                 -0.0717719
exploration/Actions Std                                   0.432033
exploration/Actions Max                                   0.992067
exploration/Actions Min                                  -0.999964
exploration/Num Paths                                     5
exploration/Average Returns                              -8.38294
exploration/env_infos/final/reward_energy Mean           -0.437258
exploration/env_infos/final/reward_energy Std             0.309092
exploration/env_infos/final/reward_energy Max            -0.0606199
exploration/env_infos/final/reward_energy Min            -1.00111
exploration/env_infos/initial/reward_energy Mean         -0.678851
exploration/env_infos/initial/reward_energy Std           0.460301
exploration/env_infos/initial/reward_energy Max          -0.207718
exploration/env_infos/initial/reward_energy Min          -1.32063
exploration/env_infos/reward_energy Mean                 -0.488178
exploration/env_infos/reward_energy Std                   0.38117
exploration/env_infos/reward_energy Max                  -0.0181209
exploration/env_infos/reward_energy Min                  -1.41249
exploration/env_infos/final/end_effector_loc Mean         0.0262904
exploration/env_infos/final/end_effector_loc Std          0.6224
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean      -0.0016868
exploration/env_infos/initial/end_effector_loc Std        0.0289491
exploration/env_infos/initial/end_effector_loc Max        0.0496033
exploration/env_infos/initial/end_effector_loc Min       -0.0486869
exploration/env_infos/end_effector_loc Mean               0.0325638
exploration/env_infos/end_effector_loc Std                0.497789
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000131054
exploration/env_infos/final/reward_dist Std               0.000239545
exploration/env_infos/final/reward_dist Max               0.00060879
exploration/env_infos/final/reward_dist Min               1.28226e-169
exploration/env_infos/initial/reward_dist Mean            0.00164774
exploration/env_infos/initial/reward_dist Std             0.00274651
exploration/env_infos/initial/reward_dist Max             0.00709166
exploration/env_infos/initial/reward_dist Min             9.31907e-07
exploration/env_infos/reward_dist Mean                    0.000217821
exploration/env_infos/reward_dist Std                     0.000783378
exploration/env_infos/reward_dist Max                     0.00709166
exploration/env_infos/reward_dist Min                     1.28226e-169
evaluation/num steps total                           292000
evaluation/num paths total                            14600
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.191257
evaluation/Rewards Std                                    0.179547
evaluation/Rewards Max                                    0.0685411
evaluation/Rewards Min                                   -1.05904
evaluation/Returns Mean                                  -3.82514
evaluation/Returns Std                                    2.66602
evaluation/Returns Max                                   -0.462482
evaluation/Returns Min                                  -11.6235
evaluation/Actions Mean                                   0.0211479
evaluation/Actions Std                                    0.213021
evaluation/Actions Max                                    0.998721
evaluation/Actions Min                                   -0.917094
evaluation/Num Paths                                     50
evaluation/Average Returns                               -3.82514
evaluation/env_infos/final/reward_energy Mean            -0.260295
evaluation/env_infos/final/reward_energy Std              0.315916
evaluation/env_infos/final/reward_energy Max             -0.00716492
evaluation/env_infos/final/reward_energy Min             -1.23208
evaluation/env_infos/initial/reward_energy Mean          -0.386418
evaluation/env_infos/initial/reward_energy Std            0.27374
evaluation/env_infos/initial/reward_energy Max           -0.0404561
evaluation/env_infos/initial/reward_energy Min           -1.12463
evaluation/env_infos/reward_energy Mean                  -0.210379
evaluation/env_infos/reward_energy Std                    0.217694
evaluation/env_infos/reward_energy Max                   -0.00271584
evaluation/env_infos/reward_energy Min                   -1.23208
evaluation/env_infos/final/end_effector_loc Mean          0.1725
evaluation/env_infos/final/end_effector_loc Std           0.45926
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean        0.000910945
evaluation/env_infos/initial/end_effector_loc Std         0.0167178
evaluation/env_infos/initial/end_effector_loc Max         0.0458922
evaluation/env_infos/initial/end_effector_loc Min        -0.0423426
evaluation/env_infos/end_effector_loc Mean                0.0677178
evaluation/env_infos/end_effector_loc Std                 0.304024
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0397893
evaluation/env_infos/final/reward_dist Std                0.136066
evaluation/env_infos/final/reward_dist Max                0.755233
evaluation/env_infos/final/reward_dist Min                3.02769e-121
evaluation/env_infos/initial/reward_dist Mean             0.00758812
evaluation/env_infos/initial/reward_dist Std              0.0130815
evaluation/env_infos/initial/reward_dist Max              0.0624677
evaluation/env_infos/initial/reward_dist Min              2.61753e-07
evaluation/env_infos/reward_dist Mean                     0.0717483
evaluation/env_infos/reward_dist Std                      0.18391
evaluation/env_infos/reward_dist Max                      0.990645
evaluation/env_infos/reward_dist Min                      5.94188e-136
time/data storing (s)                                    38.1182
time/evaluation sampling (s)                              0.648401
time/exploration sampling (s)                             0.0906462
time/logging (s)                                          0.0149378
time/saving (s)                                           0.779603
time/training (s)                                        39.6411
time/epoch (s)                                           79.2929
time/total (s)                                        22309.6
Epoch                                                   291
---------------------------------------------------  -----------------
2021-05-29 06:09:06.119559 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 292 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0165322
trainer/QF2 Loss                                          0.0222766
trainer/Policy Loss                                       3.00772
trainer/Q1 Predictions Mean                              -1.19496
trainer/Q1 Predictions Std                                1.27432
trainer/Q1 Predictions Max                                4.86987
trainer/Q1 Predictions Min                               -6.18937
trainer/Q2 Predictions Mean                              -1.12749
trainer/Q2 Predictions Std                                1.27848
trainer/Q2 Predictions Max                                5.10489
trainer/Q2 Predictions Min                               -6.18062
trainer/Q Targets Mean                                   -1.14084
trainer/Q Targets Std                                     1.28074
trainer/Q Targets Max                                     4.81991
trainer/Q Targets Min                                    -6.28787
trainer/Log Pis Mean                                      1.90697
trainer/Log Pis Std                                       1.25535
trainer/Log Pis Max                                       5.50132
trainer/Log Pis Min                                      -3.47619
trainer/Policy mu Mean                                   -0.0139818
trainer/Policy mu Std                                     0.59866
trainer/Policy mu Max                                     2.90893
trainer/Policy mu Min                                    -3.08301
trainer/Policy log std Mean                              -2.16433
trainer/Policy log std Std                                0.398567
trainer/Policy log std Max                                0.102535
trainer/Policy log std Min                               -2.6772
trainer/Alpha                                             0.0233806
trainer/Alpha Loss                                       -0.349325
exploration/num steps total                           30300
exploration/num paths total                            1515
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.172496
exploration/Rewards Std                                   0.0904116
exploration/Rewards Max                                   0.0366526
exploration/Rewards Min                                  -0.461467
exploration/Returns Mean                                 -3.44992
exploration/Returns Std                                   1.3697
exploration/Returns Max                                  -2.19477
exploration/Returns Min                                  -6.05579
exploration/Actions Mean                                  0.000274062
exploration/Actions Std                                   0.140207
exploration/Actions Max                                   0.513244
exploration/Actions Min                                  -0.436217
exploration/Num Paths                                     5
exploration/Average Returns                              -3.44992
exploration/env_infos/final/reward_energy Mean           -0.150107
exploration/env_infos/final/reward_energy Std             0.0688866
exploration/env_infos/final/reward_energy Max            -0.0838288
exploration/env_infos/final/reward_energy Min            -0.272675
exploration/env_infos/initial/reward_energy Mean         -0.271267
exploration/env_infos/initial/reward_energy Std           0.208429
exploration/env_infos/initial/reward_energy Max          -0.131736
exploration/env_infos/initial/reward_energy Min          -0.673577
exploration/env_infos/reward_energy Mean                 -0.167464
exploration/env_infos/reward_energy Std                   0.10617
exploration/env_infos/reward_energy Max                  -0.0183971
exploration/env_infos/reward_energy Min                  -0.673577
exploration/env_infos/final/end_effector_loc Mean        -0.0345172
exploration/env_infos/final/end_effector_loc Std          0.301444
exploration/env_infos/final/end_effector_loc Max          0.377195
exploration/env_infos/final/end_effector_loc Min         -0.717352
exploration/env_infos/initial/end_effector_loc Mean      -0.00205491
exploration/env_infos/initial/end_effector_loc Std        0.011919
exploration/env_infos/initial/end_effector_loc Max        0.0256622
exploration/env_infos/initial/end_effector_loc Min       -0.0218109
exploration/env_infos/end_effector_loc Mean              -0.0320826
exploration/env_infos/end_effector_loc Std                0.194368
exploration/env_infos/end_effector_loc Max                0.422108
exploration/env_infos/end_effector_loc Min               -0.717352
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.000134645
exploration/env_infos/final/reward_dist Std               0.000174997
exploration/env_infos/final/reward_dist Max               0.000429216
exploration/env_infos/final/reward_dist Min               1.12163e-24
exploration/env_infos/initial/reward_dist Mean            0.00668743
exploration/env_infos/initial/reward_dist Std             0.0114437
exploration/env_infos/initial/reward_dist Max             0.0294499
exploration/env_infos/initial/reward_dist Min             5.90278e-05
exploration/env_infos/reward_dist Mean                    0.0295118
exploration/env_infos/reward_dist Std                     0.100817
exploration/env_infos/reward_dist Max                     0.585437
exploration/env_infos/reward_dist Min                     7.29714e-30
evaluation/num steps total                           293000
evaluation/num paths total                            14650
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.215786
evaluation/Rewards Std                                    0.219213
evaluation/Rewards Max                                    0.169468
evaluation/Rewards Min                                   -1.20753
evaluation/Returns Mean                                  -4.31572
evaluation/Returns Std                                    3.06143
evaluation/Returns Max                                    0.525809
evaluation/Returns Min                                  -13.0003
evaluation/Actions Mean                                   0.0244478
evaluation/Actions Std                                    0.222921
evaluation/Actions Max                                    0.990472
evaluation/Actions Min                                   -0.998948
evaluation/Num Paths                                     50
evaluation/Average Returns                               -4.31572
evaluation/env_infos/final/reward_energy Mean            -0.294886
evaluation/env_infos/final/reward_energy Std              0.294438
evaluation/env_infos/final/reward_energy Max             -0.00373307
evaluation/env_infos/final/reward_energy Min             -1.02952
evaluation/env_infos/initial/reward_energy Mean          -0.414279
evaluation/env_infos/initial/reward_energy Std            0.315408
evaluation/env_infos/initial/reward_energy Max           -0.00156329
evaluation/env_infos/initial/reward_energy Min           -1.0841
evaluation/env_infos/reward_energy Mean                  -0.216111
evaluation/env_infos/reward_energy Std                    0.232119
evaluation/env_infos/reward_energy Max                   -0.00134554
evaluation/env_infos/reward_energy Min                   -1.16544
evaluation/env_infos/final/end_effector_loc Mean          0.156817
evaluation/env_infos/final/end_effector_loc Std           0.530512
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00160553
evaluation/env_infos/initial/end_effector_loc Std         0.0183387
evaluation/env_infos/initial/end_effector_loc Max         0.0327227
evaluation/env_infos/initial/end_effector_loc Min        -0.0499474
evaluation/env_infos/end_effector_loc Mean                0.0399626
evaluation/env_infos/end_effector_loc Std                 0.316078
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0315068
evaluation/env_infos/final/reward_dist Std                0.115516
evaluation/env_infos/final/reward_dist Max                0.71511
evaluation/env_infos/final/reward_dist Min                1.01991e-171
evaluation/env_infos/initial/reward_dist Mean             0.00425878
evaluation/env_infos/initial/reward_dist Std              0.00821161
evaluation/env_infos/initial/reward_dist Max              0.0443332
evaluation/env_infos/initial/reward_dist Min              2.10533e-08
evaluation/env_infos/reward_dist Mean                     0.0480561
evaluation/env_infos/reward_dist Std                      0.14207
evaluation/env_infos/reward_dist Max                      0.972199
evaluation/env_infos/reward_dist Min                      1.01991e-171
time/data storing (s)                                    38.2942
time/evaluation sampling (s)                              0.534764
time/exploration sampling (s)                             0.0811793
time/logging (s)                                          0.0151082
time/saving (s)                                           0.776252
time/training (s)                                        39.1861
time/epoch (s)                                           78.8876
time/total (s)                                        22391.6
Epoch                                                   292
---------------------------------------------------  -----------------
2021-05-29 06:10:28.254737 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 293 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.016817
trainer/QF2 Loss                                          0.0202934
trainer/Policy Loss                                       2.99315
trainer/Q1 Predictions Mean                              -1.16011
trainer/Q1 Predictions Std                                1.40279
trainer/Q1 Predictions Max                                4.07395
trainer/Q1 Predictions Min                               -7.91708
trainer/Q2 Predictions Mean                              -1.17321
trainer/Q2 Predictions Std                                1.38545
trainer/Q2 Predictions Max                                3.98949
trainer/Q2 Predictions Min                               -8.02768
trainer/Q Targets Mean                                   -1.14891
trainer/Q Targets Std                                     1.39742
trainer/Q Targets Max                                     3.68881
trainer/Q Targets Min                                    -7.95475
trainer/Log Pis Mean                                      1.86536
trainer/Log Pis Std                                       1.41618
trainer/Log Pis Max                                       7.11378
trainer/Log Pis Min                                      -4.22933
trainer/Policy mu Mean                                    0.102253
trainer/Policy mu Std                                     0.608511
trainer/Policy mu Max                                     3.67822
trainer/Policy mu Min                                    -2.20334
trainer/Policy log std Mean                              -2.12247
trainer/Policy log std Std                                0.420436
trainer/Policy log std Max                                0.0999333
trainer/Policy log std Min                               -2.7243
trainer/Alpha                                             0.0228541
trainer/Alpha Loss                                       -0.508628
exploration/num steps total                           30400
exploration/num paths total                            1520
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.187904
exploration/Rewards Std                                   0.0967383
exploration/Rewards Max                                  -0.0106711
exploration/Rewards Min                                  -0.402249
exploration/Returns Mean                                 -3.75808
exploration/Returns Std                                   1.31817
exploration/Returns Max                                  -1.64336
exploration/Returns Min                                  -5.18601
exploration/Actions Mean                                  0.0381311
exploration/Actions Std                                   0.230195
exploration/Actions Max                                   0.907778
exploration/Actions Min                                  -0.639122
exploration/Num Paths                                     5
exploration/Average Returns                              -3.75808
exploration/env_infos/final/reward_energy Mean           -0.235605
exploration/env_infos/final/reward_energy Std             0.192123
exploration/env_infos/final/reward_energy Max            -0.0322972
exploration/env_infos/final/reward_energy Min            -0.597167
exploration/env_infos/initial/reward_energy Mean         -0.313723
exploration/env_infos/initial/reward_energy Std           0.188808
exploration/env_infos/initial/reward_energy Max          -0.115557
exploration/env_infos/initial/reward_energy Min          -0.642566
exploration/env_infos/reward_energy Mean                 -0.266292
exploration/env_infos/reward_energy Std                   0.194874
exploration/env_infos/reward_energy Max                  -0.0112567
exploration/env_infos/reward_energy Min                  -0.937854
exploration/env_infos/final/end_effector_loc Mean         0.148978
exploration/env_infos/final/end_effector_loc Std          0.648561
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.000366149
exploration/env_infos/initial/end_effector_loc Std        0.0129404
exploration/env_infos/initial/end_effector_loc Max        0.0190917
exploration/env_infos/initial/end_effector_loc Min       -0.0319561
exploration/env_infos/end_effector_loc Mean               0.0798821
exploration/env_infos/end_effector_loc Std                0.403069
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.245436
exploration/env_infos/final/reward_dist Std               0.300598
exploration/env_infos/final/reward_dist Max               0.615112
exploration/env_infos/final/reward_dist Min               1.07694e-103
exploration/env_infos/initial/reward_dist Mean            0.00219942
exploration/env_infos/initial/reward_dist Std             0.00292217
exploration/env_infos/initial/reward_dist Max             0.00778322
exploration/env_infos/initial/reward_dist Min             9.862e-06
exploration/env_infos/reward_dist Mean                    0.068032
exploration/env_infos/reward_dist Std                     0.135265
exploration/env_infos/reward_dist Max                     0.615112
exploration/env_infos/reward_dist Min                     1.07694e-103
evaluation/num steps total                           294000
evaluation/num paths total                            14700
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.203993
evaluation/Rewards Std                                    0.226729
evaluation/Rewards Max                                    0.106303
evaluation/Rewards Min                                   -1.11118
evaluation/Returns Mean                                  -4.07986
evaluation/Returns Std                                    3.22383
evaluation/Returns Max                                    0.5854
evaluation/Returns Min                                  -13.9838
evaluation/Actions Mean                                   0.0547966
evaluation/Actions Std                                    0.259344
evaluation/Actions Max                                    0.997795
evaluation/Actions Min                                   -0.993599
evaluation/Num Paths                                     50
evaluation/Average Returns                               -4.07986
evaluation/env_infos/final/reward_energy Mean            -0.312119
evaluation/env_infos/final/reward_energy Std              0.37444
evaluation/env_infos/final/reward_energy Max             -0.00653838
evaluation/env_infos/final/reward_energy Min             -1.36015
evaluation/env_infos/initial/reward_energy Mean          -0.359797
evaluation/env_infos/initial/reward_energy Std            0.272323
evaluation/env_infos/initial/reward_energy Max           -0.00692704
evaluation/env_infos/initial/reward_energy Min           -1.03057
evaluation/env_infos/reward_energy Mean                  -0.242565
evaluation/env_infos/reward_energy Std                    0.285808
evaluation/env_infos/reward_energy Max                   -0.00302001
evaluation/env_infos/reward_energy Min                   -1.36015
evaluation/env_infos/final/end_effector_loc Mean          0.212655
evaluation/env_infos/final/end_effector_loc Std           0.532322
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.0021498
evaluation/env_infos/initial/end_effector_loc Std         0.0158081
evaluation/env_infos/initial/end_effector_loc Max         0.0385918
evaluation/env_infos/initial/end_effector_loc Min        -0.04968
evaluation/env_infos/end_effector_loc Mean                0.0697001
evaluation/env_infos/end_effector_loc Std                 0.36372
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0300142
evaluation/env_infos/final/reward_dist Std                0.110257
evaluation/env_infos/final/reward_dist Max                0.590911
evaluation/env_infos/final/reward_dist Min                5.4868e-165
evaluation/env_infos/initial/reward_dist Mean             0.00818369
evaluation/env_infos/initial/reward_dist Std              0.0150186
evaluation/env_infos/initial/reward_dist Max              0.0922055
evaluation/env_infos/initial/reward_dist Min              6.25017e-07
evaluation/env_infos/reward_dist Mean                     0.0491481
evaluation/env_infos/reward_dist Std                      0.148234
evaluation/env_infos/reward_dist Max                      0.918098
evaluation/env_infos/reward_dist Min                      5.4868e-165
time/data storing (s)                                    38.1402
time/evaluation sampling (s)                              0.660316
time/exploration sampling (s)                             0.0876442
time/logging (s)                                          0.0152189
time/saving (s)                                           0.809651
time/training (s)                                        39.2567
time/epoch (s)                                           78.9697
time/total (s)                                        22473.7
Epoch                                                   293
---------------------------------------------------  -----------------
2021-05-29 06:11:49.454287 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 294 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0244261
trainer/QF2 Loss                                          0.0245589
trainer/Policy Loss                                       3.44377
trainer/Q1 Predictions Mean                              -1.39857
trainer/Q1 Predictions Std                                1.43704
trainer/Q1 Predictions Max                                1.28033
trainer/Q1 Predictions Min                               -8.71867
trainer/Q2 Predictions Mean                              -1.43383
trainer/Q2 Predictions Std                                1.44593
trainer/Q2 Predictions Max                                1.29551
trainer/Q2 Predictions Min                               -8.69427
trainer/Q Targets Mean                                   -1.41845
trainer/Q Targets Std                                     1.44346
trainer/Q Targets Max                                     1.12733
trainer/Q Targets Min                                    -8.79776
trainer/Log Pis Mean                                      2.07123
trainer/Log Pis Std                                       1.17051
trainer/Log Pis Max                                       5.91538
trainer/Log Pis Min                                      -2.22518
trainer/Policy mu Mean                                    0.0570936
trainer/Policy mu Std                                     0.602041
trainer/Policy mu Max                                     2.49678
trainer/Policy mu Min                                    -2.41951
trainer/Policy log std Mean                              -2.1773
trainer/Policy log std Std                                0.416393
trainer/Policy log std Max                               -0.61211
trainer/Policy log std Min                               -2.67979
trainer/Alpha                                             0.021779
trainer/Alpha Loss                                        0.272659
exploration/num steps total                           30500
exploration/num paths total                            1525
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.160466
exploration/Rewards Std                                   0.0910417
exploration/Rewards Max                                   0.0212065
exploration/Rewards Min                                  -0.457283
exploration/Returns Mean                                 -3.20932
exploration/Returns Std                                   1.2778
exploration/Returns Max                                  -1.46646
exploration/Returns Min                                  -4.47311
exploration/Actions Mean                                  0.000890269
exploration/Actions Std                                   0.143824
exploration/Actions Max                                   0.549688
exploration/Actions Min                                  -0.331726
exploration/Num Paths                                     5
exploration/Average Returns                              -3.20932
exploration/env_infos/final/reward_energy Mean           -0.193101
exploration/env_infos/final/reward_energy Std             0.150429
exploration/env_infos/final/reward_energy Max            -0.0865107
exploration/env_infos/final/reward_energy Min            -0.488561
exploration/env_infos/initial/reward_energy Mean         -0.254146
exploration/env_infos/initial/reward_energy Std           0.225256
exploration/env_infos/initial/reward_energy Max          -0.0707523
exploration/env_infos/initial/reward_energy Min          -0.687409
exploration/env_infos/reward_energy Mean                 -0.173137
exploration/env_infos/reward_energy Std                   0.106751
exploration/env_infos/reward_energy Max                  -0.0244942
exploration/env_infos/reward_energy Min                  -0.687409
exploration/env_infos/final/end_effector_loc Mean         0.152017
exploration/env_infos/final/end_effector_loc Std          0.170419
exploration/env_infos/final/end_effector_loc Max          0.349575
exploration/env_infos/final/end_effector_loc Min         -0.174871
exploration/env_infos/initial/end_effector_loc Mean       0.00467926
exploration/env_infos/initial/end_effector_loc Std        0.0110575
exploration/env_infos/initial/end_effector_loc Max        0.0274844
exploration/env_infos/initial/end_effector_loc Min       -0.00908171
exploration/env_infos/end_effector_loc Mean               0.094553
exploration/env_infos/end_effector_loc Std                0.15763
exploration/env_infos/end_effector_loc Max                0.421381
exploration/env_infos/end_effector_loc Min               -0.17945
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.0231093
exploration/env_infos/final/reward_dist Std               0.0457304
exploration/env_infos/final/reward_dist Max               0.114567
exploration/env_infos/final/reward_dist Min               2.46126e-13
exploration/env_infos/initial/reward_dist Mean            0.00328579
exploration/env_infos/initial/reward_dist Std             0.00293295
exploration/env_infos/initial/reward_dist Max             0.00726462
exploration/env_infos/initial/reward_dist Min             6.26254e-06
exploration/env_infos/reward_dist Mean                    0.0188255
exploration/env_infos/reward_dist Std                     0.041719
exploration/env_infos/reward_dist Max                     0.159939
exploration/env_infos/reward_dist Min                     2.46126e-13
evaluation/num steps total                           295000
evaluation/num paths total                            14750
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.176873
evaluation/Rewards Std                                    0.200277
evaluation/Rewards Max                                    0.132727
evaluation/Rewards Min                                   -1.29431
evaluation/Returns Mean                                  -3.53747
evaluation/Returns Std                                    3.01438
evaluation/Returns Max                                    1.06753
evaluation/Returns Min                                  -14.9855
evaluation/Actions Mean                                   0.0384351
evaluation/Actions Std                                    0.223294
evaluation/Actions Max                                    0.997371
evaluation/Actions Min                                   -0.967161
evaluation/Num Paths                                     50
evaluation/Average Returns                               -3.53747
evaluation/env_infos/final/reward_energy Mean            -0.251135
evaluation/env_infos/final/reward_energy Std              0.33766
evaluation/env_infos/final/reward_energy Max             -0.00787368
evaluation/env_infos/final/reward_energy Min             -1.21788
evaluation/env_infos/initial/reward_energy Mean          -0.31347
evaluation/env_infos/initial/reward_energy Std            0.258238
evaluation/env_infos/initial/reward_energy Max           -0.0151647
evaluation/env_infos/initial/reward_energy Min           -1.06268
evaluation/env_infos/reward_energy Mean                  -0.20428
evaluation/env_infos/reward_energy Std                    0.246871
evaluation/env_infos/reward_energy Max                   -0.00467254
evaluation/env_infos/reward_energy Min                   -1.21788
evaluation/env_infos/final/end_effector_loc Mean          0.135423
evaluation/env_infos/final/end_effector_loc Std           0.526181
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000520161
evaluation/env_infos/initial/end_effector_loc Std         0.0143498
evaluation/env_infos/initial/end_effector_loc Max         0.0332846
evaluation/env_infos/initial/end_effector_loc Min        -0.0472712
evaluation/env_infos/end_effector_loc Mean                0.0424937
evaluation/env_infos/end_effector_loc Std                 0.330552
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0281834
evaluation/env_infos/final/reward_dist Std                0.103344
evaluation/env_infos/final/reward_dist Max                0.556722
evaluation/env_infos/final/reward_dist Min                4.61801e-184
evaluation/env_infos/initial/reward_dist Mean             0.00869403
evaluation/env_infos/initial/reward_dist Std              0.018679
evaluation/env_infos/initial/reward_dist Max              0.120929
evaluation/env_infos/initial/reward_dist Min              1.89318e-06
evaluation/env_infos/reward_dist Mean                     0.0436941
evaluation/env_infos/reward_dist Std                      0.13097
evaluation/env_infos/reward_dist Max                      0.988833
evaluation/env_infos/reward_dist Min                      4.61801e-184
time/data storing (s)                                    37.651
time/evaluation sampling (s)                              0.522292
time/exploration sampling (s)                             0.0795932
time/logging (s)                                          0.014818
time/saving (s)                                           0.771839
time/training (s)                                        39.0115
time/epoch (s)                                           78.051
time/total (s)                                        22554.9
Epoch                                                   294
---------------------------------------------------  -----------------
2021-05-29 06:13:10.909844 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 295 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.01331
trainer/QF2 Loss                                          0.023572
trainer/Policy Loss                                       3.33913
trainer/Q1 Predictions Mean                              -1.41671
trainer/Q1 Predictions Std                                1.29678
trainer/Q1 Predictions Max                                1.76246
trainer/Q1 Predictions Min                               -6.03468
trainer/Q2 Predictions Mean                              -1.4212
trainer/Q2 Predictions Std                                1.29583
trainer/Q2 Predictions Max                                1.78766
trainer/Q2 Predictions Min                               -6.01342
trainer/Q Targets Mean                                   -1.42749
trainer/Q Targets Std                                     1.29715
trainer/Q Targets Max                                     1.87556
trainer/Q Targets Min                                    -5.87631
trainer/Log Pis Mean                                      1.98916
trainer/Log Pis Std                                       1.13891
trainer/Log Pis Max                                       6.69853
trainer/Log Pis Min                                      -3.9707
trainer/Policy mu Mean                                    0.00645079
trainer/Policy mu Std                                     0.470078
trainer/Policy mu Max                                     2.73874
trainer/Policy mu Min                                    -2.90981
trainer/Policy log std Mean                              -2.23549
trainer/Policy log std Std                                0.30212
trainer/Policy log std Max                               -0.321285
trainer/Policy log std Min                               -2.93494
trainer/Alpha                                             0.0214217
trainer/Alpha Loss                                       -0.0416568
exploration/num steps total                           30600
exploration/num paths total                            1530
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.25329
exploration/Rewards Std                                   0.130998
exploration/Rewards Max                                  -0.011956
exploration/Rewards Min                                  -0.826072
exploration/Returns Mean                                 -5.06579
exploration/Returns Std                                   1.24865
exploration/Returns Max                                  -3.30071
exploration/Returns Min                                  -6.15928
exploration/Actions Mean                                 -0.0220142
exploration/Actions Std                                   0.187928
exploration/Actions Max                                   0.610642
exploration/Actions Min                                  -0.824375
exploration/Num Paths                                     5
exploration/Average Returns                              -5.06579
exploration/env_infos/final/reward_energy Mean           -0.180708
exploration/env_infos/final/reward_energy Std             0.193023
exploration/env_infos/final/reward_energy Max            -0.0392696
exploration/env_infos/final/reward_energy Min            -0.552113
exploration/env_infos/initial/reward_energy Mean         -0.404739
exploration/env_infos/initial/reward_energy Std           0.274012
exploration/env_infos/initial/reward_energy Max          -0.131781
exploration/env_infos/initial/reward_energy Min          -0.855032
exploration/env_infos/reward_energy Mean                 -0.214362
exploration/env_infos/reward_energy Std                   0.160163
exploration/env_infos/reward_energy Max                  -0.0132673
exploration/env_infos/reward_energy Min                  -0.855032
exploration/env_infos/final/end_effector_loc Mean        -0.125147
exploration/env_infos/final/end_effector_loc Std          0.73948
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -1
exploration/env_infos/initial/end_effector_loc Mean       0.000151352
exploration/env_infos/initial/end_effector_loc Std        0.01728
exploration/env_infos/initial/end_effector_loc Max        0.0279655
exploration/env_infos/initial/end_effector_loc Min       -0.0412188
exploration/env_infos/end_effector_loc Mean              -0.0518204
exploration/env_infos/end_effector_loc Std                0.451305
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -1
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              5.20382e-18
exploration/env_infos/final/reward_dist Std               1.04076e-17
exploration/env_infos/final/reward_dist Max               2.60191e-17
exploration/env_infos/final/reward_dist Min               4.86878e-112
exploration/env_infos/initial/reward_dist Mean            0.00959623
exploration/env_infos/initial/reward_dist Std             0.0115002
exploration/env_infos/initial/reward_dist Max             0.0316564
exploration/env_infos/initial/reward_dist Min             8.65704e-06
exploration/env_infos/reward_dist Mean                    0.051228
exploration/env_infos/reward_dist Std                     0.157908
exploration/env_infos/reward_dist Max                     0.986478
exploration/env_infos/reward_dist Min                     4.86878e-112
evaluation/num steps total                           296000
evaluation/num paths total                            14800
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.227221
evaluation/Rewards Std                                    0.216828
evaluation/Rewards Max                                    0.0641686
evaluation/Rewards Min                                   -1.38283
evaluation/Returns Mean                                  -4.54441
evaluation/Returns Std                                    2.86677
evaluation/Returns Max                                   -0.965963
evaluation/Returns Min                                  -13.2196
evaluation/Actions Mean                                   0.00524076
evaluation/Actions Std                                    0.208833
evaluation/Actions Max                                    0.996162
evaluation/Actions Min                                   -0.985732
evaluation/Num Paths                                     50
evaluation/Average Returns                               -4.54441
evaluation/env_infos/final/reward_energy Mean            -0.242082
evaluation/env_infos/final/reward_energy Std              0.255187
evaluation/env_infos/final/reward_energy Max             -0.0278516
evaluation/env_infos/final/reward_energy Min             -1.09477
evaluation/env_infos/initial/reward_energy Mean          -0.308653
evaluation/env_infos/initial/reward_energy Std            0.229193
evaluation/env_infos/initial/reward_energy Max           -0.053772
evaluation/env_infos/initial/reward_energy Min           -0.994385
evaluation/env_infos/reward_energy Mean                  -0.215309
evaluation/env_infos/reward_energy Std                    0.202286
evaluation/env_infos/reward_energy Max                   -0.00861564
evaluation/env_infos/reward_energy Min                   -1.32514
evaluation/env_infos/final/end_effector_loc Mean          0.00790577
evaluation/env_infos/final/end_effector_loc Std           0.635363
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.00130338
evaluation/env_infos/initial/end_effector_loc Std         0.0135295
evaluation/env_infos/initial/end_effector_loc Max         0.036291
evaluation/env_infos/initial/end_effector_loc Min        -0.0492866
evaluation/env_infos/end_effector_loc Mean                0.00512455
evaluation/env_infos/end_effector_loc Std                 0.379455
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.00462431
evaluation/env_infos/final/reward_dist Std                0.0243534
evaluation/env_infos/final/reward_dist Max                0.169579
evaluation/env_infos/final/reward_dist Min                5.98651e-169
evaluation/env_infos/initial/reward_dist Mean             0.00586788
evaluation/env_infos/initial/reward_dist Std              0.0112336
evaluation/env_infos/initial/reward_dist Max              0.0503644
evaluation/env_infos/initial/reward_dist Min              1.13391e-06
evaluation/env_infos/reward_dist Mean                     0.0365938
evaluation/env_infos/reward_dist Std                      0.121409
evaluation/env_infos/reward_dist Max                      0.969266
evaluation/env_infos/reward_dist Min                      5.98651e-169
time/data storing (s)                                    37.9467
time/evaluation sampling (s)                              0.717669
time/exploration sampling (s)                             0.09028
time/logging (s)                                          0.0146463
time/saving (s)                                           0.794489
time/training (s)                                        38.7746
time/epoch (s)                                           78.3384
time/total (s)                                        22636.4
Epoch                                                   295
---------------------------------------------------  -----------------
2021-05-29 06:15:17.142626 PDT | [gher-pointreacherobs-SAC-1000e-20s-disc0.97-horizon20_2021_05_28_23_55_55_0000--s-10] Epoch 296 finished
---------------------------------------------------  -----------------
replay_buffer/size                                     2000
trainer/QF1 Loss                                          0.0263885
trainer/QF2 Loss                                          0.0189442
trainer/Policy Loss                                       3.16069
trainer/Q1 Predictions Mean                              -1.35276
trainer/Q1 Predictions Std                                1.46814
trainer/Q1 Predictions Max                                1.83777
trainer/Q1 Predictions Min                               -8.23621
trainer/Q2 Predictions Mean                              -1.37814
trainer/Q2 Predictions Std                                1.46984
trainer/Q2 Predictions Max                                1.86083
trainer/Q2 Predictions Min                               -8.3824
trainer/Q Targets Mean                                   -1.35429
trainer/Q Targets Std                                     1.47341
trainer/Q Targets Max                                     1.99173
trainer/Q Targets Min                                    -8.3706
trainer/Log Pis Mean                                      1.87055
trainer/Log Pis Std                                       1.1165
trainer/Log Pis Max                                       4.81775
trainer/Log Pis Min                                      -2.67497
trainer/Policy mu Mean                                    0.0343779
trainer/Policy mu Std                                     0.470854
trainer/Policy mu Max                                     2.78275
trainer/Policy mu Min                                    -2.20897
trainer/Policy log std Mean                              -2.22452
trainer/Policy log std Std                                0.320852
trainer/Policy log std Max                               -0.435478
trainer/Policy log std Min                               -2.68882
trainer/Alpha                                             0.0220104
trainer/Alpha Loss                                       -0.493943
exploration/num steps total                           30700
exploration/num paths total                            1535
exploration/path length Mean                             20
exploration/path length Std                               0
exploration/path length Max                              20
exploration/path length Min                              20
exploration/Rewards Mean                                 -0.244196
exploration/Rewards Std                                   0.190989
exploration/Rewards Max                                  -0.0295843
exploration/Rewards Min                                  -0.929627
exploration/Returns Mean                                 -4.88392
exploration/Returns Std                                   2.26095
exploration/Returns Max                                  -2.47774
exploration/Returns Min                                  -9.12835
exploration/Actions Mean                                  0.0192651
exploration/Actions Std                                   0.22344
exploration/Actions Max                                   0.882101
exploration/Actions Min                                  -0.58253
exploration/Num Paths                                     5
exploration/Average Returns                              -4.88392
exploration/env_infos/final/reward_energy Mean           -0.347551
exploration/env_infos/final/reward_energy Std             0.255707
exploration/env_infos/final/reward_energy Max            -0.0270991
exploration/env_infos/final/reward_energy Min            -0.617664
exploration/env_infos/initial/reward_energy Mean         -0.31804
exploration/env_infos/initial/reward_energy Std           0.199348
exploration/env_infos/initial/reward_energy Max          -0.110218
exploration/env_infos/initial/reward_energy Min          -0.647681
exploration/env_infos/reward_energy Mean                 -0.250164
exploration/env_infos/reward_energy Std                   0.194965
exploration/env_infos/reward_energy Max                  -0.0139204
exploration/env_infos/reward_energy Min                  -0.883975
exploration/env_infos/final/end_effector_loc Mean        -0.0903716
exploration/env_infos/final/end_effector_loc Std          0.561442
exploration/env_infos/final/end_effector_loc Max          1
exploration/env_infos/final/end_effector_loc Min         -0.906312
exploration/env_infos/initial/end_effector_loc Mean      -0.00027857
exploration/env_infos/initial/end_effector_loc Std        0.0132678
exploration/env_infos/initial/end_effector_loc Max        0.0236441
exploration/env_infos/initial/end_effector_loc Min       -0.0216597
exploration/env_infos/end_effector_loc Mean              -0.0591042
exploration/env_infos/end_effector_loc Std                0.280034
exploration/env_infos/end_effector_loc Max                1
exploration/env_infos/end_effector_loc Min               -0.906312
exploration/env_infos/final/reward_safety Mean            0
exploration/env_infos/final/reward_safety Std             0
exploration/env_infos/final/reward_safety Max             0
exploration/env_infos/final/reward_safety Min             0
exploration/env_infos/initial/reward_safety Mean          0
exploration/env_infos/initial/reward_safety Std           0
exploration/env_infos/initial/reward_safety Max           0
exploration/env_infos/initial/reward_safety Min           0
exploration/env_infos/reward_safety Mean                  0
exploration/env_infos/reward_safety Std                   0
exploration/env_infos/reward_safety Max                   0
exploration/env_infos/reward_safety Min                   0
exploration/env_infos/final/reward_dist Mean              0.00124296
exploration/env_infos/final/reward_dist Std               0.00226648
exploration/env_infos/final/reward_dist Max               0.00576234
exploration/env_infos/final/reward_dist Min               2.02745e-114
exploration/env_infos/initial/reward_dist Mean            0.0223795
exploration/env_infos/initial/reward_dist Std             0.0291647
exploration/env_infos/initial/reward_dist Max             0.0781367
exploration/env_infos/initial/reward_dist Min             7.56758e-06
exploration/env_infos/reward_dist Mean                    0.0553241
exploration/env_infos/reward_dist Std                     0.154599
exploration/env_infos/reward_dist Max                     0.818163
exploration/env_infos/reward_dist Min                     2.02745e-114
evaluation/num steps total                           297000
evaluation/num paths total                            14850
evaluation/path length Mean                              20
evaluation/path length Std                                0
evaluation/path length Max                               20
evaluation/path length Min                               20
evaluation/Rewards Mean                                  -0.199201
evaluation/Rewards Std                                    0.190208
evaluation/Rewards Max                                    0.100827
evaluation/Rewards Min                                   -1.18217
evaluation/Returns Mean                                  -3.98402
evaluation/Returns Std                                    2.8658
evaluation/Returns Max                                    0.491092
evaluation/Returns Min                                  -15.0828
evaluation/Actions Mean                                   0.00206221
evaluation/Actions Std                                    0.235328
evaluation/Actions Max                                    0.996248
evaluation/Actions Min                                   -0.978088
evaluation/Num Paths                                     50
evaluation/Average Returns                               -3.98402
evaluation/env_infos/final/reward_energy Mean            -0.229267
evaluation/env_infos/final/reward_energy Std              0.277047
evaluation/env_infos/final/reward_energy Max             -0.024193
evaluation/env_infos/final/reward_energy Min             -1.02616
evaluation/env_infos/initial/reward_energy Mean          -0.346592
evaluation/env_infos/initial/reward_energy Std            0.263428
evaluation/env_infos/initial/reward_energy Max           -0.00578766
evaluation/env_infos/initial/reward_energy Min           -0.990364
evaluation/env_infos/reward_energy Mean                  -0.236491
evaluation/env_infos/reward_energy Std                    0.234177
evaluation/env_infos/reward_energy Max                   -0.00511393
evaluation/env_infos/reward_energy Min                   -1.25684
evaluation/env_infos/final/end_effector_loc Mean         -0.0277485
evaluation/env_infos/final/end_effector_loc Std           0.536093
evaluation/env_infos/final/end_effector_loc Max           1
evaluation/env_infos/final/end_effector_loc Min          -1
evaluation/env_infos/initial/end_effector_loc Mean       -0.000621106
evaluation/env_infos/initial/end_effector_loc Std         0.015379
evaluation/env_infos/initial/end_effector_loc Max         0.0378106
evaluation/env_infos/initial/end_effector_loc Min        -0.047639
evaluation/env_infos/end_effector_loc Mean               -0.00677685
evaluation/env_infos/end_effector_loc Std                 0.342395
evaluation/env_infos/end_effector_loc Max                 1
evaluation/env_infos/end_effector_loc Min                -1
evaluation/env_infos/final/reward_safety Mean             0
evaluation/env_infos/final/reward_safety Std              0
evaluation/env_infos/final/reward_safety Max              0
evaluation/env_infos/final/reward_safety Min              0
evaluation/env_infos/initial/reward_safety Mean           0
evaluation/env_infos/initial/reward_safety Std            0
evaluation/env_infos/initial/reward_safety Max            0
evaluation/env_infos/initial/reward_safety Min            0
evaluation/env_infos/reward_safety Mean                   0
evaluation/env_infos/reward_safety Std                    0
evaluation/env_infos/reward_safety Max                    0
evaluation/env_infos/reward_safety Min                    0
evaluation/env_infos/final/reward_dist Mean               0.0308737
evaluation/env_infos/final/reward_dist Std                0.143546
evaluation/env_infos/final/reward_dist Max                0.979281
evaluation/env_infos/final/reward_dist Min                1.33324e-128
evaluation/env_infos/initial/reward_dist Mean             0.006811
evaluation/env_infos/initial/reward_dist Std              0.0268316
evaluation/env_infos/initial/reward_dist Max              0.190726
evaluation/env_infos/initial/reward_dist Min              3.83903e-07
evaluation/env_infos/reward_dist Mean                     0.0777466
evaluation/env_infos/reward_dist Std                      0.185285
evaluation/env_infos/reward_dist Max                      0.997119
evaluation/env_infos/reward_dist Min                      1.33324e-128
time/data storing (s)                                    60.1194
time/evaluation sampling (s)                              0.650867
time/exploration sampling (s)                             0.125581
time/logging (s)                                          0.0255957
time/saving (s)                                           1.41189
time/training (s)                                        60.7468
time/epoch (s)                                          123.08
time/total (s)                                        22762.6
Epoch                                                   296
---------------------------------------------------  -----------------
